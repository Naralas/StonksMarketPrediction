{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "medical-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from DataHelper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interested-challenge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sorted-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_MA(df, price_column, n=10):\n",
    "    return df[price_column].rolling(n).mean()\n",
    "\n",
    "def pipeline_preprocessing(path, price_column, predict_n=1, thresh_diff=0.5, verbose=False):\n",
    "    df = get_data(path)\n",
    "    keep_columns = ['Date', price_column, 'Volume', 'Open']\n",
    "    df = df.loc[:, keep_columns]\n",
    "    \n",
    "    df['Difference'] = compute_column_difference(df, column=price_column, periods_offset=predict_n)\n",
    "    df['PercentageDiff'] = compute_percentage_diff(df)\n",
    "    df['Tendency'] = compute_tendency_percentage(df, diff_column='Difference', labels=['lower','higher'])\n",
    "    \n",
    "    if verbose:\n",
    "        value_counts = df.Tendency.value_counts().to_dict()\n",
    "        for value, count in value_counts.items():\n",
    "            print(f\"[{value}] : {count} ({count * 100.0 / len(df['Tendency']):.1f}%)\")\n",
    "            \n",
    "    df['MA'] = compute_MA(df, price_column)\n",
    "    df['MA_diff'] = compute_MA(df, price_column, n=20) - compute_MA(df, price_column, n=10)\n",
    "    df['RSI'] = compute_RSI(df, n=10, price_column=price_column, diff_column='Difference')\n",
    "    df['GAP'] = compute_GAP(df)\n",
    "    df['Volume_diff'] = compute_column_difference(df, column='Volume')\n",
    "    df['Next'] = shift_values(df, column='Tendency', periods=-predict_n)\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "complicated-pantyhose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>Difference</th>\n",
       "      <th>PercentageDiff</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>MA</th>\n",
       "      <th>MA_diff</th>\n",
       "      <th>RSI</th>\n",
       "      <th>GAP</th>\n",
       "      <th>Volume_diff</th>\n",
       "      <th>Next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2007-01-31</td>\n",
       "      <td>37.669998</td>\n",
       "      <td>7277500.0</td>\n",
       "      <td>36.950001</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.100376</td>\n",
       "      <td>higher</td>\n",
       "      <td>37.072</td>\n",
       "      <td>0.491001</td>\n",
       "      <td>25.038845</td>\n",
       "      <td>0.099998</td>\n",
       "      <td>2464000.0</td>\n",
       "      <td>higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2007-02-01</td>\n",
       "      <td>38.700001</td>\n",
       "      <td>26123100.0</td>\n",
       "      <td>37.950001</td>\n",
       "      <td>1.619999</td>\n",
       "      <td>4.368929</td>\n",
       "      <td>higher</td>\n",
       "      <td>37.244</td>\n",
       "      <td>0.319000</td>\n",
       "      <td>40.989804</td>\n",
       "      <td>-0.280003</td>\n",
       "      <td>18845600.0</td>\n",
       "      <td>higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2007-02-02</td>\n",
       "      <td>37.389999</td>\n",
       "      <td>25850700.0</td>\n",
       "      <td>37.230000</td>\n",
       "      <td>0.540001</td>\n",
       "      <td>1.465403</td>\n",
       "      <td>higher</td>\n",
       "      <td>37.281</td>\n",
       "      <td>0.206500</td>\n",
       "      <td>46.890518</td>\n",
       "      <td>1.470001</td>\n",
       "      <td>-272400.0</td>\n",
       "      <td>higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2007-02-05</td>\n",
       "      <td>37.160000</td>\n",
       "      <td>6110900.0</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>-0.270000</td>\n",
       "      <td>-0.721347</td>\n",
       "      <td>lower</td>\n",
       "      <td>37.302</td>\n",
       "      <td>0.125001</td>\n",
       "      <td>53.399396</td>\n",
       "      <td>0.139999</td>\n",
       "      <td>-19739800.0</td>\n",
       "      <td>higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2007-02-06</td>\n",
       "      <td>38.270000</td>\n",
       "      <td>8612700.0</td>\n",
       "      <td>37.200001</td>\n",
       "      <td>1.220001</td>\n",
       "      <td>3.292850</td>\n",
       "      <td>higher</td>\n",
       "      <td>37.486</td>\n",
       "      <td>-0.020499</td>\n",
       "      <td>82.479274</td>\n",
       "      <td>-0.040001</td>\n",
       "      <td>2501800.0</td>\n",
       "      <td>higher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date      Close      Volume       Open  Difference  PercentageDiff  \\\n",
       "20  2007-01-31  37.669998   7277500.0  36.950001    0.410000        1.100376   \n",
       "21  2007-02-01  38.700001  26123100.0  37.950001    1.619999        4.368929   \n",
       "22  2007-02-02  37.389999  25850700.0  37.230000    0.540001        1.465403   \n",
       "23  2007-02-05  37.160000   6110900.0  37.250000   -0.270000       -0.721347   \n",
       "24  2007-02-06  38.270000   8612700.0  37.200001    1.220001        3.292850   \n",
       "\n",
       "   Tendency      MA   MA_diff        RSI       GAP  Volume_diff    Next  \n",
       "20   higher  37.072  0.491001  25.038845  0.099998    2464000.0  higher  \n",
       "21   higher  37.244  0.319000  40.989804 -0.280003   18845600.0  higher  \n",
       "22   higher  37.281  0.206500  46.890518  1.470001    -272400.0  higher  \n",
       "23    lower  37.302  0.125001  53.399396  0.139999  -19739800.0  higher  \n",
       "24   higher  37.486 -0.020499  82.479274 -0.040001    2501800.0  higher  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = './data'\n",
    "QUOTATIONS = ['AMZN', 'GOOG', 'AAPL', 'GM', 'TSLA', 'JNJ', 'XOM', 'AAL', 'KO', 'WMT']\n",
    "FILE_SUFFIX = '.txt'\n",
    "price_column = 'Close'\n",
    "\n",
    "df = None\n",
    "predict_n = 5\n",
    "\n",
    "for quot in QUOTATIONS:\n",
    "    temp_df = pipeline_preprocessing(f\"{DATA_PATH}/{quot}{FILE_SUFFIX}\", predict_n=predict_n, price_column=price_column)\n",
    "    if df is None:\n",
    "        df = temp_df\n",
    "    else:\n",
    "        df = df.append(temp_df)\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seeing-adult",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MA      Close  Next\n",
      "20  37.072  37.669998     1\n",
      "21  37.244  38.700001     1\n",
      "22  37.281  37.389999     1\n",
      "23  37.302  37.160000     1\n",
      "24  37.486  38.270000     1\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class StocksDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = torch.Tensor(data.values)\n",
    "        self.target = torch.Tensor(target.values)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        datapoint = self.data[index]\n",
    "        target = self.target[index]\n",
    "        return datapoint, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "data_columns = ['MA', 'Close']\n",
    "y_column = 'Next'\n",
    "data_columns.append(y_column)\n",
    "\n",
    "dataset = df.copy()\n",
    "dataset = dataset.loc[:, data_columns]\n",
    "for col in dataset.columns:\n",
    "    dataset[col] = dataset[col].replace({'higher':1, 'stay':0, 'lower':0})\n",
    "    \n",
    "\n",
    "X = dataset.loc[:, dataset.columns != y_column]\n",
    "Y = dataset[y_column]\n",
    "\n",
    "print(dataset.head())\n",
    "\n",
    "dataset = StocksDataset(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "median-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "outside-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Softmax(1)\n",
    "        )\n",
    "        #self.classifier = nn.Linear(input_dim, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.classifier(x)\n",
    "        #print(out)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "empty-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(lr, input_dim):\n",
    "    model = LinearModel(input_dim=input_dim)\n",
    "    model = model.to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    return model, optimizer, loss_fn\n",
    "\n",
    "lr = 0.0001\n",
    "\n",
    "model, optimizer, loss_fn = create_model(lr,input_dim = len(X.columns))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "proof-colon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 0.3132617473602295, accuracy : 54.35\n",
      "Epoch 2, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 3, loss: 0.3132617473602295, accuracy : 54.33\n",
      "Epoch 4, loss: 0.8132617473602295, accuracy : 54.30\n",
      "Epoch 5, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 6, loss: 0.8132617473602295, accuracy : 54.27\n",
      "Epoch 7, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 8, loss: 0.3132617473602295, accuracy : 54.33\n",
      "Epoch 9, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 10, loss: 0.3132617473602295, accuracy : 54.32\n",
      "Epoch 11, loss: 0.3132617473602295, accuracy : 54.34\n",
      "Epoch 12, loss: 0.3132617473602295, accuracy : 54.35\n",
      "Epoch 13, loss: 0.3132617473602295, accuracy : 54.34\n",
      "Epoch 14, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 15, loss: 1.3132617473602295, accuracy : 54.24\n",
      "Epoch 16, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 17, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 18, loss: 0.3132617473602295, accuracy : 54.35\n",
      "Epoch 19, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 20, loss: 0.3132617473602295, accuracy : 54.32\n",
      "Epoch 21, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 22, loss: 0.3132617473602295, accuracy : 54.34\n",
      "Epoch 23, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 24, loss: 0.3132617473602295, accuracy : 54.33\n",
      "Epoch 25, loss: 0.8132617473602295, accuracy : 54.28\n",
      "Epoch 26, loss: 1.3132617473602295, accuracy : 54.24\n",
      "Epoch 27, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 28, loss: 0.8132617473602295, accuracy : 54.28\n",
      "Epoch 29, loss: 0.3132617473602295, accuracy : 54.32\n",
      "Epoch 30, loss: 1.3132617473602295, accuracy : 54.24\n",
      "Epoch 31, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 32, loss: 0.8132617473602295, accuracy : 54.28\n",
      "Epoch 33, loss: 0.8132617473602295, accuracy : 54.30\n",
      "Epoch 34, loss: 0.3132617473602295, accuracy : 54.33\n",
      "Epoch 35, loss: 0.8132617473602295, accuracy : 54.30\n",
      "Epoch 36, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 37, loss: 0.8132617473602295, accuracy : 54.28\n",
      "Epoch 38, loss: 0.8132617473602295, accuracy : 54.28\n",
      "Epoch 39, loss: 0.8132617473602295, accuracy : 54.28\n",
      "Epoch 40, loss: 0.8132617473602295, accuracy : 54.28\n",
      "Epoch 41, loss: 0.8132617473602295, accuracy : 54.28\n",
      "Epoch 42, loss: 0.3132617473602295, accuracy : 54.33\n",
      "Epoch 43, loss: 0.3132617473602295, accuracy : 54.34\n",
      "Epoch 44, loss: 0.3132617473602295, accuracy : 54.32\n",
      "Epoch 45, loss: 1.3132617473602295, accuracy : 54.23\n",
      "Epoch 46, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 47, loss: 0.8132617473602295, accuracy : 54.27\n",
      "Epoch 48, loss: 0.8132617473602295, accuracy : 54.29\n",
      "Epoch 49, loss: 1.3132617473602295, accuracy : 54.25\n",
      "Epoch 50, loss: 0.3132617473602295, accuracy : 54.32\n"
     ]
    }
   ],
   "source": [
    "import DL_utils\n",
    "import importlib\n",
    "importlib.reload(DL_utils)\n",
    "from DL_utils import train\n",
    "train(dataloader, model, n_epochs=50, optimizer=optimizer, loss_fn=loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-genealogy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
