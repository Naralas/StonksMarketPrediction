{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finnish-disclaimer",
   "metadata": {},
   "source": [
    "# Price stock tendency prediction pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greatest-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from DataHelper import *\n",
    "\n",
    "# increase plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "font = {'family' : 'DejaVu Sans', 'size'   : 25}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_MA(df, price_column, n=10):\n",
    "    return df[price_column].rolling(n).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_values(df, column):\n",
    "    shifted_column = df[column]\n",
    "    shifted_column = shifted_column.shift(periods=-1)    \n",
    "    return shifted_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_preprocessing(path, price_column, thresh_diff=0.5, verbose=False):\n",
    "    df = get_data(path)\n",
    "    keep_columns = ['Date', price_column, 'Volume']\n",
    "    df = df.loc[:, keep_columns]\n",
    "    \n",
    "    df['Difference'] = compute_price_difference(df, price_column=price_column)\n",
    "    df['PercentageDiff'] = compute_percentage_diff(df)\n",
    "    df['Tendency'] = compute_tendency_percentage(df, diff_column='Difference', labels=['lower','stay', 'higher'], thresh_diff=THRESH_DIFF)\n",
    "    \n",
    "    if verbose:\n",
    "        value_counts = df.Tendency.value_counts().to_dict()\n",
    "        for value, count in value_counts.items():\n",
    "            print(f\"[{value}] : {count} ({count * 100.0 / len(df['Tendency']):.1f}%)\")\n",
    "            \n",
    "    df['MA'] = compute_MA(df, price_column)\n",
    "    df['MA_diff'] = compute_MA(df, price_column, n=20) - compute_MA(df, price_column, n=10)\n",
    "    df['RSI'] = compute_RSI(df, n=10, price_column=price_column, diff_column='Difference')\n",
    "    df['Next'] = shift_values(df, column='Tendency')\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "PERFORM_GRID_SEARCH = False\n",
    "\n",
    "# default parameters\n",
    "best_params = {'DTree': {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 15}, \n",
    "               'RandomForest': {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 10, 'n_estimators': 100}, \n",
    "               'SVM': {'gamma': 'auto'}, \n",
    "               'LR': {'penalty': 'l2', 'C': 1.0}\n",
    "              }\n",
    "\n",
    "param_grid = {\n",
    "    'DTree':{\n",
    "        'criterion':('entropy', 'gini'),\n",
    "        'max_depth':[1,2,3,5,8,10],\n",
    "        'min_samples_leaf':[1,2,3,5,10,15],\n",
    "    },\n",
    "    'RandomForest':{\n",
    "        'criterion':('entropy', 'gini'),\n",
    "        'n_estimators':[50,100,200,500],\n",
    "        'max_depth':[2,3,5,8,10],\n",
    "        'min_samples_leaf':[1,2,3,5,10,15],\n",
    "        'max_features':['auto', 'sqrt', 'log2'], \n",
    "    },\n",
    "    'SVM':{\n",
    "        'C':[1.0],\n",
    "        'kernel':('linear', 'poly', 'rbf'),\n",
    "        'gamma':('scale', 'auto'),\n",
    "    },\n",
    "    'LR':\n",
    "    {\n",
    "        'penalty':('none', 'l2'),\n",
    "        'C':[0.5, 1.0]\n",
    "    },   \n",
    "    \n",
    "}\n",
    "\n",
    "if PERFORM_GRID_SEARCH:\n",
    "    print(\"Performing grid search...\")\n",
    "    dtree = DecisionTreeClassifier(random_state=42, class_weight=class_weights)\n",
    "    clf = GridSearchCV(dtree, param_grid['DTree'], n_jobs=4)\n",
    "\n",
    "    \n",
    "    clf.fit(X_train, Y_train)\n",
    "    best_params['DTree'] = clf.best_params_\n",
    "\n",
    "    random_forest = RandomForestClassifier(random_state=42, class_weight=class_weights)\n",
    "    clf = GridSearchCV(random_forest, param_grid['RandomForest'], n_jobs=8)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    best_params['RandomForest'] = clf.best_params_\n",
    "\n",
    "    \n",
    "    \"\"\"svm = SVC(random_state=42, class_weight=class_weights, cache_size=4096)\n",
    "    clf = GridSearchCV(svm, param_grid['SVM'], n_jobs=4, verbose=30)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    best_params['SVM'] = clf.best_params_\"\"\"\n",
    "    \n",
    "    lr = LogisticRegression(random_state=42, class_weight=class_weights)\n",
    "    clf = GridSearchCV(lr, param_grid['LR'], n_jobs=4)\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "TRAIN_RATIO = 0.7\n",
    "\n",
    "def pipeline_ML(df, data_columns, y_column='Next', use_class_weights=True):\n",
    "    dataset = df.copy()\n",
    "    dataset = df.loc[:, data_columns]\n",
    "    \n",
    "    X = dataset.loc[:, dataset.columns != y_column]\n",
    "    Y = dataset[y_column]\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y, train_size=TRAIN_RATIO, random_state=42)\n",
    "    print(f\"{len(X_train)} samples for training, {len(X_test)} for testing.\")\n",
    "    if use_class_weights:\n",
    "        class_weights = compute_class_weight('balanced', np.unique(Y), Y)\n",
    "        # formuse_class_weights=s dict\n",
    "        class_weights = {c:w for c,w in zip(np.unique(Y), class_weights)}\n",
    "    else:\n",
    "        class_weights=None\n",
    "        \n",
    "\n",
    "    clf_dict = {}\n",
    "\n",
    "    clf_dict['DTree'] = DecisionTreeClassifier(**best_params['DTree'], random_state=42, class_weight=class_weights)\n",
    "    clf_dict['RandomForest'] = RandomForestClassifier(**best_params['RandomForest'], random_state=42, class_weight=class_weights)\n",
    "    clf_dict['SVM'] = SVC(**best_params['SVM'], class_weight=class_weights)\n",
    "    clf_dict['LR'] = LogisticRegression(**best_params['LR'], class_weight=class_weights)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "\n",
    "    for clf_label, clf in clf_dict.items():\n",
    "        clf.fit(X_train, Y_train)\n",
    "\n",
    "    print(\"Training done.\")\n",
    "    \n",
    "    return clf_dict, (X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-harmony",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix, f1_score\n",
    "\n",
    "def evaluate(clf_dict, dataset_splits, experiment_label=''):\n",
    "    X_train, X_test, Y_train, Y_test = dataset_splits\n",
    "    for clf_label, clf in clf_dict.items():\n",
    "        with mlflow.start_run(run_name=f\"{clf_label} {experiment_label}\"):\n",
    "            Y_pred = clf.predict(X_test)\n",
    "\n",
    "            accuracy = accuracy_score(Y_pred, Y_test)\n",
    "            f1 = f1_score(Y_pred, Y_test, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "            for param, val in best_params[clf_label].items():\n",
    "                mlflow.log_param(param, val)\n",
    "            mlflow.log_metric('acc', accuracy)\n",
    "            mlflow.log_metric('f1', f1)\n",
    "            mlflow.sklearn.log_model(clf, \"sklearn model\")\n",
    "\n",
    "        print(f\"[{clf_label}] Accuracy : {accuracy:.2f}, F1 : {f1:.2f}\")\n",
    "        plot_confusion_matrix(clf, X_test, Y_test, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data'\n",
    "FILE_SUFFIX = '.txt'\n",
    "\n",
    "quotations = ['GOOG', 'AAPL', 'AMZN']\n",
    "price_column = 'Close'\n",
    "THRESH_DIFF = 0.5\n",
    "\n",
    "for i in range(0, len(quotations)):\n",
    "    if i == 0:\n",
    "        df = pipeline_preprocessing(f\"{DATA_PATH}/{quotations[i]}{FILE_SUFFIX}\", price_column=price_column, thresh_diff=THRESH_DIFF)\n",
    "    else:\n",
    "        df = df.append(pipeline_preprocessing(f\"{DATA_PATH}/{quotations[i]}{FILE_SUFFIX}\", price_column=price_column, thresh_diff=THRESH_DIFF))\n",
    "\n",
    "    \n",
    "data_columns = ['Close', 'PercentageDiff', 'MA_diff', 'RSI', 'Next', 'Volume']\n",
    "\n",
    "clf_dict, dataset_splits = pipeline_ML(df, data_columns=data_columns, use_class_weights=True)\n",
    "evaluate(clf_dict, dataset_splits, experiment_label=f\"on {quot+', ' for quot in quotations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-people",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
