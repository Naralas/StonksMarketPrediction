{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "designed-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from notebook_config import setup_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "setup_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "secret-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.stocks_data_wrapper import StocksDataWrapper\n",
    "from helpers.data_helper import *\n",
    "from helpers.plots_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "elementary-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "FILE_SUFFIX='.txt'\n",
    "\n",
    "quotation = 'IBM'\n",
    "price_column = 'Close'\n",
    "project_label='KerasLSTMRegression'\n",
    "\n",
    "predict_n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "logical-treaty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Volume</th>\n",
       "      <th>LowLen</th>\n",
       "      <th>RSI(14)</th>\n",
       "      <th>GAP</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA(10)</th>\n",
       "      <th>SMA(20)</th>\n",
       "      <th>EMA(14)</th>\n",
       "      <th>EMA_Diff</th>\n",
       "      <th>SMA(20) - SMA(10)</th>\n",
       "      <th>Difference</th>\n",
       "      <th>PercentageDiff</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NextPrice</th>\n",
       "      <th>Next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-03-21</td>\n",
       "      <td>0.015428</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>0.015787</td>\n",
       "      <td>0.015429</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.595025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014503</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>0.013679</td>\n",
       "      <td>0.619962</td>\n",
       "      <td>0.394439</td>\n",
       "      <td>0.596761</td>\n",
       "      <td>0.496869</td>\n",
       "      <td>higher</td>\n",
       "      <td>0.012863</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962-03-22</td>\n",
       "      <td>0.015334</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>0.015051</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456905</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014474</td>\n",
       "      <td>0.013587</td>\n",
       "      <td>0.013637</td>\n",
       "      <td>0.619512</td>\n",
       "      <td>0.394997</td>\n",
       "      <td>0.595125</td>\n",
       "      <td>0.477865</td>\n",
       "      <td>lower</td>\n",
       "      <td>0.013540</td>\n",
       "      <td>higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962-03-23</td>\n",
       "      <td>0.015113</td>\n",
       "      <td>0.014271</td>\n",
       "      <td>0.015565</td>\n",
       "      <td>0.015177</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505305</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.013619</td>\n",
       "      <td>0.013618</td>\n",
       "      <td>0.619054</td>\n",
       "      <td>0.395653</td>\n",
       "      <td>0.594787</td>\n",
       "      <td>0.474037</td>\n",
       "      <td>higher</td>\n",
       "      <td>0.013508</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962-03-26</td>\n",
       "      <td>0.015207</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>0.015597</td>\n",
       "      <td>0.015162</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.499957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014399</td>\n",
       "      <td>0.013656</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.618669</td>\n",
       "      <td>0.396346</td>\n",
       "      <td>0.594843</td>\n",
       "      <td>0.474674</td>\n",
       "      <td>lower</td>\n",
       "      <td>0.013540</td>\n",
       "      <td>higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962-03-27</td>\n",
       "      <td>0.015113</td>\n",
       "      <td>0.014114</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.014516</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.013658</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>0.617898</td>\n",
       "      <td>0.397285</td>\n",
       "      <td>0.592643</td>\n",
       "      <td>0.449242</td>\n",
       "      <td>lower</td>\n",
       "      <td>0.013666</td>\n",
       "      <td>higher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adjusted    Volume  \\\n",
       "0  1962-03-21  0.015428  0.014523  0.015787  0.015429  0.005020  0.003780   \n",
       "1  1962-03-22  0.015334  0.014334  0.015533  0.015051  0.004897  0.003456   \n",
       "2  1962-03-23  0.015113  0.014271  0.015565  0.015177  0.004938  0.002700   \n",
       "3  1962-03-26  0.015207  0.014334  0.015597  0.015162  0.004933  0.001944   \n",
       "4  1962-03-27  0.015113  0.014114  0.014963  0.014516  0.004723  0.005076   \n",
       "\n",
       "     LowLen   RSI(14)       GAP  ...   SMA(10)   SMA(20)   EMA(14)  EMA_Diff  \\\n",
       "0  0.002525  0.595025  0.000000  ...  0.014503  0.013555  0.013679  0.619962   \n",
       "1  0.000000  0.456905  0.001641  ...  0.014474  0.013587  0.013637  0.619512   \n",
       "2  0.000000  0.505305  0.000410  ...  0.014436  0.013619  0.013618  0.619054   \n",
       "3  0.001263  0.499957  0.000000  ...  0.014399  0.013656  0.013600  0.618669   \n",
       "4  0.000842  0.332912  0.001026  ...  0.014300  0.013658  0.013496  0.617898   \n",
       "\n",
       "   SMA(20) - SMA(10)  Difference  PercentageDiff  Tendency  NextPrice    Next  \n",
       "0           0.394439    0.596761        0.496869    higher   0.012863   lower  \n",
       "1           0.394997    0.595125        0.477865     lower   0.013540  higher  \n",
       "2           0.395653    0.594787        0.474037    higher   0.013508   lower  \n",
       "3           0.396346    0.594843        0.474674     lower   0.013540  higher  \n",
       "4           0.397285    0.592643        0.449242     lower   0.013666  higher  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wrapper = StocksDataWrapper.read_from(file_path=f\"{DATA_PATH}{quotation}{FILE_SUFFIX}\", \n",
    "                                           compute_features=True, predict_n=predict_n, normalize=True)\n",
    "\n",
    "data_wrapper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pressing-commander",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_column = 'NextPrice'\n",
    "seq_len = 5\n",
    "n_splits=10\n",
    "val_size = 0.2\n",
    "\n",
    "features = ['Close', 'Volume', 'MACD_diff', 'RSI(14)', \n",
    "            'EMA(14)', 'SMA(10)', 'SMA(20) - SMA(10)','PercentageDiff', 'LowLen', 'RSI_diff', 'BodyLen', 'Volume_diff']\n",
    "datasets_splits = data_wrapper.get_datasets(n_splits=n_splits, val_size=val_size, sequences=True, seq_len=5, y_column=y_column, features_list=features)\n",
    "\n",
    "datasets_splits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-consumption",
   "metadata": {},
   "source": [
    "https://keras.io/examples/timeseries/timeseries_weather_forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coral-purple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d881c45bcf1d400eb345fbcaec554328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ········································\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wandb run page : https://wandb.ai/ludovic_herbelin_unine/KerasLSTMRegression/runs/231lo67w\n",
      "Wandb run page : https://wandb.ai/ludovic_herbelin_unine/KerasLSTMRegression/runs/k4k51kfs\n",
      "Wandb run page : https://wandb.ai/ludovic_herbelin_unine/KerasLSTMRegression/runs/n067n6fn\n",
      "Wandb run page : https://wandb.ai/ludovic_herbelin_unine/KerasLSTMRegression/runs/1l83vx9p\n",
      "Wandb run page : https://wandb.ai/ludovic_herbelin_unine/KerasLSTMRegression/runs/2s2t9r26\n",
      "Wandb run page : https://wandb.ai/ludovic_herbelin_unine/KerasLSTMRegression/runs/2pwf7zsq\n",
      "Wandb run page : https://wandb.ai/ludovic_herbelin_unine/KerasLSTMRegression/runs/24118wcn\n",
      "Wandb run page : https://wandb.ai/ludovic_herbelin_unine/KerasLSTMRegression/runs/sejix758\n",
      "Wandb run page : https://wandb.ai/ludovic_herbelin_unine/KerasLSTMRegression/runs/3hjkqawp\n",
      "Wandb run page : https://wandb.ai/ludovic_herbelin_unine/KerasLSTMRegression/runs/y5pmbxu7\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import timeseries_dataset_from_array as build_timeseries_ds\n",
    "from trainers.keras_regression_trainer import KerasRegressionTrainer\n",
    "from models.keras_lstm_model import LSTMModel\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "config_dict = dict(\n",
    "    quotation=quotation,\n",
    "    predict_n = predict_n,\n",
    "    features=features,\n",
    "    learning_rate = 0.01,\n",
    "    batch_size = 32,\n",
    "    sequence_length=seq_len,\n",
    "    n_epochs = 50,\n",
    "    n_splits = n_splits,\n",
    "    val_size = val_size,\n",
    ")\n",
    "\n",
    "group_name = f\"[{quotation}] {seq_len}-sequences : {len(features)} features  -> predict:{predict_n}, {n_splits} splits {val_size} val\"\n",
    "\n",
    "\n",
    "for split_id, split in tqdm(enumerate(datasets_splits)):\n",
    "    #run = wandb.init(project='StockRegressionKerasLSTM', config=config_dict, group=group_name, name=f\"Split {split_id+1}\")\n",
    "    \n",
    "    (X_train, X_val, X_test, y_train, y_val, y_test) = split\n",
    "    train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(config_dict['batch_size'])\n",
    "    val_set = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(config_dict['batch_size'])\n",
    "    test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(config_dict['batch_size'])\n",
    "\n",
    "    model = LSTMModel(config_dict, seq_len, len(features), output_dim=1,\n",
    "                      learning_rate=config_dict['learning_rate'], loss='mse', metrics=['mae'])\n",
    "    trainer = KerasRegressionTrainer(model, project_label=project_label)\n",
    "    trainer.train(train_set, val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-catch",
   "metadata": {},
   "source": [
    "### Train a model with the full training set (train + validation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rational-relief",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'output_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-cd231f588ee0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfull_train_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfinal_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTMModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasRegressionTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproject_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf\"{project_label} full training-set\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_train_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'output_dim'"
     ]
    }
   ],
   "source": [
    "config_dict['n_epochs'] = 150\n",
    "\n",
    "full_train_set = train_set.concatenate(val_set)\n",
    "final_model = LSTMModel(config_dict, seq_len, len(features), learning_rate=config_dict['learning_rate'], loss='mse')\n",
    "trainer = KerasRegressionTrainer(model, project_label=f\"{project_label} full training-set\")\n",
    "trainer.train(full_train_set, val_set=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels = trainer.predict(test_set)\n",
    "\n",
    "scaled_preds = data_wrapper.get_unscaled_values(predictions, 'Close')\n",
    "scaled_labels = data_wrapper.get_unscaled_values(labels, 'Close')\n",
    "\n",
    "ax = plot_predictions(scaled_labels, scaled_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-photograph",
   "metadata": {},
   "source": [
    "### Use of lime to explain decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_tabular\n",
    "\n",
    "# https://stackoverflow.com/questions/56226621/how-to-extract-data-labels-back-from-tensorflow-dataset\n",
    "training_samples = np.concatenate([x for x, y in train_set], axis=0)\n",
    "training_labels = np.concatenate([y for x, y in train_set], axis=0)\n",
    "\n",
    "\n",
    "for batch in train_set.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "explainer = lime_tabular.RecurrentTabularExplainer(inputs, training_labels=targets,\n",
    "                                                   discretize_continuous = True,\n",
    "                                                   feature_names=X_train,\n",
    "                                                   verbose=True, mode='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = np.concatenate([x for x, y in val_set], axis=0)\n",
    "\n",
    "print(test_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/marcotcr/lime/blob/master/doc/notebooks/Submodular%20Pick%20examples.ipynb\n",
    "\n",
    "import warnings\n",
    "from lime import submodular_pick\n",
    "sp_obj = submodular_pick.SubmodularPick(texplainer, test_samples, model.predict, \n",
    "                                        sample_size=15, num_features=10, num_exps_desired=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = list(sp_obj.sp_explanations)\n",
    "\n",
    "#print(len(explanations))\n",
    "\n",
    "[exp.as_pyplot_figure(label=1) for exp in sp_obj.sp_explanations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-delivery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
