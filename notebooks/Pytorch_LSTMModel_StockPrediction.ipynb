{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "atmospheric-merit",
   "metadata": {},
   "source": [
    "# Pytorch LSTM Classification model (old)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-aerospace",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "close-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "font = {'family' : 'DejaVu Sans', 'size'   : 25}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "native-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "from StocksDataWrapper import *\n",
    "from DataHelper import *\n",
    "from Plots import *\n",
    "from DL_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "neutral-pittsburgh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-feeling",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pending-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "QUOTATIONS = ['AMZN', 'GOOG', 'AAPL', 'GM', 'TSLA', 'JNJ', 'XOM', 'AAL', 'KO', 'WMT']\n",
    "QUOTATIONS = ['JNJ']\n",
    "quotation = QUOTATIONS[0]\n",
    "FILE_SUFFIX = '.txt'\n",
    "price_column = 'Close'\n",
    "project_label='NN_LSTM_2_Classes'\n",
    "normalize = True\n",
    "seq_len = 10\n",
    "predict_n = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smoking-debate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        66.400002\n",
      "1        67.230003\n",
      "2        66.620003\n",
      "3        66.510002\n",
      "4        66.260002\n",
      "           ...    \n",
      "3520    152.470001\n",
      "3521    153.190002\n",
      "3522    154.139999\n",
      "3523    156.050003\n",
      "3524    157.380005\n",
      "Name: Close, Length: 3525, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>LowLen</th>\n",
       "      <th>RSI(14)</th>\n",
       "      <th>GAP</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA(10)</th>\n",
       "      <th>SMA(20)</th>\n",
       "      <th>EMA(14)</th>\n",
       "      <th>EMA_Diff</th>\n",
       "      <th>SMA(20) - SMA(10)</th>\n",
       "      <th>Difference</th>\n",
       "      <th>PercentageDiff</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NextPrice</th>\n",
       "      <th>Next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-02-21</td>\n",
       "      <td>0.166421</td>\n",
       "      <td>0.161556</td>\n",
       "      <td>0.172681</td>\n",
       "      <td>0.168113</td>\n",
       "      <td>0.102998</td>\n",
       "      <td>0.082627</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.244899</td>\n",
       "      <td>0.018656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165782</td>\n",
       "      <td>0.158492</td>\n",
       "      <td>0.154936</td>\n",
       "      <td>0.613648</td>\n",
       "      <td>0.534115</td>\n",
       "      <td>0.582422</td>\n",
       "      <td>0.419236</td>\n",
       "      <td>lower</td>\n",
       "      <td>0.164109</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-02-22</td>\n",
       "      <td>0.163744</td>\n",
       "      <td>0.158535</td>\n",
       "      <td>0.169820</td>\n",
       "      <td>0.166103</td>\n",
       "      <td>0.112286</td>\n",
       "      <td>0.081448</td>\n",
       "      <td>0.013993</td>\n",
       "      <td>0.215285</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164811</td>\n",
       "      <td>0.157399</td>\n",
       "      <td>0.153680</td>\n",
       "      <td>0.610599</td>\n",
       "      <td>0.533603</td>\n",
       "      <td>0.592143</td>\n",
       "      <td>0.435595</td>\n",
       "      <td>lower</td>\n",
       "      <td>0.158422</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-02-23</td>\n",
       "      <td>0.160421</td>\n",
       "      <td>0.154325</td>\n",
       "      <td>0.163729</td>\n",
       "      <td>0.160347</td>\n",
       "      <td>0.098327</td>\n",
       "      <td>0.080074</td>\n",
       "      <td>0.017223</td>\n",
       "      <td>0.143903</td>\n",
       "      <td>0.015858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163277</td>\n",
       "      <td>0.156159</td>\n",
       "      <td>0.151774</td>\n",
       "      <td>0.596044</td>\n",
       "      <td>0.535462</td>\n",
       "      <td>0.575537</td>\n",
       "      <td>0.407120</td>\n",
       "      <td>lower</td>\n",
       "      <td>0.159776</td>\n",
       "      <td>higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-02-26</td>\n",
       "      <td>0.157098</td>\n",
       "      <td>0.153227</td>\n",
       "      <td>0.163913</td>\n",
       "      <td>0.161718</td>\n",
       "      <td>0.086875</td>\n",
       "      <td>0.080883</td>\n",
       "      <td>0.025834</td>\n",
       "      <td>0.184438</td>\n",
       "      <td>0.009328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162039</td>\n",
       "      <td>0.155291</td>\n",
       "      <td>0.150316</td>\n",
       "      <td>0.606093</td>\n",
       "      <td>0.537699</td>\n",
       "      <td>0.607129</td>\n",
       "      <td>0.461296</td>\n",
       "      <td>higher</td>\n",
       "      <td>0.148493</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-02-27</td>\n",
       "      <td>0.154790</td>\n",
       "      <td>0.150938</td>\n",
       "      <td>0.152007</td>\n",
       "      <td>0.150297</td>\n",
       "      <td>0.170943</td>\n",
       "      <td>0.074148</td>\n",
       "      <td>0.035522</td>\n",
       "      <td>0.077134</td>\n",
       "      <td>0.027985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159743</td>\n",
       "      <td>0.153771</td>\n",
       "      <td>0.147431</td>\n",
       "      <td>0.574123</td>\n",
       "      <td>0.542334</td>\n",
       "      <td>0.550425</td>\n",
       "      <td>0.363490</td>\n",
       "      <td>lower</td>\n",
       "      <td>0.147409</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close    Volume  Adjusted  \\\n",
       "0  2007-02-21  0.166421  0.161556  0.172681  0.168113  0.102998  0.082627   \n",
       "1  2007-02-22  0.163744  0.158535  0.169820  0.166103  0.112286  0.081448   \n",
       "2  2007-02-23  0.160421  0.154325  0.163729  0.160347  0.098327  0.080074   \n",
       "3  2007-02-26  0.157098  0.153227  0.163913  0.161718  0.086875  0.080883   \n",
       "4  2007-02-27  0.154790  0.150938  0.152007  0.150297  0.170943  0.074148   \n",
       "\n",
       "     LowLen   RSI(14)       GAP  ...   SMA(10)   SMA(20)   EMA(14)  EMA_Diff  \\\n",
       "0  0.004306  0.244899  0.018656  ...  0.165782  0.158492  0.154936  0.613648   \n",
       "1  0.013993  0.215285  0.002798  ...  0.164811  0.157399  0.153680  0.610599   \n",
       "2  0.017223  0.143903  0.015858  ...  0.163277  0.156159  0.151774  0.596044   \n",
       "3  0.025834  0.184438  0.009328  ...  0.162039  0.155291  0.150316  0.606093   \n",
       "4  0.035522  0.077134  0.027985  ...  0.159743  0.153771  0.147431  0.574123   \n",
       "\n",
       "   SMA(20) - SMA(10)  Difference  PercentageDiff  Tendency  NextPrice    Next  \n",
       "0           0.534115    0.582422        0.419236     lower   0.164109   lower  \n",
       "1           0.533603    0.592143        0.435595     lower   0.158422   lower  \n",
       "2           0.535462    0.575537        0.407120     lower   0.159776  higher  \n",
       "3           0.537699    0.607129        0.461296    higher   0.148493   lower  \n",
       "4           0.542334    0.550425        0.363490     lower   0.147409   lower  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wrapper = StocksDataWrapper.read_from(file_path=f\"{DATA_PATH}{quotation}{FILE_SUFFIX}\", \n",
    "                                           compute_features=True, predict_n=predict_n, normalize=normalize)\n",
    "\n",
    "data_wrapper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "portuguese-russell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                   False\n",
       "Open                   False\n",
       "High                   False\n",
       "Low                    False\n",
       "Close                  False\n",
       "Volume                 False\n",
       "Adjusted               False\n",
       "LowLen                 False\n",
       "RSI(14)                False\n",
       "GAP                    False\n",
       "RSI_diff               False\n",
       "Volume_diff            False\n",
       "MACD                   False\n",
       "MACD_diff              False\n",
       "MACD_signal            False\n",
       "BodyLen                False\n",
       "BG_L_Band              False\n",
       "BG_H_Band              False\n",
       "BG_L_Band_Indicator    False\n",
       "BG_H_Band_Indicator    False\n",
       "ROC                    False\n",
       "StochOsc               False\n",
       "SMA(10)                False\n",
       "SMA(20)                False\n",
       "EMA(14)                False\n",
       "EMA_Diff               False\n",
       "SMA(20) - SMA(10)      False\n",
       "Difference             False\n",
       "PercentageDiff         False\n",
       "Tendency               False\n",
       "NextPrice              False\n",
       "Next                   False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_wrapper.df\n",
    "feature_names = data_wrapper.feature_names\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "desperate-literature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Close    Volume      MACD   RSI(14)  PercentageDiff  SMA(20) - SMA(10)\n",
       " 0  0.168113  0.102998  0.527891  0.244899        0.419236           0.534115\n",
       " 1  0.166103  0.112286  0.524049  0.215285        0.435595           0.533603\n",
       " 2  0.160347  0.098327  0.517304  0.143903        0.407120           0.535462\n",
       " 3  0.161718  0.086875  0.513423  0.184438        0.461296           0.537699\n",
       " 4  0.150297  0.170943  0.502745  0.077134        0.363490           0.542334,\n",
       " 0    0.164109\n",
       " 1    0.158422\n",
       " 2    0.159776\n",
       " 3    0.148493\n",
       " 4    0.147409\n",
       " Name: NextPrice, dtype: float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from TorchDatasets import StocksSeqDataset\n",
    "\n",
    "y_column = 'NextPrice'\n",
    "data_columns = ['Close', 'Volume'] + feature_names\n",
    "data_columns = ['MACD', 'MACD_diff', 'RSI(14)', 'PercentageDiff', 'GAP', 'Close', 'Volume', 'EMA(14)', 'SMA(10)', 'SMA(20)', 'StochOsc']\n",
    "#data_columns = ['MACD', 'MACD_diff', 'RSI(14)', 'PercentageDiff', 'GAP', 'Close']\n",
    "data_columns = ['Close', 'Volume', 'MACD', 'RSI(14)', 'PercentageDiff','SMA(20) - SMA(10)']\n",
    "data_columns += [y_column]\n",
    "\n",
    "\n",
    "dataset = df.copy()\n",
    "dataset = dataset.loc[:, data_columns]\n",
    "\n",
    "for col in dataset.columns:\n",
    "    dataset[col] = dataset[col].replace({'higher':1, 'stay':0, 'lower':0})\n",
    "\n",
    "\n",
    "    \n",
    "X = dataset.loc[:, dataset.columns != y_column]\n",
    "y = dataset[y_column]\n",
    "\n",
    "X.head(), y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joined-future",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 3481/3481 [00:00<00:00, 30477.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3481, 10, 6) (3481,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_sequences(values, seq_len):\n",
    "    sequences = np.empty((values.shape[0] - seq_len, seq_len, values.shape[1]))\n",
    "    for i in tqdm(range(0, sequences.shape[0])):\n",
    "        seq = values[i:i+seq_len].values\n",
    "        sequences[i] = seq\n",
    "        \n",
    "    return sequences\n",
    "    \n",
    "\n",
    "X_seq = generate_sequences(X, seq_len)\n",
    "y_seq = y[seq_len:]\n",
    "\n",
    "print(X_seq.shape, y_seq.shape)\n",
    "\n",
    "#print(X.head(seq_len+1).values, y.head(seq_len+1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "atlantic-defendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size : 2436, test_size : 1045\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'sort_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-84e0c486d127>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'sort_index'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "TEST_SIZE = 0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.3, random_state=42)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.3, shuffle=True)\n",
    "    \n",
    "print(f\"Train size : {len(X_train)}, test_size : {len(X_test)}\")\n",
    "\n",
    "y_test = y_test.sort_index()\n",
    "X_test = X_test.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = StocksSeqDataset(X_train, y_train)\n",
    "test_dataset = StocksSeqDataset(X_test, y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-learning",
   "metadata": {},
   "source": [
    "$Seq_X = [[x_i*N_{features}], [x_{i+1} * N_{features}], ... , x_{seq_len} * N_{features}]$\n",
    "\n",
    "$Seq_Y = [y_{seq\\_len + 1}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-knitting",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable \n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, n_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=n_layers, batch_first=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 8),\n",
    "            nn.ReLU(0.1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(0.1),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(0.1),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(8, 8),\n",
    "            nn.ReLU(0.1),\n",
    "            nn.Linear(8, output_dim),\n",
    "            #nn.Softmax(1),\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out, (hn, cn) = self.lstm(x)\n",
    "        out = self.classifier(hn[-1])\n",
    "        return out\n",
    "    \n",
    "lr = 0.01\n",
    "model, optimizer, loss_fn = create_model(LSTMModel, device=device, input_dim = len(X.columns), output_dim=1, \n",
    "                                            loss_fn=nn.MSELoss, optimizer=torch.optim.Adam, lr=lr,\n",
    "                                            use_wandb=True, project_label=project_label, hidden_dim=16, n_layers=)\n",
    "\n",
    "train(model, train_dataloader, n_epochs=100, optimizer=optimizer, acc_func=torch_mse, acc_label=\"MSE\", loss_fn=loss_fn, device=device, use_wandb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "predictions, labels = predict_reg(model, test_dataloader, device)\n",
    "\n",
    "print(labels[:10], predictions[:10])\n",
    "r2 = r2_score(labels, predictions)\n",
    "\n",
    "mse = mean_squared_error(labels, predictions)\n",
    "\n",
    "print(f\"MSE : {mse}, R2: {r2}, MAE : {mean_absolute_error(labels, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from StocksDataWrapper import *\n",
    "\n",
    "test_df = pd.DataFrame(data={'Close':predictions.reshape(-1)})\n",
    "scaled_preds = data_wrapper.get_unscaled_data(df=test_df)['Close']\n",
    "test_df = pd.DataFrame(data={'Close':labels.reshape(-1)})\n",
    "scaled_labels = data_wrapper.get_unscaled_data(df=test_df)['Close']\n",
    "\n",
    "prices_diffs = [(p-y) for p,y in zip(scaled_preds, scaled_labels)]\n",
    "ax = plot_normalized_histogram(series=pd.Series(prices_diffs, name=\"Differences\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_predictions = pd.Series(scaled_preds).rolling(10).mean()\n",
    "\n",
    "smoothed_predictions.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaled_preds[:10], scaled_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(scaled_labels, label=\"Labels\")\n",
    "ax.plot(scaled_preds, label=\"Predictions\")\n",
    "ax.plot(smoothed_predictions, label=\"Smoothed\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-washer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
