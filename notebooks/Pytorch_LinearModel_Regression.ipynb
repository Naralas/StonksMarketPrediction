{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "egyptian-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from notebook_config import setup_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "setup_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cubic-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.stocks_data_wrapper import StocksDataWrapper\n",
    "from helpers.data_helper import *\n",
    "from helpers.plots_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "derived-peace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-jaguar",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mysterious-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "FILE_SUFFIX='.txt'\n",
    "\n",
    "quotation = 'IBM'\n",
    "price_column = 'Close'\n",
    "project_label='LinearNNRegression'\n",
    "\n",
    "predict_n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "heated-execution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Volume</th>\n",
       "      <th>LowLen</th>\n",
       "      <th>RSI(14)</th>\n",
       "      <th>GAP</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA(10)</th>\n",
       "      <th>SMA(20)</th>\n",
       "      <th>EMA(14)</th>\n",
       "      <th>EMA_Diff</th>\n",
       "      <th>SMA(20) - SMA(10)</th>\n",
       "      <th>Difference</th>\n",
       "      <th>PercentageDiff</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>NextPrice</th>\n",
       "      <th>Next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1962-03-21</td>\n",
       "      <td>0.015428</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>0.015787</td>\n",
       "      <td>0.015429</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.595025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014503</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>0.013679</td>\n",
       "      <td>0.613174</td>\n",
       "      <td>0.394439</td>\n",
       "      <td>0.575048</td>\n",
       "      <td>0.643619</td>\n",
       "      <td>higher</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962-03-22</td>\n",
       "      <td>0.015334</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>0.015051</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456905</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014474</td>\n",
       "      <td>0.013587</td>\n",
       "      <td>0.013637</td>\n",
       "      <td>0.611388</td>\n",
       "      <td>0.394997</td>\n",
       "      <td>0.572212</td>\n",
       "      <td>0.611458</td>\n",
       "      <td>lower</td>\n",
       "      <td>0.014610</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1962-03-23</td>\n",
       "      <td>0.015113</td>\n",
       "      <td>0.014271</td>\n",
       "      <td>0.015565</td>\n",
       "      <td>0.015177</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505305</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.013619</td>\n",
       "      <td>0.013618</td>\n",
       "      <td>0.612154</td>\n",
       "      <td>0.395653</td>\n",
       "      <td>0.575703</td>\n",
       "      <td>0.651147</td>\n",
       "      <td>higher</td>\n",
       "      <td>0.014280</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962-03-26</td>\n",
       "      <td>0.015207</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>0.015597</td>\n",
       "      <td>0.015162</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.499957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014399</td>\n",
       "      <td>0.013656</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.612167</td>\n",
       "      <td>0.396346</td>\n",
       "      <td>0.574721</td>\n",
       "      <td>0.639898</td>\n",
       "      <td>lower</td>\n",
       "      <td>0.013823</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962-03-27</td>\n",
       "      <td>0.015113</td>\n",
       "      <td>0.014114</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.014516</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.013658</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>0.609286</td>\n",
       "      <td>0.397285</td>\n",
       "      <td>0.570357</td>\n",
       "      <td>0.590036</td>\n",
       "      <td>lower</td>\n",
       "      <td>0.013005</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adjusted    Volume  \\\n",
       "0  1962-03-21  0.015428  0.014523  0.015787  0.015429  0.005020  0.003780   \n",
       "1  1962-03-22  0.015334  0.014334  0.015533  0.015051  0.004897  0.003456   \n",
       "2  1962-03-23  0.015113  0.014271  0.015565  0.015177  0.004938  0.002700   \n",
       "3  1962-03-26  0.015207  0.014334  0.015597  0.015162  0.004933  0.001944   \n",
       "4  1962-03-27  0.015113  0.014114  0.014963  0.014516  0.004723  0.005076   \n",
       "\n",
       "     LowLen   RSI(14)       GAP  ...   SMA(10)   SMA(20)   EMA(14)  EMA_Diff  \\\n",
       "0  0.002525  0.595025  0.000000  ...  0.014503  0.013555  0.013679  0.613174   \n",
       "1  0.000000  0.456905  0.001641  ...  0.014474  0.013587  0.013637  0.611388   \n",
       "2  0.000000  0.505305  0.000410  ...  0.014436  0.013619  0.013618  0.612154   \n",
       "3  0.001263  0.499957  0.000000  ...  0.014399  0.013656  0.013600  0.612167   \n",
       "4  0.000842  0.332912  0.001026  ...  0.014300  0.013658  0.013496  0.609286   \n",
       "\n",
       "   SMA(20) - SMA(10)  Difference  PercentageDiff  Tendency  NextPrice    Next  \n",
       "0           0.394439    0.575048        0.643619    higher   0.014705  higher  \n",
       "1           0.394997    0.572212        0.611458     lower   0.014610   lower  \n",
       "2           0.395653    0.575703        0.651147    higher   0.014280   lower  \n",
       "3           0.396346    0.574721        0.639898     lower   0.013823   lower  \n",
       "4           0.397285    0.570357        0.590036     lower   0.013005   lower  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wrapper = StocksDataWrapper.read_from(file_path=f\"{DATA_PATH}{quotation}{FILE_SUFFIX}\", \n",
    "                                           compute_features=True, predict_n=predict_n, normalize=True)\n",
    "\n",
    "data_wrapper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "desperate-antarctica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prices = data_wrapper.get_unscaled_data()['Close']\n",
    "plot_prices(price_series=prices, date_series=data_wrapper['Date'], quotation_name=quotation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_normalized_histogram(data_wrapper.get_unscaled_data()['Difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opened-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from datasets.torch_datasets import StocksDataset\n",
    "\n",
    "\n",
    "y_column = 'NextPrice'\n",
    "data_columns = ['Close', 'Volume', 'MACD_diff', 'RSI(14)', 'PercentageDiff', 'LowLen', 'RSI_diff']\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_wrapper.get_datasets(n_splits=1, val_size=0.3, \n",
    "                                                             y_column='NextPrice', \n",
    "                                                             features_list=data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "olive-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size : 10355, test_size : 4438\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataset = StocksDataset(X_train,y_train)\n",
    "test_dataset = StocksDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "print(f\"Train size : {len(train_dataset)}, test_size : {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-posting",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "limiting-learning",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=7, out_features=16, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.1)\n",
      "    (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Linear(in_features=16, out_features=32, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.1)\n",
      "    (5): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (6): LeakyReLU(negative_slope=0.1)\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (9): LeakyReLU(negative_slope=0.1)\n",
      "    (10): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      "  (loss_fn): MSELoss()\n",
      ")\n",
      "Wandb run page : https://wandb.ai/ludovic_herbelin_unine/LinearNNRegression/runs/3i7hr71o\n",
      "tensor([[-0.0589],\n",
      "        [-0.0843],\n",
      "        [-0.0914],\n",
      "        [-0.0557],\n",
      "        [-0.0336],\n",
      "        [ 0.0022],\n",
      "        [-0.0049],\n",
      "        [-0.0471],\n",
      "        [-0.1064],\n",
      "        [ 0.0187],\n",
      "        [-0.1190],\n",
      "        [-0.0101],\n",
      "        [ 0.0185],\n",
      "        [ 0.0031],\n",
      "        [-0.0511],\n",
      "        [-0.0290],\n",
      "        [-0.0319],\n",
      "        [ 0.0125],\n",
      "        [ 0.0046],\n",
      "        [ 0.0003],\n",
      "        [-0.0293],\n",
      "        [ 0.0558],\n",
      "        [ 0.0353],\n",
      "        [ 0.0228],\n",
      "        [-0.0089],\n",
      "        [-0.0347],\n",
      "        [ 0.0545],\n",
      "        [-0.1736],\n",
      "        [-0.0622],\n",
      "        [ 0.0120],\n",
      "        [-0.0343],\n",
      "        [-0.0016]], device='cuda:0', grad_fn=<BackwardHookFunctionBackward>)\n",
      "tensor([0.0147, 0.0146, 0.0143, 0.0138, 0.0130, 0.0129, 0.0135, 0.0135, 0.0135,\n",
      "        0.0137, 0.0132, 0.0129, 0.0134, 0.0133, 0.0135, 0.0134, 0.0134, 0.0134,\n",
      "        0.0134, 0.0130, 0.0122, 0.0113, 0.0093, 0.0098, 0.0105, 0.0111, 0.0113,\n",
      "        0.0107, 0.0097, 0.0091, 0.0093, 0.0088], device='cuda:0')\n",
      "tensor([[-0.0438],\n",
      "        [-0.0163],\n",
      "        [-0.0423],\n",
      "        [-0.0277],\n",
      "        [-0.0653],\n",
      "        [-0.0177],\n",
      "        [-0.0169],\n",
      "        [ 0.0668],\n",
      "        [-0.0052],\n",
      "        [ 0.0169],\n",
      "        [-0.0257],\n",
      "        [-0.0096],\n",
      "        [ 0.0300],\n",
      "        [-0.0063],\n",
      "        [ 0.0374],\n",
      "        [-0.1292],\n",
      "        [-0.0332],\n",
      "        [ 0.0057],\n",
      "        [ 0.0024],\n",
      "        [ 0.0119],\n",
      "        [-0.0002],\n",
      "        [-0.0103],\n",
      "        [-0.0644],\n",
      "        [-0.0145],\n",
      "        [ 0.0182],\n",
      "        [ 0.0127],\n",
      "        [-0.0196],\n",
      "        [-0.0253],\n",
      "        [-0.0168],\n",
      "        [ 0.0035],\n",
      "        [ 0.0652],\n",
      "        [ 0.0243]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0094, 0.0092, 0.0095, 0.0090, 0.0092, 0.0091, 0.0081, 0.0069, 0.0058,\n",
      "        0.0058, 0.0035, 0.0048, 0.0054, 0.0050, 0.0034, 0.0037, 0.0037, 0.0040,\n",
      "        0.0041, 0.0033, 0.0018, 0.0010, 0.0000, 0.0017, 0.0015, 0.0019, 0.0014,\n",
      "        0.0006, 0.0009, 0.0017, 0.0009, 0.0017], device='cuda:0')\n",
      "tensor([[-0.0984],\n",
      "        [ 0.0750],\n",
      "        [-0.0058],\n",
      "        [-0.0627],\n",
      "        [ 0.0013],\n",
      "        [-0.0001],\n",
      "        [-0.0102],\n",
      "        [-0.0380],\n",
      "        [ 0.0465],\n",
      "        [-0.0235],\n",
      "        [-0.0356],\n",
      "        [-0.0092],\n",
      "        [ 0.0078],\n",
      "        [ 0.0150],\n",
      "        [-0.0307],\n",
      "        [-0.0264],\n",
      "        [-0.0337],\n",
      "        [-0.0199],\n",
      "        [-0.0952],\n",
      "        [-0.0100],\n",
      "        [-0.0270],\n",
      "        [-0.0891],\n",
      "        [ 0.0242],\n",
      "        [-0.0081],\n",
      "        [-0.0017],\n",
      "        [-0.0582],\n",
      "        [-0.0107],\n",
      "        [-0.0130],\n",
      "        [-0.0168],\n",
      "        [-0.0181],\n",
      "        [-0.0347],\n",
      "        [-0.0811]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0024, 0.0021, 0.0028, 0.0029, 0.0028, 0.0025, 0.0028, 0.0033, 0.0043,\n",
      "        0.0046, 0.0044, 0.0048, 0.0040, 0.0037, 0.0039, 0.0042, 0.0042, 0.0036,\n",
      "        0.0039, 0.0040, 0.0044, 0.0051, 0.0051, 0.0044, 0.0050, 0.0050, 0.0047,\n",
      "        0.0042, 0.0048, 0.0044, 0.0044, 0.0046], device='cuda:0')\n",
      "tensor([[-0.0639],\n",
      "        [ 0.0017],\n",
      "        [-0.0351],\n",
      "        [ 0.0063],\n",
      "        [-0.0106],\n",
      "        [ 0.0028],\n",
      "        [-0.0349],\n",
      "        [ 0.0136],\n",
      "        [-0.0243],\n",
      "        [ 0.0706],\n",
      "        [ 0.0340],\n",
      "        [ 0.1085],\n",
      "        [ 0.1537],\n",
      "        [-0.0723],\n",
      "        [-0.0096],\n",
      "        [-0.0325],\n",
      "        [-0.1083],\n",
      "        [-0.1143],\n",
      "        [-0.0112],\n",
      "        [-0.0812],\n",
      "        [-0.0377],\n",
      "        [ 0.0153],\n",
      "        [-0.0528],\n",
      "        [ 0.0060],\n",
      "        [ 0.0240],\n",
      "        [-0.0127],\n",
      "        [ 0.0085],\n",
      "        [-0.0388],\n",
      "        [ 0.0009],\n",
      "        [ 0.0035],\n",
      "        [-0.0426],\n",
      "        [-0.0334]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0050, 0.0051, 0.0051, 0.0053, 0.0055, 0.0055, 0.0065, 0.0066, 0.0065,\n",
      "        0.0064, 0.0055, 0.0054, 0.0051, 0.0057, 0.0051, 0.0048, 0.0052, 0.0048,\n",
      "        0.0049, 0.0048, 0.0049, 0.0049, 0.0052, 0.0056, 0.0054, 0.0051, 0.0048,\n",
      "        0.0045, 0.0035, 0.0040, 0.0031, 0.0028], device='cuda:0')\n",
      "tensor([[-0.0367],\n",
      "        [-0.0784],\n",
      "        [ 0.0323],\n",
      "        [ 0.0318],\n",
      "        [-0.0033],\n",
      "        [ 0.0406],\n",
      "        [ 0.0210],\n",
      "        [-0.0315],\n",
      "        [-0.0529],\n",
      "        [ 0.0195],\n",
      "        [ 0.0181],\n",
      "        [-0.0209],\n",
      "        [-0.0534],\n",
      "        [ 0.0144],\n",
      "        [-0.0111],\n",
      "        [-0.0155],\n",
      "        [-0.0524],\n",
      "        [-0.0591],\n",
      "        [-0.0002],\n",
      "        [-0.0040],\n",
      "        [ 0.0156],\n",
      "        [ 0.0150],\n",
      "        [-0.0733],\n",
      "        [ 0.0207],\n",
      "        [-0.0546],\n",
      "        [-0.0624],\n",
      "        [ 0.0010],\n",
      "        [ 0.1105],\n",
      "        [ 0.0175],\n",
      "        [ 0.0173],\n",
      "        [ 0.0756],\n",
      "        [-0.0220]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0030, 0.0022, 0.0028, 0.0027, 0.0033, 0.0034, 0.0034, 0.0038, 0.0033,\n",
      "        0.0031, 0.0031, 0.0038, 0.0032, 0.0035, 0.0031, 0.0027, 0.0023, 0.0015,\n",
      "        0.0021, 0.0020, 0.0016, 0.0024, 0.0029, 0.0025, 0.0029, 0.0032, 0.0035,\n",
      "        0.0035, 0.0031, 0.0035, 0.0043, 0.0038], device='cuda:0')\n",
      "tensor([[-0.0302],\n",
      "        [-0.0215],\n",
      "        [-0.0240],\n",
      "        [ 0.0106],\n",
      "        [-0.0094],\n",
      "        [-0.0069],\n",
      "        [ 0.0235],\n",
      "        [ 0.0003],\n",
      "        [-0.0455],\n",
      "        [ 0.0074],\n",
      "        [-0.0061],\n",
      "        [ 0.0112],\n",
      "        [ 0.0252],\n",
      "        [ 0.0615],\n",
      "        [-0.0188],\n",
      "        [ 0.0926],\n",
      "        [-0.0027],\n",
      "        [-0.0702],\n",
      "        [-0.0660],\n",
      "        [ 0.0070],\n",
      "        [-0.0673],\n",
      "        [-0.0479],\n",
      "        [-0.0168],\n",
      "        [ 0.0478],\n",
      "        [ 0.0007],\n",
      "        [ 0.0783],\n",
      "        [-0.0773],\n",
      "        [-0.0783],\n",
      "        [ 0.0153],\n",
      "        [ 0.0062],\n",
      "        [-0.0441],\n",
      "        [-0.0758]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0043, 0.0042, 0.0046, 0.0042, 0.0044, 0.0045, 0.0052, 0.0052, 0.0056,\n",
      "        0.0058, 0.0060, 0.0058, 0.0054, 0.0059, 0.0058, 0.0058, 0.0058, 0.0052,\n",
      "        0.0051, 0.0055, 0.0052, 0.0053, 0.0050, 0.0048, 0.0054, 0.0054, 0.0050,\n",
      "        0.0055, 0.0055, 0.0054, 0.0054, 0.0053], device='cuda:0')\n",
      "tensor([[-0.0554],\n",
      "        [ 0.0243],\n",
      "        [-0.0250],\n",
      "        [ 0.0318],\n",
      "        [-0.0198],\n",
      "        [ 0.0766],\n",
      "        [ 0.0198],\n",
      "        [-0.0162],\n",
      "        [-0.0087],\n",
      "        [ 0.0540],\n",
      "        [ 0.0855],\n",
      "        [-0.0347],\n",
      "        [ 0.0072],\n",
      "        [ 0.1140],\n",
      "        [ 0.0432],\n",
      "        [-0.0066],\n",
      "        [-0.0406],\n",
      "        [-0.0207],\n",
      "        [-0.0325],\n",
      "        [-0.0254],\n",
      "        [-0.0279],\n",
      "        [-0.0366],\n",
      "        [-0.0046],\n",
      "        [-0.0066],\n",
      "        [-0.0388],\n",
      "        [ 0.0079],\n",
      "        [-0.0515],\n",
      "        [-0.0034],\n",
      "        [-0.1029],\n",
      "        [-0.0957],\n",
      "        [-0.0493],\n",
      "        [ 0.0271]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0050, 0.0057, 0.0057, 0.0055, 0.0061, 0.0062, 0.0063, 0.0064, 0.0068,\n",
      "        0.0069, 0.0065, 0.0068, 0.0067, 0.0068, 0.0068, 0.0068, 0.0069, 0.0071,\n",
      "        0.0075, 0.0073, 0.0071, 0.0074, 0.0074, 0.0072, 0.0072, 0.0071, 0.0071,\n",
      "        0.0072, 0.0070, 0.0071, 0.0070, 0.0070], device='cuda:0')\n",
      "tensor([[ 0.0111],\n",
      "        [-0.0224],\n",
      "        [ 0.0281],\n",
      "        [-0.0622],\n",
      "        [ 0.0186],\n",
      "        [-0.0166],\n",
      "        [-0.0027],\n",
      "        [-0.0218],\n",
      "        [ 0.0384],\n",
      "        [ 0.0403],\n",
      "        [ 0.0734],\n",
      "        [-0.0485],\n",
      "        [ 0.0160],\n",
      "        [ 0.0672],\n",
      "        [ 0.0408],\n",
      "        [-0.0153],\n",
      "        [-0.0426],\n",
      "        [-0.0456],\n",
      "        [-0.0113],\n",
      "        [-0.0246],\n",
      "        [-0.0011],\n",
      "        [-0.0419],\n",
      "        [-0.0114],\n",
      "        [-0.0146],\n",
      "        [-0.0042],\n",
      "        [-0.0093],\n",
      "        [ 0.0144],\n",
      "        [ 0.0088],\n",
      "        [-0.0356],\n",
      "        [-0.0392],\n",
      "        [ 0.0314],\n",
      "        [ 0.0231]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0071, 0.0070, 0.0068, 0.0066, 0.0066, 0.0062, 0.0063, 0.0063, 0.0059,\n",
      "        0.0057, 0.0061, 0.0060, 0.0062, 0.0065, 0.0065, 0.0064, 0.0064, 0.0065,\n",
      "        0.0065, 0.0068, 0.0065, 0.0065, 0.0068, 0.0066, 0.0068, 0.0068, 0.0069,\n",
      "        0.0072, 0.0072, 0.0072, 0.0072, 0.0070], device='cuda:0')\n",
      "tensor([[-4.2417e-02],\n",
      "        [-3.3780e-02],\n",
      "        [-4.8582e-02],\n",
      "        [ 1.5257e-02],\n",
      "        [ 3.3658e-02],\n",
      "        [ 2.7913e-02],\n",
      "        [-1.3389e-02],\n",
      "        [ 4.2074e-02],\n",
      "        [ 7.1606e-02],\n",
      "        [-3.7823e-02],\n",
      "        [ 3.4826e-03],\n",
      "        [ 1.1861e-02],\n",
      "        [-2.0739e-02],\n",
      "        [ 4.9470e-03],\n",
      "        [ 2.5944e-02],\n",
      "        [-6.2115e-02],\n",
      "        [-2.4364e-02],\n",
      "        [ 6.9555e-03],\n",
      "        [-1.9461e-02],\n",
      "        [ 1.8472e-02],\n",
      "        [ 8.1041e-02],\n",
      "        [-1.5821e-02],\n",
      "        [-9.2391e-05],\n",
      "        [-6.5373e-02],\n",
      "        [ 1.6586e-03],\n",
      "        [-5.0078e-02],\n",
      "        [ 4.8785e-04],\n",
      "        [ 3.0006e-02],\n",
      "        [ 3.5402e-02],\n",
      "        [ 1.6985e-02],\n",
      "        [ 1.7279e-02],\n",
      "        [-1.8983e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0073, 0.0077, 0.0086, 0.0090, 0.0087, 0.0086, 0.0088, 0.0088, 0.0086,\n",
      "        0.0085, 0.0085, 0.0091, 0.0095, 0.0098, 0.0099, 0.0100, 0.0103, 0.0102,\n",
      "        0.0099, 0.0100, 0.0102, 0.0100, 0.0096, 0.0097, 0.0103, 0.0104, 0.0106,\n",
      "        0.0104, 0.0104, 0.0105, 0.0103, 0.0101], device='cuda:0')\n",
      "tensor([[-0.0293],\n",
      "        [-0.0072],\n",
      "        [-0.0029],\n",
      "        [ 0.0233],\n",
      "        [-0.1404],\n",
      "        [-0.0943],\n",
      "        [-0.0629],\n",
      "        [-0.0780],\n",
      "        [-0.0260],\n",
      "        [-0.0231],\n",
      "        [-0.0080],\n",
      "        [-0.0339],\n",
      "        [-0.0361],\n",
      "        [ 0.0512],\n",
      "        [ 0.0655],\n",
      "        [-0.0532],\n",
      "        [ 0.0551],\n",
      "        [-0.0072],\n",
      "        [-0.0474],\n",
      "        [-0.0302],\n",
      "        [-0.0259],\n",
      "        [-0.0034],\n",
      "        [-0.0029],\n",
      "        [-0.0071],\n",
      "        [-0.0444],\n",
      "        [ 0.0089],\n",
      "        [ 0.0141],\n",
      "        [-0.0393],\n",
      "        [ 0.0059],\n",
      "        [-0.0971],\n",
      "        [ 0.0242],\n",
      "        [ 0.0695]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0099, 0.0101, 0.0101, 0.0100, 0.0099, 0.0096, 0.0097, 0.0103, 0.0108,\n",
      "        0.0105, 0.0106, 0.0103, 0.0103, 0.0102, 0.0098, 0.0100, 0.0102, 0.0099,\n",
      "        0.0099, 0.0097, 0.0096, 0.0095, 0.0094, 0.0094, 0.0090, 0.0089, 0.0084,\n",
      "        0.0081, 0.0082, 0.0076, 0.0083, 0.0085], device='cuda:0')\n",
      "tensor([[-0.0466],\n",
      "        [ 0.0217],\n",
      "        [-0.0729],\n",
      "        [-0.0439],\n",
      "        [ 0.0060],\n",
      "        [ 0.0432],\n",
      "        [ 0.0124],\n",
      "        [-0.0516],\n",
      "        [-0.0056],\n",
      "        [ 0.0251],\n",
      "        [ 0.0234],\n",
      "        [-0.0191],\n",
      "        [ 0.0014],\n",
      "        [-0.0246],\n",
      "        [-0.0046],\n",
      "        [ 0.0241],\n",
      "        [ 0.0045],\n",
      "        [ 0.0443],\n",
      "        [ 0.0306],\n",
      "        [ 0.0038],\n",
      "        [ 0.0023],\n",
      "        [ 0.0077],\n",
      "        [ 0.0998],\n",
      "        [ 0.0043],\n",
      "        [-0.0208],\n",
      "        [-0.0187],\n",
      "        [ 0.0048],\n",
      "        [-0.0405],\n",
      "        [ 0.0281],\n",
      "        [-0.0050],\n",
      "        [-0.0295],\n",
      "        [-0.0316]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0088, 0.0082, 0.0085, 0.0082, 0.0081, 0.0079, 0.0080, 0.0081, 0.0080,\n",
      "        0.0078, 0.0078, 0.0077, 0.0076, 0.0077, 0.0077, 0.0079, 0.0080, 0.0086,\n",
      "        0.0081, 0.0081, 0.0079, 0.0083, 0.0085, 0.0083, 0.0084, 0.0087, 0.0088,\n",
      "        0.0093, 0.0095, 0.0093, 0.0092, 0.0092], device='cuda:0')\n",
      "tensor([[ 0.0424],\n",
      "        [ 0.0566],\n",
      "        [ 0.0514],\n",
      "        [-0.0031],\n",
      "        [-0.0336],\n",
      "        [-0.0862],\n",
      "        [ 0.0022],\n",
      "        [-0.0451],\n",
      "        [ 0.0098],\n",
      "        [-0.0016],\n",
      "        [-0.0044],\n",
      "        [-0.0288],\n",
      "        [-0.1318],\n",
      "        [-0.0536],\n",
      "        [ 0.0106],\n",
      "        [-0.0130],\n",
      "        [-0.0295],\n",
      "        [-0.0576],\n",
      "        [ 0.0093],\n",
      "        [ 0.0366],\n",
      "        [-0.0009],\n",
      "        [-0.0118],\n",
      "        [-0.0436],\n",
      "        [-0.0440],\n",
      "        [-0.0381],\n",
      "        [-0.0926],\n",
      "        [-0.0031],\n",
      "        [-0.0143],\n",
      "        [-0.0642],\n",
      "        [ 0.0246],\n",
      "        [ 0.0226],\n",
      "        [-0.0464]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0088, 0.0090, 0.0092, 0.0090, 0.0091, 0.0086, 0.0087, 0.0086, 0.0087,\n",
      "        0.0089, 0.0089, 0.0091, 0.0096, 0.0095, 0.0096, 0.0095, 0.0095, 0.0094,\n",
      "        0.0094, 0.0094, 0.0091, 0.0093, 0.0095, 0.0094, 0.0099, 0.0096, 0.0091,\n",
      "        0.0090, 0.0092, 0.0091, 0.0090, 0.0095], device='cuda:0')\n",
      "tensor([[ 0.0657],\n",
      "        [-0.0448],\n",
      "        [ 0.0858],\n",
      "        [ 0.0479],\n",
      "        [-0.0144],\n",
      "        [ 0.0035],\n",
      "        [-0.0089],\n",
      "        [-0.0274],\n",
      "        [-0.0142],\n",
      "        [-0.0294],\n",
      "        [-0.0125],\n",
      "        [-0.0188],\n",
      "        [ 0.0172],\n",
      "        [-0.0094],\n",
      "        [ 0.0806],\n",
      "        [ 0.1317],\n",
      "        [ 0.0650],\n",
      "        [-0.0069],\n",
      "        [-0.0351],\n",
      "        [-0.0758],\n",
      "        [-0.0256],\n",
      "        [ 0.0212],\n",
      "        [ 0.0177],\n",
      "        [-0.0181],\n",
      "        [-0.0070],\n",
      "        [ 0.0359],\n",
      "        [ 0.0185],\n",
      "        [ 0.0237],\n",
      "        [-0.0428],\n",
      "        [ 0.0054],\n",
      "        [ 0.0063],\n",
      "        [-0.0425]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0098, 0.0103, 0.0099, 0.0099, 0.0100, 0.0103, 0.0107, 0.0108, 0.0116,\n",
      "        0.0117, 0.0119, 0.0118, 0.0113, 0.0111, 0.0113, 0.0118, 0.0120, 0.0117,\n",
      "        0.0112, 0.0118, 0.0115, 0.0112, 0.0110, 0.0111, 0.0112, 0.0114, 0.0115,\n",
      "        0.0116, 0.0114, 0.0113, 0.0110, 0.0105], device='cuda:0')\n",
      "tensor([[-0.0273],\n",
      "        [ 0.0073],\n",
      "        [-0.0101],\n",
      "        [-0.0072],\n",
      "        [-0.0671],\n",
      "        [ 0.0794],\n",
      "        [-0.0540],\n",
      "        [ 0.0091],\n",
      "        [-0.0256],\n",
      "        [-0.0289],\n",
      "        [ 0.0258],\n",
      "        [ 0.0789],\n",
      "        [ 0.1076],\n",
      "        [-0.0113],\n",
      "        [ 0.0129],\n",
      "        [-0.0210],\n",
      "        [-0.0576],\n",
      "        [-0.0266],\n",
      "        [-0.0034],\n",
      "        [-0.0981],\n",
      "        [-0.0579],\n",
      "        [-0.0830],\n",
      "        [-0.0034],\n",
      "        [-0.0177],\n",
      "        [-0.0200],\n",
      "        [-0.0095],\n",
      "        [ 0.0043],\n",
      "        [-0.0090],\n",
      "        [-0.0338],\n",
      "        [ 0.0460],\n",
      "        [ 0.0299],\n",
      "        [ 0.0070]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0105, 0.0100, 0.0100, 0.0104, 0.0108, 0.0113, 0.0117, 0.0116, 0.0111,\n",
      "        0.0114, 0.0112, 0.0112, 0.0110, 0.0110, 0.0107, 0.0107, 0.0107, 0.0112,\n",
      "        0.0112, 0.0111, 0.0112, 0.0111, 0.0112, 0.0116, 0.0118, 0.0122, 0.0127,\n",
      "        0.0133, 0.0128, 0.0129, 0.0127, 0.0130], device='cuda:0')\n",
      "tensor([[ 0.0632],\n",
      "        [-0.0404],\n",
      "        [ 0.0150],\n",
      "        [ 0.0178],\n",
      "        [-0.0259],\n",
      "        [-0.0167],\n",
      "        [ 0.0755],\n",
      "        [ 0.0108],\n",
      "        [ 0.0087],\n",
      "        [-0.0498],\n",
      "        [ 0.0288],\n",
      "        [ 0.0448],\n",
      "        [-0.0672],\n",
      "        [-0.0856],\n",
      "        [-0.0357],\n",
      "        [-0.0390],\n",
      "        [-0.0923],\n",
      "        [ 0.0075],\n",
      "        [-0.0406],\n",
      "        [-0.0553],\n",
      "        [-0.0624],\n",
      "        [-0.0504],\n",
      "        [ 0.0224],\n",
      "        [-0.0416],\n",
      "        [-0.0614],\n",
      "        [-0.0514],\n",
      "        [-0.0117],\n",
      "        [ 0.0101],\n",
      "        [ 0.0103],\n",
      "        [-0.0036],\n",
      "        [-0.0584],\n",
      "        [-0.0482]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0140, 0.0143, 0.0145, 0.0144, 0.0161, 0.0154, 0.0156, 0.0155, 0.0149,\n",
      "        0.0152, 0.0153, 0.0151, 0.0147, 0.0144, 0.0137, 0.0140, 0.0149, 0.0148,\n",
      "        0.0147, 0.0145, 0.0145, 0.0145, 0.0147, 0.0149, 0.0151, 0.0156, 0.0157,\n",
      "        0.0156, 0.0156, 0.0156, 0.0157, 0.0158], device='cuda:0')\n",
      "tensor([[-0.0092],\n",
      "        [ 0.0143],\n",
      "        [-0.0057],\n",
      "        [-0.0165],\n",
      "        [-0.0472],\n",
      "        [ 0.0410],\n",
      "        [ 0.0786],\n",
      "        [ 0.0010],\n",
      "        [ 0.0137],\n",
      "        [ 0.0089],\n",
      "        [ 0.0035],\n",
      "        [-0.0114],\n",
      "        [ 0.0240],\n",
      "        [-0.0374],\n",
      "        [-0.0315],\n",
      "        [-0.0391],\n",
      "        [ 0.0267],\n",
      "        [ 0.0365],\n",
      "        [ 0.1080],\n",
      "        [ 0.0034],\n",
      "        [-0.0148],\n",
      "        [-0.0450],\n",
      "        [-0.0989],\n",
      "        [ 0.0153],\n",
      "        [ 0.0066],\n",
      "        [-0.0012],\n",
      "        [ 0.0027],\n",
      "        [ 0.0225],\n",
      "        [ 0.0054],\n",
      "        [ 0.0581],\n",
      "        [ 0.0400],\n",
      "        [-0.0424]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0166, 0.0170, 0.0164, 0.0166, 0.0163, 0.0162, 0.0159, 0.0162, 0.0165,\n",
      "        0.0165, 0.0165, 0.0170, 0.0176, 0.0178, 0.0175, 0.0175, 0.0172, 0.0171,\n",
      "        0.0169, 0.0173, 0.0174, 0.0177, 0.0178, 0.0178, 0.0182, 0.0182, 0.0184,\n",
      "        0.0184, 0.0183, 0.0178, 0.0175, 0.0176], device='cuda:0')\n",
      "tensor([[ 0.0873],\n",
      "        [-0.0330],\n",
      "        [ 0.0066],\n",
      "        [ 0.0384],\n",
      "        [-0.0817],\n",
      "        [-0.0552],\n",
      "        [-0.0507],\n",
      "        [ 0.0089],\n",
      "        [ 0.0038],\n",
      "        [-0.0468],\n",
      "        [-0.0078],\n",
      "        [-0.0228],\n",
      "        [-0.0182],\n",
      "        [-0.0006],\n",
      "        [-0.0427],\n",
      "        [-0.0290],\n",
      "        [-0.0338],\n",
      "        [-0.0463],\n",
      "        [-0.0381],\n",
      "        [-0.0588],\n",
      "        [ 0.0273],\n",
      "        [ 0.0027],\n",
      "        [-0.0109],\n",
      "        [ 0.0264],\n",
      "        [-0.0291],\n",
      "        [ 0.0040],\n",
      "        [-0.0175],\n",
      "        [-0.0070],\n",
      "        [-0.0192],\n",
      "        [-0.0156],\n",
      "        [-0.0143],\n",
      "        [ 0.0007]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0183, 0.0179, 0.0176, 0.0175, 0.0174, 0.0176, 0.0174, 0.0179, 0.0181,\n",
      "        0.0175, 0.0174, 0.0173, 0.0175, 0.0170, 0.0166, 0.0172, 0.0175, 0.0176,\n",
      "        0.0175, 0.0175, 0.0175, 0.0175, 0.0177, 0.0177, 0.0175, 0.0177, 0.0180,\n",
      "        0.0184, 0.0189, 0.0192, 0.0194, 0.0188], device='cuda:0')\n",
      "tensor([[ 0.0366],\n",
      "        [ 0.0173],\n",
      "        [-0.0506],\n",
      "        [ 0.0238],\n",
      "        [ 0.0144],\n",
      "        [-0.0182],\n",
      "        [-0.0201],\n",
      "        [-0.0984],\n",
      "        [-0.1383],\n",
      "        [ 0.0002],\n",
      "        [ 0.0640],\n",
      "        [ 0.0393],\n",
      "        [ 0.0760],\n",
      "        [ 0.0501],\n",
      "        [-0.0356],\n",
      "        [-0.0356],\n",
      "        [-0.0482],\n",
      "        [-0.0200],\n",
      "        [ 0.0072],\n",
      "        [ 0.0304],\n",
      "        [ 0.0416],\n",
      "        [ 0.0078],\n",
      "        [ 0.0164],\n",
      "        [ 0.0106],\n",
      "        [-0.0027],\n",
      "        [-0.0175],\n",
      "        [ 0.0047],\n",
      "        [-0.0121],\n",
      "        [-0.0479],\n",
      "        [-0.0239],\n",
      "        [-0.0170],\n",
      "        [-0.0005]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0187, 0.0182, 0.0185, 0.0180, 0.0182, 0.0177, 0.0171, 0.0173, 0.0170,\n",
      "        0.0177, 0.0175, 0.0176, 0.0179, 0.0182, 0.0185, 0.0187, 0.0183, 0.0185,\n",
      "        0.0186, 0.0184, 0.0186, 0.0186, 0.0184, 0.0183, 0.0183, 0.0186, 0.0188,\n",
      "        0.0191, 0.0194, 0.0192, 0.0191, 0.0187], device='cuda:0')\n",
      "tensor([[ 0.0563],\n",
      "        [ 0.1008],\n",
      "        [ 0.1667],\n",
      "        [-0.0347],\n",
      "        [-0.0283],\n",
      "        [-0.0455],\n",
      "        [-0.0992],\n",
      "        [-0.0957],\n",
      "        [-0.1150],\n",
      "        [-0.0126],\n",
      "        [-0.0405],\n",
      "        [ 0.0074],\n",
      "        [-0.0146],\n",
      "        [-0.0338],\n",
      "        [ 0.0705],\n",
      "        [ 0.0169],\n",
      "        [ 0.0357],\n",
      "        [-0.0440],\n",
      "        [-0.0465],\n",
      "        [-0.0157],\n",
      "        [-0.0428],\n",
      "        [ 0.0619],\n",
      "        [ 0.0033],\n",
      "        [-0.0650],\n",
      "        [-0.0373],\n",
      "        [-0.0056],\n",
      "        [ 0.0185],\n",
      "        [ 0.0003],\n",
      "        [-0.0712],\n",
      "        [-0.0093],\n",
      "        [ 0.0027],\n",
      "        [ 0.0223]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0186, 0.0179, 0.0183, 0.0184, 0.0184, 0.0180, 0.0179, 0.0178, 0.0177,\n",
      "        0.0172, 0.0171, 0.0170, 0.0173, 0.0171, 0.0171, 0.0169, 0.0157, 0.0162,\n",
      "        0.0157, 0.0161, 0.0161, 0.0158, 0.0160, 0.0164, 0.0159, 0.0160, 0.0160,\n",
      "        0.0156, 0.0149, 0.0153, 0.0150, 0.0145], device='cuda:0')\n",
      "tensor([[-0.0622],\n",
      "        [-0.0487],\n",
      "        [-0.0360],\n",
      "        [-0.0702],\n",
      "        [ 0.0120],\n",
      "        [ 0.0319],\n",
      "        [-0.0404],\n",
      "        [-0.0102],\n",
      "        [ 0.0074],\n",
      "        [ 0.0015],\n",
      "        [ 0.0248],\n",
      "        [ 0.0208],\n",
      "        [ 0.0549],\n",
      "        [-0.0322],\n",
      "        [-0.0262],\n",
      "        [-0.0662],\n",
      "        [-0.1213],\n",
      "        [ 0.0117],\n",
      "        [ 0.0476],\n",
      "        [-0.0074],\n",
      "        [ 0.0082],\n",
      "        [-0.0098],\n",
      "        [-0.0283],\n",
      "        [-0.0394],\n",
      "        [-0.0180],\n",
      "        [-0.0536],\n",
      "        [ 0.0845],\n",
      "        [ 0.0454],\n",
      "        [ 0.0399],\n",
      "        [-0.0248],\n",
      "        [-0.0368],\n",
      "        [-0.0256]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0144, 0.0146, 0.0152, 0.0154, 0.0154, 0.0155, 0.0157, 0.0157, 0.0154,\n",
      "        0.0150, 0.0143, 0.0142, 0.0132, 0.0135, 0.0143, 0.0149, 0.0142, 0.0143,\n",
      "        0.0142, 0.0146, 0.0147, 0.0153, 0.0150, 0.0152, 0.0151, 0.0150, 0.0148,\n",
      "        0.0146, 0.0142, 0.0142, 0.0145, 0.0147], device='cuda:0')\n",
      "tensor([[-0.0474],\n",
      "        [-0.0870],\n",
      "        [ 0.0620],\n",
      "        [-0.0015],\n",
      "        [-0.0312],\n",
      "        [-0.0103],\n",
      "        [-0.0316],\n",
      "        [ 0.0220],\n",
      "        [-0.0158],\n",
      "        [ 0.0114],\n",
      "        [-0.0097],\n",
      "        [ 0.0227],\n",
      "        [ 0.0191],\n",
      "        [ 0.0016],\n",
      "        [ 0.0474],\n",
      "        [ 0.0327],\n",
      "        [-0.0310],\n",
      "        [-0.0573],\n",
      "        [ 0.0080],\n",
      "        [-0.0245],\n",
      "        [-0.0424],\n",
      "        [ 0.0172],\n",
      "        [ 0.0070],\n",
      "        [-0.0474],\n",
      "        [ 0.0007],\n",
      "        [-0.0220],\n",
      "        [ 0.0009],\n",
      "        [ 0.0084],\n",
      "        [ 0.1076],\n",
      "        [-0.0021],\n",
      "        [ 0.0961],\n",
      "        [-0.0137]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0144, 0.0139, 0.0139, 0.0142, 0.0147, 0.0144, 0.0141, 0.0141, 0.0140,\n",
      "        0.0139, 0.0134, 0.0135, 0.0137, 0.0138, 0.0138, 0.0136, 0.0136, 0.0137,\n",
      "        0.0137, 0.0137, 0.0137, 0.0137, 0.0138, 0.0143, 0.0147, 0.0147, 0.0139,\n",
      "        0.0139, 0.0142, 0.0140, 0.0137, 0.0136], device='cuda:0')\n",
      "tensor([[ 0.0064],\n",
      "        [-0.0485],\n",
      "        [-0.0801],\n",
      "        [ 0.0797],\n",
      "        [-0.0241],\n",
      "        [-0.0190],\n",
      "        [ 0.0101],\n",
      "        [ 0.0097],\n",
      "        [-0.0645],\n",
      "        [-0.0338],\n",
      "        [ 0.0054],\n",
      "        [-0.0610],\n",
      "        [ 0.0175],\n",
      "        [-0.0557],\n",
      "        [-0.0475],\n",
      "        [-0.0215],\n",
      "        [-0.0023],\n",
      "        [ 0.0350],\n",
      "        [-0.0254],\n",
      "        [ 0.0184],\n",
      "        [ 0.0223],\n",
      "        [ 0.0142],\n",
      "        [ 0.0063],\n",
      "        [-0.0056],\n",
      "        [-0.0252],\n",
      "        [ 0.0125],\n",
      "        [-0.0086],\n",
      "        [-0.0169],\n",
      "        [ 0.0126],\n",
      "        [-0.0150],\n",
      "        [-0.0617],\n",
      "        [-0.0071]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0135, 0.0132, 0.0128, 0.0128, 0.0132, 0.0136, 0.0135, 0.0128, 0.0128,\n",
      "        0.0129, 0.0133, 0.0131, 0.0131, 0.0131, 0.0132, 0.0134, 0.0134, 0.0133,\n",
      "        0.0131, 0.0133, 0.0132, 0.0130, 0.0131, 0.0130, 0.0126, 0.0125, 0.0129,\n",
      "        0.0136, 0.0142, 0.0140, 0.0140, 0.0141], device='cuda:0')\n",
      "tensor([[-0.0356],\n",
      "        [ 0.0337],\n",
      "        [-0.0255],\n",
      "        [ 0.0418],\n",
      "        [ 0.0269],\n",
      "        [ 0.0375],\n",
      "        [-0.0032],\n",
      "        [ 0.1032],\n",
      "        [ 0.1085],\n",
      "        [ 0.0497],\n",
      "        [ 0.0391],\n",
      "        [ 0.0461],\n",
      "        [-0.0079],\n",
      "        [-0.0182],\n",
      "        [-0.0178],\n",
      "        [-0.0296],\n",
      "        [ 0.0118],\n",
      "        [-0.0391],\n",
      "        [-0.0194],\n",
      "        [-0.0394],\n",
      "        [-0.0747],\n",
      "        [ 0.0272],\n",
      "        [-0.0756],\n",
      "        [ 0.0132],\n",
      "        [ 0.0305],\n",
      "        [ 0.0130],\n",
      "        [-0.0338],\n",
      "        [-0.0686],\n",
      "        [-0.1359],\n",
      "        [-0.0579],\n",
      "        [-0.0032],\n",
      "        [-0.0154]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0144, 0.0150, 0.0154, 0.0157, 0.0157, 0.0156, 0.0159, 0.0158, 0.0156,\n",
      "        0.0160, 0.0161, 0.0160, 0.0158, 0.0157, 0.0155, 0.0161, 0.0158, 0.0154,\n",
      "        0.0159, 0.0153, 0.0154, 0.0154, 0.0148, 0.0146, 0.0148, 0.0156, 0.0160,\n",
      "        0.0160, 0.0161, 0.0165, 0.0166, 0.0166], device='cuda:0')\n",
      "tensor([[-0.0222],\n",
      "        [ 0.0766],\n",
      "        [-0.0436],\n",
      "        [-0.0199],\n",
      "        [ 0.0187],\n",
      "        [ 0.0050],\n",
      "        [-0.0076],\n",
      "        [-0.0088],\n",
      "        [-0.0125],\n",
      "        [-0.0157],\n",
      "        [-0.0530],\n",
      "        [ 0.0019],\n",
      "        [ 0.0070],\n",
      "        [ 0.0413],\n",
      "        [ 0.0124],\n",
      "        [ 0.0042],\n",
      "        [ 0.0156],\n",
      "        [-0.0201],\n",
      "        [ 0.0064],\n",
      "        [ 0.0134],\n",
      "        [-0.0430],\n",
      "        [-0.0273],\n",
      "        [ 0.0083],\n",
      "        [ 0.1084],\n",
      "        [ 0.0316],\n",
      "        [ 0.0274],\n",
      "        [ 0.0277],\n",
      "        [-0.0485],\n",
      "        [-0.0452],\n",
      "        [-0.0340],\n",
      "        [-0.0054],\n",
      "        [-0.0537]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0166, 0.0164, 0.0161, 0.0163, 0.0165, 0.0170, 0.0167, 0.0169, 0.0173,\n",
      "        0.0175, 0.0173, 0.0172, 0.0173, 0.0172, 0.0172, 0.0170, 0.0169, 0.0166,\n",
      "        0.0161, 0.0165, 0.0165, 0.0165, 0.0166, 0.0167, 0.0169, 0.0167, 0.0166,\n",
      "        0.0168, 0.0177, 0.0177, 0.0179, 0.0179], device='cuda:0')\n",
      "tensor([[-0.0378],\n",
      "        [ 0.0560],\n",
      "        [ 0.0072],\n",
      "        [ 0.0406],\n",
      "        [ 0.0464],\n",
      "        [ 0.0291],\n",
      "        [-0.0176],\n",
      "        [ 0.0114],\n",
      "        [-0.0019],\n",
      "        [ 0.0118],\n",
      "        [-0.0383],\n",
      "        [-0.0476],\n",
      "        [-0.0685],\n",
      "        [-0.0054],\n",
      "        [-0.0211],\n",
      "        [-0.0075],\n",
      "        [ 0.0047],\n",
      "        [ 0.0099],\n",
      "        [-0.0184],\n",
      "        [-0.0573],\n",
      "        [-0.0665],\n",
      "        [-0.0729],\n",
      "        [ 0.0508],\n",
      "        [-0.0483],\n",
      "        [ 0.0303],\n",
      "        [ 0.0414],\n",
      "        [-0.0572],\n",
      "        [-0.0582],\n",
      "        [ 0.0615],\n",
      "        [-0.0808],\n",
      "        [-0.0836],\n",
      "        [-0.1142]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0179, 0.0184, 0.0184, 0.0182, 0.0185, 0.0185, 0.0184, 0.0184, 0.0184,\n",
      "        0.0185, 0.0189, 0.0188, 0.0189, 0.0189, 0.0193, 0.0189, 0.0184, 0.0185,\n",
      "        0.0189, 0.0188, 0.0186, 0.0181, 0.0182, 0.0184, 0.0180, 0.0176, 0.0169,\n",
      "        0.0178, 0.0175, 0.0175, 0.0184, 0.0176], device='cuda:0')\n",
      "tensor([[-0.0185],\n",
      "        [ 0.0131],\n",
      "        [-0.0241],\n",
      "        [-0.0047],\n",
      "        [-0.0108],\n",
      "        [-0.0130],\n",
      "        [ 0.0072],\n",
      "        [-0.0268],\n",
      "        [ 0.0016],\n",
      "        [ 0.0098],\n",
      "        [ 0.0525],\n",
      "        [-0.0109],\n",
      "        [-0.0232],\n",
      "        [ 0.0999],\n",
      "        [ 0.0022],\n",
      "        [-0.0298],\n",
      "        [-0.0065],\n",
      "        [ 0.0222],\n",
      "        [ 0.0180],\n",
      "        [-0.0273],\n",
      "        [ 0.0131],\n",
      "        [ 0.0278],\n",
      "        [ 0.0848],\n",
      "        [-0.1216],\n",
      "        [-0.0507],\n",
      "        [-0.0198],\n",
      "        [ 0.0618],\n",
      "        [ 0.0547],\n",
      "        [ 0.0512],\n",
      "        [-0.0079],\n",
      "        [ 0.0144],\n",
      "        [-0.0227]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0181, 0.0178, 0.0181, 0.0180, 0.0176, 0.0168, 0.0164, 0.0165, 0.0163,\n",
      "        0.0168, 0.0167, 0.0172, 0.0171, 0.0170, 0.0168, 0.0167, 0.0166, 0.0159,\n",
      "        0.0156, 0.0162, 0.0168, 0.0170, 0.0173, 0.0170, 0.0168, 0.0175, 0.0177,\n",
      "        0.0175, 0.0174, 0.0177, 0.0179, 0.0181], device='cuda:0')\n",
      "tensor([[ 0.0009],\n",
      "        [-0.0387],\n",
      "        [-0.0254],\n",
      "        [-0.0041],\n",
      "        [-0.0248],\n",
      "        [-0.0024],\n",
      "        [-0.0580],\n",
      "        [-0.0504],\n",
      "        [-0.0612],\n",
      "        [ 0.0950],\n",
      "        [ 0.0275],\n",
      "        [-0.0359],\n",
      "        [-0.0212],\n",
      "        [ 0.0333],\n",
      "        [-0.0111],\n",
      "        [-0.0129],\n",
      "        [ 0.0134],\n",
      "        [-0.0471],\n",
      "        [-0.0115],\n",
      "        [ 0.0152],\n",
      "        [ 0.0049],\n",
      "        [-0.0405],\n",
      "        [-0.0195],\n",
      "        [ 0.0140],\n",
      "        [-0.0423],\n",
      "        [-0.0093],\n",
      "        [-0.0283],\n",
      "        [-0.0193],\n",
      "        [-0.0581],\n",
      "        [-0.0802],\n",
      "        [-0.0757],\n",
      "        [ 0.0035]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0181, 0.0174, 0.0172, 0.0170, 0.0174, 0.0174, 0.0173, 0.0178, 0.0182,\n",
      "        0.0184, 0.0182, 0.0185, 0.0189, 0.0186, 0.0188, 0.0188, 0.0187, 0.0188,\n",
      "        0.0193, 0.0195, 0.0195, 0.0194, 0.0195, 0.0193, 0.0195, 0.0197, 0.0202,\n",
      "        0.0200, 0.0200, 0.0201, 0.0201, 0.0200], device='cuda:0')\n",
      "tensor([[-2.7071e-03],\n",
      "        [ 4.7846e-02],\n",
      "        [-7.3622e-03],\n",
      "        [ 3.6107e-03],\n",
      "        [-3.2934e-02],\n",
      "        [-1.7827e-03],\n",
      "        [-2.0086e-02],\n",
      "        [-1.9125e-02],\n",
      "        [-1.4543e-03],\n",
      "        [-2.4849e-03],\n",
      "        [-3.1832e-02],\n",
      "        [-2.2556e-02],\n",
      "        [-2.4106e-02],\n",
      "        [ 8.9271e-03],\n",
      "        [-2.4022e-03],\n",
      "        [-5.8299e-02],\n",
      "        [-2.0607e-03],\n",
      "        [-1.2161e-02],\n",
      "        [-2.4954e-02],\n",
      "        [ 2.9845e-02],\n",
      "        [-6.6955e-05],\n",
      "        [ 2.5964e-02],\n",
      "        [-1.6977e-02],\n",
      "        [ 1.8000e-02],\n",
      "        [-4.4066e-02],\n",
      "        [ 4.0651e-02],\n",
      "        [ 1.0730e-01],\n",
      "        [-6.6251e-02],\n",
      "        [-5.5623e-02],\n",
      "        [ 1.6761e-02],\n",
      "        [ 1.2592e-02],\n",
      "        [-2.1259e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0201, 0.0202, 0.0204, 0.0203, 0.0202, 0.0204, 0.0204, 0.0210, 0.0208,\n",
      "        0.0208, 0.0210, 0.0213, 0.0210, 0.0212, 0.0214, 0.0213, 0.0210, 0.0213,\n",
      "        0.0211, 0.0210, 0.0211, 0.0206, 0.0208, 0.0210, 0.0212, 0.0210, 0.0213,\n",
      "        0.0216, 0.0213, 0.0213, 0.0213, 0.0215], device='cuda:0')\n",
      "tensor([[ 0.0211],\n",
      "        [-0.0574],\n",
      "        [ 0.0054],\n",
      "        [-0.0099],\n",
      "        [ 0.0131],\n",
      "        [-0.0209],\n",
      "        [-0.0088],\n",
      "        [-0.0576],\n",
      "        [-0.0272],\n",
      "        [ 0.0266],\n",
      "        [ 0.0144],\n",
      "        [ 0.0238],\n",
      "        [ 0.0083],\n",
      "        [-0.0124],\n",
      "        [ 0.0219],\n",
      "        [-0.0180],\n",
      "        [-0.0128],\n",
      "        [-0.0126],\n",
      "        [-0.0001],\n",
      "        [ 0.0190],\n",
      "        [-0.0326],\n",
      "        [-0.0293],\n",
      "        [-0.0240],\n",
      "        [-0.0276],\n",
      "        [-0.0178],\n",
      "        [ 0.0025],\n",
      "        [ 0.0140],\n",
      "        [-0.0047],\n",
      "        [ 0.0044],\n",
      "        [-0.0117],\n",
      "        [ 0.0536],\n",
      "        [ 0.1040]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0217, 0.0218, 0.0223, 0.0223, 0.0224, 0.0223, 0.0220, 0.0225, 0.0226,\n",
      "        0.0227, 0.0227, 0.0228, 0.0230, 0.0230, 0.0231, 0.0226, 0.0227, 0.0228,\n",
      "        0.0231, 0.0231, 0.0235, 0.0237, 0.0234, 0.0234, 0.0233, 0.0229, 0.0229,\n",
      "        0.0229, 0.0223, 0.0221, 0.0213, 0.0202], device='cuda:0')\n",
      "tensor([[-0.1007],\n",
      "        [-0.0484],\n",
      "        [ 0.0099],\n",
      "        [ 0.0118],\n",
      "        [ 0.0797],\n",
      "        [ 0.0128],\n",
      "        [-0.0510],\n",
      "        [ 0.0153],\n",
      "        [-0.0296],\n",
      "        [-0.0391],\n",
      "        [ 0.0904],\n",
      "        [ 0.0577],\n",
      "        [-0.0090],\n",
      "        [-0.0042],\n",
      "        [-0.0271],\n",
      "        [-0.0555],\n",
      "        [-0.0536],\n",
      "        [-0.0157],\n",
      "        [ 0.0162],\n",
      "        [-0.0127],\n",
      "        [ 0.0063],\n",
      "        [ 0.0123],\n",
      "        [-0.0022],\n",
      "        [ 0.0032],\n",
      "        [ 0.0075],\n",
      "        [-0.0356],\n",
      "        [-0.0376],\n",
      "        [ 0.0159],\n",
      "        [-0.0235],\n",
      "        [-0.0033],\n",
      "        [ 0.0203],\n",
      "        [ 0.0618]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0206, 0.0202, 0.0208, 0.0210, 0.0213, 0.0215, 0.0214, 0.0206, 0.0197,\n",
      "        0.0200, 0.0200, 0.0202, 0.0206, 0.0205, 0.0200, 0.0201, 0.0203, 0.0199,\n",
      "        0.0201, 0.0200, 0.0196, 0.0195, 0.0197, 0.0199, 0.0199, 0.0198, 0.0199,\n",
      "        0.0197, 0.0200, 0.0198, 0.0195, 0.0188], device='cuda:0')\n",
      "tensor([[-0.0525],\n",
      "        [-0.0102],\n",
      "        [-0.0088],\n",
      "        [ 0.0094],\n",
      "        [ 0.1106],\n",
      "        [-0.0280],\n",
      "        [ 0.0551],\n",
      "        [ 0.0137],\n",
      "        [-0.0454],\n",
      "        [ 0.0844],\n",
      "        [ 0.0917],\n",
      "        [ 0.0064],\n",
      "        [-0.0134],\n",
      "        [-0.0120],\n",
      "        [-0.0592],\n",
      "        [-0.0534],\n",
      "        [ 0.0020],\n",
      "        [-0.0167],\n",
      "        [-0.0045],\n",
      "        [-0.0352],\n",
      "        [ 0.0037],\n",
      "        [-0.0661],\n",
      "        [ 0.0911],\n",
      "        [ 0.0181],\n",
      "        [-0.0503],\n",
      "        [-0.0434],\n",
      "        [-0.0162],\n",
      "        [-0.1256],\n",
      "        [-0.0925],\n",
      "        [-0.0353],\n",
      "        [-0.0928],\n",
      "        [-0.0023]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0184, 0.0188, 0.0194, 0.0196, 0.0208, 0.0206, 0.0203, 0.0199, 0.0198,\n",
      "        0.0195, 0.0193, 0.0198, 0.0199, 0.0203, 0.0207, 0.0211, 0.0214, 0.0220,\n",
      "        0.0216, 0.0211, 0.0215, 0.0212, 0.0211, 0.0209, 0.0206, 0.0206, 0.0210,\n",
      "        0.0213, 0.0205, 0.0201, 0.0203, 0.0204], device='cuda:0')\n",
      "tensor([[-3.8448e-02],\n",
      "        [ 4.0895e-02],\n",
      "        [ 8.7030e-03],\n",
      "        [ 2.3160e-02],\n",
      "        [ 3.0735e-02],\n",
      "        [-9.9871e-02],\n",
      "        [ 4.2819e-02],\n",
      "        [-1.8580e-03],\n",
      "        [-1.3835e-02],\n",
      "        [-9.1520e-03],\n",
      "        [-4.1078e-02],\n",
      "        [-1.4215e-02],\n",
      "        [-5.8052e-02],\n",
      "        [ 1.5761e-02],\n",
      "        [ 2.1668e-02],\n",
      "        [-1.1524e-02],\n",
      "        [ 1.7880e-02],\n",
      "        [-3.3010e-05],\n",
      "        [-2.1781e-02],\n",
      "        [ 8.5764e-02],\n",
      "        [-1.6766e-02],\n",
      "        [-4.7276e-03],\n",
      "        [-2.2183e-03],\n",
      "        [-3.8962e-02],\n",
      "        [-1.5009e-02],\n",
      "        [-2.3735e-02],\n",
      "        [-6.4079e-03],\n",
      "        [-2.2969e-02],\n",
      "        [ 2.5226e-02],\n",
      "        [-6.7644e-03],\n",
      "        [-1.8257e-02],\n",
      "        [-4.5330e-04]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0199, 0.0199, 0.0206, 0.0204, 0.0201, 0.0201, 0.0200, 0.0203, 0.0201,\n",
      "        0.0200, 0.0208, 0.0210, 0.0210, 0.0214, 0.0221, 0.0217, 0.0216, 0.0210,\n",
      "        0.0213, 0.0217, 0.0220, 0.0224, 0.0225, 0.0232, 0.0240, 0.0232, 0.0234,\n",
      "        0.0248, 0.0243, 0.0238, 0.0236, 0.0239], device='cuda:0')\n",
      "tensor([[ 0.0203],\n",
      "        [ 0.0199],\n",
      "        [-0.0110],\n",
      "        [-0.0139],\n",
      "        [-0.0430],\n",
      "        [-0.0774],\n",
      "        [-0.0364],\n",
      "        [-0.0427],\n",
      "        [-0.0118],\n",
      "        [ 0.0056],\n",
      "        [-0.0204],\n",
      "        [-0.0144],\n",
      "        [ 0.0278],\n",
      "        [-0.0022],\n",
      "        [ 0.0205],\n",
      "        [ 0.0526],\n",
      "        [-0.0058],\n",
      "        [-0.1064],\n",
      "        [-0.1111],\n",
      "        [-0.0658],\n",
      "        [-0.0759],\n",
      "        [-0.0826],\n",
      "        [-0.0038],\n",
      "        [-0.0681],\n",
      "        [-0.0307],\n",
      "        [-0.0142],\n",
      "        [-0.0537],\n",
      "        [ 0.0004],\n",
      "        [-0.0498],\n",
      "        [ 0.0466],\n",
      "        [-0.0179],\n",
      "        [ 0.0026]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0244, 0.0244, 0.0233, 0.0244, 0.0249, 0.0244, 0.0246, 0.0248, 0.0246,\n",
      "        0.0239, 0.0231, 0.0225, 0.0217, 0.0220, 0.0225, 0.0220, 0.0216, 0.0217,\n",
      "        0.0214, 0.0224, 0.0235, 0.0233, 0.0242, 0.0248, 0.0245, 0.0246, 0.0245,\n",
      "        0.0236, 0.0226, 0.0217, 0.0213, 0.0205], device='cuda:0')\n",
      "tensor([[-0.0279],\n",
      "        [ 0.0570],\n",
      "        [ 0.0870],\n",
      "        [-0.0717],\n",
      "        [-0.1281],\n",
      "        [-0.0996],\n",
      "        [ 0.0306],\n",
      "        [-0.0217],\n",
      "        [-0.0306],\n",
      "        [-0.0174],\n",
      "        [ 0.0175],\n",
      "        [ 0.0192],\n",
      "        [-0.0050],\n",
      "        [-0.0198],\n",
      "        [ 0.0535],\n",
      "        [-0.0463],\n",
      "        [ 0.0609],\n",
      "        [ 0.0383],\n",
      "        [-0.0133],\n",
      "        [ 0.0135],\n",
      "        [-0.0512],\n",
      "        [-0.0056],\n",
      "        [-0.0351],\n",
      "        [ 0.0205],\n",
      "        [ 0.0211],\n",
      "        [ 0.0112],\n",
      "        [ 0.0450],\n",
      "        [ 0.0051],\n",
      "        [ 0.0096],\n",
      "        [ 0.0154],\n",
      "        [-0.0280],\n",
      "        [-0.0692]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0202, 0.0208, 0.0219, 0.0219, 0.0215, 0.0216, 0.0212, 0.0216, 0.0229,\n",
      "        0.0235, 0.0236, 0.0235, 0.0228, 0.0226, 0.0221, 0.0222, 0.0218, 0.0221,\n",
      "        0.0226, 0.0225, 0.0230, 0.0234, 0.0229, 0.0228, 0.0228, 0.0222, 0.0226,\n",
      "        0.0230, 0.0230, 0.0224, 0.0220, 0.0226], device='cuda:0')\n",
      "tensor([[-0.0042],\n",
      "        [-0.0332],\n",
      "        [-0.0325],\n",
      "        [-0.0147],\n",
      "        [-0.0078],\n",
      "        [-0.0535],\n",
      "        [-0.0716],\n",
      "        [ 0.0232],\n",
      "        [ 0.0059],\n",
      "        [ 0.0009],\n",
      "        [-0.0609],\n",
      "        [-0.0261],\n",
      "        [-0.0554],\n",
      "        [ 0.0134],\n",
      "        [ 0.0289],\n",
      "        [ 0.0014],\n",
      "        [ 0.0273],\n",
      "        [-0.0682],\n",
      "        [ 0.0259],\n",
      "        [ 0.0190],\n",
      "        [ 0.0302],\n",
      "        [ 0.0470],\n",
      "        [ 0.0194],\n",
      "        [-0.0098],\n",
      "        [-0.0186],\n",
      "        [ 0.0071],\n",
      "        [-0.0864],\n",
      "        [ 0.0775],\n",
      "        [-0.0600],\n",
      "        [ 0.0252],\n",
      "        [ 0.0183],\n",
      "        [ 0.0202]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0226, 0.0218, 0.0217, 0.0219, 0.0213, 0.0210, 0.0199, 0.0200, 0.0206,\n",
      "        0.0213, 0.0212, 0.0212, 0.0209, 0.0206, 0.0209, 0.0220, 0.0218, 0.0213,\n",
      "        0.0211, 0.0203, 0.0203, 0.0196, 0.0196, 0.0195, 0.0190, 0.0179, 0.0170,\n",
      "        0.0184, 0.0186, 0.0186, 0.0185, 0.0182], device='cuda:0')\n",
      "tensor([[ 0.0213],\n",
      "        [ 0.0130],\n",
      "        [-0.0523],\n",
      "        [ 0.0106],\n",
      "        [-0.0403],\n",
      "        [-0.0442],\n",
      "        [ 0.0270],\n",
      "        [ 0.0064],\n",
      "        [-0.0064],\n",
      "        [-0.0212],\n",
      "        [ 0.0471],\n",
      "        [ 0.0761],\n",
      "        [ 0.0139],\n",
      "        [ 0.0380],\n",
      "        [ 0.0104],\n",
      "        [ 0.0063],\n",
      "        [-0.0572],\n",
      "        [-0.0911],\n",
      "        [-0.0178],\n",
      "        [-0.0159],\n",
      "        [-0.0156],\n",
      "        [-0.0292],\n",
      "        [ 0.0028],\n",
      "        [-0.1082],\n",
      "        [ 0.0752],\n",
      "        [-0.0411],\n",
      "        [-0.0074],\n",
      "        [ 0.1203],\n",
      "        [-0.0025],\n",
      "        [-0.0498],\n",
      "        [-0.0145],\n",
      "        [ 0.1031]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0179, 0.0172, 0.0179, 0.0186, 0.0184, 0.0189, 0.0203, 0.0196, 0.0196,\n",
      "        0.0188, 0.0180, 0.0184, 0.0184, 0.0193, 0.0194, 0.0184, 0.0180, 0.0182,\n",
      "        0.0174, 0.0173, 0.0173, 0.0168, 0.0153, 0.0172, 0.0167, 0.0177, 0.0182,\n",
      "        0.0180, 0.0181, 0.0191, 0.0182, 0.0183], device='cuda:0')\n",
      "tensor([[ 0.1030],\n",
      "        [-0.0841],\n",
      "        [ 0.0644],\n",
      "        [-0.0564],\n",
      "        [ 0.0319],\n",
      "        [ 0.0150],\n",
      "        [ 0.0102],\n",
      "        [-0.0405],\n",
      "        [ 0.0232],\n",
      "        [-0.0007],\n",
      "        [-0.0024],\n",
      "        [ 0.0145],\n",
      "        [-0.0183],\n",
      "        [ 0.0079],\n",
      "        [-0.0157],\n",
      "        [-0.0164],\n",
      "        [ 0.0101],\n",
      "        [-0.0185],\n",
      "        [-0.0460],\n",
      "        [-0.0149],\n",
      "        [-0.0319],\n",
      "        [-0.0120],\n",
      "        [-0.0524],\n",
      "        [-0.0155],\n",
      "        [-0.0335],\n",
      "        [-0.0569],\n",
      "        [-0.0108],\n",
      "        [ 0.0160],\n",
      "        [-0.0695],\n",
      "        [ 0.0102],\n",
      "        [-0.0349],\n",
      "        [ 0.1229]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0188, 0.0188, 0.0196, 0.0196, 0.0201, 0.0203, 0.0199, 0.0209, 0.0214,\n",
      "        0.0213, 0.0216, 0.0219, 0.0220, 0.0224, 0.0223, 0.0220, 0.0224, 0.0231,\n",
      "        0.0229, 0.0226, 0.0218, 0.0218, 0.0228, 0.0240, 0.0245, 0.0248, 0.0251,\n",
      "        0.0244, 0.0241, 0.0247, 0.0251, 0.0258], device='cuda:0')\n",
      "tensor([[-0.0043],\n",
      "        [-0.0528],\n",
      "        [-0.0268],\n",
      "        [-0.0330],\n",
      "        [ 0.0032],\n",
      "        [ 0.0337],\n",
      "        [-0.0161],\n",
      "        [ 0.0029],\n",
      "        [-0.0229],\n",
      "        [-0.0082],\n",
      "        [-0.0762],\n",
      "        [-0.0376],\n",
      "        [ 0.0550],\n",
      "        [-0.0646],\n",
      "        [-0.1072],\n",
      "        [ 0.0361],\n",
      "        [-0.0577],\n",
      "        [-0.0084],\n",
      "        [ 0.0241],\n",
      "        [-0.0017],\n",
      "        [-0.0110],\n",
      "        [-0.0274],\n",
      "        [-0.0183],\n",
      "        [ 0.0104],\n",
      "        [-0.0057],\n",
      "        [-0.0138],\n",
      "        [ 0.0720],\n",
      "        [ 0.0281],\n",
      "        [ 0.0251],\n",
      "        [ 0.0680],\n",
      "        [-0.0481],\n",
      "        [-0.0011]], device='cuda:0', grad_fn=<AddmmBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([0.0260, 0.0252, 0.0257, 0.0259, 0.0258, 0.0248, 0.0246, 0.0244, 0.0248,\n",
      "        0.0247, 0.0244, 0.0241, 0.0239, 0.0241, 0.0243, 0.0246, 0.0243, 0.0238,\n",
      "        0.0242, 0.0254, 0.0263, 0.0267, 0.0273, 0.0270, 0.0275, 0.0261, 0.0265,\n",
      "        0.0269, 0.0268, 0.0268, 0.0277, 0.0279], device='cuda:0')\n",
      "tensor([[-0.0331],\n",
      "        [-0.0408],\n",
      "        [-0.0817],\n",
      "        [ 0.0402],\n",
      "        [-0.0002],\n",
      "        [ 0.0131],\n",
      "        [-0.0047],\n",
      "        [-0.0211],\n",
      "        [ 0.0002],\n",
      "        [-0.0146],\n",
      "        [ 0.0276],\n",
      "        [ 0.0374],\n",
      "        [ 0.0127],\n",
      "        [ 0.0029],\n",
      "        [ 0.0140],\n",
      "        [ 0.0019],\n",
      "        [-0.0047],\n",
      "        [-0.0153],\n",
      "        [ 0.0775],\n",
      "        [ 0.1188],\n",
      "        [ 0.0157],\n",
      "        [ 0.0255],\n",
      "        [-0.0082],\n",
      "        [ 0.0087],\n",
      "        [ 0.0019],\n",
      "        [-0.0009],\n",
      "        [-0.0321],\n",
      "        [ 0.0355],\n",
      "        [-0.0004],\n",
      "        [-0.0008],\n",
      "        [ 0.0213],\n",
      "        [ 0.0256]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0275, 0.0276, 0.0281, 0.0285, 0.0279, 0.0271, 0.0275, 0.0278, 0.0277,\n",
      "        0.0277, 0.0291, 0.0296, 0.0296, 0.0303, 0.0312, 0.0319, 0.0311, 0.0309,\n",
      "        0.0307, 0.0308, 0.0306, 0.0309, 0.0299, 0.0315, 0.0327, 0.0328, 0.0327,\n",
      "        0.0327, 0.0326, 0.0323, 0.0323, 0.0327], device='cuda:0')\n",
      "tensor([[-0.0268],\n",
      "        [-0.0076],\n",
      "        [-0.0184],\n",
      "        [-0.0352],\n",
      "        [-0.0032],\n",
      "        [-0.0041],\n",
      "        [ 0.0216],\n",
      "        [-0.0088],\n",
      "        [-0.0140],\n",
      "        [ 0.0277],\n",
      "        [ 0.0176],\n",
      "        [ 0.0099],\n",
      "        [ 0.0091],\n",
      "        [-0.0305],\n",
      "        [ 0.0329],\n",
      "        [ 0.0005],\n",
      "        [ 0.0088],\n",
      "        [ 0.0095],\n",
      "        [-0.0420],\n",
      "        [ 0.0718],\n",
      "        [ 0.0654],\n",
      "        [ 0.0020],\n",
      "        [-0.0022],\n",
      "        [ 0.0333],\n",
      "        [-0.0619],\n",
      "        [-0.0260],\n",
      "        [ 0.0126],\n",
      "        [-0.0315],\n",
      "        [-0.0260],\n",
      "        [-0.0479],\n",
      "        [ 0.0120],\n",
      "        [ 0.0472]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0328, 0.0321, 0.0329, 0.0339, 0.0339, 0.0332, 0.0332, 0.0332, 0.0345,\n",
      "        0.0352, 0.0348, 0.0347, 0.0347, 0.0340, 0.0327, 0.0328, 0.0332, 0.0343,\n",
      "        0.0335, 0.0328, 0.0339, 0.0335, 0.0346, 0.0349, 0.0348, 0.0351, 0.0359,\n",
      "        0.0361, 0.0360, 0.0366, 0.0376, 0.0373], device='cuda:0')\n",
      "tensor([[ 5.4533e-02],\n",
      "        [ 4.1530e-03],\n",
      "        [ 7.0996e-02],\n",
      "        [ 5.1682e-02],\n",
      "        [ 7.4675e-03],\n",
      "        [ 9.3331e-02],\n",
      "        [ 1.6708e-05],\n",
      "        [-2.1260e-02],\n",
      "        [-2.4451e-02],\n",
      "        [-4.3674e-02],\n",
      "        [-9.4127e-02],\n",
      "        [ 3.8818e-03],\n",
      "        [ 2.6063e-02],\n",
      "        [ 1.9250e-02],\n",
      "        [-7.2620e-02],\n",
      "        [-6.5404e-02],\n",
      "        [ 2.9560e-02],\n",
      "        [-2.3948e-02],\n",
      "        [-2.7129e-02],\n",
      "        [ 1.2961e-02],\n",
      "        [ 2.1582e-02],\n",
      "        [ 1.5090e-02],\n",
      "        [ 2.5311e-02],\n",
      "        [-6.0256e-02],\n",
      "        [-4.2919e-02],\n",
      "        [-3.6503e-02],\n",
      "        [-1.8510e-03],\n",
      "        [-2.4387e-02],\n",
      "        [-4.4066e-02],\n",
      "        [ 1.9876e-02],\n",
      "        [-3.6963e-02],\n",
      "        [ 1.8129e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0394, 0.0394, 0.0377, 0.0377, 0.0377, 0.0376, 0.0375, 0.0368, 0.0352,\n",
      "        0.0358, 0.0359, 0.0359, 0.0355, 0.0367, 0.0368, 0.0369, 0.0365, 0.0365,\n",
      "        0.0356, 0.0356, 0.0366, 0.0362, 0.0362, 0.0358, 0.0369, 0.0361, 0.0357,\n",
      "        0.0371, 0.0374, 0.0378, 0.0381, 0.0383], device='cuda:0')\n",
      "tensor([[ 0.0098],\n",
      "        [-0.0006],\n",
      "        [-0.0369],\n",
      "        [-0.0096],\n",
      "        [ 0.0321],\n",
      "        [ 0.0168],\n",
      "        [ 0.0798],\n",
      "        [-0.0111],\n",
      "        [ 0.0222],\n",
      "        [ 0.0010],\n",
      "        [-0.0258],\n",
      "        [-0.0272],\n",
      "        [-0.0344],\n",
      "        [-0.0168],\n",
      "        [ 0.0626],\n",
      "        [-0.0371],\n",
      "        [ 0.0047],\n",
      "        [ 0.0336],\n",
      "        [ 0.0919],\n",
      "        [ 0.0491],\n",
      "        [-0.0609],\n",
      "        [-0.0290],\n",
      "        [-0.0278],\n",
      "        [-0.0209],\n",
      "        [-0.0269],\n",
      "        [-0.0062],\n",
      "        [-0.0073],\n",
      "        [-0.0307],\n",
      "        [-0.0370],\n",
      "        [ 0.0333],\n",
      "        [-0.0178],\n",
      "        [-0.0351]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0388, 0.0397, 0.0397, 0.0397, 0.0395, 0.0395, 0.0394, 0.0394, 0.0400,\n",
      "        0.0410, 0.0402, 0.0397, 0.0397, 0.0395, 0.0397, 0.0400, 0.0399, 0.0399,\n",
      "        0.0402, 0.0405, 0.0401, 0.0402, 0.0401, 0.0402, 0.0401, 0.0393, 0.0395,\n",
      "        0.0396, 0.0392, 0.0387, 0.0397, 0.0404], device='cuda:0')\n",
      "tensor([[-0.0158],\n",
      "        [-0.0348],\n",
      "        [-0.0092],\n",
      "        [-0.0067],\n",
      "        [ 0.0039],\n",
      "        [ 0.0393],\n",
      "        [-0.0441],\n",
      "        [ 0.1298],\n",
      "        [ 0.0557],\n",
      "        [-0.0379],\n",
      "        [ 0.0021],\n",
      "        [ 0.0124],\n",
      "        [-0.0433],\n",
      "        [-0.0167],\n",
      "        [-0.0146],\n",
      "        [-0.0897],\n",
      "        [-0.1279],\n",
      "        [-0.0513],\n",
      "        [-0.0554],\n",
      "        [-0.0332],\n",
      "        [ 0.0200],\n",
      "        [-0.0288],\n",
      "        [-0.0220],\n",
      "        [-0.0240],\n",
      "        [-0.0199],\n",
      "        [-0.0626],\n",
      "        [-0.0516],\n",
      "        [-0.0140],\n",
      "        [ 0.0134],\n",
      "        [-0.0007],\n",
      "        [ 0.0093],\n",
      "        [ 0.0655]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0405, 0.0407, 0.0415, 0.0409, 0.0407, 0.0409, 0.0409, 0.0410, 0.0404,\n",
      "        0.0392, 0.0388, 0.0385, 0.0386, 0.0391, 0.0388, 0.0395, 0.0395, 0.0391,\n",
      "        0.0393, 0.0388, 0.0381, 0.0381, 0.0387, 0.0389, 0.0397, 0.0398, 0.0400,\n",
      "        0.0403, 0.0401, 0.0402, 0.0413, 0.0418], device='cuda:0')\n",
      "tensor([[-0.0697],\n",
      "        [-0.0573],\n",
      "        [ 0.0138],\n",
      "        [-0.0467],\n",
      "        [-0.0351],\n",
      "        [-0.0452],\n",
      "        [-0.0001],\n",
      "        [-0.0704],\n",
      "        [-0.0332],\n",
      "        [ 0.0307],\n",
      "        [-0.0677],\n",
      "        [-0.0286],\n",
      "        [ 0.0480],\n",
      "        [-0.0165],\n",
      "        [ 0.0498],\n",
      "        [ 0.0289],\n",
      "        [-0.0112],\n",
      "        [-0.0352],\n",
      "        [-0.1066],\n",
      "        [-0.0024],\n",
      "        [-0.0540],\n",
      "        [-0.0307],\n",
      "        [ 0.0028],\n",
      "        [ 0.0189],\n",
      "        [-0.0189],\n",
      "        [-0.0013],\n",
      "        [-0.0304],\n",
      "        [-0.0046],\n",
      "        [-0.0359],\n",
      "        [ 0.0189],\n",
      "        [-0.0678],\n",
      "        [-0.0088]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0418, 0.0411, 0.0411, 0.0414, 0.0418, 0.0414, 0.0446, 0.0448, 0.0460,\n",
      "        0.0451, 0.0454, 0.0457, 0.0455, 0.0448, 0.0456, 0.0456, 0.0478, 0.0478,\n",
      "        0.0482, 0.0480, 0.0492, 0.0492, 0.0499, 0.0496, 0.0487, 0.0498, 0.0506,\n",
      "        0.0513, 0.0505, 0.0504, 0.0503, 0.0509], device='cuda:0')\n",
      "tensor([[-0.0882],\n",
      "        [ 0.0066],\n",
      "        [-0.0108],\n",
      "        [ 0.0034],\n",
      "        [-0.0003],\n",
      "        [-0.0446],\n",
      "        [-0.0487],\n",
      "        [-0.0073],\n",
      "        [ 0.0211],\n",
      "        [-0.0788],\n",
      "        [ 0.0347],\n",
      "        [ 0.0655],\n",
      "        [-0.0874],\n",
      "        [-0.0524],\n",
      "        [-0.0391],\n",
      "        [ 0.0056],\n",
      "        [-0.0194],\n",
      "        [-0.0166],\n",
      "        [ 0.0113],\n",
      "        [ 0.0303],\n",
      "        [-0.0136],\n",
      "        [ 0.0732],\n",
      "        [ 0.0110],\n",
      "        [-0.0112],\n",
      "        [ 0.0044],\n",
      "        [-0.0037],\n",
      "        [-0.0089],\n",
      "        [-0.0297],\n",
      "        [-0.0023],\n",
      "        [-0.0014],\n",
      "        [ 0.0059],\n",
      "        [-0.0221]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0513, 0.0512, 0.0508, 0.0497, 0.0495, 0.0492, 0.0493, 0.0488, 0.0492,\n",
      "        0.0500, 0.0504, 0.0500, 0.0510, 0.0528, 0.0535, 0.0516, 0.0537, 0.0531,\n",
      "        0.0532, 0.0536, 0.0532, 0.0532, 0.0530, 0.0535, 0.0551, 0.0550, 0.0554,\n",
      "        0.0563, 0.0568, 0.0570, 0.0564, 0.0567], device='cuda:0')\n",
      "tensor([[ 0.0562],\n",
      "        [ 0.1260],\n",
      "        [-0.0325],\n",
      "        [-0.0286],\n",
      "        [ 0.0067],\n",
      "        [ 0.0080],\n",
      "        [-0.0881],\n",
      "        [ 0.0759],\n",
      "        [-0.0924],\n",
      "        [-0.0666],\n",
      "        [-0.0526],\n",
      "        [-0.0582],\n",
      "        [-0.0333],\n",
      "        [-0.0127],\n",
      "        [-0.0079],\n",
      "        [-0.0119],\n",
      "        [-0.0199],\n",
      "        [ 0.0275],\n",
      "        [-0.1126],\n",
      "        [ 0.0112],\n",
      "        [-0.0567],\n",
      "        [-0.0063],\n",
      "        [-0.0318],\n",
      "        [ 0.0133],\n",
      "        [-0.0289],\n",
      "        [-0.0032],\n",
      "        [-0.0400],\n",
      "        [-0.0272],\n",
      "        [ 0.0126],\n",
      "        [ 0.0187],\n",
      "        [ 0.0414],\n",
      "        [ 0.0252]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0572, 0.0560, 0.0537, 0.0536, 0.0545, 0.0542, 0.0532, 0.0535, 0.0545,\n",
      "        0.0545, 0.0548, 0.0532, 0.0523, 0.0502, 0.0508, 0.0513, 0.0514, 0.0520,\n",
      "        0.0526, 0.0535, 0.0543, 0.0535, 0.0535, 0.0541, 0.0541, 0.0524, 0.0543,\n",
      "        0.0532, 0.0536, 0.0538, 0.0533, 0.0527], device='cuda:0')\n",
      "tensor([[-3.8809e-02],\n",
      "        [-3.6690e-04],\n",
      "        [-6.0636e-02],\n",
      "        [ 1.2865e-02],\n",
      "        [-7.4918e-02],\n",
      "        [ 4.1865e-02],\n",
      "        [ 4.7270e-02],\n",
      "        [ 6.6334e-02],\n",
      "        [-1.0081e-01],\n",
      "        [ 2.8420e-05],\n",
      "        [-1.7641e-02],\n",
      "        [ 3.4813e-02],\n",
      "        [-6.3898e-02],\n",
      "        [ 4.3164e-02],\n",
      "        [-1.9731e-02],\n",
      "        [-2.4399e-02],\n",
      "        [-3.5956e-02],\n",
      "        [ 1.5066e-02],\n",
      "        [ 3.0876e-02],\n",
      "        [ 3.5512e-02],\n",
      "        [-1.7099e-02],\n",
      "        [ 1.2371e-02],\n",
      "        [ 1.2832e-02],\n",
      "        [-2.6170e-03],\n",
      "        [-4.2918e-02],\n",
      "        [ 2.0035e-02],\n",
      "        [ 6.3661e-02],\n",
      "        [-5.3057e-02],\n",
      "        [-2.8548e-02],\n",
      "        [ 3.2567e-03],\n",
      "        [ 1.9155e-02],\n",
      "        [ 5.1813e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0509, 0.0515, 0.0511, 0.0507, 0.0500, 0.0507, 0.0491, 0.0482, 0.0482,\n",
      "        0.0498, 0.0499, 0.0489, 0.0498, 0.0510, 0.0515, 0.0504, 0.0501, 0.0509,\n",
      "        0.0504, 0.0492, 0.0489, 0.0471, 0.0480, 0.0501, 0.0498, 0.0492, 0.0508,\n",
      "        0.0510, 0.0505, 0.0484, 0.0503, 0.0505], device='cuda:0')\n",
      "tensor([[-0.0280],\n",
      "        [ 0.0281],\n",
      "        [-0.0774],\n",
      "        [ 0.0005],\n",
      "        [-0.0379],\n",
      "        [-0.0606],\n",
      "        [-0.0748],\n",
      "        [-0.0256],\n",
      "        [ 0.0127],\n",
      "        [ 0.0359],\n",
      "        [ 0.0029],\n",
      "        [-0.0234],\n",
      "        [-0.0100],\n",
      "        [ 0.0226],\n",
      "        [ 0.0248],\n",
      "        [ 0.0698],\n",
      "        [ 0.0194],\n",
      "        [ 0.0769],\n",
      "        [ 0.0030],\n",
      "        [ 0.0138],\n",
      "        [-0.0317],\n",
      "        [-0.0417],\n",
      "        [-0.0373],\n",
      "        [-0.0082],\n",
      "        [ 0.0300],\n",
      "        [-0.0014],\n",
      "        [ 0.0729],\n",
      "        [ 0.0051],\n",
      "        [-0.0080],\n",
      "        [ 0.0070],\n",
      "        [-0.0102],\n",
      "        [-0.0310]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0494, 0.0500, 0.0492, 0.0499, 0.0501, 0.0509, 0.0513, 0.0516, 0.0531,\n",
      "        0.0552, 0.0557, 0.0562, 0.0560, 0.0551, 0.0565, 0.0564, 0.0574, 0.0573,\n",
      "        0.0569, 0.0567, 0.0563, 0.0559, 0.0558, 0.0581, 0.0578, 0.0582, 0.0585,\n",
      "        0.0597, 0.0607, 0.0617, 0.0629, 0.0620], device='cuda:0')\n",
      "tensor([[-0.0223],\n",
      "        [ 0.0079],\n",
      "        [ 0.0282],\n",
      "        [ 0.0289],\n",
      "        [ 0.0091],\n",
      "        [-0.0133],\n",
      "        [-0.0709],\n",
      "        [-0.0227],\n",
      "        [-0.0157],\n",
      "        [-0.0397],\n",
      "        [ 0.0428],\n",
      "        [ 0.0377],\n",
      "        [-0.0258],\n",
      "        [-0.0023],\n",
      "        [ 0.0738],\n",
      "        [-0.0879],\n",
      "        [ 0.0437],\n",
      "        [-0.0301],\n",
      "        [-0.0355],\n",
      "        [ 0.0016],\n",
      "        [-0.0257],\n",
      "        [ 0.0074],\n",
      "        [-0.0208],\n",
      "        [ 0.0530],\n",
      "        [ 0.1840],\n",
      "        [ 0.0107],\n",
      "        [ 0.0312],\n",
      "        [-0.0301],\n",
      "        [-0.0347],\n",
      "        [-0.0061],\n",
      "        [-0.0259],\n",
      "        [ 0.0241]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0617, 0.0619, 0.0619, 0.0613, 0.0608, 0.0598, 0.0600, 0.0597, 0.0590,\n",
      "        0.0575, 0.0575, 0.0587, 0.0584, 0.0578, 0.0585, 0.0593, 0.0600, 0.0624,\n",
      "        0.0650, 0.0693, 0.0680, 0.0669, 0.0676, 0.0681, 0.0683, 0.0681, 0.0657,\n",
      "        0.0647, 0.0626, 0.0626, 0.0654, 0.0653], device='cuda:0')\n",
      "tensor([[-0.1274],\n",
      "        [-0.0590],\n",
      "        [-0.1159],\n",
      "        [-0.1276],\n",
      "        [-0.0010],\n",
      "        [-0.0032],\n",
      "        [ 0.0079],\n",
      "        [ 0.0275],\n",
      "        [-0.0080],\n",
      "        [-0.0218],\n",
      "        [ 0.0047],\n",
      "        [-0.0339],\n",
      "        [ 0.0147],\n",
      "        [-0.0621],\n",
      "        [ 0.0284],\n",
      "        [ 0.0077],\n",
      "        [-0.0256],\n",
      "        [-0.0482],\n",
      "        [ 0.0125],\n",
      "        [ 0.0301],\n",
      "        [-0.0518],\n",
      "        [-0.0245],\n",
      "        [ 0.0512],\n",
      "        [-0.0555],\n",
      "        [-0.0779],\n",
      "        [-0.0252],\n",
      "        [-0.0493],\n",
      "        [-0.0370],\n",
      "        [-0.0101],\n",
      "        [ 0.0078],\n",
      "        [-0.0256],\n",
      "        [ 0.0066]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0630, 0.0644, 0.0659, 0.0643, 0.0637, 0.0639, 0.0653, 0.0669, 0.0665,\n",
      "        0.0653, 0.0645, 0.0650, 0.0646, 0.0653, 0.0622, 0.0615, 0.0619, 0.0600,\n",
      "        0.0591, 0.0590, 0.0607, 0.0605, 0.0601, 0.0600, 0.0606, 0.0601, 0.0598,\n",
      "        0.0607, 0.0618, 0.0608, 0.0611, 0.0622], device='cuda:0')\n",
      "tensor([[ 0.0196],\n",
      "        [ 0.0477],\n",
      "        [-0.0098],\n",
      "        [ 0.0147],\n",
      "        [ 0.0851],\n",
      "        [ 0.0538],\n",
      "        [ 0.0453],\n",
      "        [ 0.0050],\n",
      "        [-0.0218],\n",
      "        [-0.0261],\n",
      "        [-0.0230],\n",
      "        [ 0.0816],\n",
      "        [ 0.0021],\n",
      "        [-0.0249],\n",
      "        [ 0.0045],\n",
      "        [-0.0165],\n",
      "        [ 0.0187],\n",
      "        [-0.0160],\n",
      "        [ 0.0101],\n",
      "        [ 0.0060],\n",
      "        [-0.0266],\n",
      "        [ 0.0105],\n",
      "        [-0.0273],\n",
      "        [-0.0255],\n",
      "        [ 0.0133],\n",
      "        [-0.0178],\n",
      "        [-0.0341],\n",
      "        [-0.0063],\n",
      "        [ 0.0094],\n",
      "        [-0.0066],\n",
      "        [ 0.0897],\n",
      "        [-0.0473]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0621, 0.0619, 0.0606, 0.0610, 0.0606, 0.0606, 0.0598, 0.0602, 0.0608,\n",
      "        0.0610, 0.0611, 0.0607, 0.0603, 0.0603, 0.0604, 0.0601, 0.0603, 0.0600,\n",
      "        0.0589, 0.0603, 0.0603, 0.0600, 0.0592, 0.0598, 0.0580, 0.0574, 0.0589,\n",
      "        0.0587, 0.0588, 0.0585, 0.0575, 0.0562], device='cuda:0')\n",
      "tensor([[ 0.0020],\n",
      "        [ 0.0299],\n",
      "        [ 0.0040],\n",
      "        [-0.0265],\n",
      "        [ 0.0548],\n",
      "        [ 0.0530],\n",
      "        [ 0.0439],\n",
      "        [-0.0377],\n",
      "        [-0.0050],\n",
      "        [-0.0038],\n",
      "        [-0.0345],\n",
      "        [ 0.0209],\n",
      "        [-0.0562],\n",
      "        [ 0.0390],\n",
      "        [ 0.0179],\n",
      "        [ 0.0153],\n",
      "        [-0.0054],\n",
      "        [-0.0392],\n",
      "        [ 0.0150],\n",
      "        [ 0.0250],\n",
      "        [ 0.0248],\n",
      "        [ 0.0251],\n",
      "        [ 0.0346],\n",
      "        [-0.0337],\n",
      "        [-0.0240],\n",
      "        [-0.0206],\n",
      "        [-0.0260],\n",
      "        [ 0.0461],\n",
      "        [-0.0387],\n",
      "        [-0.0190],\n",
      "        [ 0.0301],\n",
      "        [ 0.0391]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0551, 0.0561, 0.0580, 0.0580, 0.0572, 0.0558, 0.0555, 0.0548, 0.0538,\n",
      "        0.0532, 0.0537, 0.0551, 0.0539, 0.0555, 0.0552, 0.0563, 0.0572, 0.0575,\n",
      "        0.0580, 0.0569, 0.0575, 0.0577, 0.0581, 0.0580, 0.0586, 0.0597, 0.0595,\n",
      "        0.0584, 0.0587, 0.0583, 0.0577, 0.0580], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0670],\n",
      "        [ 0.0068],\n",
      "        [ 0.0342],\n",
      "        [-0.0227],\n",
      "        [-0.0469],\n",
      "        [ 0.0081],\n",
      "        [-0.0268],\n",
      "        [-0.0103],\n",
      "        [-0.0586],\n",
      "        [-0.0507],\n",
      "        [-0.0032],\n",
      "        [ 0.0132],\n",
      "        [-0.0189],\n",
      "        [ 0.0175],\n",
      "        [-0.0149],\n",
      "        [-0.0019],\n",
      "        [-0.0287],\n",
      "        [-0.0074],\n",
      "        [-0.0078],\n",
      "        [-0.0203],\n",
      "        [ 0.0099],\n",
      "        [-0.0542],\n",
      "        [-0.0524],\n",
      "        [-0.0093],\n",
      "        [ 0.0064],\n",
      "        [-0.0429],\n",
      "        [-0.0448],\n",
      "        [-0.0164],\n",
      "        [-0.0155],\n",
      "        [-0.0242],\n",
      "        [ 0.0334],\n",
      "        [-0.0474]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0582, 0.0565, 0.0555, 0.0553, 0.0562, 0.0577, 0.0568, 0.0558, 0.0565,\n",
      "        0.0562, 0.0561, 0.0548, 0.0551, 0.0548, 0.0544, 0.0522, 0.0524, 0.0530,\n",
      "        0.0539, 0.0529, 0.0516, 0.0536, 0.0536, 0.0546, 0.0533, 0.0516, 0.0523,\n",
      "        0.0523, 0.0517, 0.0515, 0.0515, 0.0515], device='cuda:0')\n",
      "tensor([[-0.0351],\n",
      "        [-0.0917],\n",
      "        [-0.0169],\n",
      "        [-0.0223],\n",
      "        [-0.0474],\n",
      "        [ 0.0282],\n",
      "        [ 0.0260],\n",
      "        [-0.0539],\n",
      "        [-0.0463],\n",
      "        [ 0.0134],\n",
      "        [ 0.0073],\n",
      "        [-0.0098],\n",
      "        [ 0.0144],\n",
      "        [ 0.0730],\n",
      "        [-0.0025],\n",
      "        [ 0.1831],\n",
      "        [-0.0105],\n",
      "        [ 0.0019],\n",
      "        [-0.0240],\n",
      "        [-0.0405],\n",
      "        [ 0.0625],\n",
      "        [-0.0197],\n",
      "        [-0.0366],\n",
      "        [-0.0132],\n",
      "        [-0.0423],\n",
      "        [-0.0341],\n",
      "        [-0.0148],\n",
      "        [-0.0103],\n",
      "        [ 0.0215],\n",
      "        [ 0.0054],\n",
      "        [-0.0212],\n",
      "        [ 0.1086]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0507, 0.0508, 0.0507, 0.0504, 0.0507, 0.0508, 0.0509, 0.0511, 0.0523,\n",
      "        0.0529, 0.0540, 0.0536, 0.0516, 0.0516, 0.0505, 0.0505, 0.0508, 0.0507,\n",
      "        0.0512, 0.0506, 0.0500, 0.0506, 0.0510, 0.0518, 0.0518, 0.0515, 0.0524,\n",
      "        0.0523, 0.0515, 0.0503, 0.0506, 0.0520], device='cuda:0')\n",
      "tensor([[-0.0015],\n",
      "        [ 0.0315],\n",
      "        [ 0.0358],\n",
      "        [-0.0394],\n",
      "        [-0.0522],\n",
      "        [-0.0214],\n",
      "        [ 0.0008],\n",
      "        [ 0.0344],\n",
      "        [-0.0079],\n",
      "        [ 0.0011],\n",
      "        [-0.0052],\n",
      "        [ 0.0402],\n",
      "        [-0.0076],\n",
      "        [ 0.0694],\n",
      "        [-0.0026],\n",
      "        [ 0.0133],\n",
      "        [-0.0149],\n",
      "        [-0.1006],\n",
      "        [-0.0700],\n",
      "        [-0.0192],\n",
      "        [ 0.0235],\n",
      "        [-0.0322],\n",
      "        [-0.0307],\n",
      "        [-0.0097],\n",
      "        [-0.0758],\n",
      "        [-0.0645],\n",
      "        [-0.0888],\n",
      "        [ 0.0270],\n",
      "        [-0.0165],\n",
      "        [-0.0288],\n",
      "        [-0.0189],\n",
      "        [-0.0671]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0515, 0.0524, 0.0529, 0.0529, 0.0531, 0.0535, 0.0538, 0.0542, 0.0549,\n",
      "        0.0546, 0.0542, 0.0541, 0.0533, 0.0531, 0.0544, 0.0548, 0.0545, 0.0538,\n",
      "        0.0541, 0.0536, 0.0532, 0.0535, 0.0535, 0.0545, 0.0542, 0.0552, 0.0558,\n",
      "        0.0573, 0.0580, 0.0582, 0.0576, 0.0578], device='cuda:0')\n",
      "tensor([[ 0.1231],\n",
      "        [ 0.0109],\n",
      "        [-0.0104],\n",
      "        [-0.0819],\n",
      "        [ 0.0248],\n",
      "        [-0.0044],\n",
      "        [-0.0523],\n",
      "        [ 0.0370],\n",
      "        [ 0.0270],\n",
      "        [-0.0455],\n",
      "        [ 0.0379],\n",
      "        [-0.0710],\n",
      "        [-0.0348],\n",
      "        [-0.0369],\n",
      "        [-0.0146],\n",
      "        [ 0.0269],\n",
      "        [ 0.0493],\n",
      "        [-0.0120],\n",
      "        [-0.0219],\n",
      "        [ 0.0031],\n",
      "        [ 0.0010],\n",
      "        [-0.0350],\n",
      "        [-0.0292],\n",
      "        [ 0.0176],\n",
      "        [ 0.0088],\n",
      "        [-0.0489],\n",
      "        [-0.0296],\n",
      "        [ 0.0138],\n",
      "        [-0.0659],\n",
      "        [ 0.0129],\n",
      "        [ 0.0263],\n",
      "        [-0.0988]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0581, 0.0590, 0.0584, 0.0586, 0.0580, 0.0578, 0.0590, 0.0596, 0.0587,\n",
      "        0.0588, 0.0573, 0.0562, 0.0569, 0.0570, 0.0580, 0.0580, 0.0568, 0.0567,\n",
      "        0.0561, 0.0562, 0.0558, 0.0561, 0.0558, 0.0551, 0.0545, 0.0540, 0.0538,\n",
      "        0.0535, 0.0543, 0.0548, 0.0549, 0.0549], device='cuda:0')\n",
      "tensor([[ 0.0233],\n",
      "        [-0.0119],\n",
      "        [ 0.0116],\n",
      "        [-0.0252],\n",
      "        [-0.0119],\n",
      "        [ 0.0070],\n",
      "        [-0.0559],\n",
      "        [-0.0050],\n",
      "        [ 0.0269],\n",
      "        [-0.0046],\n",
      "        [-0.0016],\n",
      "        [ 0.0718],\n",
      "        [ 0.0090],\n",
      "        [ 0.0414],\n",
      "        [ 0.1204],\n",
      "        [-0.0210],\n",
      "        [-0.0484],\n",
      "        [-0.0726],\n",
      "        [-0.0631],\n",
      "        [-0.0744],\n",
      "        [-0.1091],\n",
      "        [ 0.0871],\n",
      "        [ 0.0280],\n",
      "        [-0.0002],\n",
      "        [-0.0220],\n",
      "        [ 0.0196],\n",
      "        [-0.0552],\n",
      "        [ 0.0078],\n",
      "        [-0.0498],\n",
      "        [-0.0754],\n",
      "        [-0.0694],\n",
      "        [-0.0552]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0549, 0.0545, 0.0552, 0.0576, 0.0564, 0.0586, 0.0590, 0.0605, 0.0604,\n",
      "        0.0629, 0.0637, 0.0629, 0.0601, 0.0595, 0.0580, 0.0590, 0.0567, 0.0571,\n",
      "        0.0583, 0.0581, 0.0570, 0.0559, 0.0564, 0.0556, 0.0555, 0.0547, 0.0546,\n",
      "        0.0552, 0.0574, 0.0585, 0.0579, 0.0597], device='cuda:0')\n",
      "tensor([[ 0.0517],\n",
      "        [ 0.0017],\n",
      "        [ 0.0080],\n",
      "        [ 0.0488],\n",
      "        [ 0.0832],\n",
      "        [ 0.0624],\n",
      "        [ 0.0132],\n",
      "        [-0.0178],\n",
      "        [-0.0153],\n",
      "        [-0.0373],\n",
      "        [ 0.0065],\n",
      "        [-0.0091],\n",
      "        [ 0.0136],\n",
      "        [ 0.0529],\n",
      "        [-0.0020],\n",
      "        [ 0.0137],\n",
      "        [ 0.0311],\n",
      "        [ 0.0240],\n",
      "        [-0.0190],\n",
      "        [ 0.0312],\n",
      "        [ 0.0388],\n",
      "        [-0.0356],\n",
      "        [-0.0682],\n",
      "        [ 0.0080],\n",
      "        [ 0.0143],\n",
      "        [-0.0524],\n",
      "        [-0.0658],\n",
      "        [-0.0606],\n",
      "        [-0.0702],\n",
      "        [ 0.0082],\n",
      "        [-0.0445],\n",
      "        [-0.0028]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0601, 0.0595, 0.0595, 0.0585, 0.0588, 0.0598, 0.0607, 0.0609, 0.0613,\n",
      "        0.0615, 0.0626, 0.0631, 0.0634, 0.0613, 0.0610, 0.0617, 0.0629, 0.0622,\n",
      "        0.0619, 0.0612, 0.0611, 0.0606, 0.0599, 0.0607, 0.0630, 0.0619, 0.0623,\n",
      "        0.0620, 0.0626, 0.0627, 0.0630, 0.0636], device='cuda:0')\n",
      "tensor([[-0.0071],\n",
      "        [ 0.0037],\n",
      "        [-0.0186],\n",
      "        [-0.0297],\n",
      "        [-0.0191],\n",
      "        [ 0.0224],\n",
      "        [ 0.0002],\n",
      "        [ 0.0435],\n",
      "        [ 0.0267],\n",
      "        [ 0.0273],\n",
      "        [-0.1189],\n",
      "        [-0.0987],\n",
      "        [ 0.0759],\n",
      "        [ 0.0488],\n",
      "        [-0.0529],\n",
      "        [-0.0281],\n",
      "        [ 0.0182],\n",
      "        [-0.0313],\n",
      "        [-0.0448],\n",
      "        [-0.0387],\n",
      "        [-0.0551],\n",
      "        [-0.0521],\n",
      "        [ 0.0220],\n",
      "        [-0.0045],\n",
      "        [-0.0010],\n",
      "        [ 0.0083],\n",
      "        [-0.0298],\n",
      "        [-0.0269],\n",
      "        [ 0.0004],\n",
      "        [-0.0722],\n",
      "        [-0.0263],\n",
      "        [ 0.0279]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0654, 0.0651, 0.0650, 0.0629, 0.0626, 0.0625, 0.0623, 0.0619, 0.0621,\n",
      "        0.0621, 0.0630, 0.0624, 0.0614, 0.0627, 0.0626, 0.0627, 0.0641, 0.0643,\n",
      "        0.0638, 0.0636, 0.0641, 0.0650, 0.0647, 0.0649, 0.0667, 0.0666, 0.0661,\n",
      "        0.0649, 0.0656, 0.0659, 0.0656, 0.0656], device='cuda:0')\n",
      "tensor([[-0.0082],\n",
      "        [-0.0106],\n",
      "        [-0.0424],\n",
      "        [ 0.0151],\n",
      "        [ 0.0122],\n",
      "        [ 0.0147],\n",
      "        [ 0.0321],\n",
      "        [ 0.0494],\n",
      "        [ 0.0770],\n",
      "        [ 0.0107],\n",
      "        [ 0.0171],\n",
      "        [ 0.0073],\n",
      "        [-0.0390],\n",
      "        [-0.0032],\n",
      "        [ 0.0013],\n",
      "        [-0.0646],\n",
      "        [-0.0958],\n",
      "        [-0.1385],\n",
      "        [-0.0883],\n",
      "        [-0.0001],\n",
      "        [-0.0434],\n",
      "        [-0.0039],\n",
      "        [ 0.0161],\n",
      "        [ 0.0575],\n",
      "        [-0.0451],\n",
      "        [ 0.0277],\n",
      "        [-0.0272],\n",
      "        [ 0.0045],\n",
      "        [-0.0291],\n",
      "        [-0.0038],\n",
      "        [ 0.0068],\n",
      "        [-0.0317]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0659, 0.0659, 0.0669, 0.0673, 0.0676, 0.0674, 0.0668, 0.0665, 0.0663,\n",
      "        0.0665, 0.0655, 0.0645, 0.0636, 0.0624, 0.0625, 0.0634, 0.0650, 0.0657,\n",
      "        0.0648, 0.0646, 0.0650, 0.0650, 0.0647, 0.0648, 0.0647, 0.0647, 0.0656,\n",
      "        0.0653, 0.0642, 0.0637, 0.0658, 0.0673], device='cuda:0')\n",
      "tensor([[-0.0271],\n",
      "        [ 0.0218],\n",
      "        [-0.0635],\n",
      "        [-0.0280],\n",
      "        [ 0.0091],\n",
      "        [-0.0055],\n",
      "        [-0.0494],\n",
      "        [-0.0203],\n",
      "        [-0.0177],\n",
      "        [ 0.0154],\n",
      "        [-0.0096],\n",
      "        [ 0.0926],\n",
      "        [-0.0361],\n",
      "        [ 0.0494],\n",
      "        [ 0.0176],\n",
      "        [ 0.0429],\n",
      "        [ 0.0024],\n",
      "        [-0.0356],\n",
      "        [-0.0346],\n",
      "        [-0.0041],\n",
      "        [ 0.0548],\n",
      "        [ 0.0451],\n",
      "        [ 0.0190],\n",
      "        [-0.0751],\n",
      "        [ 0.0164],\n",
      "        [-0.0083],\n",
      "        [ 0.0750],\n",
      "        [-0.0737],\n",
      "        [-0.0349],\n",
      "        [-0.0690],\n",
      "        [ 0.0078],\n",
      "        [ 0.0186]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0659, 0.0637, 0.0646, 0.0660, 0.0653, 0.0656, 0.0668, 0.0669, 0.0677,\n",
      "        0.0678, 0.0678, 0.0680, 0.0679, 0.0676, 0.0691, 0.0690, 0.0708, 0.0680,\n",
      "        0.0634, 0.0649, 0.0646, 0.0648, 0.0648, 0.0630, 0.0623, 0.0613, 0.0607,\n",
      "        0.0599, 0.0617, 0.0618, 0.0618, 0.0607], device='cuda:0')\n",
      "tensor([[ 0.0420],\n",
      "        [ 0.0085],\n",
      "        [-0.0042],\n",
      "        [-0.0011],\n",
      "        [ 0.0077],\n",
      "        [ 0.0177],\n",
      "        [-0.0205],\n",
      "        [-0.0049],\n",
      "        [ 0.0920],\n",
      "        [ 0.0147],\n",
      "        [ 0.0094],\n",
      "        [-0.0546],\n",
      "        [-0.0255],\n",
      "        [-0.0978],\n",
      "        [ 0.0422],\n",
      "        [-0.0050],\n",
      "        [-0.0656],\n",
      "        [-0.0061],\n",
      "        [ 0.0116],\n",
      "        [ 0.0503],\n",
      "        [-0.0594],\n",
      "        [ 0.0422],\n",
      "        [-0.0538],\n",
      "        [-0.0340],\n",
      "        [-0.0843],\n",
      "        [ 0.0946],\n",
      "        [-0.0370],\n",
      "        [-0.0069],\n",
      "        [ 0.0231],\n",
      "        [-0.0417],\n",
      "        [ 0.0215],\n",
      "        [-0.0076]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0621, 0.0633, 0.0624, 0.0646, 0.0639, 0.0631, 0.0632, 0.0633, 0.0637,\n",
      "        0.0639, 0.0633, 0.0621, 0.0622, 0.0620, 0.0611, 0.0600, 0.0594, 0.0586,\n",
      "        0.0585, 0.0575, 0.0555, 0.0578, 0.0583, 0.0584, 0.0573, 0.0563, 0.0569,\n",
      "        0.0568, 0.0569, 0.0562, 0.0568, 0.0582], device='cuda:0')\n",
      "tensor([[-0.0283],\n",
      "        [ 0.0200],\n",
      "        [-0.0406],\n",
      "        [-0.0016],\n",
      "        [ 0.0298],\n",
      "        [ 0.0269],\n",
      "        [ 0.0884],\n",
      "        [ 0.0865],\n",
      "        [ 0.0380],\n",
      "        [ 0.0127],\n",
      "        [-0.0471],\n",
      "        [ 0.0341],\n",
      "        [ 0.0277],\n",
      "        [ 0.0168],\n",
      "        [-0.0171],\n",
      "        [ 0.0017],\n",
      "        [ 0.0463],\n",
      "        [ 0.0191],\n",
      "        [ 0.0134],\n",
      "        [ 0.0062],\n",
      "        [-0.0247],\n",
      "        [-0.0370],\n",
      "        [-0.0218],\n",
      "        [-0.0157],\n",
      "        [ 0.0078],\n",
      "        [ 0.0457],\n",
      "        [-0.0560],\n",
      "        [ 0.0843],\n",
      "        [-0.0952],\n",
      "        [-0.0150],\n",
      "        [-0.0337],\n",
      "        [ 0.0049]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0594, 0.0594, 0.0603, 0.0607, 0.0605, 0.0591, 0.0578, 0.0564, 0.0563,\n",
      "        0.0572, 0.0577, 0.0590, 0.0580, 0.0574, 0.0571, 0.0565, 0.0569, 0.0574,\n",
      "        0.0565, 0.0546, 0.0539, 0.0537, 0.0519, 0.0493, 0.0516, 0.0511, 0.0508,\n",
      "        0.0476, 0.0476, 0.0486, 0.0492, 0.0493], device='cuda:0')\n",
      "tensor([[ 0.0265],\n",
      "        [-0.0293],\n",
      "        [ 0.0037],\n",
      "        [ 0.0058],\n",
      "        [-0.0333],\n",
      "        [-0.0113],\n",
      "        [-0.0028],\n",
      "        [-0.0109],\n",
      "        [-0.0802],\n",
      "        [-0.0388],\n",
      "        [-0.0424],\n",
      "        [-0.0861],\n",
      "        [-0.0326],\n",
      "        [ 0.0029],\n",
      "        [ 0.0015],\n",
      "        [ 0.0149],\n",
      "        [ 0.0194],\n",
      "        [ 0.0140],\n",
      "        [ 0.0113],\n",
      "        [-0.0113],\n",
      "        [-0.0704],\n",
      "        [ 0.0286],\n",
      "        [-0.0237],\n",
      "        [ 0.0064],\n",
      "        [-0.0402],\n",
      "        [-0.1387],\n",
      "        [-0.1066],\n",
      "        [-0.0636],\n",
      "        [-0.0245],\n",
      "        [ 0.0069],\n",
      "        [ 0.0054],\n",
      "        [ 0.0006]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0482, 0.0474, 0.0457, 0.0441, 0.0447, 0.0445, 0.0418, 0.0399, 0.0387,\n",
      "        0.0393, 0.0376, 0.0379, 0.0419, 0.0438, 0.0464, 0.0485, 0.0476, 0.0476,\n",
      "        0.0448, 0.0445, 0.0436, 0.0441, 0.0434, 0.0420, 0.0419, 0.0419, 0.0447,\n",
      "        0.0435, 0.0450, 0.0446, 0.0441, 0.0415], device='cuda:0')\n",
      "tensor([[-0.0269],\n",
      "        [ 0.0195],\n",
      "        [ 0.0386],\n",
      "        [ 0.0111],\n",
      "        [-0.1119],\n",
      "        [-0.0475],\n",
      "        [-0.0739],\n",
      "        [ 0.0049],\n",
      "        [-0.0644],\n",
      "        [-0.0445],\n",
      "        [-0.0105],\n",
      "        [-0.0264],\n",
      "        [ 0.0114],\n",
      "        [-0.0730],\n",
      "        [ 0.0016],\n",
      "        [-0.0171],\n",
      "        [-0.0251],\n",
      "        [-0.0257],\n",
      "        [ 0.0159],\n",
      "        [-0.0170],\n",
      "        [-0.0127],\n",
      "        [ 0.1011],\n",
      "        [ 0.0240],\n",
      "        [ 0.0470],\n",
      "        [ 0.0172],\n",
      "        [ 0.0605],\n",
      "        [-0.0021],\n",
      "        [-0.0871],\n",
      "        [ 0.0010],\n",
      "        [-0.0192],\n",
      "        [ 0.0038],\n",
      "        [-0.0348]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0410, 0.0417, 0.0415, 0.0415, 0.0398, 0.0407, 0.0399, 0.0385, 0.0380,\n",
      "        0.0404, 0.0408, 0.0398, 0.0392, 0.0401, 0.0402, 0.0407, 0.0420, 0.0417,\n",
      "        0.0416, 0.0407, 0.0414, 0.0407, 0.0405, 0.0404, 0.0404, 0.0406, 0.0403,\n",
      "        0.0396, 0.0398, 0.0397, 0.0394, 0.0387], device='cuda:0')\n",
      "tensor([[-0.0531],\n",
      "        [ 0.0023],\n",
      "        [-0.0130],\n",
      "        [-0.0187],\n",
      "        [ 0.0348],\n",
      "        [-0.0799],\n",
      "        [ 0.0472],\n",
      "        [-0.0894],\n",
      "        [ 0.0892],\n",
      "        [-0.0009],\n",
      "        [-0.0636],\n",
      "        [ 0.0188],\n",
      "        [-0.0100],\n",
      "        [-0.0420],\n",
      "        [ 0.0104],\n",
      "        [ 0.0906],\n",
      "        [ 0.0882],\n",
      "        [ 0.0546],\n",
      "        [ 0.0378],\n",
      "        [ 0.0365],\n",
      "        [-0.0012],\n",
      "        [-0.0493],\n",
      "        [-0.0054],\n",
      "        [-0.0081],\n",
      "        [ 0.0089],\n",
      "        [ 0.0423],\n",
      "        [ 0.0158],\n",
      "        [-0.0067],\n",
      "        [-0.0658],\n",
      "        [-0.0661],\n",
      "        [ 0.0129],\n",
      "        [-0.0254]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0375, 0.0370, 0.0352, 0.0334, 0.0350, 0.0363, 0.0373, 0.0373, 0.0385,\n",
      "        0.0396, 0.0428, 0.0431, 0.0430, 0.0434, 0.0448, 0.0436, 0.0430, 0.0431,\n",
      "        0.0444, 0.0450, 0.0457, 0.0452, 0.0441, 0.0442, 0.0435, 0.0436, 0.0447,\n",
      "        0.0460, 0.0469, 0.0458, 0.0453, 0.0471], device='cuda:0')\n",
      "tensor([[ 0.0068],\n",
      "        [ 0.0669],\n",
      "        [-0.0028],\n",
      "        [ 0.0032],\n",
      "        [ 0.0046],\n",
      "        [-0.0006],\n",
      "        [ 0.0007],\n",
      "        [-0.0006],\n",
      "        [-0.0432],\n",
      "        [ 0.0036],\n",
      "        [ 0.0133],\n",
      "        [ 0.0245],\n",
      "        [-0.0177],\n",
      "        [-0.0667],\n",
      "        [ 0.0204],\n",
      "        [-0.0478],\n",
      "        [-0.0237],\n",
      "        [-0.1523],\n",
      "        [-0.0519],\n",
      "        [-0.0074],\n",
      "        [ 0.0319],\n",
      "        [ 0.0311],\n",
      "        [-0.0734],\n",
      "        [-0.0429],\n",
      "        [-0.0544],\n",
      "        [ 0.0398],\n",
      "        [ 0.0058],\n",
      "        [-0.0391],\n",
      "        [-0.0577],\n",
      "        [ 0.0226],\n",
      "        [ 0.0005],\n",
      "        [ 0.0027]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0489, 0.0489, 0.0492, 0.0496, 0.0496, 0.0509, 0.0514, 0.0532, 0.0533,\n",
      "        0.0529, 0.0512, 0.0507, 0.0493, 0.0497, 0.0496, 0.0499, 0.0494, 0.0479,\n",
      "        0.0495, 0.0490, 0.0487, 0.0504, 0.0492, 0.0495, 0.0508, 0.0512, 0.0502,\n",
      "        0.0515, 0.0507, 0.0507, 0.0498, 0.0502], device='cuda:0')\n",
      "tensor([[ 0.0046],\n",
      "        [ 0.0019],\n",
      "        [ 0.0291],\n",
      "        [ 0.0779],\n",
      "        [ 0.0007],\n",
      "        [-0.0222],\n",
      "        [-0.0035],\n",
      "        [-0.0011],\n",
      "        [-0.0039],\n",
      "        [-0.0024],\n",
      "        [ 0.0020],\n",
      "        [ 0.0337],\n",
      "        [ 0.0280],\n",
      "        [-0.1022],\n",
      "        [ 0.0191],\n",
      "        [-0.0069],\n",
      "        [-0.0134],\n",
      "        [-0.0320],\n",
      "        [ 0.0951],\n",
      "        [ 0.0194],\n",
      "        [ 0.0155],\n",
      "        [ 0.0369],\n",
      "        [-0.0106],\n",
      "        [ 0.0144],\n",
      "        [-0.0097],\n",
      "        [-0.0064],\n",
      "        [-0.0469],\n",
      "        [-0.0410],\n",
      "        [-0.0144],\n",
      "        [ 0.0006],\n",
      "        [-0.0639],\n",
      "        [ 0.0583]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0510, 0.0513, 0.0509, 0.0509, 0.0500, 0.0500, 0.0499, 0.0493, 0.0495,\n",
      "        0.0508, 0.0513, 0.0516, 0.0513, 0.0536, 0.0533, 0.0535, 0.0549, 0.0543,\n",
      "        0.0544, 0.0554, 0.0554, 0.0557, 0.0557, 0.0556, 0.0541, 0.0542, 0.0546,\n",
      "        0.0546, 0.0552, 0.0557, 0.0554, 0.0545], device='cuda:0')\n",
      "tensor([[ 0.0273],\n",
      "        [-0.0495],\n",
      "        [-0.0302],\n",
      "        [-0.0180],\n",
      "        [ 0.0238],\n",
      "        [-0.0230],\n",
      "        [-0.0220],\n",
      "        [-0.0120],\n",
      "        [ 0.0017],\n",
      "        [ 0.0164],\n",
      "        [ 0.0131],\n",
      "        [-0.0280],\n",
      "        [-0.0765],\n",
      "        [-0.0138],\n",
      "        [-0.0122],\n",
      "        [-0.0074],\n",
      "        [ 0.0056],\n",
      "        [-0.0066],\n",
      "        [-0.0397],\n",
      "        [ 0.0772],\n",
      "        [-0.0367],\n",
      "        [ 0.0391],\n",
      "        [-0.0500],\n",
      "        [ 0.0193],\n",
      "        [-0.0383],\n",
      "        [ 0.0597],\n",
      "        [-0.0192],\n",
      "        [ 0.0044],\n",
      "        [-0.0440],\n",
      "        [-0.0033],\n",
      "        [ 0.0148],\n",
      "        [-0.0136]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0551, 0.0559, 0.0564, 0.0562, 0.0558, 0.0546, 0.0554, 0.0558, 0.0554,\n",
      "        0.0550, 0.0545, 0.0553, 0.0553, 0.0550, 0.0539, 0.0544, 0.0546, 0.0551,\n",
      "        0.0552, 0.0555, 0.0567, 0.0577, 0.0569, 0.0557, 0.0576, 0.0580, 0.0581,\n",
      "        0.0583, 0.0588, 0.0602, 0.0612, 0.0607], device='cuda:0')\n",
      "tensor([[-1.1656e-02],\n",
      "        [ 2.3542e-02],\n",
      "        [ 3.4214e-02],\n",
      "        [ 5.7559e-02],\n",
      "        [-2.2384e-02],\n",
      "        [ 3.3286e-03],\n",
      "        [-1.3055e-02],\n",
      "        [-4.9213e-02],\n",
      "        [-5.5465e-02],\n",
      "        [ 6.4275e-02],\n",
      "        [-8.8450e-02],\n",
      "        [ 1.2250e-01],\n",
      "        [ 8.5800e-02],\n",
      "        [-1.6425e-02],\n",
      "        [ 2.7515e-02],\n",
      "        [-3.9758e-02],\n",
      "        [ 2.6967e-02],\n",
      "        [ 1.1312e-03],\n",
      "        [ 1.9888e-02],\n",
      "        [ 2.3624e-02],\n",
      "        [ 7.4089e-03],\n",
      "        [ 1.2530e-02],\n",
      "        [ 1.4873e-02],\n",
      "        [-1.7062e-02],\n",
      "        [-3.5610e-02],\n",
      "        [-1.0617e-02],\n",
      "        [ 5.2837e-04],\n",
      "        [ 4.9810e-02],\n",
      "        [-1.8757e-02],\n",
      "        [-7.8764e-05],\n",
      "        [-3.3640e-02],\n",
      "        [-2.6762e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0604, 0.0607, 0.0609, 0.0614, 0.0602, 0.0585, 0.0582, 0.0588, 0.0599,\n",
      "        0.0606, 0.0596, 0.0602, 0.0608, 0.0606, 0.0604, 0.0612, 0.0623, 0.0630,\n",
      "        0.0631, 0.0631, 0.0629, 0.0643, 0.0666, 0.0663, 0.0666, 0.0660, 0.0659,\n",
      "        0.0654, 0.0647, 0.0646, 0.0648, 0.0653], device='cuda:0')\n",
      "tensor([[-0.0139],\n",
      "        [-0.1290],\n",
      "        [ 0.0147],\n",
      "        [-0.0141],\n",
      "        [-0.0379],\n",
      "        [-0.0623],\n",
      "        [-0.0158],\n",
      "        [ 0.0076],\n",
      "        [ 0.0119],\n",
      "        [-0.0199],\n",
      "        [ 0.0384],\n",
      "        [-0.0017],\n",
      "        [ 0.0310],\n",
      "        [-0.0151],\n",
      "        [-0.0318],\n",
      "        [-0.0195],\n",
      "        [-0.0064],\n",
      "        [-0.0342],\n",
      "        [-0.0075],\n",
      "        [-0.0476],\n",
      "        [-0.0070],\n",
      "        [ 0.0240],\n",
      "        [ 0.0593],\n",
      "        [ 0.0399],\n",
      "        [-0.0353],\n",
      "        [-0.0283],\n",
      "        [-0.0005],\n",
      "        [-0.0065],\n",
      "        [-0.0120],\n",
      "        [-0.0897],\n",
      "        [-0.0575],\n",
      "        [-0.0891]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0649, 0.0650, 0.0652, 0.0648, 0.0653, 0.0659, 0.0660, 0.0660, 0.0650,\n",
      "        0.0650, 0.0653, 0.0655, 0.0649, 0.0639, 0.0643, 0.0648, 0.0641, 0.0639,\n",
      "        0.0646, 0.0648, 0.0653, 0.0660, 0.0662, 0.0652, 0.0642, 0.0642, 0.0641,\n",
      "        0.0638, 0.0627, 0.0621, 0.0616, 0.0616], device='cuda:0')\n",
      "tensor([[ 0.0245],\n",
      "        [-0.0067],\n",
      "        [-0.0072],\n",
      "        [-0.0241],\n",
      "        [ 0.0030],\n",
      "        [ 0.0094],\n",
      "        [-0.0858],\n",
      "        [ 0.0489],\n",
      "        [-0.0025],\n",
      "        [-0.0305],\n",
      "        [ 0.0361],\n",
      "        [ 0.0631],\n",
      "        [ 0.0377],\n",
      "        [ 0.0062],\n",
      "        [ 0.0165],\n",
      "        [-0.0917],\n",
      "        [ 0.0010],\n",
      "        [-0.0427],\n",
      "        [ 0.0157],\n",
      "        [-0.0571],\n",
      "        [ 0.0050],\n",
      "        [-0.0554],\n",
      "        [-0.0584],\n",
      "        [-0.0041],\n",
      "        [-0.0023],\n",
      "        [ 0.0056],\n",
      "        [ 0.0010],\n",
      "        [ 0.0240],\n",
      "        [ 0.0479],\n",
      "        [ 0.0274],\n",
      "        [ 0.0086],\n",
      "        [-0.0061]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0611, 0.0600, 0.0596, 0.0606, 0.0615, 0.0629, 0.0620, 0.0613, 0.0603,\n",
      "        0.0604, 0.0596, 0.0580, 0.0584, 0.0578, 0.0566, 0.0573, 0.0558, 0.0545,\n",
      "        0.0559, 0.0567, 0.0574, 0.0560, 0.0567, 0.0571, 0.0565, 0.0552, 0.0549,\n",
      "        0.0551, 0.0552, 0.0546, 0.0542, 0.0544], device='cuda:0')\n",
      "tensor([[-0.0084],\n",
      "        [ 0.0162],\n",
      "        [-0.0383],\n",
      "        [-0.0185],\n",
      "        [ 0.0080],\n",
      "        [ 0.0013],\n",
      "        [-0.0037],\n",
      "        [ 0.0173],\n",
      "        [ 0.1097],\n",
      "        [ 0.0698],\n",
      "        [-0.0018],\n",
      "        [-0.0080],\n",
      "        [-0.0128],\n",
      "        [-0.0343],\n",
      "        [-0.0216],\n",
      "        [ 0.0340],\n",
      "        [-0.0538],\n",
      "        [-0.0889],\n",
      "        [-0.0830],\n",
      "        [-0.0517],\n",
      "        [ 0.0381],\n",
      "        [-0.0014],\n",
      "        [ 0.0159],\n",
      "        [ 0.0242],\n",
      "        [-0.0307],\n",
      "        [ 0.0114],\n",
      "        [ 0.0203],\n",
      "        [-0.0234],\n",
      "        [ 0.0134],\n",
      "        [-0.0078],\n",
      "        [ 0.0328],\n",
      "        [-0.0424]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0549, 0.0556, 0.0558, 0.0561, 0.0555, 0.0543, 0.0542, 0.0554, 0.0551,\n",
      "        0.0520, 0.0516, 0.0511, 0.0503, 0.0508, 0.0513, 0.0520, 0.0515, 0.0511,\n",
      "        0.0508, 0.0499, 0.0515, 0.0508, 0.0495, 0.0501, 0.0492, 0.0485, 0.0485,\n",
      "        0.0482, 0.0478, 0.0483, 0.0495, 0.0508], device='cuda:0')\n",
      "tensor([[ 0.0315],\n",
      "        [-0.0775],\n",
      "        [ 0.0141],\n",
      "        [ 0.0210],\n",
      "        [-0.0223],\n",
      "        [-0.0114],\n",
      "        [-0.0037],\n",
      "        [ 0.1417],\n",
      "        [ 0.0024],\n",
      "        [ 0.0154],\n",
      "        [ 0.0131],\n",
      "        [ 0.0029],\n",
      "        [-0.0069],\n",
      "        [-0.0301],\n",
      "        [ 0.0392],\n",
      "        [ 0.0330],\n",
      "        [-0.0242],\n",
      "        [-0.0657],\n",
      "        [-0.0753],\n",
      "        [-0.0566],\n",
      "        [-0.0273],\n",
      "        [-0.0216],\n",
      "        [-0.0153],\n",
      "        [ 0.0101],\n",
      "        [-0.0120],\n",
      "        [-0.0130],\n",
      "        [-0.0836],\n",
      "        [-0.0483],\n",
      "        [-0.0529],\n",
      "        [ 0.0199],\n",
      "        [-0.0193],\n",
      "        [-0.0286]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0504, 0.0549, 0.0553, 0.0540, 0.0532, 0.0537, 0.0551, 0.0559, 0.0551,\n",
      "        0.0549, 0.0552, 0.0540, 0.0525, 0.0519, 0.0515, 0.0534, 0.0539, 0.0541,\n",
      "        0.0531, 0.0528, 0.0516, 0.0515, 0.0523, 0.0518, 0.0518, 0.0525, 0.0529,\n",
      "        0.0534, 0.0528, 0.0527, 0.0525, 0.0526], device='cuda:0')\n",
      "tensor([[-0.0077],\n",
      "        [ 0.0127],\n",
      "        [-0.0073],\n",
      "        [-0.0158],\n",
      "        [-0.0274],\n",
      "        [-0.0424],\n",
      "        [-0.0433],\n",
      "        [ 0.0195],\n",
      "        [-0.0113],\n",
      "        [ 0.0165],\n",
      "        [ 0.0302],\n",
      "        [ 0.0524],\n",
      "        [-0.0090],\n",
      "        [-0.0341],\n",
      "        [ 0.0670],\n",
      "        [-0.0473],\n",
      "        [-0.0383],\n",
      "        [ 0.0134],\n",
      "        [ 0.0127],\n",
      "        [-0.1320],\n",
      "        [-0.0274],\n",
      "        [ 0.0040],\n",
      "        [ 0.0657],\n",
      "        [-0.0677],\n",
      "        [-0.1060],\n",
      "        [ 0.0627],\n",
      "        [-0.0077],\n",
      "        [-0.0039],\n",
      "        [-0.0406],\n",
      "        [-0.0446],\n",
      "        [-0.0931],\n",
      "        [-0.0089]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0522, 0.0525, 0.0530, 0.0531, 0.0534, 0.0537, 0.0536, 0.0527, 0.0529,\n",
      "        0.0551, 0.0538, 0.0534, 0.0536, 0.0537, 0.0537, 0.0528, 0.0525, 0.0520,\n",
      "        0.0520, 0.0513, 0.0509, 0.0512, 0.0517, 0.0498, 0.0505, 0.0523, 0.0516,\n",
      "        0.0516, 0.0514, 0.0513, 0.0509, 0.0497], device='cuda:0')\n",
      "tensor([[-0.0468],\n",
      "        [-0.0556],\n",
      "        [-0.0003],\n",
      "        [-0.0701],\n",
      "        [-0.0538],\n",
      "        [-0.0304],\n",
      "        [ 0.0341],\n",
      "        [-0.0445],\n",
      "        [ 0.0014],\n",
      "        [-0.0447],\n",
      "        [-0.0473],\n",
      "        [ 0.0315],\n",
      "        [-0.0075],\n",
      "        [-0.0761],\n",
      "        [ 0.0076],\n",
      "        [ 0.0009],\n",
      "        [ 0.0256],\n",
      "        [ 0.0661],\n",
      "        [ 0.0500],\n",
      "        [ 0.0606],\n",
      "        [-0.0242],\n",
      "        [-0.0224],\n",
      "        [-0.0261],\n",
      "        [-0.0381],\n",
      "        [-0.1082],\n",
      "        [-0.0275],\n",
      "        [-0.0926],\n",
      "        [ 0.0138],\n",
      "        [ 0.0168],\n",
      "        [ 0.0740],\n",
      "        [-0.0261],\n",
      "        [-0.0364]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0502, 0.0502, 0.0520, 0.0518, 0.0503, 0.0500, 0.0496, 0.0493, 0.0496,\n",
      "        0.0513, 0.0521, 0.0529, 0.0539, 0.0538, 0.0565, 0.0547, 0.0556, 0.0548,\n",
      "        0.0557, 0.0574, 0.0573, 0.0563, 0.0580, 0.0608, 0.0608, 0.0614, 0.0624,\n",
      "        0.0613, 0.0601, 0.0595, 0.0608, 0.0603], device='cuda:0')\n",
      "tensor([[ 0.0136],\n",
      "        [ 0.0277],\n",
      "        [ 0.0240],\n",
      "        [-0.0421],\n",
      "        [-0.0517],\n",
      "        [-0.1077],\n",
      "        [ 0.0122],\n",
      "        [ 0.0149],\n",
      "        [-0.0350],\n",
      "        [ 0.0100],\n",
      "        [-0.0303],\n",
      "        [-0.0549],\n",
      "        [-0.0044],\n",
      "        [-0.0335],\n",
      "        [-0.0518],\n",
      "        [ 0.0223],\n",
      "        [ 0.0039],\n",
      "        [ 0.0256],\n",
      "        [-0.0096],\n",
      "        [-0.0064],\n",
      "        [ 0.1240],\n",
      "        [ 0.1305],\n",
      "        [ 0.0306],\n",
      "        [ 0.0223],\n",
      "        [-0.0581],\n",
      "        [-0.0552],\n",
      "        [-0.0463],\n",
      "        [-0.0028],\n",
      "        [ 0.0044],\n",
      "        [-0.0327],\n",
      "        [ 0.0095],\n",
      "        [ 0.0034]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0598, 0.0602, 0.0594, 0.0610, 0.0613, 0.0613, 0.0607, 0.0606, 0.0613,\n",
      "        0.0616, 0.0613, 0.0634, 0.0633, 0.0633, 0.0642, 0.0666, 0.0677, 0.0659,\n",
      "        0.0672, 0.0678, 0.0677, 0.0677, 0.0676, 0.0679, 0.0689, 0.0689, 0.0680,\n",
      "        0.0678, 0.0686, 0.0690, 0.0686, 0.0690], device='cuda:0')\n",
      "tensor([[-0.0348],\n",
      "        [ 0.0255],\n",
      "        [-0.0328],\n",
      "        [ 0.0097],\n",
      "        [ 0.0301],\n",
      "        [-0.0180],\n",
      "        [-0.0447],\n",
      "        [ 0.0181],\n",
      "        [ 0.0281],\n",
      "        [ 0.0389],\n",
      "        [-0.0267],\n",
      "        [-0.0346],\n",
      "        [ 0.0024],\n",
      "        [-0.0227],\n",
      "        [-0.0523],\n",
      "        [ 0.0110],\n",
      "        [ 0.0001],\n",
      "        [ 0.0141],\n",
      "        [-0.0042],\n",
      "        [ 0.0123],\n",
      "        [ 0.0750],\n",
      "        [ 0.0234],\n",
      "        [ 0.0119],\n",
      "        [-0.0143],\n",
      "        [ 0.0097],\n",
      "        [ 0.0994],\n",
      "        [ 0.0354],\n",
      "        [ 0.0460],\n",
      "        [-0.0325],\n",
      "        [-0.0224],\n",
      "        [-0.0157],\n",
      "        [ 0.0219]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0679, 0.0680, 0.0680, 0.0676, 0.0678, 0.0678, 0.0679, 0.0669, 0.0687,\n",
      "        0.0674, 0.0678, 0.0687, 0.0696, 0.0699, 0.0705, 0.0714, 0.0709, 0.0712,\n",
      "        0.0701, 0.0689, 0.0685, 0.0688, 0.0688, 0.0698, 0.0697, 0.0696, 0.0699,\n",
      "        0.0710, 0.0711, 0.0717, 0.0716, 0.0705], device='cuda:0')\n",
      "tensor([[-0.0012],\n",
      "        [-0.0005],\n",
      "        [ 0.0183],\n",
      "        [ 0.0549],\n",
      "        [-0.0124],\n",
      "        [-0.0154],\n",
      "        [-0.0034],\n",
      "        [-0.0188],\n",
      "        [-0.0130],\n",
      "        [-0.0084],\n",
      "        [-0.0112],\n",
      "        [ 0.0196],\n",
      "        [-0.0145],\n",
      "        [-0.0052],\n",
      "        [-0.0061],\n",
      "        [-0.0259],\n",
      "        [-0.0154],\n",
      "        [ 0.0124],\n",
      "        [-0.1079],\n",
      "        [-0.0578],\n",
      "        [ 0.0903],\n",
      "        [ 0.0273],\n",
      "        [ 0.0695],\n",
      "        [ 0.0195],\n",
      "        [ 0.0246],\n",
      "        [-0.0035],\n",
      "        [-0.0494],\n",
      "        [ 0.0273],\n",
      "        [-0.0438],\n",
      "        [ 0.0138],\n",
      "        [ 0.0134],\n",
      "        [ 0.0205]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0710, 0.0718, 0.0726, 0.0733, 0.0731, 0.0727, 0.0730, 0.0730, 0.0746,\n",
      "        0.0738, 0.0740, 0.0740, 0.0742, 0.0731, 0.0723, 0.0717, 0.0717, 0.0708,\n",
      "        0.0705, 0.0707, 0.0719, 0.0711, 0.0705, 0.0702, 0.0715, 0.0725, 0.0719,\n",
      "        0.0703, 0.0714, 0.0713, 0.0709, 0.0720], device='cuda:0')\n",
      "tensor([[-0.0116],\n",
      "        [ 0.0014],\n",
      "        [ 0.0120],\n",
      "        [-0.0236],\n",
      "        [-0.0338],\n",
      "        [-0.0342],\n",
      "        [ 0.0072],\n",
      "        [-0.0036],\n",
      "        [-0.0039],\n",
      "        [-0.0259],\n",
      "        [ 0.0605],\n",
      "        [ 0.0119],\n",
      "        [ 0.0452],\n",
      "        [-0.0248],\n",
      "        [ 0.0120],\n",
      "        [ 0.0003],\n",
      "        [-0.0211],\n",
      "        [ 0.0159],\n",
      "        [ 0.0952],\n",
      "        [-0.0582],\n",
      "        [-0.0415],\n",
      "        [ 0.0087],\n",
      "        [ 0.0561],\n",
      "        [ 0.0105],\n",
      "        [-0.0102],\n",
      "        [-0.0182],\n",
      "        [-0.0168],\n",
      "        [-0.0091],\n",
      "        [-0.0388],\n",
      "        [ 0.0137],\n",
      "        [-0.0321],\n",
      "        [ 0.0286]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0714, 0.0727, 0.0739, 0.0743, 0.0754, 0.0757, 0.0759, 0.0761, 0.0761,\n",
      "        0.0741, 0.0747, 0.0750, 0.0748, 0.0739, 0.0735, 0.0741, 0.0735, 0.0731,\n",
      "        0.0723, 0.0735, 0.0751, 0.0746, 0.0749, 0.0744, 0.0745, 0.0746, 0.0742,\n",
      "        0.0740, 0.0734, 0.0734, 0.0730, 0.0732], device='cuda:0')\n",
      "tensor([[ 0.0081],\n",
      "        [ 0.0344],\n",
      "        [-0.0414],\n",
      "        [ 0.0930],\n",
      "        [-0.0195],\n",
      "        [ 0.0384],\n",
      "        [-0.0134],\n",
      "        [-0.0151],\n",
      "        [ 0.0508],\n",
      "        [ 0.0546],\n",
      "        [ 0.0030],\n",
      "        [-0.0374],\n",
      "        [-0.0658],\n",
      "        [-0.0490],\n",
      "        [-0.0943],\n",
      "        [-0.0816],\n",
      "        [ 0.0690],\n",
      "        [-0.0400],\n",
      "        [ 0.0056],\n",
      "        [-0.0103],\n",
      "        [ 0.0473],\n",
      "        [ 0.0129],\n",
      "        [-0.0192],\n",
      "        [ 0.0009],\n",
      "        [ 0.0084],\n",
      "        [-0.0466],\n",
      "        [ 0.0163],\n",
      "        [ 0.0097],\n",
      "        [ 0.0859],\n",
      "        [ 0.0012],\n",
      "        [ 0.0771],\n",
      "        [-0.0139]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0733, 0.0740, 0.0752, 0.0761, 0.0761, 0.0750, 0.0745, 0.0742, 0.0732,\n",
      "        0.0736, 0.0724, 0.0725, 0.0728, 0.0730, 0.0744, 0.0749, 0.0747, 0.0739,\n",
      "        0.0745, 0.0747, 0.0754, 0.0776, 0.0773, 0.0788, 0.0790, 0.0794, 0.0795,\n",
      "        0.0807, 0.0807, 0.0812, 0.0810, 0.0800], device='cuda:0')\n",
      "tensor([[ 0.1561],\n",
      "        [ 0.0385],\n",
      "        [ 0.0094],\n",
      "        [ 0.0282],\n",
      "        [-0.0414],\n",
      "        [-0.0035],\n",
      "        [-0.0483],\n",
      "        [-0.0246],\n",
      "        [-0.0378],\n",
      "        [-0.0532],\n",
      "        [ 0.0055],\n",
      "        [ 0.0067],\n",
      "        [ 0.0188],\n",
      "        [ 0.0030],\n",
      "        [ 0.0013],\n",
      "        [-0.0152],\n",
      "        [ 0.0227],\n",
      "        [ 0.0038],\n",
      "        [-0.0450],\n",
      "        [ 0.0094],\n",
      "        [ 0.0047],\n",
      "        [ 0.0654],\n",
      "        [-0.0483],\n",
      "        [-0.0072],\n",
      "        [-0.0370],\n",
      "        [ 0.0131],\n",
      "        [ 0.0163],\n",
      "        [-0.0615],\n",
      "        [-0.0350],\n",
      "        [ 0.0214],\n",
      "        [ 0.0012],\n",
      "        [-0.0358]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0790, 0.0783, 0.0779, 0.0777, 0.0782, 0.0783, 0.0769, 0.0766, 0.0762,\n",
      "        0.0773, 0.0771, 0.0772, 0.0767, 0.0763, 0.0755, 0.0751, 0.0749, 0.0744,\n",
      "        0.0740, 0.0747, 0.0751, 0.0747, 0.0743, 0.0745, 0.0753, 0.0751, 0.0748,\n",
      "        0.0748, 0.0748, 0.0768, 0.0762, 0.0767], device='cuda:0')\n",
      "tensor([[-0.0201],\n",
      "        [-0.0112],\n",
      "        [ 0.0364],\n",
      "        [ 0.0323],\n",
      "        [ 0.0703],\n",
      "        [ 0.0278],\n",
      "        [ 0.0557],\n",
      "        [-0.0148],\n",
      "        [-0.0353],\n",
      "        [-0.0389],\n",
      "        [-0.0567],\n",
      "        [-0.0602],\n",
      "        [-0.0378],\n",
      "        [-0.0528],\n",
      "        [-0.0543],\n",
      "        [ 0.0441],\n",
      "        [-0.0700],\n",
      "        [ 0.0016],\n",
      "        [ 0.0145],\n",
      "        [-0.0180],\n",
      "        [ 0.0463],\n",
      "        [ 0.0239],\n",
      "        [-0.0217],\n",
      "        [-0.0032],\n",
      "        [ 0.0184],\n",
      "        [ 0.0117],\n",
      "        [-0.0361],\n",
      "        [ 0.0044],\n",
      "        [ 0.0809],\n",
      "        [ 0.0020],\n",
      "        [ 0.0167],\n",
      "        [ 0.0251]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0764, 0.0768, 0.0760, 0.0740, 0.0755, 0.0753, 0.0738, 0.0730, 0.0715,\n",
      "        0.0702, 0.0668, 0.0682, 0.0702, 0.0701, 0.0721, 0.0730, 0.0727, 0.0713,\n",
      "        0.0699, 0.0702, 0.0704, 0.0718, 0.0727, 0.0731, 0.0723, 0.0707, 0.0696,\n",
      "        0.0685, 0.0686, 0.0697, 0.0724, 0.0715], device='cuda:0')\n",
      "tensor([[-0.0752],\n",
      "        [ 0.0443],\n",
      "        [ 0.0033],\n",
      "        [ 0.0297],\n",
      "        [-0.0362],\n",
      "        [ 0.0253],\n",
      "        [ 0.0568],\n",
      "        [-0.0190],\n",
      "        [-0.0124],\n",
      "        [ 0.0149],\n",
      "        [-0.0286],\n",
      "        [ 0.0156],\n",
      "        [-0.0151],\n",
      "        [ 0.0056],\n",
      "        [-0.0240],\n",
      "        [ 0.0274],\n",
      "        [ 0.0912],\n",
      "        [ 0.0464],\n",
      "        [ 0.0542],\n",
      "        [ 0.0137],\n",
      "        [ 0.0449],\n",
      "        [-0.0261],\n",
      "        [-0.0207],\n",
      "        [-0.0043],\n",
      "        [ 0.0049],\n",
      "        [-0.0188],\n",
      "        [-0.0741],\n",
      "        [-0.0327],\n",
      "        [-0.0557],\n",
      "        [ 0.0555],\n",
      "        [ 0.0050],\n",
      "        [-0.0460]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0717, 0.0714, 0.0717, 0.0722, 0.0738, 0.0726, 0.0718, 0.0710, 0.0721,\n",
      "        0.0731, 0.0747, 0.0753, 0.0747, 0.0745, 0.0744, 0.0759, 0.0762, 0.0750,\n",
      "        0.0743, 0.0741, 0.0748, 0.0739, 0.0728, 0.0727, 0.0718, 0.0730, 0.0732,\n",
      "        0.0750, 0.0757, 0.0773, 0.0774, 0.0780], device='cuda:0')\n",
      "tensor([[-0.0520],\n",
      "        [-0.0083],\n",
      "        [-0.0280],\n",
      "        [-0.0188],\n",
      "        [-0.0199],\n",
      "        [ 0.0489],\n",
      "        [-0.0206],\n",
      "        [-0.0026],\n",
      "        [ 0.0247],\n",
      "        [-0.0023],\n",
      "        [-0.0443],\n",
      "        [-0.0290],\n",
      "        [ 0.0154],\n",
      "        [ 0.0126],\n",
      "        [-0.0220],\n",
      "        [-0.0060],\n",
      "        [ 0.0117],\n",
      "        [ 0.0048],\n",
      "        [ 0.0006],\n",
      "        [ 0.0197],\n",
      "        [-0.0333],\n",
      "        [-0.0266],\n",
      "        [ 0.0532],\n",
      "        [ 0.0467],\n",
      "        [-0.0223],\n",
      "        [ 0.1473],\n",
      "        [-0.0509],\n",
      "        [-0.0060],\n",
      "        [-0.0156],\n",
      "        [ 0.0073],\n",
      "        [-0.0416],\n",
      "        [ 0.0240]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0796, 0.0796, 0.0793, 0.0779, 0.0788, 0.0799, 0.0807, 0.0805, 0.0809,\n",
      "        0.0820, 0.0844, 0.0837, 0.0856, 0.0837, 0.0841, 0.0850, 0.0844, 0.0836,\n",
      "        0.0820, 0.0822, 0.0823, 0.0841, 0.0843, 0.0840, 0.0861, 0.0866, 0.0872,\n",
      "        0.0860, 0.0850, 0.0849, 0.0863, 0.0855], device='cuda:0')\n",
      "tensor([[ 0.0405],\n",
      "        [ 0.0006],\n",
      "        [-0.0660],\n",
      "        [ 0.0410],\n",
      "        [-0.0584],\n",
      "        [ 0.0127],\n",
      "        [ 0.0104],\n",
      "        [-0.0814],\n",
      "        [ 0.0797],\n",
      "        [-0.0342],\n",
      "        [ 0.0193],\n",
      "        [ 0.0068],\n",
      "        [-0.0123],\n",
      "        [-0.0177],\n",
      "        [-0.0003],\n",
      "        [ 0.0059],\n",
      "        [-0.0177],\n",
      "        [ 0.0231],\n",
      "        [ 0.0457],\n",
      "        [-0.0254],\n",
      "        [ 0.0242],\n",
      "        [ 0.0095],\n",
      "        [ 0.0013],\n",
      "        [ 0.0307],\n",
      "        [ 0.0291],\n",
      "        [ 0.0223],\n",
      "        [ 0.0845],\n",
      "        [-0.0238],\n",
      "        [ 0.0107],\n",
      "        [-0.0196],\n",
      "        [-0.0117],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0856, 0.0831, 0.0825, 0.0806, 0.0826, 0.0816, 0.0851, 0.0843, 0.0840,\n",
      "        0.0849, 0.0848, 0.0845, 0.0852, 0.0858, 0.0867, 0.0856, 0.0855, 0.0841,\n",
      "        0.0841, 0.0824, 0.0812, 0.0818, 0.0829, 0.0840, 0.0833, 0.0843, 0.0826,\n",
      "        0.0818, 0.0809, 0.0806, 0.0806, 0.0807], device='cuda:0')\n",
      "tensor([[-0.0286],\n",
      "        [-0.0309],\n",
      "        [-0.0118],\n",
      "        [ 0.0005],\n",
      "        [-0.0033],\n",
      "        [ 0.0170],\n",
      "        [ 0.0321],\n",
      "        [ 0.0192],\n",
      "        [ 0.0285],\n",
      "        [ 0.0097],\n",
      "        [-0.0366],\n",
      "        [-0.0350],\n",
      "        [-0.0105],\n",
      "        [ 0.0116],\n",
      "        [-0.0123],\n",
      "        [-0.0038],\n",
      "        [-0.0895],\n",
      "        [-0.0607],\n",
      "        [-0.0592],\n",
      "        [-0.0754],\n",
      "        [ 0.0048],\n",
      "        [ 0.0430],\n",
      "        [ 0.1379],\n",
      "        [ 0.1471],\n",
      "        [ 0.0020],\n",
      "        [ 0.0006],\n",
      "        [-0.0052],\n",
      "        [ 0.0156],\n",
      "        [ 0.0052],\n",
      "        [-0.0646],\n",
      "        [-0.0972],\n",
      "        [ 0.0235]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0822, 0.0833, 0.0823, 0.0828, 0.0822, 0.0812, 0.0811, 0.0828, 0.0820,\n",
      "        0.0812, 0.0788, 0.0770, 0.0775, 0.0764, 0.0771, 0.0788, 0.0788, 0.0809,\n",
      "        0.0803, 0.0792, 0.0804, 0.0785, 0.0777, 0.0765, 0.0743, 0.0752, 0.0752,\n",
      "        0.0745, 0.0726, 0.0721, 0.0728, 0.0728], device='cuda:0')\n",
      "tensor([[ 0.0500],\n",
      "        [-0.0055],\n",
      "        [-0.0686],\n",
      "        [ 0.0201],\n",
      "        [ 0.0465],\n",
      "        [ 0.0206],\n",
      "        [ 0.0275],\n",
      "        [ 0.0827],\n",
      "        [ 0.0214],\n",
      "        [-0.0171],\n",
      "        [-0.0592],\n",
      "        [-0.0572],\n",
      "        [-0.0515],\n",
      "        [ 0.0112],\n",
      "        [ 0.0129],\n",
      "        [ 0.0232],\n",
      "        [ 0.0573],\n",
      "        [ 0.1300],\n",
      "        [ 0.0178],\n",
      "        [ 0.0076],\n",
      "        [-0.0635],\n",
      "        [-0.0540],\n",
      "        [-0.0601],\n",
      "        [-0.0233],\n",
      "        [-0.0397],\n",
      "        [ 0.0009],\n",
      "        [-0.0023],\n",
      "        [-0.0020],\n",
      "        [-0.0370],\n",
      "        [-0.0029],\n",
      "        [-0.0034],\n",
      "        [-0.0179]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0753, 0.0771, 0.0762, 0.0749, 0.0736, 0.0722, 0.0722, 0.0743, 0.0737,\n",
      "        0.0758, 0.0764, 0.0761, 0.0779, 0.0780, 0.0755, 0.0747, 0.0734, 0.0746,\n",
      "        0.0756, 0.0739, 0.0742, 0.0719, 0.0731, 0.0732, 0.0751, 0.0743, 0.0708,\n",
      "        0.0688, 0.0693, 0.0694, 0.0709, 0.0734], device='cuda:0')\n",
      "tensor([[-0.0575],\n",
      "        [ 0.0156],\n",
      "        [-0.0868],\n",
      "        [-0.0394],\n",
      "        [ 0.0248],\n",
      "        [ 0.1205],\n",
      "        [-0.0010],\n",
      "        [-0.0201],\n",
      "        [ 0.1015],\n",
      "        [ 0.0075],\n",
      "        [-0.0270],\n",
      "        [-0.0033],\n",
      "        [-0.0122],\n",
      "        [-0.0271],\n",
      "        [ 0.0079],\n",
      "        [-0.0323],\n",
      "        [ 0.0272],\n",
      "        [ 0.0365],\n",
      "        [ 0.0728],\n",
      "        [-0.0257],\n",
      "        [ 0.0058],\n",
      "        [-0.0051],\n",
      "        [-0.0603],\n",
      "        [-0.0030],\n",
      "        [-0.0418],\n",
      "        [-0.0416],\n",
      "        [-0.0751],\n",
      "        [-0.0452],\n",
      "        [-0.0427],\n",
      "        [ 0.0406],\n",
      "        [-0.0072],\n",
      "        [-0.0380]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0752, 0.0733, 0.0722, 0.0749, 0.0722, 0.0735, 0.0737, 0.0737, 0.0731,\n",
      "        0.0728, 0.0749, 0.0748, 0.0746, 0.0754, 0.0736, 0.0727, 0.0731, 0.0727,\n",
      "        0.0725, 0.0717, 0.0705, 0.0703, 0.0697, 0.0697, 0.0692, 0.0700, 0.0694,\n",
      "        0.0694, 0.0692, 0.0686, 0.0686, 0.0691], device='cuda:0')\n",
      "tensor([[ 0.0211],\n",
      "        [ 0.0016],\n",
      "        [-0.0146],\n",
      "        [-0.0081],\n",
      "        [-0.0121],\n",
      "        [-0.0028],\n",
      "        [ 0.1220],\n",
      "        [-0.0065],\n",
      "        [-0.0027],\n",
      "        [ 0.0974],\n",
      "        [-0.0102],\n",
      "        [-0.0910],\n",
      "        [-0.0030],\n",
      "        [-0.0581],\n",
      "        [ 0.0135],\n",
      "        [-0.0846],\n",
      "        [-0.0811],\n",
      "        [ 0.0212],\n",
      "        [-0.0348],\n",
      "        [-0.0188],\n",
      "        [ 0.0404],\n",
      "        [-0.0332],\n",
      "        [ 0.0126],\n",
      "        [ 0.0019],\n",
      "        [ 0.1197],\n",
      "        [-0.0808],\n",
      "        [ 0.0353],\n",
      "        [-0.0263],\n",
      "        [ 0.0098],\n",
      "        [-0.0051],\n",
      "        [ 0.0322],\n",
      "        [-0.0177]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0688, 0.0706, 0.0705, 0.0705, 0.0702, 0.0696, 0.0684, 0.0686, 0.0688,\n",
      "        0.0681, 0.0673, 0.0652, 0.0665, 0.0670, 0.0687, 0.0610, 0.0573, 0.0607,\n",
      "        0.0601, 0.0575, 0.0550, 0.0573, 0.0576, 0.0575, 0.0569, 0.0568, 0.0562,\n",
      "        0.0541, 0.0550, 0.0573, 0.0580, 0.0580], device='cuda:0')\n",
      "tensor([[-0.0989],\n",
      "        [-0.0575],\n",
      "        [ 0.0154],\n",
      "        [-0.0510],\n",
      "        [-0.0348],\n",
      "        [-0.0877],\n",
      "        [ 0.0312],\n",
      "        [ 0.1095],\n",
      "        [ 0.0050],\n",
      "        [ 0.0530],\n",
      "        [ 0.0016],\n",
      "        [ 0.0080],\n",
      "        [-0.0107],\n",
      "        [-0.0074],\n",
      "        [ 0.0197],\n",
      "        [ 0.0224],\n",
      "        [-0.0465],\n",
      "        [ 0.0397],\n",
      "        [-0.0094],\n",
      "        [-0.0388],\n",
      "        [-0.0378],\n",
      "        [-0.0440],\n",
      "        [ 0.0006],\n",
      "        [-0.0354],\n",
      "        [ 0.0299],\n",
      "        [ 0.0070],\n",
      "        [-0.0164],\n",
      "        [-0.0300],\n",
      "        [-0.0198],\n",
      "        [ 0.0271],\n",
      "        [-0.0067],\n",
      "        [-0.0072]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0616, 0.0637, 0.0640, 0.0632, 0.0639, 0.0643, 0.0656, 0.0668, 0.0634,\n",
      "        0.0652, 0.0656, 0.0660, 0.0650, 0.0649, 0.0629, 0.0635, 0.0638, 0.0635,\n",
      "        0.0624, 0.0622, 0.0624, 0.0640, 0.0629, 0.0646, 0.0663, 0.0655, 0.0634,\n",
      "        0.0647, 0.0622, 0.0610, 0.0624, 0.0612], device='cuda:0')\n",
      "tensor([[ 0.0106],\n",
      "        [-0.0673],\n",
      "        [ 0.0424],\n",
      "        [-0.0333],\n",
      "        [-0.0089],\n",
      "        [-0.0739],\n",
      "        [ 0.0109],\n",
      "        [ 0.0024],\n",
      "        [-0.0202],\n",
      "        [-0.0010],\n",
      "        [ 0.0129],\n",
      "        [-0.0336],\n",
      "        [-0.0586],\n",
      "        [ 0.0016],\n",
      "        [ 0.0292],\n",
      "        [ 0.0802],\n",
      "        [-0.0156],\n",
      "        [-0.0335],\n",
      "        [-0.0355],\n",
      "        [ 0.0297],\n",
      "        [ 0.0694],\n",
      "        [ 0.0284],\n",
      "        [ 0.0046],\n",
      "        [ 0.0150],\n",
      "        [-0.0522],\n",
      "        [ 0.0239],\n",
      "        [ 0.0481],\n",
      "        [ 0.0053],\n",
      "        [-0.0300],\n",
      "        [ 0.0329],\n",
      "        [-0.0048],\n",
      "        [-0.0408]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0593, 0.0585, 0.0602, 0.0593, 0.0590, 0.0570, 0.0561, 0.0555, 0.0577,\n",
      "        0.0590, 0.0584, 0.0550, 0.0547, 0.0551, 0.0533, 0.0516, 0.0544, 0.0548,\n",
      "        0.0525, 0.0517, 0.0508, 0.0541, 0.0560, 0.0543, 0.0536, 0.0524, 0.0514,\n",
      "        0.0488, 0.0478, 0.0480, 0.0480, 0.0483], device='cuda:0')\n",
      "tensor([[-6.4286e-02],\n",
      "        [-1.1277e-01],\n",
      "        [ 5.6052e-02],\n",
      "        [-5.9715e-02],\n",
      "        [ 2.6440e-02],\n",
      "        [-3.8345e-02],\n",
      "        [ 6.5600e-02],\n",
      "        [ 1.4190e-02],\n",
      "        [-1.6655e-02],\n",
      "        [ 1.2533e-01],\n",
      "        [ 3.6360e-02],\n",
      "        [ 2.8702e-02],\n",
      "        [-3.4787e-02],\n",
      "        [ 2.5337e-02],\n",
      "        [-1.2001e-03],\n",
      "        [-1.4115e-03],\n",
      "        [ 5.0902e-03],\n",
      "        [-4.0981e-02],\n",
      "        [-5.3002e-02],\n",
      "        [-2.2835e-02],\n",
      "        [-1.4967e-02],\n",
      "        [-4.1403e-02],\n",
      "        [ 4.2634e-04],\n",
      "        [-4.3875e-02],\n",
      "        [-1.0877e-02],\n",
      "        [-1.4391e-02],\n",
      "        [ 1.5194e-03],\n",
      "        [ 2.6574e-02],\n",
      "        [ 2.5940e-02],\n",
      "        [ 1.2416e-02],\n",
      "        [-1.2140e-04],\n",
      "        [ 3.1851e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0516, 0.0507, 0.0513, 0.0527, 0.0548, 0.0533, 0.0531, 0.0545, 0.0539,\n",
      "        0.0535, 0.0536, 0.0529, 0.0525, 0.0534, 0.0531, 0.0519, 0.0507, 0.0506,\n",
      "        0.0508, 0.0505, 0.0495, 0.0480, 0.0481, 0.0484, 0.0476, 0.0497, 0.0491,\n",
      "        0.0502, 0.0508, 0.0505, 0.0503, 0.0509], device='cuda:0')\n",
      "tensor([[ 0.0417],\n",
      "        [-0.0004],\n",
      "        [ 0.0024],\n",
      "        [-0.0159],\n",
      "        [ 0.0096],\n",
      "        [ 0.0068],\n",
      "        [ 0.0028],\n",
      "        [-0.0319],\n",
      "        [ 0.0174],\n",
      "        [ 0.0155],\n",
      "        [ 0.0020],\n",
      "        [-0.0138],\n",
      "        [ 0.0105],\n",
      "        [ 0.0139],\n",
      "        [-0.0072],\n",
      "        [-0.0079],\n",
      "        [-0.0106],\n",
      "        [ 0.0721],\n",
      "        [ 0.0110],\n",
      "        [-0.0778],\n",
      "        [-0.0875],\n",
      "        [-0.0429],\n",
      "        [-0.0790],\n",
      "        [-0.0139],\n",
      "        [ 0.0193],\n",
      "        [ 0.0193],\n",
      "        [-0.0338],\n",
      "        [ 0.0344],\n",
      "        [ 0.1282],\n",
      "        [ 0.0619],\n",
      "        [-0.0503],\n",
      "        [ 0.0055]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0507, 0.0510, 0.0504, 0.0506, 0.0521, 0.0528, 0.0515, 0.0517, 0.0535,\n",
      "        0.0544, 0.0545, 0.0542, 0.0543, 0.0538, 0.0533, 0.0534, 0.0525, 0.0526,\n",
      "        0.0538, 0.0545, 0.0528, 0.0515, 0.0503, 0.0486, 0.0498, 0.0514, 0.0516,\n",
      "        0.0497, 0.0488, 0.0495, 0.0487, 0.0485], device='cuda:0')\n",
      "tensor([[ 0.0137],\n",
      "        [-0.0107],\n",
      "        [-0.0035],\n",
      "        [-0.0099],\n",
      "        [-0.0777],\n",
      "        [-0.0287],\n",
      "        [ 0.0374],\n",
      "        [ 0.0217],\n",
      "        [ 0.0092],\n",
      "        [ 0.0288],\n",
      "        [-0.0021],\n",
      "        [-0.0010],\n",
      "        [ 0.0435],\n",
      "        [-0.1083],\n",
      "        [-0.0045],\n",
      "        [-0.0358],\n",
      "        [-0.0065],\n",
      "        [ 0.0603],\n",
      "        [ 0.0595],\n",
      "        [ 0.0198],\n",
      "        [ 0.0029],\n",
      "        [ 0.0333],\n",
      "        [-0.0105],\n",
      "        [-0.0205],\n",
      "        [ 0.0024],\n",
      "        [ 0.0043],\n",
      "        [-0.0312],\n",
      "        [-0.0162],\n",
      "        [-0.0486],\n",
      "        [ 0.0162],\n",
      "        [-0.0387],\n",
      "        [ 0.0074]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0488, 0.0499, 0.0499, 0.0501, 0.0491, 0.0488, 0.0478, 0.0467, 0.0462,\n",
      "        0.0473, 0.0470, 0.0478, 0.0486, 0.0484, 0.0475, 0.0469, 0.0481, 0.0474,\n",
      "        0.0488, 0.0469, 0.0461, 0.0466, 0.0464, 0.0457, 0.0452, 0.0452, 0.0449,\n",
      "        0.0445, 0.0446, 0.0453, 0.0448, 0.0429], device='cuda:0')\n",
      "tensor([[-0.0646],\n",
      "        [-0.0435],\n",
      "        [ 0.0025],\n",
      "        [-0.0223],\n",
      "        [ 0.0337],\n",
      "        [-0.0325],\n",
      "        [-0.0269],\n",
      "        [-0.0267],\n",
      "        [ 0.0113],\n",
      "        [ 0.0499],\n",
      "        [ 0.1174],\n",
      "        [ 0.1252],\n",
      "        [ 0.0202],\n",
      "        [ 0.0303],\n",
      "        [-0.0108],\n",
      "        [-0.0085],\n",
      "        [-0.1306],\n",
      "        [ 0.0133],\n",
      "        [-0.0269],\n",
      "        [ 0.0333],\n",
      "        [-0.0446],\n",
      "        [-0.0201],\n",
      "        [ 0.0180],\n",
      "        [ 0.0247],\n",
      "        [-0.0188],\n",
      "        [-0.0205],\n",
      "        [ 0.0195],\n",
      "        [ 0.0184],\n",
      "        [ 0.0141],\n",
      "        [-0.0330],\n",
      "        [ 0.0059],\n",
      "        [-0.0625]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0440, 0.0435, 0.0454, 0.0458, 0.0458, 0.0479, 0.0484, 0.0487, 0.0476,\n",
      "        0.0471, 0.0479, 0.0465, 0.0453, 0.0445, 0.0446, 0.0438, 0.0436, 0.0444,\n",
      "        0.0461, 0.0446, 0.0433, 0.0435, 0.0435, 0.0432, 0.0427, 0.0415, 0.0395,\n",
      "        0.0403, 0.0391, 0.0394, 0.0442, 0.0454], device='cuda:0')\n",
      "tensor([[-0.0703],\n",
      "        [-0.0557],\n",
      "        [-0.0058],\n",
      "        [-0.0261],\n",
      "        [ 0.0284],\n",
      "        [ 0.0287],\n",
      "        [ 0.1195],\n",
      "        [-0.0258],\n",
      "        [-0.0216],\n",
      "        [-0.0005],\n",
      "        [-0.0043],\n",
      "        [ 0.0165],\n",
      "        [-0.0348],\n",
      "        [-0.0299],\n",
      "        [-0.1020],\n",
      "        [ 0.0396],\n",
      "        [-0.1086],\n",
      "        [ 0.0425],\n",
      "        [ 0.0177],\n",
      "        [-0.0070],\n",
      "        [ 0.0053],\n",
      "        [ 0.0453],\n",
      "        [ 0.0151],\n",
      "        [ 0.0388],\n",
      "        [-0.0024],\n",
      "        [ 0.0183],\n",
      "        [-0.0861],\n",
      "        [-0.0281],\n",
      "        [ 0.0035],\n",
      "        [-0.0636],\n",
      "        [-0.0146],\n",
      "        [ 0.0309]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0438, 0.0450, 0.0448, 0.0450, 0.0456, 0.0463, 0.0460, 0.0441, 0.0416,\n",
      "        0.0407, 0.0420, 0.0402, 0.0403, 0.0400, 0.0410, 0.0424, 0.0441, 0.0423,\n",
      "        0.0423, 0.0407, 0.0404, 0.0398, 0.0398, 0.0393, 0.0388, 0.0397, 0.0374,\n",
      "        0.0376, 0.0368, 0.0379, 0.0374, 0.0372], device='cuda:0')\n",
      "tensor([[ 1.4684e-02],\n",
      "        [ 9.8732e-03],\n",
      "        [-4.2267e-03],\n",
      "        [-1.9929e-02],\n",
      "        [ 2.8687e-03],\n",
      "        [-1.5140e-02],\n",
      "        [ 2.9729e-02],\n",
      "        [-4.6779e-02],\n",
      "        [-3.6746e-02],\n",
      "        [-7.9675e-03],\n",
      "        [ 1.1031e-02],\n",
      "        [ 3.7510e-02],\n",
      "        [-2.6464e-02],\n",
      "        [ 8.1163e-03],\n",
      "        [-6.5472e-02],\n",
      "        [-7.6802e-02],\n",
      "        [ 3.9294e-03],\n",
      "        [ 8.4114e-03],\n",
      "        [-7.6820e-02],\n",
      "        [ 9.4947e-02],\n",
      "        [-1.8692e-03],\n",
      "        [ 2.2341e-02],\n",
      "        [-2.9939e-02],\n",
      "        [-4.0533e-02],\n",
      "        [-3.8026e-02],\n",
      "        [-5.8531e-02],\n",
      "        [-9.9889e-03],\n",
      "        [-9.6779e-05],\n",
      "        [-3.0166e-02],\n",
      "        [ 1.0999e-02],\n",
      "        [-5.8116e-04],\n",
      "        [ 4.5940e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0364, 0.0374, 0.0349, 0.0339, 0.0345, 0.0336, 0.0318, 0.0314, 0.0295,\n",
      "        0.0269, 0.0256, 0.0279, 0.0285, 0.0299, 0.0311, 0.0314, 0.0307, 0.0300,\n",
      "        0.0294, 0.0291, 0.0282, 0.0277, 0.0280, 0.0278, 0.0273, 0.0269, 0.0292,\n",
      "        0.0286, 0.0315, 0.0327, 0.0333, 0.0336], device='cuda:0')\n",
      "tensor([[ 0.0080],\n",
      "        [ 0.0194],\n",
      "        [-0.0249],\n",
      "        [-0.0031],\n",
      "        [ 0.0245],\n",
      "        [ 0.0438],\n",
      "        [ 0.0144],\n",
      "        [ 0.0083],\n",
      "        [-0.0266],\n",
      "        [ 0.0105],\n",
      "        [ 0.0498],\n",
      "        [-0.0085],\n",
      "        [ 0.0364],\n",
      "        [-0.0769],\n",
      "        [-0.0194],\n",
      "        [-0.0415],\n",
      "        [ 0.0429],\n",
      "        [-0.0153],\n",
      "        [ 0.0451],\n",
      "        [ 0.0290],\n",
      "        [-0.0208],\n",
      "        [-0.0095],\n",
      "        [ 0.0138],\n",
      "        [-0.0317],\n",
      "        [-0.0178],\n",
      "        [-0.0059],\n",
      "        [-0.0112],\n",
      "        [ 0.0397],\n",
      "        [-0.0331],\n",
      "        [-0.0900],\n",
      "        [ 0.0822],\n",
      "        [ 0.0448]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0331, 0.0330, 0.0339, 0.0351, 0.0376, 0.0362, 0.0345, 0.0342, 0.0331,\n",
      "        0.0341, 0.0373, 0.0377, 0.0366, 0.0373, 0.0367, 0.0386, 0.0350, 0.0360,\n",
      "        0.0370, 0.0368, 0.0353, 0.0353, 0.0345, 0.0339, 0.0321, 0.0308, 0.0305,\n",
      "        0.0314, 0.0311, 0.0321, 0.0330, 0.0333], device='cuda:0')\n",
      "tensor([[ 0.0624],\n",
      "        [ 0.0076],\n",
      "        [ 0.0141],\n",
      "        [-0.0177],\n",
      "        [-0.0062],\n",
      "        [ 0.0089],\n",
      "        [ 0.0203],\n",
      "        [-0.0427],\n",
      "        [-0.0435],\n",
      "        [-0.0997],\n",
      "        [ 0.1475],\n",
      "        [ 0.0019],\n",
      "        [ 0.0539],\n",
      "        [-0.0039],\n",
      "        [ 0.0063],\n",
      "        [-0.0308],\n",
      "        [-0.0359],\n",
      "        [ 0.0263],\n",
      "        [-0.0187],\n",
      "        [ 0.0137],\n",
      "        [ 0.0255],\n",
      "        [ 0.0205],\n",
      "        [-0.0706],\n",
      "        [ 0.0258],\n",
      "        [-0.0746],\n",
      "        [ 0.0292],\n",
      "        [ 0.0393],\n",
      "        [-0.0019],\n",
      "        [ 0.0167],\n",
      "        [ 0.0356],\n",
      "        [-0.0042],\n",
      "        [-0.0322]], device='cuda:0', grad_fn=<AddmmBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([0.0331, 0.0311, 0.0304, 0.0308, 0.0298, 0.0293, 0.0305, 0.0315, 0.0314,\n",
      "        0.0308, 0.0301, 0.0295, 0.0314, 0.0309, 0.0306, 0.0308, 0.0297, 0.0301,\n",
      "        0.0294, 0.0286, 0.0292, 0.0303, 0.0306, 0.0302, 0.0299, 0.0297, 0.0289,\n",
      "        0.0305, 0.0313, 0.0307, 0.0304, 0.0290], device='cuda:0')\n",
      "tensor([[-0.0432],\n",
      "        [-0.0237],\n",
      "        [-0.0151],\n",
      "        [ 0.0261],\n",
      "        [-0.0234],\n",
      "        [ 0.0431],\n",
      "        [ 0.0925],\n",
      "        [ 0.0161],\n",
      "        [ 0.0638],\n",
      "        [ 0.0143],\n",
      "        [-0.0451],\n",
      "        [-0.0396],\n",
      "        [-0.0638],\n",
      "        [ 0.0299],\n",
      "        [ 0.0743],\n",
      "        [ 0.0622],\n",
      "        [ 0.0484],\n",
      "        [ 0.0148],\n",
      "        [-0.0076],\n",
      "        [ 0.0626],\n",
      "        [ 0.0119],\n",
      "        [ 0.0140],\n",
      "        [ 0.0126],\n",
      "        [-0.0257],\n",
      "        [-0.0170],\n",
      "        [ 0.0049],\n",
      "        [ 0.0059],\n",
      "        [-0.0087],\n",
      "        [-0.0122],\n",
      "        [-0.0444],\n",
      "        [ 0.0018],\n",
      "        [-0.0608]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0282, 0.0274, 0.0280, 0.0279, 0.0290, 0.0288, 0.0288, 0.0288, 0.0338,\n",
      "        0.0360, 0.0347, 0.0363, 0.0377, 0.0373, 0.0397, 0.0386, 0.0391, 0.0394,\n",
      "        0.0402, 0.0428, 0.0443, 0.0457, 0.0433, 0.0450, 0.0450, 0.0452, 0.0433,\n",
      "        0.0420, 0.0433, 0.0434, 0.0443, 0.0457], device='cuda:0')\n",
      "tensor([[-0.0165],\n",
      "        [-0.0100],\n",
      "        [-0.0146],\n",
      "        [-0.0268],\n",
      "        [ 0.0674],\n",
      "        [-0.0354],\n",
      "        [ 0.0073],\n",
      "        [ 0.0643],\n",
      "        [-0.0075],\n",
      "        [ 0.0003],\n",
      "        [-0.0180],\n",
      "        [-0.0172],\n",
      "        [-0.0128],\n",
      "        [-0.0074],\n",
      "        [ 0.0059],\n",
      "        [-0.0025],\n",
      "        [ 0.0236],\n",
      "        [ 0.0195],\n",
      "        [-0.0118],\n",
      "        [ 0.0320],\n",
      "        [ 0.0107],\n",
      "        [-0.0357],\n",
      "        [ 0.0215],\n",
      "        [ 0.0098],\n",
      "        [-0.0043],\n",
      "        [ 0.0200],\n",
      "        [ 0.0324],\n",
      "        [-0.0550],\n",
      "        [ 0.0487],\n",
      "        [ 0.0147],\n",
      "        [ 0.0271],\n",
      "        [ 0.0128]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0440, 0.0443, 0.0455, 0.0448, 0.0455, 0.0443, 0.0436, 0.0448, 0.0443,\n",
      "        0.0453, 0.0441, 0.0440, 0.0426, 0.0425, 0.0411, 0.0427, 0.0427, 0.0420,\n",
      "        0.0417, 0.0416, 0.0409, 0.0392, 0.0392, 0.0391, 0.0402, 0.0426, 0.0422,\n",
      "        0.0412, 0.0426, 0.0426, 0.0435, 0.0435], device='cuda:0')\n",
      "tensor([[-0.0315],\n",
      "        [ 0.0108],\n",
      "        [ 0.0272],\n",
      "        [-0.0232],\n",
      "        [-0.0217],\n",
      "        [-0.0016],\n",
      "        [-0.0051],\n",
      "        [-0.0029],\n",
      "        [-0.0309],\n",
      "        [-0.0299],\n",
      "        [-0.0264],\n",
      "        [ 0.1396],\n",
      "        [-0.0841],\n",
      "        [-0.0025],\n",
      "        [ 0.0079],\n",
      "        [-0.0417],\n",
      "        [-0.0601],\n",
      "        [ 0.0093],\n",
      "        [-0.0110],\n",
      "        [ 0.0246],\n",
      "        [ 0.0191],\n",
      "        [ 0.0179],\n",
      "        [ 0.0557],\n",
      "        [-0.0503],\n",
      "        [ 0.0525],\n",
      "        [-0.0283],\n",
      "        [-0.0150],\n",
      "        [-0.0258],\n",
      "        [-0.0709],\n",
      "        [-0.0293],\n",
      "        [ 0.0057],\n",
      "        [ 0.0266]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0425, 0.0438, 0.0433, 0.0421, 0.0418, 0.0415, 0.0405, 0.0404, 0.0427,\n",
      "        0.0425, 0.0420, 0.0438, 0.0426, 0.0434, 0.0426, 0.0440, 0.0445, 0.0467,\n",
      "        0.0467, 0.0449, 0.0447, 0.0454, 0.0445, 0.0435, 0.0439, 0.0453, 0.0445,\n",
      "        0.0437, 0.0435, 0.0442, 0.0451, 0.0452], device='cuda:0')\n",
      "tensor([[-0.0028],\n",
      "        [-0.0102],\n",
      "        [-0.0056],\n",
      "        [-0.1027],\n",
      "        [ 0.0199],\n",
      "        [ 0.0239],\n",
      "        [ 0.0843],\n",
      "        [ 0.0031],\n",
      "        [ 0.0456],\n",
      "        [ 0.0206],\n",
      "        [-0.0081],\n",
      "        [-0.0584],\n",
      "        [ 0.0418],\n",
      "        [ 0.0234],\n",
      "        [ 0.0276],\n",
      "        [-0.0276],\n",
      "        [-0.0116],\n",
      "        [ 0.0136],\n",
      "        [-0.0023],\n",
      "        [ 0.0173],\n",
      "        [-0.0235],\n",
      "        [-0.0079],\n",
      "        [ 0.0223],\n",
      "        [-0.0508],\n",
      "        [ 0.0005],\n",
      "        [ 0.0265],\n",
      "        [-0.0155],\n",
      "        [-0.0039],\n",
      "        [ 0.0054],\n",
      "        [-0.0067],\n",
      "        [ 0.0106],\n",
      "        [ 0.0170]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0447, 0.0451, 0.0438, 0.0433, 0.0432, 0.0428, 0.0423, 0.0416, 0.0422,\n",
      "        0.0408, 0.0410, 0.0422, 0.0417, 0.0436, 0.0432, 0.0429, 0.0425, 0.0424,\n",
      "        0.0424, 0.0423, 0.0418, 0.0417, 0.0410, 0.0416, 0.0426, 0.0412, 0.0414,\n",
      "        0.0421, 0.0418, 0.0411, 0.0405, 0.0403], device='cuda:0')\n",
      "tensor([[-0.0700],\n",
      "        [-0.0171],\n",
      "        [-0.0031],\n",
      "        [ 0.0031],\n",
      "        [-0.0014],\n",
      "        [-0.0361],\n",
      "        [ 0.0283],\n",
      "        [ 0.0333],\n",
      "        [-0.0760],\n",
      "        [ 0.0216],\n",
      "        [-0.0603],\n",
      "        [ 0.0146],\n",
      "        [-0.0103],\n",
      "        [-0.0226],\n",
      "        [ 0.0057],\n",
      "        [ 0.0100],\n",
      "        [ 0.0357],\n",
      "        [-0.0696],\n",
      "        [ 0.0337],\n",
      "        [-0.0571],\n",
      "        [-0.0503],\n",
      "        [-0.0181],\n",
      "        [-0.0469],\n",
      "        [ 0.0154],\n",
      "        [-0.0562],\n",
      "        [ 0.0117],\n",
      "        [ 0.0123],\n",
      "        [-0.0376],\n",
      "        [ 0.0042],\n",
      "        [ 0.0056],\n",
      "        [ 0.0199],\n",
      "        [ 0.0080]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0401, 0.0390, 0.0377, 0.0381, 0.0370, 0.0370, 0.0374, 0.0383, 0.0369,\n",
      "        0.0366, 0.0362, 0.0352, 0.0356, 0.0348, 0.0339, 0.0349, 0.0345, 0.0331,\n",
      "        0.0338, 0.0345, 0.0345, 0.0333, 0.0328, 0.0331, 0.0339, 0.0345, 0.0333,\n",
      "        0.0342, 0.0357, 0.0357, 0.0342, 0.0347], device='cuda:0')\n",
      "tensor([[-0.0374],\n",
      "        [-0.0802],\n",
      "        [-0.0312],\n",
      "        [-0.0308],\n",
      "        [-0.0254],\n",
      "        [ 0.0353],\n",
      "        [-0.0756],\n",
      "        [ 0.0074],\n",
      "        [-0.0355],\n",
      "        [-0.0422],\n",
      "        [-0.0126],\n",
      "        [-0.0231],\n",
      "        [-0.0807],\n",
      "        [-0.0283],\n",
      "        [-0.0498],\n",
      "        [-0.0085],\n",
      "        [ 0.0071],\n",
      "        [-0.0068],\n",
      "        [ 0.0151],\n",
      "        [ 0.0152],\n",
      "        [ 0.0061],\n",
      "        [-0.0572],\n",
      "        [-0.0127],\n",
      "        [-0.0231],\n",
      "        [-0.0663],\n",
      "        [-0.0325],\n",
      "        [-0.0855],\n",
      "        [-0.0097],\n",
      "        [ 0.0087],\n",
      "        [ 0.0671],\n",
      "        [ 0.0517],\n",
      "        [ 0.0839]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0345, 0.0339, 0.0349, 0.0336, 0.0339, 0.0342, 0.0339, 0.0338, 0.0333,\n",
      "        0.0338, 0.0357, 0.0366, 0.0358, 0.0364, 0.0371, 0.0374, 0.0386, 0.0370,\n",
      "        0.0363, 0.0349, 0.0364, 0.0384, 0.0401, 0.0401, 0.0415, 0.0413, 0.0415,\n",
      "        0.0429, 0.0423, 0.0424, 0.0425, 0.0419], device='cuda:0')\n",
      "tensor([[ 0.0066],\n",
      "        [ 0.0530],\n",
      "        [ 0.0016],\n",
      "        [ 0.0187],\n",
      "        [-0.0242],\n",
      "        [-0.0378],\n",
      "        [ 0.0002],\n",
      "        [ 0.0325],\n",
      "        [-0.0279],\n",
      "        [ 0.0245],\n",
      "        [ 0.0182],\n",
      "        [-0.0295],\n",
      "        [ 0.0632],\n",
      "        [-0.0830],\n",
      "        [ 0.0124],\n",
      "        [-0.0527],\n",
      "        [ 0.0204],\n",
      "        [ 0.0217],\n",
      "        [ 0.0372],\n",
      "        [ 0.0079],\n",
      "        [-0.0151],\n",
      "        [ 0.0016],\n",
      "        [ 0.0186],\n",
      "        [ 0.0096],\n",
      "        [ 0.0029],\n",
      "        [ 0.0487],\n",
      "        [-0.0730],\n",
      "        [-0.0960],\n",
      "        [ 0.0494],\n",
      "        [ 0.0085],\n",
      "        [-0.0680],\n",
      "        [-0.0249]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0432, 0.0436, 0.0437, 0.0443, 0.0424, 0.0431, 0.0442, 0.0430, 0.0431,\n",
      "        0.0434, 0.0431, 0.0438, 0.0444, 0.0448, 0.0446, 0.0447, 0.0456, 0.0471,\n",
      "        0.0461, 0.0464, 0.0471, 0.0458, 0.0455, 0.0460, 0.0462, 0.0463, 0.0470,\n",
      "        0.0471, 0.0476, 0.0469, 0.0459, 0.0454], device='cuda:0')\n",
      "tensor([[-0.0287],\n",
      "        [ 0.0019],\n",
      "        [-0.0232],\n",
      "        [-0.0202],\n",
      "        [-0.0221],\n",
      "        [-0.0456],\n",
      "        [ 0.0823],\n",
      "        [-0.1158],\n",
      "        [ 0.0672],\n",
      "        [-0.0359],\n",
      "        [-0.0462],\n",
      "        [ 0.0134],\n",
      "        [-0.0077],\n",
      "        [-0.0111],\n",
      "        [ 0.0139],\n",
      "        [ 0.0005],\n",
      "        [ 0.0075],\n",
      "        [-0.0500],\n",
      "        [-0.0323],\n",
      "        [ 0.0079],\n",
      "        [-0.0221],\n",
      "        [-0.0154],\n",
      "        [-0.0185],\n",
      "        [-0.0103],\n",
      "        [ 0.0065],\n",
      "        [ 0.0316],\n",
      "        [ 0.0206],\n",
      "        [ 0.0514],\n",
      "        [ 0.0138],\n",
      "        [-0.0167],\n",
      "        [ 0.0608],\n",
      "        [ 0.0516]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0457, 0.0441, 0.0442, 0.0445, 0.0449, 0.0441, 0.0444, 0.0447, 0.0456,\n",
      "        0.0456, 0.0455, 0.0450, 0.0445, 0.0457, 0.0466, 0.0466, 0.0464, 0.0466,\n",
      "        0.0469, 0.0476, 0.0486, 0.0484, 0.0482, 0.0487, 0.0490, 0.0503, 0.0499,\n",
      "        0.0519, 0.0515, 0.0522, 0.0545, 0.0554], device='cuda:0')\n",
      "tensor([[ 0.0235],\n",
      "        [ 0.0485],\n",
      "        [ 0.0448],\n",
      "        [-0.0123],\n",
      "        [-0.0151],\n",
      "        [ 0.0035],\n",
      "        [ 0.0363],\n",
      "        [-0.0310],\n",
      "        [-0.0010],\n",
      "        [-0.1116],\n",
      "        [-0.0048],\n",
      "        [-0.0190],\n",
      "        [-0.0011],\n",
      "        [ 0.0083],\n",
      "        [ 0.0170],\n",
      "        [ 0.0388],\n",
      "        [-0.0309],\n",
      "        [-0.0107],\n",
      "        [ 0.0428],\n",
      "        [-0.0419],\n",
      "        [-0.1127],\n",
      "        [ 0.0196],\n",
      "        [-0.0434],\n",
      "        [-0.0620],\n",
      "        [-0.0420],\n",
      "        [-0.0218],\n",
      "        [-0.0039],\n",
      "        [ 0.0229],\n",
      "        [-0.0135],\n",
      "        [-0.0229],\n",
      "        [ 0.0504],\n",
      "        [ 0.0614]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0538, 0.0545, 0.0558, 0.0558, 0.0545, 0.0548, 0.0564, 0.0568, 0.0573,\n",
      "        0.0578, 0.0586, 0.0569, 0.0557, 0.0556, 0.0569, 0.0561, 0.0553, 0.0557,\n",
      "        0.0555, 0.0562, 0.0579, 0.0581, 0.0576, 0.0582, 0.0575, 0.0563, 0.0562,\n",
      "        0.0573, 0.0573, 0.0573, 0.0564, 0.0567], device='cuda:0')\n",
      "tensor([[-0.0118],\n",
      "        [-0.0187],\n",
      "        [-0.0103],\n",
      "        [-0.0053],\n",
      "        [-0.0330],\n",
      "        [-0.0390],\n",
      "        [-0.0307],\n",
      "        [-0.0236],\n",
      "        [ 0.0152],\n",
      "        [ 0.0147],\n",
      "        [-0.0059],\n",
      "        [ 0.0076],\n",
      "        [-0.0609],\n",
      "        [-0.0892],\n",
      "        [-0.0568],\n",
      "        [-0.0378],\n",
      "        [-0.0533],\n",
      "        [ 0.0389],\n",
      "        [ 0.0370],\n",
      "        [ 0.0131],\n",
      "        [-0.0351],\n",
      "        [ 0.0159],\n",
      "        [ 0.0125],\n",
      "        [ 0.0217],\n",
      "        [-0.0498],\n",
      "        [ 0.0900],\n",
      "        [ 0.0470],\n",
      "        [ 0.0591],\n",
      "        [-0.0185],\n",
      "        [-0.0423],\n",
      "        [ 0.0870],\n",
      "        [-0.0635]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0575, 0.0571, 0.0580, 0.0592, 0.0579, 0.0574, 0.0580, 0.0569, 0.0569,\n",
      "        0.0571, 0.0570, 0.0581, 0.0580, 0.0570, 0.0573, 0.0576, 0.0576, 0.0581,\n",
      "        0.0580, 0.0595, 0.0610, 0.0604, 0.0601, 0.0599, 0.0598, 0.0580, 0.0585,\n",
      "        0.0562, 0.0564, 0.0572, 0.0579, 0.0576], device='cuda:0')\n",
      "tensor([[ 0.0736],\n",
      "        [ 0.0327],\n",
      "        [ 0.0383],\n",
      "        [-0.0298],\n",
      "        [-0.0017],\n",
      "        [ 0.0363],\n",
      "        [ 0.0213],\n",
      "        [ 0.0175],\n",
      "        [-0.0347],\n",
      "        [ 0.0158],\n",
      "        [ 0.0274],\n",
      "        [ 0.0232],\n",
      "        [ 0.0405],\n",
      "        [ 0.0103],\n",
      "        [ 0.0331],\n",
      "        [ 0.0007],\n",
      "        [-0.0215],\n",
      "        [ 0.0422],\n",
      "        [-0.0289],\n",
      "        [ 0.0061],\n",
      "        [ 0.0388],\n",
      "        [ 0.0187],\n",
      "        [ 0.0378],\n",
      "        [ 0.0017],\n",
      "        [ 0.0192],\n",
      "        [ 0.0036],\n",
      "        [ 0.0043],\n",
      "        [ 0.0083],\n",
      "        [-0.0010],\n",
      "        [-0.0279],\n",
      "        [-0.0277],\n",
      "        [ 0.0480]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0575, 0.0571, 0.0573, 0.0563, 0.0563, 0.0556, 0.0555, 0.0542, 0.0553,\n",
      "        0.0545, 0.0544, 0.0547, 0.0569, 0.0564, 0.0566, 0.0562, 0.0552, 0.0552,\n",
      "        0.0554, 0.0556, 0.0566, 0.0556, 0.0545, 0.0548, 0.0545, 0.0555, 0.0565,\n",
      "        0.0557, 0.0567, 0.0563, 0.0554, 0.0555], device='cuda:0')\n",
      "tensor([[ 2.6566e-02],\n",
      "        [ 3.3026e-02],\n",
      "        [ 2.3267e-02],\n",
      "        [-2.5699e-02],\n",
      "        [-4.8136e-02],\n",
      "        [-9.2773e-02],\n",
      "        [ 2.3678e-02],\n",
      "        [-3.6679e-02],\n",
      "        [-3.6291e-02],\n",
      "        [ 1.8890e-02],\n",
      "        [ 1.4818e-02],\n",
      "        [-1.9349e-02],\n",
      "        [-5.6042e-02],\n",
      "        [ 2.3068e-02],\n",
      "        [-7.0302e-03],\n",
      "        [ 5.8560e-02],\n",
      "        [-7.9017e-05],\n",
      "        [ 9.9330e-03],\n",
      "        [ 2.8893e-02],\n",
      "        [-5.2991e-02],\n",
      "        [-2.3296e-02],\n",
      "        [-4.3052e-02],\n",
      "        [-5.7767e-02],\n",
      "        [-6.6308e-02],\n",
      "        [-3.6312e-02],\n",
      "        [-2.4693e-02],\n",
      "        [ 3.0757e-02],\n",
      "        [-2.2278e-02],\n",
      "        [-9.4814e-03],\n",
      "        [-4.2038e-03],\n",
      "        [ 5.9662e-02],\n",
      "        [-2.3912e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0554, 0.0555, 0.0562, 0.0568, 0.0576, 0.0572, 0.0581, 0.0601, 0.0593,\n",
      "        0.0606, 0.0601, 0.0610, 0.0620, 0.0618, 0.0615, 0.0621, 0.0624, 0.0618,\n",
      "        0.0622, 0.0619, 0.0628, 0.0624, 0.0628, 0.0633, 0.0627, 0.0624, 0.0623,\n",
      "        0.0617, 0.0610, 0.0606, 0.0607, 0.0612], device='cuda:0')\n",
      "tensor([[-0.0314],\n",
      "        [-0.0682],\n",
      "        [ 0.0431],\n",
      "        [ 0.0338],\n",
      "        [ 0.0097],\n",
      "        [ 0.0023],\n",
      "        [ 0.0009],\n",
      "        [-0.0162],\n",
      "        [ 0.0032],\n",
      "        [ 0.0206],\n",
      "        [-0.0319],\n",
      "        [-0.0031],\n",
      "        [ 0.0052],\n",
      "        [ 0.0505],\n",
      "        [-0.0218],\n",
      "        [ 0.0309],\n",
      "        [-0.0140],\n",
      "        [ 0.0378],\n",
      "        [-0.0164],\n",
      "        [ 0.0256],\n",
      "        [ 0.0113],\n",
      "        [-0.0173],\n",
      "        [ 0.0350],\n",
      "        [ 0.0710],\n",
      "        [-0.0306],\n",
      "        [-0.0161],\n",
      "        [ 0.0753],\n",
      "        [-0.0952],\n",
      "        [-0.0765],\n",
      "        [-0.0178],\n",
      "        [-0.0408],\n",
      "        [-0.0344]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0613, 0.0621, 0.0611, 0.0613, 0.0613, 0.0611, 0.0610, 0.0622, 0.0624,\n",
      "        0.0618, 0.0620, 0.0618, 0.0629, 0.0626, 0.0626, 0.0629, 0.0632, 0.0634,\n",
      "        0.0632, 0.0620, 0.0613, 0.0615, 0.0603, 0.0610, 0.0601, 0.0604, 0.0611,\n",
      "        0.0615, 0.0625, 0.0623, 0.0629, 0.0634], device='cuda:0')\n",
      "tensor([[ 0.0380],\n",
      "        [ 0.0190],\n",
      "        [ 0.0360],\n",
      "        [ 0.0627],\n",
      "        [ 0.0062],\n",
      "        [ 0.0272],\n",
      "        [-0.0121],\n",
      "        [-0.0083],\n",
      "        [-0.0299],\n",
      "        [-0.0219],\n",
      "        [-0.0159],\n",
      "        [-0.0019],\n",
      "        [ 0.0260],\n",
      "        [-0.0319],\n",
      "        [ 0.0147],\n",
      "        [ 0.0819],\n",
      "        [-0.0043],\n",
      "        [-0.0621],\n",
      "        [-0.0297],\n",
      "        [-0.0357],\n",
      "        [-0.0608],\n",
      "        [ 0.0225],\n",
      "        [-0.0117],\n",
      "        [ 0.0782],\n",
      "        [-0.0740],\n",
      "        [-0.0285],\n",
      "        [ 0.0214],\n",
      "        [ 0.0212],\n",
      "        [ 0.0018],\n",
      "        [ 0.0667],\n",
      "        [-0.0631],\n",
      "        [-0.1006]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0625, 0.0628, 0.0632, 0.0627, 0.0628, 0.0629, 0.0646, 0.0646, 0.0646,\n",
      "        0.0657, 0.0650, 0.0646, 0.0645, 0.0654, 0.0645, 0.0638, 0.0638, 0.0635,\n",
      "        0.0634, 0.0631, 0.0632, 0.0638, 0.0629, 0.0628, 0.0610, 0.0612, 0.0588,\n",
      "        0.0582, 0.0586, 0.0585, 0.0585, 0.0567], device='cuda:0')\n",
      "tensor([[-0.0612],\n",
      "        [-0.0798],\n",
      "        [-0.0067],\n",
      "        [-0.0749],\n",
      "        [-0.0328],\n",
      "        [-0.0027],\n",
      "        [ 0.0124],\n",
      "        [-0.0318],\n",
      "        [-0.0314],\n",
      "        [ 0.0180],\n",
      "        [ 0.0195],\n",
      "        [-0.0095],\n",
      "        [ 0.0333],\n",
      "        [-0.0104],\n",
      "        [-0.0541],\n",
      "        [-0.0751],\n",
      "        [-0.0285],\n",
      "        [ 0.0118],\n",
      "        [-0.0357],\n",
      "        [ 0.0107],\n",
      "        [ 0.0352],\n",
      "        [-0.0148],\n",
      "        [ 0.0269],\n",
      "        [ 0.0368],\n",
      "        [ 0.0128],\n",
      "        [-0.0248],\n",
      "        [ 0.0456],\n",
      "        [ 0.0420],\n",
      "        [ 0.0302],\n",
      "        [-0.0171],\n",
      "        [-0.0568],\n",
      "        [-0.0137]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0564, 0.0573, 0.0585, 0.0593, 0.0594, 0.0610, 0.0608, 0.0598, 0.0597,\n",
      "        0.0581, 0.0573, 0.0576, 0.0578, 0.0588, 0.0581, 0.0587, 0.0585, 0.0597,\n",
      "        0.0607, 0.0604, 0.0609, 0.0602, 0.0611, 0.0617, 0.0608, 0.0607, 0.0603,\n",
      "        0.0603, 0.0610, 0.0613, 0.0607, 0.0612], device='cuda:0')\n",
      "tensor([[-1.6616e-02],\n",
      "        [-8.6037e-04],\n",
      "        [ 1.3359e-03],\n",
      "        [-9.2807e-03],\n",
      "        [ 3.1223e-02],\n",
      "        [-1.2294e-03],\n",
      "        [-2.3655e-02],\n",
      "        [ 3.0671e-02],\n",
      "        [-3.9360e-03],\n",
      "        [ 4.8167e-02],\n",
      "        [ 4.8686e-02],\n",
      "        [-2.8131e-02],\n",
      "        [-6.4669e-02],\n",
      "        [-1.3998e-02],\n",
      "        [-1.1366e-05],\n",
      "        [ 3.4862e-02],\n",
      "        [ 9.3090e-02],\n",
      "        [ 5.3232e-02],\n",
      "        [-4.5979e-02],\n",
      "        [ 9.4121e-02],\n",
      "        [-2.6461e-02],\n",
      "        [-4.3621e-02],\n",
      "        [-1.4622e-03],\n",
      "        [-3.3648e-02],\n",
      "        [ 3.0312e-03],\n",
      "        [-3.5029e-02],\n",
      "        [-2.3782e-02],\n",
      "        [-5.8509e-03],\n",
      "        [ 1.7043e-02],\n",
      "        [ 4.0352e-02],\n",
      "        [-2.5406e-02],\n",
      "        [ 3.4300e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0609, 0.0607, 0.0604, 0.0604, 0.0601, 0.0596, 0.0590, 0.0592, 0.0605,\n",
      "        0.0605, 0.0609, 0.0626, 0.0629, 0.0624, 0.0635, 0.0631, 0.0624, 0.0613,\n",
      "        0.0616, 0.0616, 0.0610, 0.0608, 0.0601, 0.0601, 0.0606, 0.0606, 0.0613,\n",
      "        0.0620, 0.0626, 0.0613, 0.0616, 0.0610], device='cuda:0')\n",
      "tensor([[ 0.0487],\n",
      "        [-0.0320],\n",
      "        [ 0.0224],\n",
      "        [ 0.0365],\n",
      "        [-0.0150],\n",
      "        [ 0.0297],\n",
      "        [-0.0634],\n",
      "        [-0.0315],\n",
      "        [-0.0413],\n",
      "        [-0.0005],\n",
      "        [ 0.0358],\n",
      "        [ 0.0092],\n",
      "        [ 0.0251],\n",
      "        [ 0.0175],\n",
      "        [ 0.0777],\n",
      "        [-0.0594],\n",
      "        [-0.0267],\n",
      "        [ 0.0090],\n",
      "        [-0.0400],\n",
      "        [-0.0117],\n",
      "        [-0.0105],\n",
      "        [ 0.0133],\n",
      "        [-0.0299],\n",
      "        [-0.0182],\n",
      "        [ 0.0083],\n",
      "        [ 0.0321],\n",
      "        [-0.0205],\n",
      "        [ 0.0426],\n",
      "        [ 0.0025],\n",
      "        [-0.0146],\n",
      "        [ 0.0148],\n",
      "        [-0.0289]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0604, 0.0599, 0.0600, 0.0612, 0.0620, 0.0624, 0.0617, 0.0608, 0.0601,\n",
      "        0.0606, 0.0604, 0.0598, 0.0601, 0.0595, 0.0617, 0.0611, 0.0609, 0.0606,\n",
      "        0.0605, 0.0621, 0.0623, 0.0621, 0.0621, 0.0622, 0.0625, 0.0624, 0.0629,\n",
      "        0.0628, 0.0635, 0.0634, 0.0633, 0.0647], device='cuda:0')\n",
      "tensor([[ 0.0737],\n",
      "        [-0.0067],\n",
      "        [ 0.0150],\n",
      "        [ 0.0525],\n",
      "        [ 0.0191],\n",
      "        [ 0.0421],\n",
      "        [-0.0131],\n",
      "        [-0.0485],\n",
      "        [ 0.0108],\n",
      "        [-0.0318],\n",
      "        [-0.0206],\n",
      "        [-0.0586],\n",
      "        [ 0.0158],\n",
      "        [-0.0280],\n",
      "        [ 0.0077],\n",
      "        [-0.0629],\n",
      "        [-0.0409],\n",
      "        [ 0.0207],\n",
      "        [-0.0020],\n",
      "        [-0.0393],\n",
      "        [-0.0606],\n",
      "        [-0.0193],\n",
      "        [-0.0383],\n",
      "        [ 0.0213],\n",
      "        [-0.0582],\n",
      "        [-0.0278],\n",
      "        [ 0.0027],\n",
      "        [ 0.0070],\n",
      "        [-0.0840],\n",
      "        [ 0.0171],\n",
      "        [-0.0612],\n",
      "        [-0.0764]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0643, 0.0646, 0.0649, 0.0646, 0.0644, 0.0644, 0.0643, 0.0650, 0.0641,\n",
      "        0.0634, 0.0626, 0.0632, 0.0636, 0.0624, 0.0624, 0.0628, 0.0621, 0.0618,\n",
      "        0.0621, 0.0624, 0.0624, 0.0630, 0.0615, 0.0610, 0.0612, 0.0610, 0.0608,\n",
      "        0.0604, 0.0587, 0.0569, 0.0570, 0.0573], device='cuda:0')\n",
      "tensor([[-0.0112],\n",
      "        [ 0.0328],\n",
      "        [ 0.0887],\n",
      "        [ 0.0917],\n",
      "        [-0.0473],\n",
      "        [-0.0051],\n",
      "        [-0.0189],\n",
      "        [-0.0135],\n",
      "        [ 0.0293],\n",
      "        [ 0.0361],\n",
      "        [ 0.0478],\n",
      "        [-0.0039],\n",
      "        [-0.0089],\n",
      "        [ 0.0238],\n",
      "        [ 0.0174],\n",
      "        [-0.0194],\n",
      "        [-0.0249],\n",
      "        [-0.0293],\n",
      "        [-0.0065],\n",
      "        [-0.0120],\n",
      "        [ 0.0269],\n",
      "        [ 0.0185],\n",
      "        [-0.0098],\n",
      "        [-0.0686],\n",
      "        [-0.0262],\n",
      "        [ 0.0237],\n",
      "        [ 0.0063],\n",
      "        [-0.0023],\n",
      "        [ 0.0424],\n",
      "        [ 0.0371],\n",
      "        [ 0.0232],\n",
      "        [ 0.0369]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0579, 0.0574, 0.0571, 0.0575, 0.0579, 0.0583, 0.0576, 0.0564, 0.0561,\n",
      "        0.0561, 0.0553, 0.0552, 0.0555, 0.0555, 0.0561, 0.0557, 0.0552, 0.0545,\n",
      "        0.0532, 0.0538, 0.0537, 0.0542, 0.0531, 0.0532, 0.0539, 0.0535, 0.0548,\n",
      "        0.0547, 0.0554, 0.0554, 0.0549, 0.0550], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0525],\n",
      "        [ 0.0160],\n",
      "        [-0.0110],\n",
      "        [ 0.0080],\n",
      "        [ 0.0118],\n",
      "        [-0.0317],\n",
      "        [ 0.0082],\n",
      "        [ 0.0074],\n",
      "        [ 0.0186],\n",
      "        [-0.0216],\n",
      "        [-0.0054],\n",
      "        [-0.0109],\n",
      "        [-0.0323],\n",
      "        [-0.0290],\n",
      "        [ 0.0057],\n",
      "        [ 0.0030],\n",
      "        [-0.0142],\n",
      "        [ 0.0258],\n",
      "        [-0.0090],\n",
      "        [-0.0605],\n",
      "        [-0.0370],\n",
      "        [ 0.0888],\n",
      "        [-0.0498],\n",
      "        [-0.0949],\n",
      "        [-0.0685],\n",
      "        [ 0.0780],\n",
      "        [-0.0519],\n",
      "        [ 0.0174],\n",
      "        [ 0.1182],\n",
      "        [ 0.0402],\n",
      "        [ 0.0016],\n",
      "        [-0.0098]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0556, 0.0570, 0.0571, 0.0567, 0.0567, 0.0575, 0.0574, 0.0576, 0.0581,\n",
      "        0.0593, 0.0596, 0.0587, 0.0590, 0.0587, 0.0580, 0.0579, 0.0574, 0.0579,\n",
      "        0.0572, 0.0574, 0.0573, 0.0578, 0.0605, 0.0616, 0.0619, 0.0613, 0.0613,\n",
      "        0.0614, 0.0616, 0.0609, 0.0597, 0.0595], device='cuda:0')\n",
      "tensor([[ 0.1130],\n",
      "        [ 0.0979],\n",
      "        [ 0.0408],\n",
      "        [-0.0447],\n",
      "        [ 0.0421],\n",
      "        [-0.0868],\n",
      "        [-0.0367],\n",
      "        [-0.0390],\n",
      "        [-0.0021],\n",
      "        [ 0.0184],\n",
      "        [ 0.0037],\n",
      "        [-0.0289],\n",
      "        [-0.0159],\n",
      "        [-0.0134],\n",
      "        [-0.0049],\n",
      "        [-0.0190],\n",
      "        [ 0.0171],\n",
      "        [ 0.0019],\n",
      "        [-0.0170],\n",
      "        [ 0.0051],\n",
      "        [ 0.0134],\n",
      "        [ 0.0398],\n",
      "        [-0.0168],\n",
      "        [-0.0291],\n",
      "        [-0.0305],\n",
      "        [-0.0071],\n",
      "        [-0.0374],\n",
      "        [-0.0618],\n",
      "        [ 0.0323],\n",
      "        [ 0.0085],\n",
      "        [-0.0227],\n",
      "        [-0.0253]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0599, 0.0604, 0.0602, 0.0604, 0.0601, 0.0594, 0.0587, 0.0591, 0.0599,\n",
      "        0.0593, 0.0593, 0.0602, 0.0598, 0.0601, 0.0600, 0.0602, 0.0608, 0.0605,\n",
      "        0.0598, 0.0596, 0.0597, 0.0603, 0.0594, 0.0600, 0.0596, 0.0600, 0.0600,\n",
      "        0.0598, 0.0591, 0.0583, 0.0583, 0.0583], device='cuda:0')\n",
      "tensor([[-0.0346],\n",
      "        [-0.0340],\n",
      "        [ 0.0283],\n",
      "        [-0.0140],\n",
      "        [-0.0095],\n",
      "        [-0.0579],\n",
      "        [ 0.0339],\n",
      "        [-0.0422],\n",
      "        [-0.0863],\n",
      "        [-0.0439],\n",
      "        [ 0.0134],\n",
      "        [ 0.0034],\n",
      "        [ 0.0259],\n",
      "        [-0.0197],\n",
      "        [-0.0069],\n",
      "        [ 0.0330],\n",
      "        [ 0.0203],\n",
      "        [ 0.0097],\n",
      "        [ 0.0206],\n",
      "        [ 0.0283],\n",
      "        [ 0.0093],\n",
      "        [-0.0175],\n",
      "        [ 0.0284],\n",
      "        [ 0.0198],\n",
      "        [-0.0041],\n",
      "        [-0.0047],\n",
      "        [ 0.0033],\n",
      "        [-0.0224],\n",
      "        [-0.0013],\n",
      "        [ 0.0024],\n",
      "        [ 0.0233],\n",
      "        [ 0.0397]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0584, 0.0583, 0.0573, 0.0562, 0.0572, 0.0564, 0.0568, 0.0566, 0.0573,\n",
      "        0.0570, 0.0573, 0.0576, 0.0578, 0.0582, 0.0572, 0.0567, 0.0569, 0.0567,\n",
      "        0.0569, 0.0564, 0.0561, 0.0567, 0.0569, 0.0571, 0.0567, 0.0563, 0.0568,\n",
      "        0.0571, 0.0571, 0.0567, 0.0576, 0.0576], device='cuda:0')\n",
      "tensor([[-0.0166],\n",
      "        [-0.0267],\n",
      "        [-0.0242],\n",
      "        [ 0.0306],\n",
      "        [ 0.0213],\n",
      "        [ 0.0100],\n",
      "        [-0.0013],\n",
      "        [ 0.0363],\n",
      "        [ 0.1252],\n",
      "        [-0.0907],\n",
      "        [ 0.0270],\n",
      "        [ 0.0219],\n",
      "        [ 0.0327],\n",
      "        [-0.0342],\n",
      "        [ 0.0628],\n",
      "        [-0.0077],\n",
      "        [-0.0394],\n",
      "        [-0.0317],\n",
      "        [ 0.0151],\n",
      "        [-0.0336],\n",
      "        [-0.0497],\n",
      "        [-0.0137],\n",
      "        [ 0.0581],\n",
      "        [ 0.0842],\n",
      "        [ 0.0912],\n",
      "        [-0.0475],\n",
      "        [-0.0170],\n",
      "        [ 0.0020],\n",
      "        [ 0.0230],\n",
      "        [-0.0683],\n",
      "        [ 0.0007],\n",
      "        [-0.0028]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0571, 0.0567, 0.0562, 0.0544, 0.0545, 0.0554, 0.0551, 0.0548, 0.0553,\n",
      "        0.0573, 0.0575, 0.0570, 0.0578, 0.0569, 0.0569, 0.0576, 0.0576, 0.0593,\n",
      "        0.0600, 0.0601, 0.0595, 0.0583, 0.0587, 0.0584, 0.0588, 0.0584, 0.0576,\n",
      "        0.0578, 0.0582, 0.0588, 0.0584, 0.0587], device='cuda:0')\n",
      "tensor([[-0.0369],\n",
      "        [-0.0484],\n",
      "        [ 0.0164],\n",
      "        [-0.0562],\n",
      "        [-0.0086],\n",
      "        [ 0.0161],\n",
      "        [-0.0168],\n",
      "        [-0.0569],\n",
      "        [-0.0425],\n",
      "        [-0.0214],\n",
      "        [-0.0302],\n",
      "        [-0.0171],\n",
      "        [ 0.0903],\n",
      "        [-0.0467],\n",
      "        [ 0.0573],\n",
      "        [ 0.0626],\n",
      "        [ 0.0661],\n",
      "        [ 0.0373],\n",
      "        [-0.0757],\n",
      "        [-0.0166],\n",
      "        [ 0.0764],\n",
      "        [ 0.0644],\n",
      "        [ 0.0164],\n",
      "        [-0.0387],\n",
      "        [-0.0297],\n",
      "        [ 0.0129],\n",
      "        [-0.0207],\n",
      "        [-0.0286],\n",
      "        [-0.0197],\n",
      "        [ 0.0010],\n",
      "        [-0.0127],\n",
      "        [-0.0040]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0593, 0.0589, 0.0586, 0.0584, 0.0587, 0.0593, 0.0597, 0.0605, 0.0605,\n",
      "        0.0607, 0.0612, 0.0615, 0.0601, 0.0607, 0.0595, 0.0595, 0.0601, 0.0595,\n",
      "        0.0593, 0.0594, 0.0593, 0.0597, 0.0601, 0.0602, 0.0597, 0.0593, 0.0591,\n",
      "        0.0593, 0.0592, 0.0587, 0.0590, 0.0595], device='cuda:0')\n",
      "tensor([[-0.0256],\n",
      "        [-0.1442],\n",
      "        [-0.0235],\n",
      "        [ 0.0453],\n",
      "        [ 0.0479],\n",
      "        [ 0.0030],\n",
      "        [-0.0321],\n",
      "        [-0.0088],\n",
      "        [ 0.0096],\n",
      "        [-0.0313],\n",
      "        [-0.0212],\n",
      "        [-0.0037],\n",
      "        [-0.0220],\n",
      "        [-0.0180],\n",
      "        [-0.0109],\n",
      "        [-0.0211],\n",
      "        [ 0.0275],\n",
      "        [-0.0025],\n",
      "        [ 0.0053],\n",
      "        [-0.0155],\n",
      "        [-0.0061],\n",
      "        [ 0.0075],\n",
      "        [-0.0137],\n",
      "        [-0.0249],\n",
      "        [-0.0048],\n",
      "        [ 0.0089],\n",
      "        [ 0.0388],\n",
      "        [-0.0922],\n",
      "        [-0.0501],\n",
      "        [ 0.0091],\n",
      "        [-0.0323],\n",
      "        [-0.0432]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0591, 0.0591, 0.0584, 0.0571, 0.0570, 0.0577, 0.0575, 0.0574, 0.0569,\n",
      "        0.0570, 0.0567, 0.0567, 0.0563, 0.0561, 0.0561, 0.0559, 0.0563, 0.0565,\n",
      "        0.0556, 0.0549, 0.0550, 0.0542, 0.0531, 0.0518, 0.0530, 0.0534, 0.0528,\n",
      "        0.0524, 0.0513, 0.0522, 0.0516, 0.0525], device='cuda:0')\n",
      "tensor([[ 0.0145],\n",
      "        [-0.0429],\n",
      "        [ 0.0101],\n",
      "        [ 0.0438],\n",
      "        [-0.0431],\n",
      "        [ 0.0168],\n",
      "        [-0.0373],\n",
      "        [-0.0213],\n",
      "        [-0.0476],\n",
      "        [ 0.0018],\n",
      "        [-0.0382],\n",
      "        [ 0.0224],\n",
      "        [-0.0466],\n",
      "        [ 0.0373],\n",
      "        [-0.0408],\n",
      "        [ 0.0353],\n",
      "        [-0.0357],\n",
      "        [ 0.0195],\n",
      "        [ 0.0164],\n",
      "        [ 0.0026],\n",
      "        [ 0.0075],\n",
      "        [ 0.0026],\n",
      "        [-0.0645],\n",
      "        [ 0.0015],\n",
      "        [ 0.0047],\n",
      "        [ 0.0850],\n",
      "        [ 0.0940],\n",
      "        [ 0.0773],\n",
      "        [ 0.0687],\n",
      "        [-0.0222],\n",
      "        [-0.0470],\n",
      "        [-0.0770]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0527, 0.0518, 0.0514, 0.0514, 0.0515, 0.0511, 0.0515, 0.0511, 0.0510,\n",
      "        0.0502, 0.0505, 0.0510, 0.0520, 0.0518, 0.0518, 0.0519, 0.0515, 0.0505,\n",
      "        0.0514, 0.0526, 0.0549, 0.0549, 0.0554, 0.0556, 0.0557, 0.0569, 0.0580,\n",
      "        0.0582, 0.0579, 0.0593, 0.0595, 0.0593], device='cuda:0')\n",
      "tensor([[-0.0043],\n",
      "        [ 0.0450],\n",
      "        [ 0.0167],\n",
      "        [ 0.0303],\n",
      "        [ 0.0004],\n",
      "        [-0.0292],\n",
      "        [-0.0566],\n",
      "        [-0.0964],\n",
      "        [-0.0740],\n",
      "        [ 0.0157],\n",
      "        [-0.0215],\n",
      "        [ 0.0021],\n",
      "        [-0.0243],\n",
      "        [ 0.0258],\n",
      "        [ 0.0267],\n",
      "        [ 0.0129],\n",
      "        [ 0.0257],\n",
      "        [ 0.0146],\n",
      "        [-0.0226],\n",
      "        [ 0.0107],\n",
      "        [-0.0535],\n",
      "        [-0.0577],\n",
      "        [ 0.0310],\n",
      "        [ 0.0308],\n",
      "        [-0.0622],\n",
      "        [-0.0526],\n",
      "        [ 0.0402],\n",
      "        [-0.0308],\n",
      "        [-0.0261],\n",
      "        [ 0.0034],\n",
      "        [ 0.0399],\n",
      "        [ 0.0489]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0584, 0.0577, 0.0582, 0.0574, 0.0576, 0.0574, 0.0590, 0.0583, 0.0593,\n",
      "        0.0596, 0.0593, 0.0588, 0.0581, 0.0595, 0.0584, 0.0582, 0.0579, 0.0577,\n",
      "        0.0578, 0.0570, 0.0566, 0.0577, 0.0592, 0.0593, 0.0590, 0.0598, 0.0601,\n",
      "        0.0598, 0.0617, 0.0608, 0.0604, 0.0593], device='cuda:0')\n",
      "tensor([[ 0.0187],\n",
      "        [ 0.0463],\n",
      "        [ 0.0329],\n",
      "        [ 0.0146],\n",
      "        [-0.0541],\n",
      "        [-0.0183],\n",
      "        [ 0.1059],\n",
      "        [-0.0157],\n",
      "        [ 0.0002],\n",
      "        [-0.0021],\n",
      "        [ 0.0039],\n",
      "        [-0.0158],\n",
      "        [-0.0517],\n",
      "        [-0.0371],\n",
      "        [-0.0321],\n",
      "        [-0.0342],\n",
      "        [-0.0167],\n",
      "        [ 0.0086],\n",
      "        [ 0.0127],\n",
      "        [-0.0292],\n",
      "        [ 0.0103],\n",
      "        [ 0.0022],\n",
      "        [ 0.0115],\n",
      "        [ 0.0014],\n",
      "        [ 0.0742],\n",
      "        [ 0.0196],\n",
      "        [ 0.0654],\n",
      "        [ 0.0142],\n",
      "        [ 0.0037],\n",
      "        [ 0.0003],\n",
      "        [ 0.0082],\n",
      "        [-0.0109]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0602, 0.0592, 0.0598, 0.0594, 0.0582, 0.0570, 0.0577, 0.0580, 0.0574,\n",
      "        0.0567, 0.0565, 0.0569, 0.0570, 0.0576, 0.0575, 0.0571, 0.0570, 0.0573,\n",
      "        0.0597, 0.0593, 0.0588, 0.0604, 0.0599, 0.0605, 0.0607, 0.0613, 0.0615,\n",
      "        0.0623, 0.0630, 0.0637, 0.0631, 0.0672], device='cuda:0')\n",
      "tensor([[ 0.0465],\n",
      "        [ 0.0313],\n",
      "        [ 0.0173],\n",
      "        [ 0.0083],\n",
      "        [ 0.1190],\n",
      "        [ 0.0445],\n",
      "        [ 0.0308],\n",
      "        [-0.0158],\n",
      "        [-0.0106],\n",
      "        [-0.0888],\n",
      "        [-0.0227],\n",
      "        [-0.0507],\n",
      "        [ 0.0250],\n",
      "        [-0.0120],\n",
      "        [ 0.0507],\n",
      "        [ 0.0333],\n",
      "        [ 0.0203],\n",
      "        [-0.0017],\n",
      "        [-0.0098],\n",
      "        [ 0.0115],\n",
      "        [-0.0274],\n",
      "        [ 0.0114],\n",
      "        [-0.0077],\n",
      "        [-0.0276],\n",
      "        [ 0.0513],\n",
      "        [ 0.0854],\n",
      "        [-0.0477],\n",
      "        [-0.0219],\n",
      "        [-0.0221],\n",
      "        [ 0.0111],\n",
      "        [ 0.0451],\n",
      "        [ 0.0375]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0649, 0.0659, 0.0652, 0.0663, 0.0660, 0.0656, 0.0660, 0.0659, 0.0668,\n",
      "        0.0683, 0.0679, 0.0674, 0.0673, 0.0683, 0.0686, 0.0684, 0.0685, 0.0678,\n",
      "        0.0671, 0.0672, 0.0669, 0.0674, 0.0696, 0.0693, 0.0691, 0.0706, 0.0691,\n",
      "        0.0695, 0.0678, 0.0674, 0.0663, 0.0660], device='cuda:0')\n",
      "tensor([[-0.0099],\n",
      "        [-0.0497],\n",
      "        [-0.0840],\n",
      "        [ 0.0664],\n",
      "        [-0.0282],\n",
      "        [-0.0456],\n",
      "        [ 0.0746],\n",
      "        [-0.0608],\n",
      "        [ 0.0318],\n",
      "        [-0.0308],\n",
      "        [-0.0200],\n",
      "        [-0.0560],\n",
      "        [-0.0321],\n",
      "        [-0.0323],\n",
      "        [-0.0433],\n",
      "        [ 0.0251],\n",
      "        [ 0.0314],\n",
      "        [ 0.0020],\n",
      "        [ 0.0123],\n",
      "        [ 0.0435],\n",
      "        [ 0.0054],\n",
      "        [ 0.1602],\n",
      "        [ 0.1232],\n",
      "        [ 0.0602],\n",
      "        [-0.0243],\n",
      "        [ 0.0097],\n",
      "        [ 0.0002],\n",
      "        [ 0.0106],\n",
      "        [-0.0266],\n",
      "        [ 0.0253],\n",
      "        [ 0.0136],\n",
      "        [ 0.0191]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0653, 0.0647, 0.0646, 0.0646, 0.0635, 0.0637, 0.0619, 0.0625, 0.0625,\n",
      "        0.0635, 0.0624, 0.0640, 0.0631, 0.0630, 0.0643, 0.0638, 0.0665, 0.0655,\n",
      "        0.0652, 0.0631, 0.0631, 0.0633, 0.0622, 0.0625, 0.0628, 0.0619, 0.0615,\n",
      "        0.0612, 0.0603, 0.0613, 0.0587, 0.0622], device='cuda:0')\n",
      "tensor([[-0.0273],\n",
      "        [-0.0403],\n",
      "        [-0.0130],\n",
      "        [-0.0783],\n",
      "        [-0.0022],\n",
      "        [-0.0009],\n",
      "        [-0.0084],\n",
      "        [-0.0499],\n",
      "        [-0.0396],\n",
      "        [ 0.0127],\n",
      "        [-0.0270],\n",
      "        [ 0.0149],\n",
      "        [ 0.0177],\n",
      "        [-0.0337],\n",
      "        [-0.0360],\n",
      "        [-0.0238],\n",
      "        [-0.0435],\n",
      "        [-0.0246],\n",
      "        [ 0.0098],\n",
      "        [ 0.0150],\n",
      "        [ 0.0745],\n",
      "        [ 0.0103],\n",
      "        [ 0.0286],\n",
      "        [ 0.0062],\n",
      "        [-0.0235],\n",
      "        [-0.0146],\n",
      "        [ 0.0182],\n",
      "        [-0.0332],\n",
      "        [-0.0820],\n",
      "        [ 0.0389],\n",
      "        [-0.0078],\n",
      "        [-0.0711]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0602, 0.0600, 0.0587, 0.0581, 0.0592, 0.0586, 0.0586, 0.0574, 0.0575,\n",
      "        0.0570, 0.0578, 0.0578, 0.0586, 0.0587, 0.0598, 0.0602, 0.0608, 0.0598,\n",
      "        0.0591, 0.0603, 0.0614, 0.0615, 0.0628, 0.0628, 0.0622, 0.0617, 0.0628,\n",
      "        0.0622, 0.0617, 0.0617, 0.0620, 0.0605], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0010],\n",
      "        [ 0.0438],\n",
      "        [ 0.0219],\n",
      "        [-0.0003],\n",
      "        [-0.0277],\n",
      "        [-0.0066],\n",
      "        [ 0.0302],\n",
      "        [-0.0201],\n",
      "        [ 0.0456],\n",
      "        [ 0.0209],\n",
      "        [ 0.0617],\n",
      "        [ 0.0410],\n",
      "        [ 0.0066],\n",
      "        [ 0.0150],\n",
      "        [-0.0458],\n",
      "        [ 0.0035],\n",
      "        [-0.0598],\n",
      "        [-0.0234],\n",
      "        [-0.0531],\n",
      "        [-0.0448],\n",
      "        [ 0.0006],\n",
      "        [ 0.0056],\n",
      "        [ 0.0675],\n",
      "        [-0.0257],\n",
      "        [ 0.0178],\n",
      "        [-0.0142],\n",
      "        [-0.0109],\n",
      "        [ 0.0394],\n",
      "        [ 0.0190],\n",
      "        [ 0.0380],\n",
      "        [ 0.0119],\n",
      "        [-0.0214]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0642, 0.0647, 0.0645, 0.0678, 0.0721, 0.0700, 0.0705, 0.0688, 0.0703,\n",
      "        0.0712, 0.0708, 0.0711, 0.0706, 0.0711, 0.0709, 0.0727, 0.0731, 0.0739,\n",
      "        0.0721, 0.0723, 0.0725, 0.0712, 0.0727, 0.0726, 0.0718, 0.0728, 0.0731,\n",
      "        0.0726, 0.0728, 0.0719, 0.0725, 0.0717], device='cuda:0')\n",
      "tensor([[-0.0200],\n",
      "        [-0.0213],\n",
      "        [-0.0050],\n",
      "        [-0.0233],\n",
      "        [ 0.0003],\n",
      "        [-0.0609],\n",
      "        [-0.0713],\n",
      "        [ 0.1005],\n",
      "        [-0.0912],\n",
      "        [-0.0974],\n",
      "        [-0.0102],\n",
      "        [-0.0055],\n",
      "        [ 0.0134],\n",
      "        [ 0.0119],\n",
      "        [-0.0112],\n",
      "        [ 0.0049],\n",
      "        [-0.0078],\n",
      "        [-0.0062],\n",
      "        [-0.0279],\n",
      "        [-0.0385],\n",
      "        [-0.0694],\n",
      "        [ 0.0464],\n",
      "        [-0.0252],\n",
      "        [ 0.0020],\n",
      "        [-0.0309],\n",
      "        [-0.0086],\n",
      "        [ 0.0162],\n",
      "        [ 0.0411],\n",
      "        [ 0.0061],\n",
      "        [ 0.0491],\n",
      "        [-0.0266],\n",
      "        [ 0.0216]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0710, 0.0703, 0.0688, 0.0692, 0.0698, 0.0712, 0.0717, 0.0709, 0.0717,\n",
      "        0.0712, 0.0717, 0.0711, 0.0704, 0.0700, 0.0705, 0.0690, 0.0693, 0.0696,\n",
      "        0.0695, 0.0711, 0.0704, 0.0707, 0.0719, 0.0716, 0.0722, 0.0718, 0.0715,\n",
      "        0.0713, 0.0719, 0.0724, 0.0724, 0.0740], device='cuda:0')\n",
      "tensor([[-0.0035],\n",
      "        [-0.0310],\n",
      "        [-0.0200],\n",
      "        [-0.0277],\n",
      "        [ 0.0664],\n",
      "        [ 0.0606],\n",
      "        [ 0.0861],\n",
      "        [-0.0189],\n",
      "        [ 0.0693],\n",
      "        [ 0.0142],\n",
      "        [-0.0711],\n",
      "        [-0.0474],\n",
      "        [-0.0004],\n",
      "        [-0.0757],\n",
      "        [ 0.0031],\n",
      "        [-0.0215],\n",
      "        [-0.0057],\n",
      "        [ 0.0019],\n",
      "        [-0.0086],\n",
      "        [ 0.0530],\n",
      "        [-0.0857],\n",
      "        [ 0.0188],\n",
      "        [-0.0593],\n",
      "        [-0.0402],\n",
      "        [-0.0629],\n",
      "        [ 0.0076],\n",
      "        [-0.0035],\n",
      "        [ 0.0164],\n",
      "        [-0.0247],\n",
      "        [ 0.0222],\n",
      "        [-0.0375],\n",
      "        [-0.0209]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0740, 0.0737, 0.0729, 0.0754, 0.0745, 0.0745, 0.0739, 0.0735, 0.0750,\n",
      "        0.0745, 0.0754, 0.0748, 0.0749, 0.0752, 0.0728, 0.0728, 0.0727, 0.0730,\n",
      "        0.0728, 0.0719, 0.0713, 0.0722, 0.0723, 0.0728, 0.0719, 0.0724, 0.0735,\n",
      "        0.0739, 0.0746, 0.0751, 0.0726, 0.0719], device='cuda:0')\n",
      "tensor([[-0.0072],\n",
      "        [ 0.1018],\n",
      "        [ 0.0887],\n",
      "        [ 0.0196],\n",
      "        [-0.0252],\n",
      "        [-0.0350],\n",
      "        [ 0.0191],\n",
      "        [-0.0050],\n",
      "        [-0.0041],\n",
      "        [-0.0125],\n",
      "        [ 0.0180],\n",
      "        [ 0.0005],\n",
      "        [ 0.0122],\n",
      "        [-0.0368],\n",
      "        [ 0.0092],\n",
      "        [-0.0008],\n",
      "        [-0.0029],\n",
      "        [ 0.0052],\n",
      "        [ 0.0067],\n",
      "        [-0.0106],\n",
      "        [ 0.0616],\n",
      "        [ 0.0054],\n",
      "        [ 0.0408],\n",
      "        [-0.0445],\n",
      "        [-0.0052],\n",
      "        [ 0.0852],\n",
      "        [-0.0493],\n",
      "        [ 0.0247],\n",
      "        [ 0.0472],\n",
      "        [-0.0315],\n",
      "        [ 0.0301],\n",
      "        [ 0.0244]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0728, 0.0722, 0.0714, 0.0718, 0.0717, 0.0708, 0.0713, 0.0721, 0.0715,\n",
      "        0.0717, 0.0719, 0.0711, 0.0713, 0.0713, 0.0714, 0.0704, 0.0705, 0.0708,\n",
      "        0.0705, 0.0727, 0.0722, 0.0727, 0.0721, 0.0722, 0.0728, 0.0697, 0.0688,\n",
      "        0.0684, 0.0666, 0.0665, 0.0669, 0.0675], device='cuda:0')\n",
      "tensor([[-0.0227],\n",
      "        [-0.1383],\n",
      "        [-0.1115],\n",
      "        [-0.0387],\n",
      "        [-0.0167],\n",
      "        [ 0.0230],\n",
      "        [ 0.0183],\n",
      "        [-0.0201],\n",
      "        [ 0.0558],\n",
      "        [ 0.0129],\n",
      "        [ 0.0453],\n",
      "        [-0.0079],\n",
      "        [ 0.0159],\n",
      "        [-0.0068],\n",
      "        [-0.0095],\n",
      "        [ 0.0321],\n",
      "        [-0.0045],\n",
      "        [ 0.0080],\n",
      "        [ 0.0111],\n",
      "        [ 0.0833],\n",
      "        [-0.0169],\n",
      "        [ 0.0346],\n",
      "        [-0.0301],\n",
      "        [ 0.0135],\n",
      "        [-0.0230],\n",
      "        [-0.0041],\n",
      "        [ 0.0134],\n",
      "        [ 0.0031],\n",
      "        [-0.0254],\n",
      "        [-0.0195],\n",
      "        [ 0.0061],\n",
      "        [ 0.0188]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0683, 0.0680, 0.0666, 0.0675, 0.0680, 0.0674, 0.0662, 0.0662, 0.0659,\n",
      "        0.0677, 0.0675, 0.0660, 0.0653, 0.0635, 0.0634, 0.0640, 0.0625, 0.0628,\n",
      "        0.0628, 0.0631, 0.0624, 0.0621, 0.0628, 0.0616, 0.0616, 0.0624, 0.0631,\n",
      "        0.0634, 0.0629, 0.0621, 0.0625, 0.0643], device='cuda:0')\n",
      "tensor([[ 0.0216],\n",
      "        [-0.0184],\n",
      "        [-0.0414],\n",
      "        [-0.0046],\n",
      "        [ 0.0074],\n",
      "        [-0.0067],\n",
      "        [ 0.0142],\n",
      "        [ 0.0630],\n",
      "        [ 0.0580],\n",
      "        [-0.0081],\n",
      "        [ 0.1350],\n",
      "        [ 0.1112],\n",
      "        [-0.0150],\n",
      "        [-0.0114],\n",
      "        [ 0.0098],\n",
      "        [-0.0439],\n",
      "        [-0.0082],\n",
      "        [ 0.0414],\n",
      "        [ 0.0002],\n",
      "        [-0.0223],\n",
      "        [-0.0034],\n",
      "        [ 0.0068],\n",
      "        [-0.0216],\n",
      "        [ 0.0028],\n",
      "        [ 0.0274],\n",
      "        [ 0.0686],\n",
      "        [ 0.0112],\n",
      "        [-0.0683],\n",
      "        [-0.0024],\n",
      "        [ 0.1029],\n",
      "        [-0.0256],\n",
      "        [-0.0038]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0626, 0.0621, 0.0638, 0.0637, 0.0637, 0.0660, 0.0653, 0.0649, 0.0653,\n",
      "        0.0644, 0.0640, 0.0629, 0.0629, 0.0634, 0.0634, 0.0629, 0.0628, 0.0634,\n",
      "        0.0618, 0.0613, 0.0606, 0.0607, 0.0604, 0.0593, 0.0590, 0.0595, 0.0609,\n",
      "        0.0616, 0.0609, 0.0607, 0.0649, 0.0634], device='cuda:0')\n",
      "tensor([[ 0.0642],\n",
      "        [ 0.0480],\n",
      "        [-0.0240],\n",
      "        [ 0.0835],\n",
      "        [-0.0055],\n",
      "        [ 0.0315],\n",
      "        [ 0.0247],\n",
      "        [-0.0015],\n",
      "        [-0.0681],\n",
      "        [ 0.0241],\n",
      "        [ 0.0167],\n",
      "        [ 0.0355],\n",
      "        [ 0.0079],\n",
      "        [-0.0257],\n",
      "        [-0.0073],\n",
      "        [-0.0141],\n",
      "        [-0.0365],\n",
      "        [ 0.0182],\n",
      "        [-0.0137],\n",
      "        [ 0.0090],\n",
      "        [-0.0076],\n",
      "        [ 0.0089],\n",
      "        [-0.0024],\n",
      "        [-0.0430],\n",
      "        [ 0.0255],\n",
      "        [-0.0453],\n",
      "        [ 0.0007],\n",
      "        [-0.0190],\n",
      "        [ 0.0317],\n",
      "        [-0.0326],\n",
      "        [-0.0050],\n",
      "        [ 0.0327]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0609, 0.0618, 0.0612, 0.0613, 0.0607, 0.0606, 0.0613, 0.0613, 0.0618,\n",
      "        0.0621, 0.0603, 0.0587, 0.0607, 0.0593, 0.0584, 0.0579, 0.0564, 0.0554,\n",
      "        0.0550, 0.0538, 0.0545, 0.0548, 0.0545, 0.0541, 0.0542, 0.0545, 0.0563,\n",
      "        0.0544, 0.0557, 0.0554, 0.0553, 0.0548], device='cuda:0')\n",
      "tensor([[ 0.0240],\n",
      "        [-0.0443],\n",
      "        [-0.0181],\n",
      "        [ 0.0056],\n",
      "        [ 0.0285],\n",
      "        [ 0.0504],\n",
      "        [-0.0471],\n",
      "        [ 0.0365],\n",
      "        [ 0.0091],\n",
      "        [ 0.0354],\n",
      "        [-0.0415],\n",
      "        [ 0.0280],\n",
      "        [-0.0058],\n",
      "        [ 0.0344],\n",
      "        [-0.0538],\n",
      "        [ 0.0245],\n",
      "        [ 0.0010],\n",
      "        [-0.0094],\n",
      "        [ 0.0996],\n",
      "        [ 0.0880],\n",
      "        [ 0.0705],\n",
      "        [-0.0095],\n",
      "        [ 0.0096],\n",
      "        [-0.0137],\n",
      "        [-0.0637],\n",
      "        [ 0.0586],\n",
      "        [ 0.0475],\n",
      "        [ 0.0229],\n",
      "        [-0.0299],\n",
      "        [ 0.0043],\n",
      "        [-0.0179],\n",
      "        [-0.0446]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0533, 0.0538, 0.0536, 0.0550, 0.0542, 0.0545, 0.0545, 0.0539, 0.0538,\n",
      "        0.0535, 0.0535, 0.0539, 0.0570, 0.0569, 0.0584, 0.0584, 0.0578, 0.0575,\n",
      "        0.0579, 0.0584, 0.0601, 0.0594, 0.0591, 0.0582, 0.0578, 0.0575, 0.0587,\n",
      "        0.0579, 0.0563, 0.0567, 0.0576, 0.0563], device='cuda:0')\n",
      "tensor([[ 0.0288],\n",
      "        [-0.0164],\n",
      "        [-0.0363],\n",
      "        [ 0.0127],\n",
      "        [-0.0673],\n",
      "        [ 0.0195],\n",
      "        [ 0.0135],\n",
      "        [-0.0369],\n",
      "        [-0.0266],\n",
      "        [ 0.0300],\n",
      "        [-0.0614],\n",
      "        [ 0.0151],\n",
      "        [-0.0345],\n",
      "        [ 0.0237],\n",
      "        [-0.0153],\n",
      "        [-0.0065],\n",
      "        [ 0.0567],\n",
      "        [ 0.0209],\n",
      "        [ 0.0425],\n",
      "        [-0.0090],\n",
      "        [ 0.0614],\n",
      "        [-0.0417],\n",
      "        [ 0.0096],\n",
      "        [-0.0056],\n",
      "        [-0.0583],\n",
      "        [-0.0546],\n",
      "        [ 0.0129],\n",
      "        [ 0.0111],\n",
      "        [ 0.0050],\n",
      "        [ 0.0210],\n",
      "        [-0.0216],\n",
      "        [-0.0335]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0573, 0.0573, 0.0572, 0.0566, 0.0567, 0.0545, 0.0557, 0.0556, 0.0553,\n",
      "        0.0603, 0.0579, 0.0604, 0.0598, 0.0597, 0.0635, 0.0634, 0.0625, 0.0629,\n",
      "        0.0622, 0.0622, 0.0649, 0.0641, 0.0635, 0.0646, 0.0638, 0.0638, 0.0618,\n",
      "        0.0626, 0.0624, 0.0629, 0.0615, 0.0600], device='cuda:0')\n",
      "tensor([[ 0.0027],\n",
      "        [ 0.0014],\n",
      "        [-0.0889],\n",
      "        [-0.0159],\n",
      "        [-0.0293],\n",
      "        [-0.0181],\n",
      "        [ 0.0184],\n",
      "        [-0.0433],\n",
      "        [-0.0092],\n",
      "        [ 0.0749],\n",
      "        [ 0.0300],\n",
      "        [ 0.0389],\n",
      "        [-0.0452],\n",
      "        [-0.0214],\n",
      "        [ 0.0091],\n",
      "        [ 0.0151],\n",
      "        [-0.0027],\n",
      "        [-0.0825],\n",
      "        [-0.0158],\n",
      "        [ 0.0210],\n",
      "        [-0.0307],\n",
      "        [-0.0279],\n",
      "        [ 0.0211],\n",
      "        [-0.0406],\n",
      "        [ 0.0360],\n",
      "        [ 0.0131],\n",
      "        [-0.0167],\n",
      "        [-0.0029],\n",
      "        [ 0.0275],\n",
      "        [ 0.0314],\n",
      "        [-0.0593],\n",
      "        [-0.0322]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0601, 0.0595, 0.0621, 0.0626, 0.0612, 0.0606, 0.0598, 0.0601, 0.0590,\n",
      "        0.0587, 0.0576, 0.0575, 0.0539, 0.0556, 0.0557, 0.0548, 0.0554, 0.0539,\n",
      "        0.0529, 0.0528, 0.0535, 0.0542, 0.0532, 0.0517, 0.0514, 0.0505, 0.0511,\n",
      "        0.0502, 0.0495, 0.0477, 0.0446, 0.0454], device='cuda:0')\n",
      "tensor([[-0.0432],\n",
      "        [ 0.0095],\n",
      "        [ 0.0059],\n",
      "        [ 0.0344],\n",
      "        [ 0.0440],\n",
      "        [ 0.1116],\n",
      "        [-0.0103],\n",
      "        [-0.0330],\n",
      "        [-0.0149],\n",
      "        [ 0.0190],\n",
      "        [ 0.0598],\n",
      "        [-0.0027],\n",
      "        [ 0.0252],\n",
      "        [-0.0244],\n",
      "        [-0.0011],\n",
      "        [ 0.0032],\n",
      "        [-0.0155],\n",
      "        [-0.0417],\n",
      "        [-0.0366],\n",
      "        [ 0.0131],\n",
      "        [ 0.0713],\n",
      "        [ 0.0428],\n",
      "        [ 0.0149],\n",
      "        [ 0.0357],\n",
      "        [ 0.0191],\n",
      "        [-0.0364],\n",
      "        [-0.0078],\n",
      "        [ 0.0441],\n",
      "        [ 0.0167],\n",
      "        [ 0.0487],\n",
      "        [ 0.0056],\n",
      "        [-0.0424]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0433, 0.0486, 0.0467, 0.0466, 0.0455, 0.0463, 0.0455, 0.0438, 0.0439,\n",
      "        0.0452, 0.0448, 0.0439, 0.0433, 0.0421, 0.0411, 0.0412, 0.0412, 0.0412,\n",
      "        0.0443, 0.0439, 0.0442, 0.0461, 0.0451, 0.0455, 0.0455, 0.0449, 0.0445,\n",
      "        0.0461, 0.0455, 0.0458, 0.0443, 0.0423], device='cuda:0')\n",
      "tensor([[ 1.6935e-02],\n",
      "        [-3.5355e-02],\n",
      "        [-2.5325e-02],\n",
      "        [-5.8594e-02],\n",
      "        [ 2.1379e-02],\n",
      "        [-1.1420e-02],\n",
      "        [-3.0232e-02],\n",
      "        [-4.6342e-02],\n",
      "        [-1.7294e-03],\n",
      "        [-3.6629e-02],\n",
      "        [ 1.5704e-02],\n",
      "        [ 3.9921e-02],\n",
      "        [-7.0354e-02],\n",
      "        [-5.5838e-05],\n",
      "        [ 1.1366e-02],\n",
      "        [ 2.8438e-02],\n",
      "        [ 5.2754e-02],\n",
      "        [-3.4440e-04],\n",
      "        [ 7.6859e-03],\n",
      "        [ 3.8000e-03],\n",
      "        [-1.0437e-02],\n",
      "        [ 2.5161e-02],\n",
      "        [ 4.8200e-02],\n",
      "        [ 3.3034e-03],\n",
      "        [-3.2086e-02],\n",
      "        [-4.7583e-02],\n",
      "        [-6.3723e-02],\n",
      "        [ 3.9666e-02],\n",
      "        [-2.0765e-02],\n",
      "        [ 1.8122e-02],\n",
      "        [ 9.6313e-03],\n",
      "        [-8.3049e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0424, 0.0436, 0.0433, 0.0427, 0.0433, 0.0438, 0.0430, 0.0432, 0.0442,\n",
      "        0.0454, 0.0460, 0.0473, 0.0449, 0.0461, 0.0469, 0.0473, 0.0494, 0.0480,\n",
      "        0.0482, 0.0477, 0.0486, 0.0492, 0.0492, 0.0502, 0.0520, 0.0502, 0.0511,\n",
      "        0.0491, 0.0491, 0.0502, 0.0508, 0.0513], device='cuda:0')\n",
      "tensor([[ 0.0111],\n",
      "        [ 0.0276],\n",
      "        [ 0.0001],\n",
      "        [-0.0196],\n",
      "        [-0.0024],\n",
      "        [-0.0280],\n",
      "        [ 0.0175],\n",
      "        [ 0.0147],\n",
      "        [ 0.0016],\n",
      "        [ 0.0041],\n",
      "        [-0.0124],\n",
      "        [ 0.0566],\n",
      "        [ 0.0203],\n",
      "        [ 0.0282],\n",
      "        [-0.0229],\n",
      "        [-0.0123],\n",
      "        [ 0.0834],\n",
      "        [ 0.0528],\n",
      "        [ 0.0105],\n",
      "        [ 0.0140],\n",
      "        [-0.0176],\n",
      "        [ 0.0226],\n",
      "        [ 0.0069],\n",
      "        [-0.0012],\n",
      "        [-0.0554],\n",
      "        [ 0.0527],\n",
      "        [ 0.0070],\n",
      "        [ 0.0172],\n",
      "        [ 0.0054],\n",
      "        [ 0.0259],\n",
      "        [-0.0212],\n",
      "        [ 0.0283]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0507, 0.0513, 0.0501, 0.0510, 0.0523, 0.0529, 0.0539, 0.0536, 0.0533,\n",
      "        0.0535, 0.0548, 0.0575, 0.0560, 0.0566, 0.0582, 0.0576, 0.0587, 0.0576,\n",
      "        0.0573, 0.0572, 0.0567, 0.0575, 0.0576, 0.0581, 0.0578, 0.0576, 0.0572,\n",
      "        0.0566, 0.0582, 0.0584, 0.0578, 0.0595], device='cuda:0')\n",
      "tensor([[-0.0480],\n",
      "        [-0.0141],\n",
      "        [ 0.0124],\n",
      "        [ 0.0371],\n",
      "        [ 0.0295],\n",
      "        [ 0.0279],\n",
      "        [ 0.0110],\n",
      "        [ 0.0126],\n",
      "        [ 0.0253],\n",
      "        [-0.0604],\n",
      "        [ 0.0326],\n",
      "        [-0.0641],\n",
      "        [-0.0640],\n",
      "        [-0.0504],\n",
      "        [ 0.0035],\n",
      "        [ 0.0075],\n",
      "        [-0.0471],\n",
      "        [-0.0906],\n",
      "        [ 0.0617],\n",
      "        [ 0.0247],\n",
      "        [-0.0216],\n",
      "        [ 0.0291],\n",
      "        [-0.0459],\n",
      "        [ 0.0235],\n",
      "        [-0.0053],\n",
      "        [-0.0088],\n",
      "        [ 0.0050],\n",
      "        [ 0.0174],\n",
      "        [-0.0208],\n",
      "        [ 0.0314],\n",
      "        [ 0.0406],\n",
      "        [ 0.0065]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0595, 0.0595, 0.0621, 0.0619, 0.0591, 0.0587, 0.0597, 0.0604, 0.0603,\n",
      "        0.0600, 0.0595, 0.0585, 0.0575, 0.0581, 0.0588, 0.0604, 0.0594, 0.0593,\n",
      "        0.0566, 0.0588, 0.0584, 0.0591, 0.0585, 0.0588, 0.0582, 0.0601, 0.0593,\n",
      "        0.0598, 0.0612, 0.0597, 0.0604, 0.0588], device='cuda:0')\n",
      "tensor([[ 0.0230],\n",
      "        [-0.0024],\n",
      "        [ 0.0302],\n",
      "        [-0.0051],\n",
      "        [-0.0070],\n",
      "        [-0.0549],\n",
      "        [-0.0733],\n",
      "        [ 0.0706],\n",
      "        [ 0.0256],\n",
      "        [-0.0134],\n",
      "        [-0.0207],\n",
      "        [-0.0350],\n",
      "        [ 0.0344],\n",
      "        [ 0.1491],\n",
      "        [ 0.0876],\n",
      "        [ 0.0478],\n",
      "        [-0.0122],\n",
      "        [ 0.0440],\n",
      "        [-0.0393],\n",
      "        [-0.0308],\n",
      "        [ 0.0432],\n",
      "        [-0.0747],\n",
      "        [-0.0248],\n",
      "        [-0.0538],\n",
      "        [-0.0053],\n",
      "        [-0.0292],\n",
      "        [-0.0511],\n",
      "        [ 0.0156],\n",
      "        [-0.0285],\n",
      "        [ 0.0288],\n",
      "        [-0.0162],\n",
      "        [ 0.0317]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0570, 0.0560, 0.0564, 0.0570, 0.0579, 0.0590, 0.0610, 0.0607, 0.0634,\n",
      "        0.0635, 0.0625, 0.0640, 0.0631, 0.0638, 0.0618, 0.0610, 0.0616, 0.0610,\n",
      "        0.0607, 0.0585, 0.0594, 0.0588, 0.0594, 0.0581, 0.0576, 0.0594, 0.0604,\n",
      "        0.0616, 0.0593, 0.0600, 0.0601, 0.0600], device='cuda:0')\n",
      "tensor([[ 0.0010],\n",
      "        [-0.0038],\n",
      "        [-0.0067],\n",
      "        [ 0.0073],\n",
      "        [-0.0268],\n",
      "        [-0.0457],\n",
      "        [ 0.1667],\n",
      "        [ 0.0300],\n",
      "        [ 0.0112],\n",
      "        [ 0.0035],\n",
      "        [-0.0153],\n",
      "        [-0.0151],\n",
      "        [-0.0322],\n",
      "        [ 0.0436],\n",
      "        [ 0.0016],\n",
      "        [ 0.0109],\n",
      "        [-0.0525],\n",
      "        [-0.0065],\n",
      "        [ 0.0331],\n",
      "        [ 0.0168],\n",
      "        [ 0.0003],\n",
      "        [-0.0075],\n",
      "        [ 0.0261],\n",
      "        [ 0.0347],\n",
      "        [-0.0332],\n",
      "        [ 0.1021],\n",
      "        [ 0.0086],\n",
      "        [-0.0261],\n",
      "        [-0.0362],\n",
      "        [-0.0387],\n",
      "        [-0.0311],\n",
      "        [-0.0173]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0644, 0.0649, 0.0653, 0.0653, 0.0657, 0.0650, 0.0657, 0.0638, 0.0638,\n",
      "        0.0628, 0.0619, 0.0612, 0.0593, 0.0609, 0.0610, 0.0615, 0.0604, 0.0591,\n",
      "        0.0588, 0.0560, 0.0569, 0.0584, 0.0569, 0.0590, 0.0578, 0.0559, 0.0570,\n",
      "        0.0600, 0.0601, 0.0616, 0.0622, 0.0610], device='cuda:0')\n",
      "tensor([[ 1.8039e-02],\n",
      "        [ 4.6057e-02],\n",
      "        [ 8.6663e-02],\n",
      "        [ 1.8377e-03],\n",
      "        [ 3.1924e-03],\n",
      "        [-1.6737e-02],\n",
      "        [ 3.7566e-05],\n",
      "        [ 2.8348e-02],\n",
      "        [ 2.5738e-02],\n",
      "        [ 1.3569e-01],\n",
      "        [ 8.2235e-02],\n",
      "        [ 7.3797e-04],\n",
      "        [-3.4927e-02],\n",
      "        [-8.0463e-02],\n",
      "        [-4.8141e-02],\n",
      "        [-6.4522e-02],\n",
      "        [ 4.5953e-02],\n",
      "        [ 6.7671e-03],\n",
      "        [ 5.6638e-03],\n",
      "        [ 4.4714e-02],\n",
      "        [ 5.7916e-03],\n",
      "        [-2.9729e-02],\n",
      "        [ 4.6395e-02],\n",
      "        [-4.4149e-03],\n",
      "        [-3.8247e-03],\n",
      "        [-4.7459e-02],\n",
      "        [ 7.7054e-03],\n",
      "        [ 3.5522e-02],\n",
      "        [ 3.8675e-02],\n",
      "        [-3.3760e-02],\n",
      "        [ 1.6203e-02],\n",
      "        [ 6.6010e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0618, 0.0609, 0.0624, 0.0637, 0.0652, 0.0628, 0.0606, 0.0603, 0.0595,\n",
      "        0.0593, 0.0595, 0.0584, 0.0597, 0.0594, 0.0575, 0.0576, 0.0578, 0.0575,\n",
      "        0.0575, 0.0581, 0.0570, 0.0573, 0.0567, 0.0556, 0.0566, 0.0569, 0.0563,\n",
      "        0.0566, 0.0557, 0.0551, 0.0547, 0.0536], device='cuda:0')\n",
      "tensor([[-0.0142],\n",
      "        [-0.0050],\n",
      "        [-0.0481],\n",
      "        [ 0.0528],\n",
      "        [-0.0184],\n",
      "        [ 0.0981],\n",
      "        [-0.0191],\n",
      "        [ 0.0290],\n",
      "        [-0.0628],\n",
      "        [-0.0807],\n",
      "        [ 0.0234],\n",
      "        [ 0.0067],\n",
      "        [ 0.0097],\n",
      "        [ 0.1029],\n",
      "        [ 0.1145],\n",
      "        [ 0.0487],\n",
      "        [-0.0097],\n",
      "        [-0.0074],\n",
      "        [-0.0207],\n",
      "        [-0.0044],\n",
      "        [-0.0486],\n",
      "        [-0.0253],\n",
      "        [ 0.0075],\n",
      "        [ 0.0272],\n",
      "        [ 0.0140],\n",
      "        [ 0.0667],\n",
      "        [-0.0430],\n",
      "        [-0.0389],\n",
      "        [-0.0228],\n",
      "        [-0.0020],\n",
      "        [-0.0175],\n",
      "        [-0.0698]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0536, 0.0539, 0.0539, 0.0531, 0.0522, 0.0539, 0.0541, 0.0566, 0.0572,\n",
      "        0.0566, 0.0559, 0.0545, 0.0538, 0.0539, 0.0538, 0.0551, 0.0545, 0.0542,\n",
      "        0.0563, 0.0554, 0.0570, 0.0566, 0.0572, 0.0560, 0.0553, 0.0550, 0.0542,\n",
      "        0.0562, 0.0553, 0.0536, 0.0533, 0.0544], device='cuda:0')\n",
      "tensor([[ 0.0139],\n",
      "        [ 0.0602],\n",
      "        [-0.0287],\n",
      "        [-0.0169],\n",
      "        [-0.0461],\n",
      "        [ 0.0208],\n",
      "        [-0.0077],\n",
      "        [ 0.0060],\n",
      "        [-0.0397],\n",
      "        [ 0.0319],\n",
      "        [-0.0093],\n",
      "        [-0.0149],\n",
      "        [ 0.0601],\n",
      "        [ 0.0144],\n",
      "        [ 0.0057],\n",
      "        [-0.0049],\n",
      "        [ 0.0405],\n",
      "        [ 0.0329],\n",
      "        [ 0.0672],\n",
      "        [ 0.0414],\n",
      "        [ 0.0379],\n",
      "        [ 0.0336],\n",
      "        [-0.0443],\n",
      "        [ 0.0314],\n",
      "        [-0.0058],\n",
      "        [-0.0117],\n",
      "        [-0.0402],\n",
      "        [-0.0105],\n",
      "        [-0.0274],\n",
      "        [-0.0339],\n",
      "        [ 0.0175],\n",
      "        [ 0.0132]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0551, 0.0541, 0.0529, 0.0520, 0.0516, 0.0516, 0.0536, 0.0525, 0.0517,\n",
      "        0.0505, 0.0511, 0.0516, 0.0535, 0.0522, 0.0520, 0.0520, 0.0523, 0.0529,\n",
      "        0.0520, 0.0511, 0.0500, 0.0505, 0.0497, 0.0489, 0.0491, 0.0485, 0.0491,\n",
      "        0.0469, 0.0477, 0.0477, 0.0476, 0.0473], device='cuda:0')\n",
      "tensor([[ 2.5309e-02],\n",
      "        [-3.1461e-02],\n",
      "        [ 2.6569e-05],\n",
      "        [ 1.0085e-02],\n",
      "        [ 3.7716e-02],\n",
      "        [-6.8556e-03],\n",
      "        [-4.9208e-02],\n",
      "        [-5.5713e-02],\n",
      "        [ 4.3331e-02],\n",
      "        [-4.4856e-03],\n",
      "        [-4.4185e-02],\n",
      "        [ 9.9185e-03],\n",
      "        [-1.4068e-02],\n",
      "        [ 7.3578e-02],\n",
      "        [ 1.4778e-01],\n",
      "        [-1.2223e-02],\n",
      "        [ 3.6326e-02],\n",
      "        [-4.2018e-03],\n",
      "        [-3.9483e-02],\n",
      "        [-2.0632e-02],\n",
      "        [-1.6967e-02],\n",
      "        [-4.2189e-02],\n",
      "        [ 2.8765e-02],\n",
      "        [ 2.4208e-03],\n",
      "        [-6.3611e-03],\n",
      "        [ 6.9515e-02],\n",
      "        [-2.6268e-02],\n",
      "        [-2.6388e-02],\n",
      "        [ 5.2726e-02],\n",
      "        [-2.4184e-02],\n",
      "        [ 8.5324e-03],\n",
      "        [ 3.2938e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0477, 0.0476, 0.0473, 0.0464, 0.0463, 0.0470, 0.0491, 0.0492, 0.0501,\n",
      "        0.0519, 0.0514, 0.0505, 0.0492, 0.0497, 0.0495, 0.0485, 0.0491, 0.0504,\n",
      "        0.0508, 0.0514, 0.0502, 0.0498, 0.0488, 0.0486, 0.0494, 0.0508, 0.0510,\n",
      "        0.0504, 0.0501, 0.0491, 0.0491, 0.0479], device='cuda:0')\n",
      "tensor([[ 8.6384e-02],\n",
      "        [ 5.7345e-02],\n",
      "        [-1.2765e-02],\n",
      "        [-4.3376e-02],\n",
      "        [ 7.5312e-03],\n",
      "        [ 7.5294e-02],\n",
      "        [-9.1376e-03],\n",
      "        [ 8.3569e-03],\n",
      "        [-3.7945e-02],\n",
      "        [ 2.0238e-02],\n",
      "        [-4.2681e-02],\n",
      "        [-3.0092e-02],\n",
      "        [-9.2751e-04],\n",
      "        [-1.2064e-02],\n",
      "        [ 1.2014e-02],\n",
      "        [-5.6633e-04],\n",
      "        [ 1.4365e-02],\n",
      "        [-2.2052e-02],\n",
      "        [ 3.1142e-02],\n",
      "        [ 6.0831e-02],\n",
      "        [ 3.1824e-02],\n",
      "        [-9.6618e-03],\n",
      "        [ 6.6806e-05],\n",
      "        [ 8.7956e-04],\n",
      "        [ 4.2830e-02],\n",
      "        [-1.4949e-02],\n",
      "        [-4.2016e-02],\n",
      "        [ 1.6297e-01],\n",
      "        [ 1.3312e-01],\n",
      "        [ 6.6879e-03],\n",
      "        [ 1.1546e-02],\n",
      "        [-4.7055e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0479, 0.0480, 0.0480, 0.0476, 0.0476, 0.0473, 0.0467, 0.0479, 0.0476,\n",
      "        0.0476, 0.0470, 0.0461, 0.0463, 0.0458, 0.0455, 0.0457, 0.0464, 0.0461,\n",
      "        0.0461, 0.0473, 0.0470, 0.0474, 0.0495, 0.0497, 0.0479, 0.0480, 0.0491,\n",
      "        0.0501, 0.0491, 0.0495, 0.0492, 0.0477], device='cuda:0')\n",
      "tensor([[ 0.1634],\n",
      "        [-0.0655],\n",
      "        [ 0.0179],\n",
      "        [ 0.1115],\n",
      "        [-0.0226],\n",
      "        [-0.0036],\n",
      "        [-0.0608],\n",
      "        [-0.0441],\n",
      "        [-0.0552],\n",
      "        [ 0.0045],\n",
      "        [ 0.0298],\n",
      "        [-0.0030],\n",
      "        [ 0.0246],\n",
      "        [-0.0172],\n",
      "        [-0.0395],\n",
      "        [-0.0080],\n",
      "        [ 0.0176],\n",
      "        [-0.0233],\n",
      "        [-0.0433],\n",
      "        [-0.0492],\n",
      "        [ 0.0311],\n",
      "        [-0.0069],\n",
      "        [ 0.0292],\n",
      "        [ 0.0676],\n",
      "        [ 0.0444],\n",
      "        [-0.0177],\n",
      "        [-0.0100],\n",
      "        [ 0.0387],\n",
      "        [-0.0206],\n",
      "        [ 0.0181],\n",
      "        [ 0.0138],\n",
      "        [ 0.0033]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0476, 0.0480, 0.0483, 0.0479, 0.0467, 0.0467, 0.0463, 0.0460, 0.0467,\n",
      "        0.0458, 0.0469, 0.0466, 0.0452, 0.0445, 0.0445, 0.0446, 0.0454, 0.0466,\n",
      "        0.0467, 0.0463, 0.0455, 0.0446, 0.0445, 0.0455, 0.0449, 0.0451, 0.0452,\n",
      "        0.0440, 0.0455, 0.0436, 0.0446, 0.0445], device='cuda:0')\n",
      "tensor([[ 0.0105],\n",
      "        [ 0.0154],\n",
      "        [-0.0184],\n",
      "        [ 0.0055],\n",
      "        [-0.0256],\n",
      "        [ 0.0419],\n",
      "        [-0.0138],\n",
      "        [ 0.0210],\n",
      "        [-0.0081],\n",
      "        [ 0.0307],\n",
      "        [-0.0080],\n",
      "        [-0.0189],\n",
      "        [ 0.0216],\n",
      "        [-0.0246],\n",
      "        [-0.0899],\n",
      "        [-0.0678],\n",
      "        [ 0.0469],\n",
      "        [-0.0460],\n",
      "        [ 0.0181],\n",
      "        [-0.0661],\n",
      "        [-0.0421],\n",
      "        [ 0.0232],\n",
      "        [-0.0403],\n",
      "        [ 0.0317],\n",
      "        [-0.0730],\n",
      "        [ 0.0035],\n",
      "        [ 0.1621],\n",
      "        [ 0.0212],\n",
      "        [ 0.0542],\n",
      "        [-0.0107],\n",
      "        [-0.0103],\n",
      "        [-0.0210]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0457, 0.0458, 0.0448, 0.0457, 0.0463, 0.0467, 0.0463, 0.0442, 0.0427,\n",
      "        0.0424, 0.0412, 0.0412, 0.0417, 0.0414, 0.0411, 0.0410, 0.0405, 0.0407,\n",
      "        0.0392, 0.0386, 0.0415, 0.0433, 0.0433, 0.0426, 0.0415, 0.0408, 0.0417,\n",
      "        0.0424, 0.0427, 0.0430, 0.0417, 0.0410], device='cuda:0')\n",
      "tensor([[-0.0297],\n",
      "        [-0.0174],\n",
      "        [-0.0080],\n",
      "        [-0.0375],\n",
      "        [ 0.0698],\n",
      "        [ 0.0275],\n",
      "        [-0.0618],\n",
      "        [ 0.0656],\n",
      "        [ 0.0499],\n",
      "        [ 0.0138],\n",
      "        [ 0.0237],\n",
      "        [ 0.0042],\n",
      "        [ 0.0647],\n",
      "        [ 0.0592],\n",
      "        [ 0.0914],\n",
      "        [-0.0348],\n",
      "        [-0.0172],\n",
      "        [ 0.0236],\n",
      "        [-0.0105],\n",
      "        [-0.0443],\n",
      "        [-0.0426],\n",
      "        [ 0.0209],\n",
      "        [-0.0204],\n",
      "        [-0.0259],\n",
      "        [-0.0108],\n",
      "        [-0.0201],\n",
      "        [ 0.0373],\n",
      "        [ 0.0142],\n",
      "        [-0.0193],\n",
      "        [ 0.0683],\n",
      "        [-0.0114],\n",
      "        [-0.0068]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0410, 0.0402, 0.0402, 0.0405, 0.0404, 0.0424, 0.0429, 0.0451, 0.0451,\n",
      "        0.0446, 0.0433, 0.0445, 0.0452, 0.0439, 0.0436, 0.0443, 0.0452, 0.0449,\n",
      "        0.0438, 0.0440, 0.0446, 0.0466, 0.0477, 0.0473, 0.0479, 0.0470, 0.0480,\n",
      "        0.0474, 0.0469, 0.0483, 0.0479, 0.0495], device='cuda:0')\n",
      "tensor([[-0.0485],\n",
      "        [-0.0721],\n",
      "        [-0.0302],\n",
      "        [-0.0401],\n",
      "        [ 0.0072],\n",
      "        [ 0.0313],\n",
      "        [-0.0452],\n",
      "        [-0.0465],\n",
      "        [ 0.0038],\n",
      "        [-0.0359],\n",
      "        [-0.0079],\n",
      "        [ 0.0144],\n",
      "        [ 0.0155],\n",
      "        [-0.0020],\n",
      "        [ 0.0057],\n",
      "        [-0.0398],\n",
      "        [ 0.0452],\n",
      "        [ 0.0368],\n",
      "        [-0.0207],\n",
      "        [-0.0591],\n",
      "        [-0.0186],\n",
      "        [ 0.0195],\n",
      "        [-0.0565],\n",
      "        [ 0.0130],\n",
      "        [-0.0389],\n",
      "        [ 0.0169],\n",
      "        [ 0.0062],\n",
      "        [-0.0461],\n",
      "        [-0.0433],\n",
      "        [-0.0485],\n",
      "        [-0.0914],\n",
      "        [ 0.0292]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0480, 0.0477, 0.0477, 0.0477, 0.0477, 0.0486, 0.0485, 0.0502, 0.0513,\n",
      "        0.0538, 0.0528, 0.0533, 0.0545, 0.0535, 0.0539, 0.0536, 0.0547, 0.0567,\n",
      "        0.0559, 0.0547, 0.0551, 0.0548, 0.0554, 0.0554, 0.0533, 0.0532, 0.0538,\n",
      "        0.0531, 0.0528, 0.0542, 0.0542, 0.0548], device='cuda:0')\n",
      "tensor([[-0.0264],\n",
      "        [ 0.0062],\n",
      "        [-0.0392],\n",
      "        [ 0.0066],\n",
      "        [-0.0155],\n",
      "        [ 0.0142],\n",
      "        [-0.0123],\n",
      "        [ 0.0330],\n",
      "        [ 0.0190],\n",
      "        [ 0.0044],\n",
      "        [-0.0197],\n",
      "        [ 0.0553],\n",
      "        [-0.0194],\n",
      "        [ 0.0136],\n",
      "        [-0.0462],\n",
      "        [-0.0636],\n",
      "        [ 0.1294],\n",
      "        [-0.0116],\n",
      "        [ 0.0024],\n",
      "        [ 0.0196],\n",
      "        [ 0.0226],\n",
      "        [ 0.0377],\n",
      "        [ 0.0187],\n",
      "        [-0.0320],\n",
      "        [-0.0367],\n",
      "        [-0.0417],\n",
      "        [-0.0144],\n",
      "        [-0.0061],\n",
      "        [ 0.0080],\n",
      "        [ 0.0418],\n",
      "        [ 0.0215],\n",
      "        [ 0.0356]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0544, 0.0520, 0.0526, 0.0539, 0.0535, 0.0538, 0.0541, 0.0528, 0.0514,\n",
      "        0.0505, 0.0498, 0.0486, 0.0500, 0.0504, 0.0495, 0.0491, 0.0502, 0.0485,\n",
      "        0.0485, 0.0491, 0.0488, 0.0505, 0.0510, 0.0505, 0.0513, 0.0504, 0.0514,\n",
      "        0.0520, 0.0513, 0.0528, 0.0533, 0.0533], device='cuda:0')\n",
      "tensor([[-0.0427],\n",
      "        [-0.0240],\n",
      "        [-0.0253],\n",
      "        [-0.0224],\n",
      "        [ 0.0143],\n",
      "        [-0.0051],\n",
      "        [ 0.0097],\n",
      "        [ 0.0098],\n",
      "        [-0.0491],\n",
      "        [-0.0312],\n",
      "        [ 0.0740],\n",
      "        [ 0.0834],\n",
      "        [ 0.0448],\n",
      "        [ 0.0881],\n",
      "        [ 0.0195],\n",
      "        [-0.0171],\n",
      "        [-0.0215],\n",
      "        [ 0.0865],\n",
      "        [ 0.0214],\n",
      "        [ 0.0254],\n",
      "        [-0.0001],\n",
      "        [ 0.0103],\n",
      "        [-0.0102],\n",
      "        [-0.1238],\n",
      "        [-0.0516],\n",
      "        [-0.0171],\n",
      "        [ 0.0039],\n",
      "        [-0.0339],\n",
      "        [-0.0398],\n",
      "        [-0.0470],\n",
      "        [-0.0856],\n",
      "        [ 0.1150]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0536, 0.0536, 0.0542, 0.0541, 0.0539, 0.0559, 0.0570, 0.0569, 0.0560,\n",
      "        0.0554, 0.0562, 0.0567, 0.0584, 0.0587, 0.0576, 0.0573, 0.0564, 0.0566,\n",
      "        0.0569, 0.0572, 0.0576, 0.0573, 0.0572, 0.0562, 0.0567, 0.0562, 0.0559,\n",
      "        0.0559, 0.0550, 0.0548, 0.0545, 0.0551], device='cuda:0')\n",
      "tensor([[-5.2638e-02],\n",
      "        [-5.9297e-02],\n",
      "        [ 1.8855e-02],\n",
      "        [-5.5485e-03],\n",
      "        [ 1.7254e-02],\n",
      "        [ 2.5666e-02],\n",
      "        [-2.8585e-02],\n",
      "        [-1.6924e-02],\n",
      "        [ 1.7068e-02],\n",
      "        [ 7.9600e-03],\n",
      "        [ 1.7070e-03],\n",
      "        [ 3.1517e-04],\n",
      "        [-4.0315e-05],\n",
      "        [-1.2348e-02],\n",
      "        [ 2.3012e-02],\n",
      "        [ 7.9352e-02],\n",
      "        [ 7.4736e-02],\n",
      "        [-9.8534e-03],\n",
      "        [-5.3767e-03],\n",
      "        [ 2.0060e-03],\n",
      "        [-3.8635e-02],\n",
      "        [ 6.0609e-02],\n",
      "        [ 2.0199e-02],\n",
      "        [ 6.7355e-03],\n",
      "        [ 3.3226e-02],\n",
      "        [-2.5144e-02],\n",
      "        [ 2.2523e-02],\n",
      "        [ 1.0344e-01],\n",
      "        [ 5.0709e-02],\n",
      "        [ 8.9376e-02],\n",
      "        [ 1.0007e-01],\n",
      "        [ 2.6331e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0547, 0.0542, 0.0538, 0.0539, 0.0539, 0.0533, 0.0536, 0.0539, 0.0533,\n",
      "        0.0519, 0.0516, 0.0495, 0.0494, 0.0501, 0.0511, 0.0505, 0.0513, 0.0510,\n",
      "        0.0498, 0.0497, 0.0500, 0.0514, 0.0529, 0.0522, 0.0519, 0.0529, 0.0529,\n",
      "        0.0523, 0.0523, 0.0516, 0.0520, 0.0528], device='cuda:0')\n",
      "tensor([[-0.0228],\n",
      "        [-0.0382],\n",
      "        [ 0.0224],\n",
      "        [ 0.0147],\n",
      "        [-0.0304],\n",
      "        [ 0.0057],\n",
      "        [ 0.0515],\n",
      "        [ 0.0609],\n",
      "        [ 0.0781],\n",
      "        [ 0.0884],\n",
      "        [ 0.0929],\n",
      "        [ 0.0738],\n",
      "        [-0.0784],\n",
      "        [ 0.0315],\n",
      "        [ 0.0103],\n",
      "        [-0.0167],\n",
      "        [-0.0471],\n",
      "        [-0.0264],\n",
      "        [ 0.0082],\n",
      "        [-0.0554],\n",
      "        [-0.0045],\n",
      "        [-0.0028],\n",
      "        [-0.0132],\n",
      "        [-0.0298],\n",
      "        [-0.0154],\n",
      "        [-0.0343],\n",
      "        [-0.0742],\n",
      "        [-0.0338],\n",
      "        [ 0.0084],\n",
      "        [-0.0300],\n",
      "        [-0.0291],\n",
      "        [-0.0509]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0533, 0.0545, 0.0597, 0.0569, 0.0597, 0.0595, 0.0595, 0.0585, 0.0603,\n",
      "        0.0604, 0.0594, 0.0593, 0.0585, 0.0581, 0.0573, 0.0581, 0.0582, 0.0595,\n",
      "        0.0587, 0.0582, 0.0562, 0.0553, 0.0554, 0.0551, 0.0544, 0.0542, 0.0550,\n",
      "        0.0550, 0.0587, 0.0584, 0.0587, 0.0613], device='cuda:0')\n",
      "tensor([[ 0.0914],\n",
      "        [-0.0468],\n",
      "        [-0.0090],\n",
      "        [-0.0252],\n",
      "        [-0.0291],\n",
      "        [ 0.0399],\n",
      "        [-0.0085],\n",
      "        [ 0.0265],\n",
      "        [ 0.0369],\n",
      "        [-0.0509],\n",
      "        [ 0.0158],\n",
      "        [ 0.0069],\n",
      "        [ 0.0228],\n",
      "        [ 0.0165],\n",
      "        [ 0.0682],\n",
      "        [ 0.0196],\n",
      "        [-0.0186],\n",
      "        [-0.0159],\n",
      "        [-0.0033],\n",
      "        [-0.0280],\n",
      "        [ 0.0076],\n",
      "        [-0.0581],\n",
      "        [ 0.0315],\n",
      "        [-0.0358],\n",
      "        [ 0.0145],\n",
      "        [ 0.0161],\n",
      "        [-0.0409],\n",
      "        [ 0.0075],\n",
      "        [ 0.0037],\n",
      "        [ 0.0207],\n",
      "        [-0.0868],\n",
      "        [-0.0378]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0626, 0.0615, 0.0624, 0.0624, 0.0622, 0.0632, 0.0640, 0.0631, 0.0650,\n",
      "        0.0659, 0.0663, 0.0663, 0.0656, 0.0650, 0.0668, 0.0663, 0.0674, 0.0683,\n",
      "        0.0683, 0.0690, 0.0714, 0.0699, 0.0709, 0.0705, 0.0712, 0.0708, 0.0690,\n",
      "        0.0674, 0.0683, 0.0687, 0.0694, 0.0740], device='cuda:0')\n",
      "tensor([[ 0.0623],\n",
      "        [-0.0365],\n",
      "        [ 0.0328],\n",
      "        [ 0.0366],\n",
      "        [ 0.0128],\n",
      "        [-0.0054],\n",
      "        [-0.0156],\n",
      "        [ 0.0947],\n",
      "        [ 0.0753],\n",
      "        [ 0.0650],\n",
      "        [-0.0009],\n",
      "        [ 0.0284],\n",
      "        [-0.0200],\n",
      "        [-0.0771],\n",
      "        [-0.0033],\n",
      "        [-0.0119],\n",
      "        [ 0.0024],\n",
      "        [-0.0351],\n",
      "        [ 0.0506],\n",
      "        [-0.0319],\n",
      "        [ 0.0680],\n",
      "        [ 0.0349],\n",
      "        [ 0.0115],\n",
      "        [-0.0027],\n",
      "        [ 0.0194],\n",
      "        [ 0.0261],\n",
      "        [ 0.0054],\n",
      "        [ 0.0153],\n",
      "        [ 0.0468],\n",
      "        [-0.0346],\n",
      "        [-0.0302],\n",
      "        [ 0.0076]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0756, 0.0765, 0.0793, 0.0784, 0.0793, 0.0753, 0.0746, 0.0787, 0.0777,\n",
      "        0.0805, 0.0808, 0.0784, 0.0752, 0.0776, 0.0771, 0.0748, 0.0750, 0.0770,\n",
      "        0.0774, 0.0814, 0.0799, 0.0802, 0.0792, 0.0820, 0.0804, 0.0815, 0.0815,\n",
      "        0.0779, 0.0777, 0.0799, 0.0796, 0.0793], device='cuda:0')\n",
      "tensor([[ 0.0105],\n",
      "        [-0.0671],\n",
      "        [-0.0133],\n",
      "        [-0.0189],\n",
      "        [ 0.0209],\n",
      "        [-0.0798],\n",
      "        [ 0.0508],\n",
      "        [ 0.0546],\n",
      "        [-0.0516],\n",
      "        [ 0.0275],\n",
      "        [ 0.0146],\n",
      "        [ 0.0195],\n",
      "        [-0.0369],\n",
      "        [ 0.0188],\n",
      "        [ 0.0040],\n",
      "        [ 0.0582],\n",
      "        [ 0.0437],\n",
      "        [ 0.0443],\n",
      "        [-0.0302],\n",
      "        [-0.0310],\n",
      "        [-0.1025],\n",
      "        [-0.0278],\n",
      "        [ 0.0506],\n",
      "        [ 0.0177],\n",
      "        [ 0.0025],\n",
      "        [ 0.0141],\n",
      "        [-0.0146],\n",
      "        [-0.0087],\n",
      "        [ 0.0181],\n",
      "        [-0.0043],\n",
      "        [-0.0220],\n",
      "        [ 0.0061]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0758, 0.0767, 0.0784, 0.0792, 0.0781, 0.0829, 0.0829, 0.0849, 0.0849,\n",
      "        0.0902, 0.0931, 0.0923, 0.0913, 0.0902, 0.0916, 0.0882, 0.0863, 0.0879,\n",
      "        0.0910, 0.0900, 0.0938, 0.0911, 0.0913, 0.0945, 0.0931, 0.0948, 0.0942,\n",
      "        0.0944, 0.0905, 0.0936, 0.0941, 0.0960], device='cuda:0')\n",
      "tensor([[-0.0331],\n",
      "        [-0.0462],\n",
      "        [-0.0088],\n",
      "        [-0.0227],\n",
      "        [ 0.0144],\n",
      "        [-0.0325],\n",
      "        [ 0.1020],\n",
      "        [ 0.0386],\n",
      "        [-0.0398],\n",
      "        [-0.0040],\n",
      "        [ 0.0446],\n",
      "        [-0.0007],\n",
      "        [ 0.0460],\n",
      "        [ 0.0271],\n",
      "        [-0.0205],\n",
      "        [-0.1075],\n",
      "        [ 0.0379],\n",
      "        [ 0.1059],\n",
      "        [-0.0732],\n",
      "        [-0.0191],\n",
      "        [ 0.0294],\n",
      "        [ 0.0116],\n",
      "        [-0.0431],\n",
      "        [ 0.0324],\n",
      "        [ 0.0478],\n",
      "        [-0.0095],\n",
      "        [ 0.0112],\n",
      "        [ 0.0309],\n",
      "        [ 0.0317],\n",
      "        [-0.0262],\n",
      "        [-0.0282],\n",
      "        [ 0.0336]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0948, 0.0964, 0.0964, 0.0966, 0.0972, 0.0978, 0.0979, 0.0984, 0.0970,\n",
      "        0.0963, 0.0925, 0.0916, 0.0941, 0.0931, 0.0960, 0.0957, 0.0975, 0.0953,\n",
      "        0.0941, 0.0935, 0.0957, 0.0954, 0.0931, 0.0923, 0.0945, 0.0945, 0.0976,\n",
      "        0.0975, 0.0969, 0.0969, 0.0972, 0.0954], device='cuda:0')\n",
      "tensor([[ 0.0850],\n",
      "        [-0.0376],\n",
      "        [ 0.0093],\n",
      "        [ 0.0100],\n",
      "        [ 0.0411],\n",
      "        [-0.0078],\n",
      "        [-0.0238],\n",
      "        [-0.0090],\n",
      "        [-0.0318],\n",
      "        [ 0.1135],\n",
      "        [-0.0382],\n",
      "        [ 0.0130],\n",
      "        [ 0.0160],\n",
      "        [-0.0140],\n",
      "        [-0.0144],\n",
      "        [ 0.0104],\n",
      "        [ 0.0312],\n",
      "        [-0.0229],\n",
      "        [ 0.0634],\n",
      "        [ 0.0212],\n",
      "        [-0.0096],\n",
      "        [ 0.0023],\n",
      "        [ 0.0383],\n",
      "        [ 0.0042],\n",
      "        [-0.0057],\n",
      "        [ 0.0197],\n",
      "        [-0.0139],\n",
      "        [-0.0210],\n",
      "        [-0.0038],\n",
      "        [-0.0522],\n",
      "        [ 0.0510],\n",
      "        [ 0.0476]], device='cuda:0', grad_fn=<AddmmBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([0.0973, 0.0998, 0.0993, 0.0976, 0.1009, 0.1013, 0.1010, 0.1015, 0.1024,\n",
      "        0.0998, 0.1015, 0.0991, 0.0997, 0.0994, 0.0998, 0.0975, 0.0975, 0.0987,\n",
      "        0.0997, 0.0990, 0.1013, 0.1015, 0.1013, 0.1016, 0.1022, 0.1038, 0.1009,\n",
      "        0.1016, 0.1012, 0.1019, 0.1026, 0.1034], device='cuda:0')\n",
      "tensor([[-0.0438],\n",
      "        [ 0.0283],\n",
      "        [ 0.0216],\n",
      "        [-0.0301],\n",
      "        [-0.0222],\n",
      "        [-0.0003],\n",
      "        [ 0.0266],\n",
      "        [ 0.0249],\n",
      "        [ 0.0082],\n",
      "        [-0.0014],\n",
      "        [ 0.0537],\n",
      "        [ 0.0075],\n",
      "        [-0.0690],\n",
      "        [ 0.0099],\n",
      "        [ 0.0091],\n",
      "        [-0.0391],\n",
      "        [ 0.0242],\n",
      "        [ 0.0136],\n",
      "        [-0.0154],\n",
      "        [-0.0326],\n",
      "        [ 0.0519],\n",
      "        [ 0.0206],\n",
      "        [-0.0501],\n",
      "        [-0.0064],\n",
      "        [ 0.0141],\n",
      "        [-0.0253],\n",
      "        [ 0.0232],\n",
      "        [ 0.0539],\n",
      "        [ 0.0217],\n",
      "        [ 0.0073],\n",
      "        [-0.0314],\n",
      "        [ 0.0261]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1066, 0.1071, 0.1091, 0.1100, 0.1108, 0.1137, 0.1124, 0.1167, 0.1165,\n",
      "        0.1192, 0.1159, 0.1190, 0.1177, 0.1192, 0.1189, 0.1165, 0.1171, 0.1183,\n",
      "        0.1174, 0.1196, 0.1195, 0.1187, 0.1171, 0.1171, 0.1183, 0.1168, 0.1153,\n",
      "        0.1153, 0.1121, 0.1115, 0.1136, 0.1161], device='cuda:0')\n",
      "tensor([[-0.0170],\n",
      "        [-0.0309],\n",
      "        [-0.0953],\n",
      "        [-0.0596],\n",
      "        [-0.0262],\n",
      "        [ 0.0057],\n",
      "        [-0.0221],\n",
      "        [ 0.0105],\n",
      "        [ 0.0409],\n",
      "        [-0.0447],\n",
      "        [-0.0184],\n",
      "        [-0.0271],\n",
      "        [ 0.0166],\n",
      "        [-0.0083],\n",
      "        [-0.0340],\n",
      "        [-0.0238],\n",
      "        [-0.0013],\n",
      "        [ 0.0107],\n",
      "        [ 0.0413],\n",
      "        [ 0.0910],\n",
      "        [ 0.1166],\n",
      "        [ 0.0004],\n",
      "        [-0.0200],\n",
      "        [ 0.1358],\n",
      "        [ 0.0196],\n",
      "        [ 0.0166],\n",
      "        [-0.0285],\n",
      "        [-0.0304],\n",
      "        [ 0.0562],\n",
      "        [-0.0217],\n",
      "        [ 0.0038],\n",
      "        [-0.0012]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1173, 0.1158, 0.1142, 0.1121, 0.1128, 0.1148, 0.1153, 0.1174, 0.1143,\n",
      "        0.1146, 0.1150, 0.1156, 0.1192, 0.1201, 0.1236, 0.1245, 0.1238, 0.1248,\n",
      "        0.1261, 0.1266, 0.1263, 0.1260, 0.1235, 0.1201, 0.1224, 0.1227, 0.1236,\n",
      "        0.1215, 0.1243, 0.1221, 0.1242, 0.1263], device='cuda:0')\n",
      "tensor([[ 4.0594e-02],\n",
      "        [ 1.7224e-02],\n",
      "        [-2.2494e-03],\n",
      "        [-2.2117e-02],\n",
      "        [ 3.8642e-02],\n",
      "        [-6.4126e-03],\n",
      "        [-2.1374e-02],\n",
      "        [-1.9369e-02],\n",
      "        [ 5.0388e-03],\n",
      "        [-2.0942e-02],\n",
      "        [-1.5662e-02],\n",
      "        [ 3.4876e-02],\n",
      "        [ 5.6444e-02],\n",
      "        [ 6.5365e-03],\n",
      "        [ 1.5550e-02],\n",
      "        [ 1.3277e-02],\n",
      "        [ 6.3777e-06],\n",
      "        [ 3.1774e-02],\n",
      "        [ 6.5927e-03],\n",
      "        [-6.1425e-03],\n",
      "        [-6.7613e-02],\n",
      "        [ 2.7736e-02],\n",
      "        [ 3.7028e-02],\n",
      "        [ 2.5415e-02],\n",
      "        [ 5.7011e-02],\n",
      "        [ 4.6030e-02],\n",
      "        [-7.5525e-02],\n",
      "        [ 3.0290e-02],\n",
      "        [-5.0574e-02],\n",
      "        [-1.2050e-03],\n",
      "        [-4.3365e-02],\n",
      "        [ 5.4897e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1235, 0.1239, 0.1248, 0.1226, 0.1223, 0.1235, 0.1288, 0.1289, 0.1276,\n",
      "        0.1294, 0.1292, 0.1264, 0.1248, 0.1229, 0.1233, 0.1230, 0.1239, 0.1218,\n",
      "        0.1221, 0.1212, 0.1202, 0.1202, 0.1198, 0.1207, 0.1230, 0.1243, 0.1260,\n",
      "        0.1243, 0.1254, 0.1239, 0.1217, 0.1183], device='cuda:0')\n",
      "tensor([[ 0.0340],\n",
      "        [-0.0037],\n",
      "        [ 0.0380],\n",
      "        [ 0.0108],\n",
      "        [ 0.0248],\n",
      "        [ 0.0989],\n",
      "        [ 0.0296],\n",
      "        [ 0.0213],\n",
      "        [ 0.0264],\n",
      "        [ 0.0050],\n",
      "        [-0.0629],\n",
      "        [-0.0076],\n",
      "        [-0.0282],\n",
      "        [-0.0053],\n",
      "        [ 0.0083],\n",
      "        [-0.0239],\n",
      "        [ 0.0146],\n",
      "        [-0.0284],\n",
      "        [-0.0049],\n",
      "        [-0.0442],\n",
      "        [-0.0073],\n",
      "        [-0.0111],\n",
      "        [ 0.0040],\n",
      "        [ 0.0288],\n",
      "        [ 0.0207],\n",
      "        [ 0.0311],\n",
      "        [-0.0593],\n",
      "        [ 0.0120],\n",
      "        [-0.0004],\n",
      "        [ 0.0087],\n",
      "        [-0.0675],\n",
      "        [-0.0037]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1180, 0.1199, 0.1212, 0.1193, 0.1218, 0.1208, 0.1221, 0.1246, 0.1252,\n",
      "        0.1251, 0.1251, 0.1242, 0.1248, 0.1258, 0.1245, 0.1261, 0.1269, 0.1270,\n",
      "        0.1260, 0.1279, 0.1302, 0.1326, 0.1317, 0.1328, 0.1317, 0.1305, 0.1320,\n",
      "        0.1341, 0.1356, 0.1367, 0.1369, 0.1393], device='cuda:0')\n",
      "tensor([[ 0.0628],\n",
      "        [ 0.0704],\n",
      "        [ 0.0997],\n",
      "        [-0.0121],\n",
      "        [ 0.0560],\n",
      "        [ 0.0402],\n",
      "        [ 0.0299],\n",
      "        [-0.0821],\n",
      "        [ 0.0686],\n",
      "        [-0.0843],\n",
      "        [-0.0653],\n",
      "        [ 0.0117],\n",
      "        [-0.0859],\n",
      "        [-0.0266],\n",
      "        [ 0.0030],\n",
      "        [ 0.0054],\n",
      "        [-0.0281],\n",
      "        [ 0.0043],\n",
      "        [-0.0022],\n",
      "        [-0.0344],\n",
      "        [-0.0104],\n",
      "        [-0.0384],\n",
      "        [-0.0574],\n",
      "        [-0.0023],\n",
      "        [ 0.0563],\n",
      "        [-0.0464],\n",
      "        [-0.0720],\n",
      "        [-0.0291],\n",
      "        [ 0.0088],\n",
      "        [-0.0403],\n",
      "        [-0.0274],\n",
      "        [-0.0133]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1378, 0.1373, 0.1385, 0.1363, 0.1363, 0.1328, 0.1348, 0.1339, 0.1307,\n",
      "        0.1322, 0.1325, 0.1319, 0.1335, 0.1319, 0.1304, 0.1304, 0.1301, 0.1270,\n",
      "        0.1251, 0.1249, 0.1251, 0.1267, 0.1286, 0.1305, 0.1313, 0.1277, 0.1280,\n",
      "        0.1264, 0.1266, 0.1286, 0.1260, 0.1235], device='cuda:0')\n",
      "tensor([[-0.0310],\n",
      "        [-0.0381],\n",
      "        [-0.0141],\n",
      "        [-0.0131],\n",
      "        [ 0.0086],\n",
      "        [-0.0755],\n",
      "        [ 0.0401],\n",
      "        [ 0.0514],\n",
      "        [ 0.0516],\n",
      "        [ 0.0066],\n",
      "        [ 0.0290],\n",
      "        [ 0.0443],\n",
      "        [-0.0297],\n",
      "        [-0.0130],\n",
      "        [-0.0047],\n",
      "        [-0.0165],\n",
      "        [ 0.0079],\n",
      "        [ 0.0105],\n",
      "        [-0.0095],\n",
      "        [-0.0041],\n",
      "        [-0.0449],\n",
      "        [-0.0085],\n",
      "        [-0.0155],\n",
      "        [ 0.0638],\n",
      "        [ 0.0456],\n",
      "        [-0.0238],\n",
      "        [ 0.0725],\n",
      "        [-0.0060],\n",
      "        [-0.0437],\n",
      "        [ 0.0040],\n",
      "        [ 0.0047],\n",
      "        [ 0.0054]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1236, 0.1215, 0.1243, 0.1193, 0.1211, 0.1199, 0.1208, 0.1196, 0.1215,\n",
      "        0.1212, 0.1251, 0.1271, 0.1249, 0.1235, 0.1218, 0.1235, 0.1239, 0.1245,\n",
      "        0.1267, 0.1258, 0.1267, 0.1279, 0.1274, 0.1261, 0.1248, 0.1245, 0.1270,\n",
      "        0.1274, 0.1266, 0.1263, 0.1251, 0.1251], device='cuda:0')\n",
      "tensor([[-0.0213],\n",
      "        [-0.0063],\n",
      "        [-0.0274],\n",
      "        [-0.0059],\n",
      "        [-0.0406],\n",
      "        [-0.0484],\n",
      "        [-0.0055],\n",
      "        [-0.0438],\n",
      "        [-0.0361],\n",
      "        [-0.0109],\n",
      "        [ 0.0298],\n",
      "        [ 0.0043],\n",
      "        [ 0.0136],\n",
      "        [-0.0626],\n",
      "        [ 0.0176],\n",
      "        [-0.0538],\n",
      "        [-0.0235],\n",
      "        [-0.0221],\n",
      "        [ 0.0195],\n",
      "        [-0.0166],\n",
      "        [ 0.0339],\n",
      "        [-0.0500],\n",
      "        [ 0.0549],\n",
      "        [ 0.0089],\n",
      "        [-0.0635],\n",
      "        [ 0.0052],\n",
      "        [ 0.0005],\n",
      "        [-0.0340],\n",
      "        [ 0.0279],\n",
      "        [-0.0071],\n",
      "        [ 0.0038],\n",
      "        [-0.0290]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1239, 0.1212, 0.1230, 0.1236, 0.1230, 0.1211, 0.1189, 0.1179, 0.1186,\n",
      "        0.1170, 0.1161, 0.1164, 0.1152, 0.1155, 0.1150, 0.1158, 0.1115, 0.1091,\n",
      "        0.1112, 0.1080, 0.1094, 0.1105, 0.1094, 0.1117, 0.1102, 0.1102, 0.1103,\n",
      "        0.1099, 0.1096, 0.1097, 0.1121, 0.1140], device='cuda:0')\n",
      "tensor([[-0.0503],\n",
      "        [-0.0516],\n",
      "        [ 0.0086],\n",
      "        [ 0.0071],\n",
      "        [ 0.0109],\n",
      "        [-0.0219],\n",
      "        [-0.0348],\n",
      "        [ 0.0311],\n",
      "        [-0.0107],\n",
      "        [-0.0633],\n",
      "        [-0.0334],\n",
      "        [ 0.0040],\n",
      "        [-0.0876],\n",
      "        [ 0.1080],\n",
      "        [-0.0083],\n",
      "        [ 0.0137],\n",
      "        [-0.0356],\n",
      "        [ 0.0077],\n",
      "        [ 0.1805],\n",
      "        [ 0.0535],\n",
      "        [ 0.0664],\n",
      "        [ 0.0502],\n",
      "        [-0.0231],\n",
      "        [ 0.0308],\n",
      "        [ 0.0566],\n",
      "        [-0.0399],\n",
      "        [-0.0212],\n",
      "        [-0.0263],\n",
      "        [-0.0245],\n",
      "        [ 0.0530],\n",
      "        [-0.0056],\n",
      "        [-0.0598]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1106, 0.1109, 0.1124, 0.1130, 0.1118, 0.1097, 0.1078, 0.1088, 0.1083,\n",
      "        0.1109, 0.1114, 0.1118, 0.1130, 0.1150, 0.1153, 0.1162, 0.1153, 0.1139,\n",
      "        0.1133, 0.1133, 0.1152, 0.1170, 0.1150, 0.1152, 0.1130, 0.1130, 0.1118,\n",
      "        0.1091, 0.1103, 0.1102, 0.1106, 0.1093], device='cuda:0')\n",
      "tensor([[ 0.0155],\n",
      "        [-0.0323],\n",
      "        [-0.0520],\n",
      "        [-0.0049],\n",
      "        [ 0.0220],\n",
      "        [ 0.0482],\n",
      "        [-0.0102],\n",
      "        [-0.0073],\n",
      "        [ 0.0174],\n",
      "        [-0.0012],\n",
      "        [-0.0179],\n",
      "        [-0.0177],\n",
      "        [-0.0458],\n",
      "        [-0.0103],\n",
      "        [ 0.0178],\n",
      "        [ 0.0211],\n",
      "        [ 0.0308],\n",
      "        [-0.0573],\n",
      "        [-0.0124],\n",
      "        [ 0.0074],\n",
      "        [-0.0299],\n",
      "        [-0.0100],\n",
      "        [ 0.0402],\n",
      "        [-0.0645],\n",
      "        [ 0.0675],\n",
      "        [-0.0465],\n",
      "        [ 0.0140],\n",
      "        [-0.0186],\n",
      "        [-0.0063],\n",
      "        [ 0.0327],\n",
      "        [ 0.0234],\n",
      "        [ 0.0467]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1136, 0.1121, 0.1139, 0.1133, 0.1119, 0.1115, 0.1105, 0.1115, 0.1128,\n",
      "        0.1145, 0.1145, 0.1150, 0.1183, 0.1180, 0.1173, 0.1139, 0.1145, 0.1156,\n",
      "        0.1140, 0.1134, 0.1121, 0.1133, 0.1142, 0.1128, 0.1112, 0.1099, 0.1090,\n",
      "        0.1081, 0.1080, 0.1068, 0.1074, 0.1066], device='cuda:0')\n",
      "tensor([[ 0.0389],\n",
      "        [-0.0973],\n",
      "        [ 0.0130],\n",
      "        [ 0.0048],\n",
      "        [ 0.0852],\n",
      "        [-0.0190],\n",
      "        [ 0.0212],\n",
      "        [-0.0110],\n",
      "        [-0.0099],\n",
      "        [ 0.0071],\n",
      "        [ 0.0338],\n",
      "        [-0.0195],\n",
      "        [ 0.0300],\n",
      "        [ 0.0490],\n",
      "        [-0.0105],\n",
      "        [-0.0462],\n",
      "        [-0.0301],\n",
      "        [ 0.0135],\n",
      "        [ 0.0182],\n",
      "        [ 0.0139],\n",
      "        [ 0.0147],\n",
      "        [-0.0408],\n",
      "        [ 0.0780],\n",
      "        [ 0.0646],\n",
      "        [ 0.0279],\n",
      "        [ 0.0049],\n",
      "        [-0.0373],\n",
      "        [-0.0282],\n",
      "        [ 0.0123],\n",
      "        [-0.0228],\n",
      "        [-0.0015],\n",
      "        [-0.0219]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1077, 0.1080, 0.1081, 0.1086, 0.1052, 0.1056, 0.1055, 0.1056, 0.1038,\n",
      "        0.1041, 0.1040, 0.0997, 0.0978, 0.1009, 0.1019, 0.1013, 0.1057, 0.1050,\n",
      "        0.1053, 0.1037, 0.1025, 0.1049, 0.1056, 0.1056, 0.1072, 0.1062, 0.1056,\n",
      "        0.1074, 0.1072, 0.1050, 0.1040, 0.1050], device='cuda:0')\n",
      "tensor([[-0.0374],\n",
      "        [ 0.0197],\n",
      "        [-0.0164],\n",
      "        [-0.0428],\n",
      "        [-0.0529],\n",
      "        [-0.0344],\n",
      "        [-0.0376],\n",
      "        [ 0.0008],\n",
      "        [-0.0630],\n",
      "        [-0.0162],\n",
      "        [-0.0075],\n",
      "        [ 0.0433],\n",
      "        [-0.0087],\n",
      "        [-0.0285],\n",
      "        [-0.0014],\n",
      "        [ 0.0077],\n",
      "        [-0.0696],\n",
      "        [ 0.0605],\n",
      "        [-0.0157],\n",
      "        [ 0.1114],\n",
      "        [ 0.1498],\n",
      "        [ 0.0020],\n",
      "        [ 0.0656],\n",
      "        [ 0.0216],\n",
      "        [ 0.0155],\n",
      "        [-0.0679],\n",
      "        [-0.0476],\n",
      "        [ 0.0056],\n",
      "        [-0.0476],\n",
      "        [ 0.0182],\n",
      "        [ 0.0151],\n",
      "        [ 0.0370]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1074, 0.1084, 0.1074, 0.1068, 0.1071, 0.1060, 0.1052, 0.1072, 0.1086,\n",
      "        0.1094, 0.1087, 0.1114, 0.1140, 0.1164, 0.1227, 0.1245, 0.1239, 0.1207,\n",
      "        0.1257, 0.1238, 0.1251, 0.1239, 0.1246, 0.1261, 0.1260, 0.1263, 0.1294,\n",
      "        0.1271, 0.1282, 0.1289, 0.1280, 0.1288], device='cuda:0')\n",
      "tensor([[-0.0156],\n",
      "        [ 0.0283],\n",
      "        [ 0.0882],\n",
      "        [ 0.0233],\n",
      "        [ 0.0031],\n",
      "        [-0.0426],\n",
      "        [ 0.0102],\n",
      "        [-0.0240],\n",
      "        [-0.0018],\n",
      "        [-0.0573],\n",
      "        [ 0.0082],\n",
      "        [ 0.0158],\n",
      "        [-0.0365],\n",
      "        [ 0.0156],\n",
      "        [-0.0123],\n",
      "        [ 0.0042],\n",
      "        [ 0.1620],\n",
      "        [ 0.0154],\n",
      "        [-0.0193],\n",
      "        [-0.0233],\n",
      "        [ 0.0221],\n",
      "        [-0.0166],\n",
      "        [ 0.0851],\n",
      "        [ 0.0315],\n",
      "        [ 0.0151],\n",
      "        [-0.0425],\n",
      "        [ 0.0148],\n",
      "        [-0.0369],\n",
      "        [-0.0461],\n",
      "        [ 0.1158],\n",
      "        [-0.0539],\n",
      "        [ 0.0591]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1274, 0.1267, 0.1269, 0.1254, 0.1254, 0.1264, 0.1243, 0.1257, 0.1251,\n",
      "        0.1254, 0.1297, 0.1304, 0.1314, 0.1302, 0.1294, 0.1295, 0.1274, 0.1269,\n",
      "        0.1271, 0.1279, 0.1292, 0.1274, 0.1255, 0.1245, 0.1239, 0.1246, 0.1239,\n",
      "        0.1236, 0.1230, 0.1243, 0.1227, 0.1246], device='cuda:0')\n",
      "tensor([[-0.0013],\n",
      "        [-0.0674],\n",
      "        [ 0.0696],\n",
      "        [ 0.0343],\n",
      "        [-0.0192],\n",
      "        [-0.0042],\n",
      "        [-0.0080],\n",
      "        [-0.0043],\n",
      "        [ 0.0046],\n",
      "        [ 0.0654],\n",
      "        [-0.0068],\n",
      "        [ 0.1037],\n",
      "        [ 0.0781],\n",
      "        [-0.0693],\n",
      "        [-0.0024],\n",
      "        [-0.0514],\n",
      "        [-0.0281],\n",
      "        [-0.0378],\n",
      "        [ 0.0083],\n",
      "        [ 0.0102],\n",
      "        [ 0.0312],\n",
      "        [ 0.0422],\n",
      "        [ 0.0505],\n",
      "        [ 0.0137],\n",
      "        [ 0.0215],\n",
      "        [ 0.0144],\n",
      "        [-0.0217],\n",
      "        [-0.0516],\n",
      "        [ 0.0617],\n",
      "        [-0.0605],\n",
      "        [ 0.0699],\n",
      "        [-0.0398]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1254, 0.1239, 0.1246, 0.1295, 0.1285, 0.1292, 0.1302, 0.1304, 0.1283,\n",
      "        0.1273, 0.1282, 0.1304, 0.1279, 0.1295, 0.1294, 0.1304, 0.1313, 0.1292,\n",
      "        0.1292, 0.1263, 0.1271, 0.1257, 0.1261, 0.1257, 0.1242, 0.1224, 0.1239,\n",
      "        0.1236, 0.1255, 0.1255, 0.1280, 0.1261], device='cuda:0')\n",
      "tensor([[-2.0660e-02],\n",
      "        [ 1.4236e-03],\n",
      "        [-1.5715e-03],\n",
      "        [ 4.6407e-02],\n",
      "        [-3.6715e-02],\n",
      "        [-7.3214e-03],\n",
      "        [ 2.7883e-02],\n",
      "        [-1.7925e-02],\n",
      "        [ 7.5951e-02],\n",
      "        [-3.9524e-02],\n",
      "        [ 6.1050e-02],\n",
      "        [ 3.0440e-02],\n",
      "        [ 5.0456e-02],\n",
      "        [-1.1441e-02],\n",
      "        [-3.6657e-02],\n",
      "        [ 1.0034e-02],\n",
      "        [ 1.6274e-04],\n",
      "        [ 1.8582e-02],\n",
      "        [ 1.4184e-03],\n",
      "        [ 1.7359e-01],\n",
      "        [ 3.9594e-02],\n",
      "        [ 4.5873e-02],\n",
      "        [ 7.6285e-02],\n",
      "        [-8.2514e-02],\n",
      "        [-5.7049e-02],\n",
      "        [-8.9989e-03],\n",
      "        [-1.2200e-02],\n",
      "        [-5.6397e-02],\n",
      "        [-8.5898e-02],\n",
      "        [-2.9564e-02],\n",
      "        [ 7.6858e-03],\n",
      "        [-1.0390e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1248, 0.1245, 0.1224, 0.1227, 0.1199, 0.1207, 0.1190, 0.1199, 0.1214,\n",
      "        0.1209, 0.1198, 0.1209, 0.1212, 0.1261, 0.1260, 0.1252, 0.1269, 0.1274,\n",
      "        0.1269, 0.1261, 0.1266, 0.1261, 0.1236, 0.1224, 0.1221, 0.1229, 0.1221,\n",
      "        0.1229, 0.1269, 0.1257, 0.1280, 0.1279], device='cuda:0')\n",
      "tensor([[ 0.0265],\n",
      "        [ 0.0417],\n",
      "        [-0.0212],\n",
      "        [-0.0287],\n",
      "        [-0.0397],\n",
      "        [ 0.0161],\n",
      "        [-0.0304],\n",
      "        [-0.0104],\n",
      "        [ 0.0574],\n",
      "        [ 0.1362],\n",
      "        [ 0.0541],\n",
      "        [ 0.0774],\n",
      "        [-0.0254],\n",
      "        [ 0.0855],\n",
      "        [ 0.0882],\n",
      "        [ 0.0508],\n",
      "        [ 0.0217],\n",
      "        [ 0.0146],\n",
      "        [-0.0634],\n",
      "        [-0.0379],\n",
      "        [-0.0441],\n",
      "        [ 0.0023],\n",
      "        [-0.0226],\n",
      "        [-0.0165],\n",
      "        [-0.0014],\n",
      "        [-0.0111],\n",
      "        [ 0.0333],\n",
      "        [-0.0847],\n",
      "        [ 0.0628],\n",
      "        [-0.0329],\n",
      "        [ 0.0531],\n",
      "        [-0.0532]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1270, 0.1267, 0.1273, 0.1322, 0.1338, 0.1372, 0.1379, 0.1381, 0.1397,\n",
      "        0.1425, 0.1421, 0.1418, 0.1409, 0.1432, 0.1419, 0.1406, 0.1426, 0.1428,\n",
      "        0.1384, 0.1363, 0.1387, 0.1366, 0.1359, 0.1364, 0.1387, 0.1387, 0.1376,\n",
      "        0.1388, 0.1395, 0.1379, 0.1390, 0.1412], device='cuda:0')\n",
      "tensor([[-0.0007],\n",
      "        [ 0.0256],\n",
      "        [-0.0215],\n",
      "        [-0.0084],\n",
      "        [-0.0522],\n",
      "        [-0.0197],\n",
      "        [-0.0089],\n",
      "        [-0.0114],\n",
      "        [-0.0070],\n",
      "        [ 0.0781],\n",
      "        [-0.0643],\n",
      "        [-0.0357],\n",
      "        [-0.0105],\n",
      "        [-0.0140],\n",
      "        [ 0.0247],\n",
      "        [-0.0368],\n",
      "        [-0.0177],\n",
      "        [-0.0032],\n",
      "        [ 0.0260],\n",
      "        [-0.0330],\n",
      "        [ 0.0270],\n",
      "        [ 0.0792],\n",
      "        [-0.0430],\n",
      "        [-0.0343],\n",
      "        [ 0.0384],\n",
      "        [ 0.0724],\n",
      "        [ 0.0212],\n",
      "        [ 0.0048],\n",
      "        [-0.0183],\n",
      "        [-0.0467],\n",
      "        [ 0.0299],\n",
      "        [-0.0259]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1401, 0.1401, 0.1376, 0.1344, 0.1338, 0.1360, 0.1364, 0.1342, 0.1329,\n",
      "        0.1326, 0.1323, 0.1348, 0.1335, 0.1328, 0.1316, 0.1277, 0.1288, 0.1300,\n",
      "        0.1302, 0.1307, 0.1320, 0.1316, 0.1301, 0.1307, 0.1270, 0.1279, 0.1294,\n",
      "        0.1307, 0.1319, 0.1333, 0.1339, 0.1338], device='cuda:0')\n",
      "tensor([[ 0.0255],\n",
      "        [-0.0247],\n",
      "        [ 0.0520],\n",
      "        [ 0.0030],\n",
      "        [ 0.0167],\n",
      "        [-0.0223],\n",
      "        [ 0.0125],\n",
      "        [-0.0468],\n",
      "        [-0.0427],\n",
      "        [-0.0002],\n",
      "        [-0.0167],\n",
      "        [-0.0242],\n",
      "        [ 0.0233],\n",
      "        [-0.0384],\n",
      "        [ 0.0347],\n",
      "        [-0.0334],\n",
      "        [-0.0652],\n",
      "        [ 0.0251],\n",
      "        [ 0.0181],\n",
      "        [-0.0287],\n",
      "        [-0.0096],\n",
      "        [ 0.0184],\n",
      "        [ 0.0778],\n",
      "        [ 0.0288],\n",
      "        [ 0.0276],\n",
      "        [-0.0114],\n",
      "        [-0.0395],\n",
      "        [ 0.0497],\n",
      "        [ 0.1087],\n",
      "        [-0.0325],\n",
      "        [-0.0326],\n",
      "        [-0.0095]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1313, 0.1314, 0.1316, 0.1331, 0.1326, 0.1329, 0.1308, 0.1298, 0.1301,\n",
      "        0.1291, 0.1288, 0.1283, 0.1280, 0.1292, 0.1308, 0.1317, 0.1344, 0.1345,\n",
      "        0.1319, 0.1325, 0.1331, 0.1351, 0.1378, 0.1378, 0.1373, 0.1359, 0.1353,\n",
      "        0.1347, 0.1339, 0.1319, 0.1326, 0.1332], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0712],\n",
      "        [-0.1174],\n",
      "        [ 0.0475],\n",
      "        [-0.0190],\n",
      "        [-0.0027],\n",
      "        [ 0.0251],\n",
      "        [ 0.0400],\n",
      "        [ 0.0256],\n",
      "        [ 0.0122],\n",
      "        [-0.0245],\n",
      "        [ 0.0442],\n",
      "        [-0.0073],\n",
      "        [ 0.0555],\n",
      "        [-0.0352],\n",
      "        [-0.0640],\n",
      "        [ 0.0258],\n",
      "        [-0.0565],\n",
      "        [-0.0447],\n",
      "        [-0.0213],\n",
      "        [-0.0286],\n",
      "        [ 0.0816],\n",
      "        [ 0.0242],\n",
      "        [ 0.0647],\n",
      "        [ 0.0315],\n",
      "        [ 0.0621],\n",
      "        [ 0.0419],\n",
      "        [ 0.0135],\n",
      "        [ 0.0014],\n",
      "        [-0.0131],\n",
      "        [-0.0057],\n",
      "        [ 0.0078],\n",
      "        [ 0.0377]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1339, 0.1325, 0.1339, 0.1311, 0.1314, 0.1295, 0.1233, 0.1208, 0.1238,\n",
      "        0.1226, 0.1223, 0.1217, 0.1209, 0.1217, 0.1235, 0.1248, 0.1261, 0.1271,\n",
      "        0.1269, 0.1282, 0.1276, 0.1269, 0.1277, 0.1266, 0.1239, 0.1260, 0.1269,\n",
      "        0.1274, 0.1289, 0.1325, 0.1335, 0.1328], device='cuda:0')\n",
      "tensor([[ 5.4762e-07],\n",
      "        [-7.5859e-03],\n",
      "        [ 1.1261e-01],\n",
      "        [ 1.4176e-01],\n",
      "        [ 1.1347e-01],\n",
      "        [ 7.6995e-02],\n",
      "        [ 2.4660e-02],\n",
      "        [ 3.7956e-03],\n",
      "        [ 1.1342e-02],\n",
      "        [ 4.0906e-02],\n",
      "        [ 9.8686e-02],\n",
      "        [-6.8345e-02],\n",
      "        [-3.5852e-02],\n",
      "        [ 1.2898e-02],\n",
      "        [-7.3156e-03],\n",
      "        [ 5.7936e-02],\n",
      "        [ 1.2315e-02],\n",
      "        [-2.5016e-02],\n",
      "        [ 2.7279e-02],\n",
      "        [-4.5866e-02],\n",
      "        [ 1.3456e-01],\n",
      "        [ 2.6649e-02],\n",
      "        [-1.1780e-02],\n",
      "        [-3.5677e-02],\n",
      "        [ 4.0158e-02],\n",
      "        [-3.5973e-02],\n",
      "        [ 3.5657e-02],\n",
      "        [-2.6152e-02],\n",
      "        [-5.3416e-02],\n",
      "        [ 1.5787e-02],\n",
      "        [ 2.0716e-02],\n",
      "        [-1.1405e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1333, 0.1341, 0.1335, 0.1332, 0.1345, 0.1366, 0.1338, 0.1348, 0.1359,\n",
      "        0.1372, 0.1362, 0.1357, 0.1335, 0.1333, 0.1323, 0.1311, 0.1308, 0.1302,\n",
      "        0.1304, 0.1300, 0.1292, 0.1294, 0.1313, 0.1323, 0.1302, 0.1305, 0.1322,\n",
      "        0.1322, 0.1319, 0.1313, 0.1302, 0.1308], device='cuda:0')\n",
      "tensor([[-0.0029],\n",
      "        [-0.0170],\n",
      "        [-0.0204],\n",
      "        [-0.0654],\n",
      "        [ 0.0211],\n",
      "        [ 0.0062],\n",
      "        [-0.0109],\n",
      "        [ 0.0256],\n",
      "        [ 0.0667],\n",
      "        [-0.0012],\n",
      "        [-0.0082],\n",
      "        [-0.0017],\n",
      "        [-0.0401],\n",
      "        [-0.0071],\n",
      "        [-0.0303],\n",
      "        [ 0.0777],\n",
      "        [ 0.0272],\n",
      "        [-0.0166],\n",
      "        [ 0.0298],\n",
      "        [ 0.0040],\n",
      "        [-0.0427],\n",
      "        [-0.0551],\n",
      "        [ 0.1126],\n",
      "        [-0.0266],\n",
      "        [ 0.0317],\n",
      "        [ 0.0295],\n",
      "        [-0.0056],\n",
      "        [ 0.0272],\n",
      "        [-0.0553],\n",
      "        [-0.0040],\n",
      "        [ 0.0021],\n",
      "        [ 0.0924]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1310, 0.1323, 0.1332, 0.1335, 0.1317, 0.1310, 0.1308, 0.1313, 0.1323,\n",
      "        0.1304, 0.1313, 0.1319, 0.1304, 0.1320, 0.1304, 0.1271, 0.1269, 0.1270,\n",
      "        0.1302, 0.1276, 0.1276, 0.1266, 0.1274, 0.1276, 0.1274, 0.1276, 0.1291,\n",
      "        0.1319, 0.1319, 0.1335, 0.1325, 0.1314], device='cuda:0')\n",
      "tensor([[ 0.0127],\n",
      "        [ 0.0439],\n",
      "        [-0.0558],\n",
      "        [-0.0155],\n",
      "        [ 0.0402],\n",
      "        [-0.1000],\n",
      "        [ 0.0069],\n",
      "        [-0.0053],\n",
      "        [-0.0464],\n",
      "        [ 0.0247],\n",
      "        [ 0.0455],\n",
      "        [-0.0229],\n",
      "        [ 0.0205],\n",
      "        [-0.0153],\n",
      "        [-0.0289],\n",
      "        [ 0.0318],\n",
      "        [ 0.0172],\n",
      "        [ 0.0193],\n",
      "        [ 0.0140],\n",
      "        [-0.0357],\n",
      "        [ 0.0203],\n",
      "        [-0.0133],\n",
      "        [-0.0066],\n",
      "        [ 0.0440],\n",
      "        [-0.0359],\n",
      "        [-0.0041],\n",
      "        [ 0.0327],\n",
      "        [-0.0216],\n",
      "        [ 0.0580],\n",
      "        [-0.0534],\n",
      "        [-0.0566],\n",
      "        [-0.0188]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1313, 0.1332, 0.1348, 0.1326, 0.1319, 0.1335, 0.1348, 0.1356, 0.1341,\n",
      "        0.1353, 0.1369, 0.1382, 0.1376, 0.1367, 0.1372, 0.1397, 0.1406, 0.1401,\n",
      "        0.1421, 0.1422, 0.1443, 0.1440, 0.1449, 0.1463, 0.1455, 0.1449, 0.1449,\n",
      "        0.1463, 0.1457, 0.1435, 0.1444, 0.1483], device='cuda:0')\n",
      "tensor([[-0.0059],\n",
      "        [-0.0004],\n",
      "        [-0.0710],\n",
      "        [ 0.0176],\n",
      "        [-0.0174],\n",
      "        [ 0.0073],\n",
      "        [-0.0184],\n",
      "        [ 0.0069],\n",
      "        [ 0.0343],\n",
      "        [ 0.0570],\n",
      "        [ 0.0091],\n",
      "        [ 0.0099],\n",
      "        [ 0.0315],\n",
      "        [-0.0421],\n",
      "        [ 0.0116],\n",
      "        [ 0.0174],\n",
      "        [ 0.1240],\n",
      "        [ 0.0190],\n",
      "        [-0.0258],\n",
      "        [-0.0655],\n",
      "        [-0.0143],\n",
      "        [ 0.0089],\n",
      "        [-0.0649],\n",
      "        [ 0.0500],\n",
      "        [-0.0337],\n",
      "        [-0.0418],\n",
      "        [-0.0375],\n",
      "        [-0.0795],\n",
      "        [-0.0192],\n",
      "        [-0.0850],\n",
      "        [ 0.0388],\n",
      "        [-0.1099]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1469, 0.1481, 0.1515, 0.1539, 0.1567, 0.1562, 0.1581, 0.1605, 0.1608,\n",
      "        0.1612, 0.1623, 0.1629, 0.1626, 0.1611, 0.1617, 0.1642, 0.1676, 0.1643,\n",
      "        0.1602, 0.1630, 0.1630, 0.1645, 0.1565, 0.1583, 0.1561, 0.1567, 0.1570,\n",
      "        0.1609, 0.1649, 0.1589, 0.1571, 0.1573], device='cuda:0')\n",
      "tensor([[ 0.0080],\n",
      "        [ 0.0750],\n",
      "        [ 0.0351],\n",
      "        [-0.0098],\n",
      "        [ 0.0283],\n",
      "        [-0.1501],\n",
      "        [-0.0758],\n",
      "        [ 0.0112],\n",
      "        [ 0.0473],\n",
      "        [-0.0179],\n",
      "        [-0.0150],\n",
      "        [-0.0345],\n",
      "        [-0.0338],\n",
      "        [ 0.0300],\n",
      "        [-0.0063],\n",
      "        [ 0.0119],\n",
      "        [ 0.0260],\n",
      "        [ 0.0854],\n",
      "        [-0.0253],\n",
      "        [ 0.0024],\n",
      "        [ 0.0112],\n",
      "        [-0.0080],\n",
      "        [-0.0272],\n",
      "        [-0.0055],\n",
      "        [-0.0037],\n",
      "        [-0.0012],\n",
      "        [ 0.0475],\n",
      "        [ 0.0474],\n",
      "        [-0.0415],\n",
      "        [-0.0355],\n",
      "        [ 0.0082],\n",
      "        [-0.1265]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1511, 0.1555, 0.1578, 0.1574, 0.1599, 0.1590, 0.1573, 0.1596, 0.1633,\n",
      "        0.1626, 0.1636, 0.1638, 0.1646, 0.1664, 0.1658, 0.1638, 0.1645, 0.1652,\n",
      "        0.1683, 0.1667, 0.1686, 0.1694, 0.1683, 0.1667, 0.1676, 0.1648, 0.1589,\n",
      "        0.1593, 0.1576, 0.1559, 0.1540, 0.1531], device='cuda:0')\n",
      "tensor([[-0.0672],\n",
      "        [-0.0615],\n",
      "        [ 0.0425],\n",
      "        [ 0.1081],\n",
      "        [ 0.0533],\n",
      "        [-0.0454],\n",
      "        [-0.0353],\n",
      "        [ 0.0034],\n",
      "        [ 0.0520],\n",
      "        [ 0.0507],\n",
      "        [-0.0003],\n",
      "        [-0.0114],\n",
      "        [-0.0122],\n",
      "        [ 0.0004],\n",
      "        [-0.0150],\n",
      "        [ 0.0197],\n",
      "        [-0.0867],\n",
      "        [ 0.0250],\n",
      "        [ 0.0014],\n",
      "        [ 0.0046],\n",
      "        [ 0.0386],\n",
      "        [ 0.0182],\n",
      "        [ 0.0459],\n",
      "        [ 0.0029],\n",
      "        [-0.0116],\n",
      "        [ 0.0233],\n",
      "        [-0.0125],\n",
      "        [ 0.0028],\n",
      "        [-0.0268],\n",
      "        [ 0.0131],\n",
      "        [-0.0374],\n",
      "        [ 0.0852]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1561, 0.1602, 0.1567, 0.1584, 0.1583, 0.1589, 0.1607, 0.1598, 0.1580,\n",
      "        0.1567, 0.1565, 0.1555, 0.1550, 0.1568, 0.1596, 0.1568, 0.1590, 0.1574,\n",
      "        0.1558, 0.1573, 0.1602, 0.1570, 0.1581, 0.1576, 0.1607, 0.1609, 0.1635,\n",
      "        0.1633, 0.1609, 0.1636, 0.1614, 0.1640], device='cuda:0')\n",
      "tensor([[ 0.0572],\n",
      "        [ 0.0132],\n",
      "        [-0.0082],\n",
      "        [-0.0021],\n",
      "        [-0.0041],\n",
      "        [ 0.0484],\n",
      "        [ 0.0306],\n",
      "        [ 0.0353],\n",
      "        [ 0.0849],\n",
      "        [-0.0143],\n",
      "        [-0.0515],\n",
      "        [ 0.0504],\n",
      "        [ 0.0750],\n",
      "        [-0.0255],\n",
      "        [ 0.0351],\n",
      "        [-0.0549],\n",
      "        [-0.0086],\n",
      "        [-0.0179],\n",
      "        [-0.0276],\n",
      "        [-0.0190],\n",
      "        [ 0.0604],\n",
      "        [-0.0349],\n",
      "        [-0.0598],\n",
      "        [-0.0724],\n",
      "        [-0.0060],\n",
      "        [-0.0142],\n",
      "        [-0.0009],\n",
      "        [-0.0092],\n",
      "        [ 0.1638],\n",
      "        [ 0.0005],\n",
      "        [ 0.0904],\n",
      "        [ 0.0845]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1669, 0.1691, 0.1713, 0.1689, 0.1652, 0.1660, 0.1627, 0.1645, 0.1629,\n",
      "        0.1593, 0.1567, 0.1576, 0.1578, 0.1565, 0.1556, 0.1524, 0.1518, 0.1509,\n",
      "        0.1534, 0.1514, 0.1500, 0.1506, 0.1543, 0.1595, 0.1612, 0.1607, 0.1605,\n",
      "        0.1611, 0.1578, 0.1587, 0.1577, 0.1540], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1375],\n",
      "        [ 0.0034],\n",
      "        [-0.0140],\n",
      "        [-0.0738],\n",
      "        [-0.0690],\n",
      "        [ 0.0073],\n",
      "        [ 0.0226],\n",
      "        [-0.0475],\n",
      "        [-0.0139],\n",
      "        [-0.0072],\n",
      "        [-0.0156],\n",
      "        [-0.0069],\n",
      "        [ 0.0356],\n",
      "        [ 0.0210],\n",
      "        [-0.0427],\n",
      "        [ 0.0215],\n",
      "        [-0.0217],\n",
      "        [ 0.0228],\n",
      "        [-0.0326],\n",
      "        [-0.0007],\n",
      "        [ 0.0771],\n",
      "        [ 0.0406],\n",
      "        [ 0.0264],\n",
      "        [ 0.0082],\n",
      "        [ 0.0143],\n",
      "        [ 0.0132],\n",
      "        [ 0.0960],\n",
      "        [ 0.0277],\n",
      "        [-0.0541],\n",
      "        [-0.0022],\n",
      "        [ 0.0810],\n",
      "        [-0.0508]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1559, 0.1568, 0.1555, 0.1574, 0.1561, 0.1542, 0.1536, 0.1519, 0.1549,\n",
      "        0.1521, 0.1537, 0.1549, 0.1540, 0.1543, 0.1537, 0.1562, 0.1573, 0.1567,\n",
      "        0.1522, 0.1515, 0.1511, 0.1528, 0.1497, 0.1452, 0.1410, 0.1379, 0.1366,\n",
      "        0.1363, 0.1364, 0.1385, 0.1379, 0.1379], device='cuda:0')\n",
      "tensor([[-0.0391],\n",
      "        [-0.0007],\n",
      "        [-0.0087],\n",
      "        [-0.0170],\n",
      "        [-0.0550],\n",
      "        [ 0.0047],\n",
      "        [ 0.0211],\n",
      "        [-0.0606],\n",
      "        [-0.0189],\n",
      "        [-0.0005],\n",
      "        [ 0.0569],\n",
      "        [ 0.0200],\n",
      "        [ 0.0081],\n",
      "        [ 0.0176],\n",
      "        [-0.0371],\n",
      "        [-0.0544],\n",
      "        [ 0.0135],\n",
      "        [ 0.0541],\n",
      "        [ 0.0386],\n",
      "        [-0.0676],\n",
      "        [-0.0156],\n",
      "        [ 0.0851],\n",
      "        [ 0.0062],\n",
      "        [ 0.0804],\n",
      "        [ 0.0624],\n",
      "        [ 0.0107],\n",
      "        [ 0.0428],\n",
      "        [-0.0826],\n",
      "        [ 0.0643],\n",
      "        [-0.0683],\n",
      "        [ 0.0371],\n",
      "        [-0.1067]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1391, 0.1370, 0.1357, 0.1369, 0.1372, 0.1359, 0.1362, 0.1353, 0.1356,\n",
      "        0.1354, 0.1342, 0.1354, 0.1372, 0.1390, 0.1393, 0.1379, 0.1406, 0.1422,\n",
      "        0.1452, 0.1437, 0.1437, 0.1449, 0.1474, 0.1474, 0.1460, 0.1446, 0.1413,\n",
      "        0.1415, 0.1453, 0.1465, 0.1505, 0.1506], device='cuda:0')\n",
      "tensor([[-0.0124],\n",
      "        [ 0.0384],\n",
      "        [ 0.1033],\n",
      "        [ 0.1554],\n",
      "        [ 0.0671],\n",
      "        [ 0.0207],\n",
      "        [-0.0320],\n",
      "        [ 0.1193],\n",
      "        [-0.0530],\n",
      "        [ 0.0160],\n",
      "        [-0.0993],\n",
      "        [-0.0157],\n",
      "        [-0.0165],\n",
      "        [ 0.0230],\n",
      "        [-0.0020],\n",
      "        [ 0.0137],\n",
      "        [-0.0163],\n",
      "        [ 0.0131],\n",
      "        [-0.0434],\n",
      "        [ 0.0251],\n",
      "        [-0.0536],\n",
      "        [-0.0640],\n",
      "        [-0.0172],\n",
      "        [-0.0503],\n",
      "        [-0.0312],\n",
      "        [ 0.0219],\n",
      "        [-0.0594],\n",
      "        [ 0.0021],\n",
      "        [ 0.0675],\n",
      "        [-0.0113],\n",
      "        [-0.0208],\n",
      "        [-0.0496]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1509, 0.1452, 0.1429, 0.1425, 0.1440, 0.1432, 0.1441, 0.1424, 0.1444,\n",
      "        0.1452, 0.1431, 0.1410, 0.1407, 0.1393, 0.1395, 0.1378, 0.1378, 0.1353,\n",
      "        0.1384, 0.1320, 0.1313, 0.1248, 0.1267, 0.1248, 0.1235, 0.1260, 0.1238,\n",
      "        0.1246, 0.1227, 0.1240, 0.1229, 0.1242], device='cuda:0')\n",
      "tensor([[ 0.0102],\n",
      "        [ 0.0292],\n",
      "        [-0.0069],\n",
      "        [ 0.0813],\n",
      "        [-0.0485],\n",
      "        [ 0.0284],\n",
      "        [ 0.0370],\n",
      "        [ 0.0346],\n",
      "        [ 0.0210],\n",
      "        [-0.0161],\n",
      "        [-0.0030],\n",
      "        [ 0.0604],\n",
      "        [ 0.0699],\n",
      "        [ 0.0481],\n",
      "        [ 0.0153],\n",
      "        [-0.0441],\n",
      "        [-0.0424],\n",
      "        [-0.0371],\n",
      "        [-0.0100],\n",
      "        [ 0.0567],\n",
      "        [-0.0253],\n",
      "        [-0.0020],\n",
      "        [ 0.0108],\n",
      "        [-0.0027],\n",
      "        [-0.0132],\n",
      "        [-0.0346],\n",
      "        [ 0.0153],\n",
      "        [ 0.1445],\n",
      "        [-0.0263],\n",
      "        [-0.0095],\n",
      "        [-0.0344],\n",
      "        [ 0.0646]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1240, 0.1249, 0.1233, 0.1235, 0.1248, 0.1267, 0.1300, 0.1294, 0.1261,\n",
      "        0.1240, 0.1242, 0.1261, 0.1269, 0.1257, 0.1223, 0.1240, 0.1248, 0.1230,\n",
      "        0.1260, 0.1266, 0.1263, 0.1279, 0.1308, 0.1295, 0.1308, 0.1311, 0.1341,\n",
      "        0.1326, 0.1316, 0.1302, 0.1316, 0.1305], device='cuda:0')\n",
      "tensor([[ 0.0811],\n",
      "        [ 0.0382],\n",
      "        [ 0.0120],\n",
      "        [ 0.0085],\n",
      "        [-0.0440],\n",
      "        [ 0.0128],\n",
      "        [-0.0146],\n",
      "        [-0.0644],\n",
      "        [ 0.0009],\n",
      "        [ 0.0191],\n",
      "        [-0.0426],\n",
      "        [-0.0241],\n",
      "        [ 0.0381],\n",
      "        [-0.0568],\n",
      "        [-0.0005],\n",
      "        [ 0.0475],\n",
      "        [-0.1288],\n",
      "        [ 0.0673],\n",
      "        [-0.0510],\n",
      "        [-0.0409],\n",
      "        [-0.0396],\n",
      "        [-0.0281],\n",
      "        [ 0.0327],\n",
      "        [-0.0032],\n",
      "        [ 0.0929],\n",
      "        [ 0.0172],\n",
      "        [ 0.0257],\n",
      "        [ 0.0676],\n",
      "        [ 0.0104],\n",
      "        [ 0.0011],\n",
      "        [ 0.0195],\n",
      "        [ 0.0376]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1319, 0.1319, 0.1301, 0.1314, 0.1320, 0.1304, 0.1288, 0.1285, 0.1261,\n",
      "        0.1230, 0.1248, 0.1248, 0.1232, 0.1235, 0.1224, 0.1248, 0.1267, 0.1260,\n",
      "        0.1266, 0.1258, 0.1251, 0.1229, 0.1183, 0.1208, 0.1224, 0.1224, 0.1286,\n",
      "        0.1257, 0.1257, 0.1311, 0.1298, 0.1310], device='cuda:0')\n",
      "tensor([[ 0.0146],\n",
      "        [-0.0151],\n",
      "        [-0.0389],\n",
      "        [-0.0547],\n",
      "        [-0.0090],\n",
      "        [ 0.0325],\n",
      "        [ 0.0370],\n",
      "        [-0.0044],\n",
      "        [ 0.0011],\n",
      "        [-0.0085],\n",
      "        [ 0.0150],\n",
      "        [ 0.0154],\n",
      "        [-0.0502],\n",
      "        [ 0.0081],\n",
      "        [ 0.0013],\n",
      "        [ 0.0298],\n",
      "        [-0.0411],\n",
      "        [-0.1082],\n",
      "        [-0.0440],\n",
      "        [ 0.0029],\n",
      "        [ 0.0118],\n",
      "        [-0.0085],\n",
      "        [-0.0221],\n",
      "        [-0.0058],\n",
      "        [-0.0072],\n",
      "        [-0.0065],\n",
      "        [ 0.0466],\n",
      "        [ 0.0286],\n",
      "        [ 0.0895],\n",
      "        [ 0.0590],\n",
      "        [ 0.0354],\n",
      "        [-0.0334]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1335, 0.1342, 0.1326, 0.1328, 0.1369, 0.1378, 0.1403, 0.1424, 0.1410,\n",
      "        0.1387, 0.1382, 0.1390, 0.1373, 0.1395, 0.1441, 0.1437, 0.1450, 0.1456,\n",
      "        0.1500, 0.1496, 0.1481, 0.1453, 0.1455, 0.1443, 0.1438, 0.1459, 0.1465,\n",
      "        0.1453, 0.1447, 0.1494, 0.1481, 0.1511], device='cuda:0')\n",
      "tensor([[ 0.0099],\n",
      "        [ 0.0440],\n",
      "        [ 0.0087],\n",
      "        [-0.0040],\n",
      "        [-0.0020],\n",
      "        [-0.0028],\n",
      "        [-0.0079],\n",
      "        [ 0.0107],\n",
      "        [ 0.0062],\n",
      "        [ 0.0014],\n",
      "        [ 0.0015],\n",
      "        [ 0.0780],\n",
      "        [ 0.0626],\n",
      "        [ 0.0144],\n",
      "        [ 0.0336],\n",
      "        [ 0.0065],\n",
      "        [ 0.0014],\n",
      "        [ 0.0172],\n",
      "        [ 0.0380],\n",
      "        [-0.1105],\n",
      "        [ 0.0174],\n",
      "        [-0.0439],\n",
      "        [-0.0518],\n",
      "        [ 0.0688],\n",
      "        [-0.0603],\n",
      "        [ 0.0638],\n",
      "        [ 0.0270],\n",
      "        [ 0.0059],\n",
      "        [ 0.0410],\n",
      "        [-0.0273],\n",
      "        [-0.0428],\n",
      "        [ 0.0144]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1518, 0.1515, 0.1545, 0.1534, 0.1543, 0.1562, 0.1576, 0.1612, 0.1645,\n",
      "        0.1626, 0.1587, 0.1607, 0.1580, 0.1592, 0.1555, 0.1573, 0.1571, 0.1537,\n",
      "        0.1546, 0.1508, 0.1519, 0.1550, 0.1556, 0.1589, 0.1578, 0.1578, 0.1661,\n",
      "        0.1629, 0.1629, 0.1599, 0.1629, 0.1640], device='cuda:0')\n",
      "tensor([[ 6.7006e-03],\n",
      "        [ 8.1476e-03],\n",
      "        [-1.6550e-02],\n",
      "        [ 4.4477e-02],\n",
      "        [ 2.7691e-02],\n",
      "        [-1.1875e-02],\n",
      "        [ 9.0813e-02],\n",
      "        [ 7.8225e-02],\n",
      "        [-1.9371e-02],\n",
      "        [-2.0843e-05],\n",
      "        [ 9.0540e-02],\n",
      "        [ 1.6770e-02],\n",
      "        [-1.6555e-02],\n",
      "        [-3.4863e-02],\n",
      "        [-1.0306e-01],\n",
      "        [ 1.2412e-02],\n",
      "        [-2.5532e-02],\n",
      "        [ 1.9547e-02],\n",
      "        [ 5.5728e-02],\n",
      "        [-4.0597e-02],\n",
      "        [ 8.1101e-02],\n",
      "        [-8.7176e-02],\n",
      "        [-6.6236e-02],\n",
      "        [-5.0250e-02],\n",
      "        [ 1.0328e-02],\n",
      "        [-2.6518e-02],\n",
      "        [ 1.3453e-02],\n",
      "        [-3.8414e-02],\n",
      "        [-1.8819e-02],\n",
      "        [ 1.0473e-02],\n",
      "        [ 4.7406e-02],\n",
      "        [-6.2946e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1680, 0.1698, 0.1704, 0.1732, 0.1778, 0.1776, 0.1754, 0.1741, 0.1732,\n",
      "        0.1760, 0.1770, 0.1757, 0.1704, 0.1708, 0.1658, 0.1657, 0.1664, 0.1657,\n",
      "        0.1704, 0.1708, 0.1728, 0.1697, 0.1692, 0.1664, 0.1700, 0.1713, 0.1697,\n",
      "        0.1711, 0.1695, 0.1670, 0.1669, 0.1657], device='cuda:0')\n",
      "tensor([[ 0.0143],\n",
      "        [-0.0032],\n",
      "        [ 0.0740],\n",
      "        [-0.0226],\n",
      "        [ 0.0300],\n",
      "        [-0.0081],\n",
      "        [ 0.0316],\n",
      "        [-0.0248],\n",
      "        [-0.0078],\n",
      "        [-0.0154],\n",
      "        [ 0.0149],\n",
      "        [ 0.0015],\n",
      "        [ 0.1027],\n",
      "        [ 0.0552],\n",
      "        [-0.0015],\n",
      "        [-0.0352],\n",
      "        [-0.0434],\n",
      "        [-0.0134],\n",
      "        [ 0.0530],\n",
      "        [-0.0292],\n",
      "        [ 0.0012],\n",
      "        [-0.0030],\n",
      "        [-0.0482],\n",
      "        [-0.0011],\n",
      "        [ 0.0448],\n",
      "        [ 0.0765],\n",
      "        [-0.0052],\n",
      "        [-0.0059],\n",
      "        [-0.0070],\n",
      "        [ 0.0724],\n",
      "        [-0.0035],\n",
      "        [-0.0264]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1692, 0.1720, 0.1713, 0.1707, 0.1713, 0.1735, 0.1754, 0.1769, 0.1790,\n",
      "        0.1773, 0.1760, 0.1726, 0.1744, 0.1747, 0.1757, 0.1742, 0.1776, 0.1770,\n",
      "        0.1779, 0.1813, 0.1785, 0.1791, 0.1793, 0.1779, 0.1751, 0.1729, 0.1713,\n",
      "        0.1698, 0.1711, 0.1722, 0.1711, 0.1714], device='cuda:0')\n",
      "tensor([[ 0.0876],\n",
      "        [ 0.0301],\n",
      "        [ 0.0389],\n",
      "        [ 0.0539],\n",
      "        [ 0.0128],\n",
      "        [ 0.0098],\n",
      "        [-0.0312],\n",
      "        [ 0.0414],\n",
      "        [-0.0330],\n",
      "        [-0.0279],\n",
      "        [ 0.0136],\n",
      "        [ 0.0447],\n",
      "        [ 0.0616],\n",
      "        [ 0.0402],\n",
      "        [ 0.1208],\n",
      "        [-0.0189],\n",
      "        [ 0.0214],\n",
      "        [ 0.0614],\n",
      "        [ 0.0573],\n",
      "        [-0.0019],\n",
      "        [-0.0131],\n",
      "        [-0.0291],\n",
      "        [-0.0038],\n",
      "        [-0.0229],\n",
      "        [ 0.0331],\n",
      "        [-0.0191],\n",
      "        [ 0.0541],\n",
      "        [-0.0063],\n",
      "        [ 0.0762],\n",
      "        [-0.0293],\n",
      "        [-0.0729],\n",
      "        [ 0.0491]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1725, 0.1708, 0.1688, 0.1689, 0.1700, 0.1732, 0.1748, 0.1776, 0.1803,\n",
      "        0.1819, 0.1855, 0.1853, 0.1868, 0.1849, 0.1846, 0.1871, 0.1871, 0.1869,\n",
      "        0.1838, 0.1790, 0.1770, 0.1773, 0.1795, 0.1731, 0.1726, 0.1716, 0.1705,\n",
      "        0.1670, 0.1664, 0.1670, 0.1710, 0.1720], device='cuda:0')\n",
      "tensor([[-0.0479],\n",
      "        [-0.0592],\n",
      "        [ 0.0300],\n",
      "        [ 0.0163],\n",
      "        [-0.0363],\n",
      "        [ 0.0100],\n",
      "        [ 0.0314],\n",
      "        [-0.0237],\n",
      "        [-0.0509],\n",
      "        [-0.0073],\n",
      "        [ 0.0032],\n",
      "        [ 0.0224],\n",
      "        [-0.0233],\n",
      "        [-0.0426],\n",
      "        [-0.0045],\n",
      "        [ 0.0343],\n",
      "        [-0.0113],\n",
      "        [ 0.0065],\n",
      "        [-0.0191],\n",
      "        [ 0.0239],\n",
      "        [ 0.0128],\n",
      "        [ 0.0532],\n",
      "        [-0.0143],\n",
      "        [-0.0443],\n",
      "        [ 0.0071],\n",
      "        [ 0.0610],\n",
      "        [ 0.0265],\n",
      "        [ 0.0048],\n",
      "        [ 0.0172],\n",
      "        [ 0.0809],\n",
      "        [ 0.0091],\n",
      "        [-0.0417]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1667, 0.1657, 0.1671, 0.1642, 0.1584, 0.1646, 0.1629, 0.1648, 0.1649,\n",
      "        0.1611, 0.1584, 0.1587, 0.1633, 0.1640, 0.1655, 0.1590, 0.1611, 0.1596,\n",
      "        0.1548, 0.1573, 0.1564, 0.1522, 0.1462, 0.1401, 0.1026, 0.1165, 0.1257,\n",
      "        0.1224, 0.1233, 0.1130, 0.1201, 0.1201], device='cuda:0')\n",
      "tensor([[ 0.1126],\n",
      "        [-0.1084],\n",
      "        [-0.1545],\n",
      "        [ 0.0348],\n",
      "        [-0.0021],\n",
      "        [-0.0194],\n",
      "        [ 0.0045],\n",
      "        [ 0.0510],\n",
      "        [ 0.0251],\n",
      "        [ 0.0564],\n",
      "        [ 0.0403],\n",
      "        [-0.0541],\n",
      "        [ 0.0210],\n",
      "        [ 0.0302],\n",
      "        [-0.0695],\n",
      "        [ 0.0296],\n",
      "        [-0.0048],\n",
      "        [ 0.0188],\n",
      "        [ 0.0302],\n",
      "        [-0.0063],\n",
      "        [-0.0550],\n",
      "        [ 0.0005],\n",
      "        [-0.0710],\n",
      "        [-0.0136],\n",
      "        [-0.0473],\n",
      "        [-0.0278],\n",
      "        [ 0.0352],\n",
      "        [-0.0036],\n",
      "        [-0.0598],\n",
      "        [-0.0508],\n",
      "        [ 0.0506],\n",
      "        [-0.0226]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1227, 0.1254, 0.1277, 0.1246, 0.1232, 0.1269, 0.1218, 0.1202, 0.1198,\n",
      "        0.1215, 0.1251, 0.1243, 0.1224, 0.1198, 0.1205, 0.1173, 0.1198, 0.1195,\n",
      "        0.1207, 0.1196, 0.1164, 0.1115, 0.1121, 0.1112, 0.1065, 0.1080, 0.1100,\n",
      "        0.1124, 0.1153, 0.1118, 0.1108, 0.1167], device='cuda:0')\n",
      "tensor([[-0.0420],\n",
      "        [-0.0272],\n",
      "        [ 0.0491],\n",
      "        [-0.0045],\n",
      "        [ 0.0258],\n",
      "        [ 0.0703],\n",
      "        [ 0.1000],\n",
      "        [ 0.0359],\n",
      "        [ 0.0784],\n",
      "        [-0.0229],\n",
      "        [-0.0036],\n",
      "        [-0.0434],\n",
      "        [-0.0136],\n",
      "        [-0.0444],\n",
      "        [-0.0735],\n",
      "        [-0.0734],\n",
      "        [-0.0803],\n",
      "        [-0.0281],\n",
      "        [ 0.0951],\n",
      "        [-0.0413],\n",
      "        [ 0.0387],\n",
      "        [-0.0213],\n",
      "        [ 0.0736],\n",
      "        [ 0.0706],\n",
      "        [ 0.0244],\n",
      "        [-0.0661],\n",
      "        [-0.0093],\n",
      "        [ 0.0109],\n",
      "        [ 0.0021],\n",
      "        [-0.0250],\n",
      "        [-0.0455],\n",
      "        [ 0.0340]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1177, 0.1211, 0.1171, 0.1192, 0.1204, 0.1204, 0.1218, 0.1223, 0.1174,\n",
      "        0.1177, 0.1189, 0.1171, 0.1233, 0.1246, 0.1258, 0.1264, 0.1164, 0.1198,\n",
      "        0.1168, 0.1179, 0.1176, 0.1212, 0.1198, 0.1127, 0.1111, 0.1118, 0.1112,\n",
      "        0.1145, 0.1128, 0.1139, 0.1150, 0.1134], device='cuda:0')\n",
      "tensor([[-0.0184],\n",
      "        [ 0.0189],\n",
      "        [ 0.0156],\n",
      "        [-0.0062],\n",
      "        [ 0.0246],\n",
      "        [ 0.0778],\n",
      "        [-0.0010],\n",
      "        [ 0.1016],\n",
      "        [-0.0035],\n",
      "        [ 0.0177],\n",
      "        [-0.0482],\n",
      "        [-0.0424],\n",
      "        [ 0.0003],\n",
      "        [-0.0081],\n",
      "        [-0.0179],\n",
      "        [-0.0505],\n",
      "        [ 0.0556],\n",
      "        [-0.0104],\n",
      "        [ 0.0156],\n",
      "        [ 0.0258],\n",
      "        [ 0.0461],\n",
      "        [ 0.0116],\n",
      "        [ 0.0393],\n",
      "        [ 0.0092],\n",
      "        [-0.0078],\n",
      "        [ 0.0392],\n",
      "        [-0.0849],\n",
      "        [-0.0216],\n",
      "        [ 0.0084],\n",
      "        [-0.0559],\n",
      "        [ 0.0010],\n",
      "        [-0.0333]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1106, 0.1105, 0.1094, 0.1090, 0.1083, 0.1080, 0.1096, 0.1125, 0.1121,\n",
      "        0.1130, 0.1150, 0.1139, 0.1136, 0.1146, 0.1168, 0.1170, 0.1179, 0.1159,\n",
      "        0.1174, 0.1195, 0.1189, 0.1192, 0.1183, 0.1187, 0.1192, 0.1196, 0.1184,\n",
      "        0.1150, 0.1171, 0.1171, 0.1153, 0.1168], device='cuda:0')\n",
      "tensor([[-0.0223],\n",
      "        [-0.0102],\n",
      "        [ 0.0061],\n",
      "        [-0.0064],\n",
      "        [ 0.0118],\n",
      "        [ 0.0093],\n",
      "        [ 0.0094],\n",
      "        [-0.0068],\n",
      "        [ 0.0167],\n",
      "        [ 0.0484],\n",
      "        [-0.0554],\n",
      "        [-0.0568],\n",
      "        [-0.0463],\n",
      "        [-0.0595],\n",
      "        [-0.0267],\n",
      "        [-0.0359],\n",
      "        [-0.0369],\n",
      "        [-0.0266],\n",
      "        [ 0.0459],\n",
      "        [ 0.0475],\n",
      "        [ 0.0479],\n",
      "        [-0.0134],\n",
      "        [ 0.1388],\n",
      "        [ 0.1143],\n",
      "        [ 0.1161],\n",
      "        [ 0.0782],\n",
      "        [ 0.0060],\n",
      "        [-0.0048],\n",
      "        [-0.0012],\n",
      "        [ 0.0616],\n",
      "        [-0.0214],\n",
      "        [-0.0007]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1164, 0.1156, 0.1150, 0.1143, 0.1125, 0.1106, 0.1071, 0.1084, 0.1057,\n",
      "        0.1049, 0.1078, 0.1077, 0.1077, 0.1102, 0.1097, 0.1125, 0.1146, 0.1149,\n",
      "        0.1179, 0.1122, 0.1155, 0.1153, 0.1143, 0.1140, 0.1134, 0.1150, 0.1152,\n",
      "        0.1156, 0.1153, 0.1143, 0.1146, 0.1155], device='cuda:0')\n",
      "tensor([[ 0.0259],\n",
      "        [ 0.0091],\n",
      "        [ 0.0070],\n",
      "        [ 0.0161],\n",
      "        [ 0.0085],\n",
      "        [ 0.0186],\n",
      "        [ 0.0136],\n",
      "        [-0.0182],\n",
      "        [ 0.0560],\n",
      "        [ 0.0067],\n",
      "        [-0.0123],\n",
      "        [ 0.0001],\n",
      "        [ 0.0386],\n",
      "        [-0.0113],\n",
      "        [-0.0243],\n",
      "        [-0.0043],\n",
      "        [-0.0154],\n",
      "        [ 0.0070],\n",
      "        [-0.0301],\n",
      "        [-0.0242],\n",
      "        [ 0.0283],\n",
      "        [-0.0316],\n",
      "        [ 0.0055],\n",
      "        [-0.0236],\n",
      "        [ 0.0757],\n",
      "        [ 0.0696],\n",
      "        [ 0.0271],\n",
      "        [ 0.0395],\n",
      "        [ 0.0392],\n",
      "        [ 0.0332],\n",
      "        [-0.0015],\n",
      "        [ 0.0046]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1161, 0.1145, 0.1121, 0.1112, 0.1112, 0.1117, 0.1091, 0.1091, 0.1111,\n",
      "        0.1125, 0.1108, 0.1093, 0.1112, 0.1100, 0.1091, 0.1097, 0.1088, 0.1086,\n",
      "        0.1083, 0.1136, 0.1143, 0.1137, 0.1145, 0.1158, 0.1150, 0.1184, 0.1170,\n",
      "        0.1177, 0.1189, 0.1209, 0.1211, 0.1190], device='cuda:0')\n",
      "tensor([[ 0.0039],\n",
      "        [ 0.0139],\n",
      "        [ 0.0798],\n",
      "        [ 0.0156],\n",
      "        [-0.0035],\n",
      "        [ 0.0161],\n",
      "        [ 0.0271],\n",
      "        [ 0.0334],\n",
      "        [ 0.2021],\n",
      "        [ 0.0994],\n",
      "        [ 0.0712],\n",
      "        [ 0.0521],\n",
      "        [-0.0200],\n",
      "        [ 0.0226],\n",
      "        [ 0.0074],\n",
      "        [ 0.0039],\n",
      "        [ 0.0307],\n",
      "        [ 0.0349],\n",
      "        [ 0.0233],\n",
      "        [-0.0340],\n",
      "        [-0.0251],\n",
      "        [-0.0159],\n",
      "        [ 0.0390],\n",
      "        [ 0.0116],\n",
      "        [ 0.0114],\n",
      "        [-0.0085],\n",
      "        [-0.0298],\n",
      "        [ 0.0350],\n",
      "        [ 0.1035],\n",
      "        [-0.0574],\n",
      "        [-0.0539],\n",
      "        [ 0.0172]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1195, 0.1190, 0.1227, 0.1260, 0.1292, 0.1285, 0.1283, 0.1307, 0.1307,\n",
      "        0.1311, 0.1302, 0.1333, 0.1305, 0.1314, 0.1300, 0.1304, 0.1286, 0.1286,\n",
      "        0.1280, 0.1301, 0.1285, 0.1271, 0.1271, 0.1245, 0.1226, 0.1252, 0.1255,\n",
      "        0.1238, 0.1269, 0.1292, 0.1298, 0.1292], device='cuda:0')\n",
      "tensor([[-0.0030],\n",
      "        [-0.0009],\n",
      "        [ 0.0627],\n",
      "        [-0.0232],\n",
      "        [ 0.0533],\n",
      "        [ 0.1428],\n",
      "        [ 0.0183],\n",
      "        [-0.0308],\n",
      "        [-0.0245],\n",
      "        [-0.0723],\n",
      "        [-0.0033],\n",
      "        [ 0.0035],\n",
      "        [ 0.0154],\n",
      "        [-0.0855],\n",
      "        [ 0.0314],\n",
      "        [-0.0703],\n",
      "        [ 0.0074],\n",
      "        [-0.0252],\n",
      "        [-0.0337],\n",
      "        [-0.0372],\n",
      "        [ 0.0070],\n",
      "        [-0.0350],\n",
      "        [-0.0069],\n",
      "        [-0.0139],\n",
      "        [ 0.0303],\n",
      "        [ 0.0069],\n",
      "        [-0.0114],\n",
      "        [ 0.0609],\n",
      "        [-0.0160],\n",
      "        [-0.0405],\n",
      "        [ 0.0048],\n",
      "        [ 0.1176]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1292, 0.1274, 0.1270, 0.1261, 0.1243, 0.1211, 0.1212, 0.1201, 0.1167,\n",
      "        0.1174, 0.1161, 0.1161, 0.1139, 0.1115, 0.1117, 0.1139, 0.1125, 0.1133,\n",
      "        0.1146, 0.1140, 0.1124, 0.1109, 0.1153, 0.1140, 0.1127, 0.1131, 0.1158,\n",
      "        0.1149, 0.1165, 0.1161, 0.1150, 0.1156], device='cuda:0')\n",
      "tensor([[-0.0005],\n",
      "        [ 0.0146],\n",
      "        [ 0.0543],\n",
      "        [ 0.0098],\n",
      "        [-0.0005],\n",
      "        [ 0.0346],\n",
      "        [-0.0567],\n",
      "        [ 0.0302],\n",
      "        [-0.0590],\n",
      "        [ 0.0618],\n",
      "        [-0.0817],\n",
      "        [-0.0220],\n",
      "        [-0.0381],\n",
      "        [ 0.0288],\n",
      "        [ 0.0252],\n",
      "        [-0.0202],\n",
      "        [-0.0398],\n",
      "        [-0.0119],\n",
      "        [ 0.0643],\n",
      "        [-0.0007],\n",
      "        [-0.0074],\n",
      "        [-0.0372],\n",
      "        [ 0.0307],\n",
      "        [ 0.0269],\n",
      "        [ 0.0508],\n",
      "        [-0.0062],\n",
      "        [ 0.0033],\n",
      "        [ 0.0585],\n",
      "        [ 0.0493],\n",
      "        [ 0.0475],\n",
      "        [-0.0427],\n",
      "        [-0.1099]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1139, 0.1139, 0.1145, 0.1130, 0.1140, 0.1133, 0.1145, 0.1152, 0.1170,\n",
      "        0.1170, 0.1164, 0.1159, 0.1152, 0.1153, 0.1177, 0.1179, 0.1209, 0.1195,\n",
      "        0.1208, 0.1221, 0.1238, 0.1276, 0.1252, 0.1282, 0.1276, 0.1261, 0.1258,\n",
      "        0.1243, 0.1227, 0.1233, 0.1255, 0.1271], device='cuda:0')\n",
      "tensor([[-0.0115],\n",
      "        [-0.0422],\n",
      "        [-0.0607],\n",
      "        [-0.0643],\n",
      "        [-0.0005],\n",
      "        [-0.0038],\n",
      "        [-0.0167],\n",
      "        [-0.0194],\n",
      "        [-0.0140],\n",
      "        [ 0.0650],\n",
      "        [ 0.0396],\n",
      "        [-0.0189],\n",
      "        [ 0.0476],\n",
      "        [ 0.0395],\n",
      "        [-0.0339],\n",
      "        [ 0.0897],\n",
      "        [-0.0588],\n",
      "        [ 0.0347],\n",
      "        [ 0.0337],\n",
      "        [-0.0188],\n",
      "        [-0.0034],\n",
      "        [ 0.0109],\n",
      "        [ 0.0495],\n",
      "        [-0.0023],\n",
      "        [ 0.0147],\n",
      "        [ 0.0120],\n",
      "        [ 0.0267],\n",
      "        [ 0.0506],\n",
      "        [ 0.0917],\n",
      "        [ 0.0804],\n",
      "        [-0.0056],\n",
      "        [ 0.0194]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1258, 0.1251, 0.1227, 0.1214, 0.1221, 0.1223, 0.1221, 0.1184, 0.1190,\n",
      "        0.1195, 0.1171, 0.1171, 0.1174, 0.1173, 0.1189, 0.1201, 0.1177, 0.1211,\n",
      "        0.1217, 0.1207, 0.1204, 0.1215, 0.1235, 0.1249, 0.1236, 0.1217, 0.1229,\n",
      "        0.1230, 0.1233, 0.1230, 0.1236, 0.1239], device='cuda:0')\n",
      "tensor([[-0.0128],\n",
      "        [ 0.0065],\n",
      "        [-0.0240],\n",
      "        [ 0.0276],\n",
      "        [ 0.0049],\n",
      "        [ 0.0887],\n",
      "        [-0.0100],\n",
      "        [-0.0215],\n",
      "        [-0.0074],\n",
      "        [-0.0628],\n",
      "        [ 0.0133],\n",
      "        [-0.0127],\n",
      "        [ 0.0161],\n",
      "        [-0.0252],\n",
      "        [ 0.0521],\n",
      "        [ 0.0043],\n",
      "        [-0.0024],\n",
      "        [ 0.0557],\n",
      "        [ 0.0159],\n",
      "        [-0.0575],\n",
      "        [-0.0314],\n",
      "        [ 0.0003],\n",
      "        [ 0.0074],\n",
      "        [-0.0009],\n",
      "        [ 0.0197],\n",
      "        [-0.0113],\n",
      "        [ 0.0602],\n",
      "        [-0.0126],\n",
      "        [ 0.0963],\n",
      "        [ 0.0063],\n",
      "        [ 0.0523],\n",
      "        [ 0.1145]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1257, 0.1263, 0.1260, 0.1254, 0.1264, 0.1261, 0.1254, 0.1263, 0.1246,\n",
      "        0.1236, 0.1254, 0.1251, 0.1246, 0.1248, 0.1238, 0.1251, 0.1261, 0.1264,\n",
      "        0.1274, 0.1270, 0.1283, 0.1274, 0.1267, 0.1252, 0.1274, 0.1263, 0.1295,\n",
      "        0.1305, 0.1328, 0.1350, 0.1338, 0.1323], device='cuda:0')\n",
      "tensor([[ 0.1677],\n",
      "        [ 0.1677],\n",
      "        [ 0.1429],\n",
      "        [-0.0737],\n",
      "        [ 0.0358],\n",
      "        [ 0.0246],\n",
      "        [-0.0753],\n",
      "        [-0.0095],\n",
      "        [-0.0053],\n",
      "        [-0.0165],\n",
      "        [-0.0037],\n",
      "        [ 0.0293],\n",
      "        [ 0.0446],\n",
      "        [ 0.0247],\n",
      "        [ 0.0210],\n",
      "        [-0.0350],\n",
      "        [-0.0346],\n",
      "        [ 0.0243],\n",
      "        [-0.0322],\n",
      "        [ 0.0121],\n",
      "        [ 0.0110],\n",
      "        [-0.0418],\n",
      "        [ 0.0566],\n",
      "        [ 0.0056],\n",
      "        [ 0.0029],\n",
      "        [ 0.0236],\n",
      "        [ 0.0148],\n",
      "        [-0.0390],\n",
      "        [-0.0059],\n",
      "        [-0.0580],\n",
      "        [ 0.0400],\n",
      "        [ 0.0005]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1316, 0.1302, 0.1314, 0.1307, 0.1300, 0.1283, 0.1295, 0.1280, 0.1307,\n",
      "        0.1294, 0.1286, 0.1289, 0.1264, 0.1264, 0.1238, 0.1243, 0.1242, 0.1223,\n",
      "        0.1230, 0.1235, 0.1242, 0.1223, 0.1220, 0.1208, 0.1204, 0.1211, 0.1199,\n",
      "        0.1189, 0.1202, 0.1136, 0.1100, 0.1108], device='cuda:0')\n",
      "tensor([[-0.0383],\n",
      "        [ 0.0113],\n",
      "        [ 0.0717],\n",
      "        [-0.0216],\n",
      "        [-0.0351],\n",
      "        [-0.0567],\n",
      "        [-0.0323],\n",
      "        [-0.0156],\n",
      "        [ 0.0286],\n",
      "        [-0.0276],\n",
      "        [-0.0241],\n",
      "        [-0.0474],\n",
      "        [-0.0805],\n",
      "        [ 0.0450],\n",
      "        [-0.0141],\n",
      "        [ 0.0028],\n",
      "        [-0.0057],\n",
      "        [-0.0379],\n",
      "        [ 0.0586],\n",
      "        [ 0.0458],\n",
      "        [-0.0366],\n",
      "        [ 0.0126],\n",
      "        [ 0.0264],\n",
      "        [-0.0218],\n",
      "        [ 0.0189],\n",
      "        [ 0.0444],\n",
      "        [ 0.0345],\n",
      "        [ 0.0286],\n",
      "        [ 0.0331],\n",
      "        [ 0.0107],\n",
      "        [-0.0328],\n",
      "        [-0.0306]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1097, 0.1102, 0.1108, 0.1106, 0.1102, 0.1091, 0.1096, 0.1088, 0.1072,\n",
      "        0.1080, 0.1083, 0.1103, 0.1106, 0.1119, 0.1119, 0.1097, 0.1117, 0.1122,\n",
      "        0.1142, 0.1134, 0.1134, 0.1148, 0.1148, 0.1159, 0.1159, 0.1161, 0.1155,\n",
      "        0.1146, 0.1134, 0.1124, 0.1114, 0.1099], device='cuda:0')\n",
      "tensor([[ 0.0194],\n",
      "        [ 0.0133],\n",
      "        [ 0.0777],\n",
      "        [-0.1081],\n",
      "        [ 0.0635],\n",
      "        [-0.0390],\n",
      "        [ 0.0567],\n",
      "        [ 0.0329],\n",
      "        [-0.0414],\n",
      "        [ 0.0405],\n",
      "        [ 0.1146],\n",
      "        [ 0.0412],\n",
      "        [ 0.0444],\n",
      "        [ 0.0936],\n",
      "        [ 0.0436],\n",
      "        [ 0.0659],\n",
      "        [ 0.0214],\n",
      "        [ 0.0133],\n",
      "        [-0.0718],\n",
      "        [-0.0552],\n",
      "        [ 0.0273],\n",
      "        [ 0.0188],\n",
      "        [-0.0294],\n",
      "        [ 0.0234],\n",
      "        [ 0.0090],\n",
      "        [ 0.0253],\n",
      "        [-0.0103],\n",
      "        [-0.0204],\n",
      "        [ 0.0043],\n",
      "        [ 0.0034],\n",
      "        [ 0.0095],\n",
      "        [ 0.0075]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1100, 0.1103, 0.1102, 0.1096, 0.1115, 0.1139, 0.1122, 0.1124, 0.1130,\n",
      "        0.1119, 0.1105, 0.1100, 0.1103, 0.1102, 0.1100, 0.1086, 0.1102, 0.1106,\n",
      "        0.1108, 0.1094, 0.1102, 0.1100, 0.1097, 0.1087, 0.1093, 0.1118, 0.1111,\n",
      "        0.1099, 0.1100, 0.1111, 0.1100, 0.1103], device='cuda:0')\n",
      "tensor([[-0.0162],\n",
      "        [-0.0273],\n",
      "        [-0.0224],\n",
      "        [-0.0329],\n",
      "        [ 0.0393],\n",
      "        [ 0.0336],\n",
      "        [ 0.0317],\n",
      "        [-0.0091],\n",
      "        [ 0.1317],\n",
      "        [ 0.1434],\n",
      "        [ 0.0176],\n",
      "        [ 0.0593],\n",
      "        [-0.0517],\n",
      "        [-0.0951],\n",
      "        [ 0.0015],\n",
      "        [ 0.0162],\n",
      "        [-0.0052],\n",
      "        [ 0.0128],\n",
      "        [-0.0113],\n",
      "        [ 0.0417],\n",
      "        [ 0.0193],\n",
      "        [-0.0125],\n",
      "        [-0.0152],\n",
      "        [ 0.0042],\n",
      "        [ 0.0501],\n",
      "        [-0.0082],\n",
      "        [-0.0403],\n",
      "        [ 0.1011],\n",
      "        [ 0.0367],\n",
      "        [-0.0061],\n",
      "        [-0.0472],\n",
      "        [-0.0183]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1096, 0.1117, 0.1130, 0.1158, 0.1152, 0.1124, 0.1128, 0.1133, 0.1130,\n",
      "        0.1125, 0.1131, 0.1161, 0.1152, 0.1162, 0.1164, 0.1162, 0.1177, 0.1162,\n",
      "        0.1158, 0.1139, 0.1155, 0.1148, 0.1139, 0.1136, 0.1142, 0.1146, 0.1165,\n",
      "        0.1161, 0.1153, 0.1150, 0.1171, 0.1193], device='cuda:0')\n",
      "tensor([[ 0.0233],\n",
      "        [ 0.0209],\n",
      "        [ 0.0122],\n",
      "        [ 0.1022],\n",
      "        [ 0.0717],\n",
      "        [ 0.1907],\n",
      "        [ 0.0275],\n",
      "        [ 0.0262],\n",
      "        [ 0.0533],\n",
      "        [-0.0241],\n",
      "        [-0.0010],\n",
      "        [-0.0513],\n",
      "        [ 0.0519],\n",
      "        [ 0.0252],\n",
      "        [ 0.0183],\n",
      "        [ 0.0276],\n",
      "        [ 0.0654],\n",
      "        [ 0.0109],\n",
      "        [ 0.0122],\n",
      "        [ 0.0086],\n",
      "        [-0.0159],\n",
      "        [ 0.0457],\n",
      "        [-0.0424],\n",
      "        [-0.0286],\n",
      "        [-0.0011],\n",
      "        [-0.0231],\n",
      "        [-0.0043],\n",
      "        [ 0.0409],\n",
      "        [-0.0412],\n",
      "        [-0.0433],\n",
      "        [-0.0244],\n",
      "        [-0.0249]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1204, 0.1190, 0.1195, 0.1171, 0.1179, 0.1180, 0.1171, 0.1162, 0.1167,\n",
      "        0.1142, 0.1149, 0.1153, 0.1177, 0.1179, 0.1201, 0.1181, 0.1187, 0.1190,\n",
      "        0.1193, 0.1198, 0.1186, 0.1180, 0.1177, 0.1180, 0.1187, 0.1170, 0.1174,\n",
      "        0.1171, 0.1179, 0.1177, 0.1177, 0.1179], device='cuda:0')\n",
      "tensor([[ 0.0416],\n",
      "        [-0.0168],\n",
      "        [-0.0503],\n",
      "        [-0.0161],\n",
      "        [ 0.0097],\n",
      "        [-0.0137],\n",
      "        [-0.0437],\n",
      "        [ 0.0912],\n",
      "        [ 0.0983],\n",
      "        [ 0.0186],\n",
      "        [-0.0022],\n",
      "        [-0.0468],\n",
      "        [-0.0205],\n",
      "        [ 0.0132],\n",
      "        [ 0.0195],\n",
      "        [-0.0408],\n",
      "        [-0.0309],\n",
      "        [ 0.0333],\n",
      "        [-0.0305],\n",
      "        [-0.0202],\n",
      "        [-0.0351],\n",
      "        [ 0.1240],\n",
      "        [-0.0301],\n",
      "        [ 0.0320],\n",
      "        [ 0.0362],\n",
      "        [-0.0071],\n",
      "        [ 0.0020],\n",
      "        [ 0.0764],\n",
      "        [ 0.0153],\n",
      "        [-0.0146],\n",
      "        [ 0.0328],\n",
      "        [ 0.0272]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1183, 0.1180, 0.1195, 0.1124, 0.1094, 0.1097, 0.1090, 0.1059, 0.1086,\n",
      "        0.1077, 0.1077, 0.1097, 0.1086, 0.1080, 0.1078, 0.1012, 0.1024, 0.1015,\n",
      "        0.1009, 0.1037, 0.1038, 0.1029, 0.1024, 0.1010, 0.0997, 0.0987, 0.0982,\n",
      "        0.0991, 0.0988, 0.0963, 0.0970, 0.0948], device='cuda:0')\n",
      "tensor([[ 2.1531e-02],\n",
      "        [-2.0672e-02],\n",
      "        [ 3.1892e-02],\n",
      "        [ 4.4748e-02],\n",
      "        [-3.2225e-02],\n",
      "        [-2.3488e-02],\n",
      "        [ 5.3119e-02],\n",
      "        [-4.0107e-02],\n",
      "        [-6.9715e-05],\n",
      "        [ 3.3453e-02],\n",
      "        [ 5.2665e-03],\n",
      "        [ 1.2545e-02],\n",
      "        [ 2.4569e-02],\n",
      "        [ 5.5994e-02],\n",
      "        [ 1.8718e-02],\n",
      "        [ 4.5583e-02],\n",
      "        [ 3.0925e-02],\n",
      "        [ 1.5775e-02],\n",
      "        [ 5.0206e-02],\n",
      "        [-1.7548e-03],\n",
      "        [-2.0784e-02],\n",
      "        [ 5.4451e-02],\n",
      "        [ 2.1523e-02],\n",
      "        [-8.4140e-03],\n",
      "        [-8.7223e-02],\n",
      "        [ 2.3687e-02],\n",
      "        [-4.5532e-03],\n",
      "        [-1.5163e-02],\n",
      "        [-2.5309e-02],\n",
      "        [-2.3946e-02],\n",
      "        [-4.5149e-02],\n",
      "        [ 2.9727e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0957, 0.0950, 0.0957, 0.0966, 0.0967, 0.0964, 0.0963, 0.0954, 0.0978,\n",
      "        0.0973, 0.0982, 0.0990, 0.0993, 0.0981, 0.0975, 0.0962, 0.0960, 0.0954,\n",
      "        0.0979, 0.0984, 0.0972, 0.0964, 0.0951, 0.0942, 0.0953, 0.0939, 0.0931,\n",
      "        0.0929, 0.0913, 0.0926, 0.0925, 0.0931], device='cuda:0')\n",
      "tensor([[ 0.0586],\n",
      "        [ 0.0452],\n",
      "        [ 0.0377],\n",
      "        [ 0.0150],\n",
      "        [ 0.0066],\n",
      "        [-0.0580],\n",
      "        [ 0.0303],\n",
      "        [ 0.0095],\n",
      "        [-0.0241],\n",
      "        [ 0.0214],\n",
      "        [ 0.0385],\n",
      "        [ 0.1085],\n",
      "        [ 0.2071],\n",
      "        [-0.0040],\n",
      "        [ 0.1084],\n",
      "        [ 0.0507],\n",
      "        [-0.0165],\n",
      "        [ 0.0247],\n",
      "        [ 0.0251],\n",
      "        [-0.0468],\n",
      "        [-0.0230],\n",
      "        [-0.0044],\n",
      "        [-0.0266],\n",
      "        [ 0.0103],\n",
      "        [ 0.0274],\n",
      "        [ 0.0278],\n",
      "        [ 0.0193],\n",
      "        [ 0.0433],\n",
      "        [ 0.0391],\n",
      "        [ 0.0317],\n",
      "        [ 0.0172],\n",
      "        [ 0.0295]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0933, 0.0923, 0.0926, 0.0919, 0.0919, 0.0964, 0.0975, 0.0988, 0.0985,\n",
      "        0.0993, 0.0981, 0.0976, 0.0987, 0.0963, 0.0966, 0.0990, 0.0975, 0.0982,\n",
      "        0.0972, 0.0948, 0.0950, 0.0959, 0.0939, 0.0951, 0.0956, 0.0956, 0.0972,\n",
      "        0.0962, 0.0969, 0.0984, 0.1000, 0.1025], device='cuda:0')\n",
      "tensor([[-0.0585],\n",
      "        [-0.0664],\n",
      "        [ 0.0065],\n",
      "        [ 0.0821],\n",
      "        [ 0.1060],\n",
      "        [ 0.0736],\n",
      "        [ 0.0164],\n",
      "        [-0.0184],\n",
      "        [ 0.0136],\n",
      "        [ 0.0143],\n",
      "        [-0.0345],\n",
      "        [ 0.0012],\n",
      "        [-0.0100],\n",
      "        [ 0.0220],\n",
      "        [ 0.0169],\n",
      "        [ 0.0547],\n",
      "        [ 0.0796],\n",
      "        [ 0.0365],\n",
      "        [-0.0450],\n",
      "        [ 0.0188],\n",
      "        [-0.0169],\n",
      "        [ 0.0142],\n",
      "        [ 0.0159],\n",
      "        [-0.0309],\n",
      "        [-0.0382],\n",
      "        [-0.0127],\n",
      "        [-0.0201],\n",
      "        [-0.0542],\n",
      "        [ 0.0029],\n",
      "        [-0.0385],\n",
      "        [ 0.0190],\n",
      "        [ 0.0017]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1021, 0.1018, 0.1001, 0.1026, 0.1032, 0.1032, 0.1029, 0.1022, 0.1046,\n",
      "        0.1026, 0.1019, 0.1035, 0.1032, 0.1034, 0.1035, 0.1046, 0.1047, 0.1056,\n",
      "        0.1053, 0.1071, 0.1065, 0.1080, 0.1062, 0.1062, 0.1071, 0.1090, 0.1094,\n",
      "        0.1083, 0.1074, 0.1065, 0.1047, 0.1037], device='cuda:0')\n",
      "tensor([[ 0.0733],\n",
      "        [-0.0144],\n",
      "        [ 0.0544],\n",
      "        [ 0.1132],\n",
      "        [-0.0591],\n",
      "        [ 0.0785],\n",
      "        [ 0.0036],\n",
      "        [-0.0207],\n",
      "        [ 0.0180],\n",
      "        [-0.0203],\n",
      "        [ 0.0126],\n",
      "        [ 0.0222],\n",
      "        [-0.0430],\n",
      "        [ 0.0076],\n",
      "        [ 0.0252],\n",
      "        [-0.0189],\n",
      "        [-0.0271],\n",
      "        [-0.0186],\n",
      "        [ 0.0942],\n",
      "        [ 0.0848],\n",
      "        [ 0.0595],\n",
      "        [ 0.0185],\n",
      "        [-0.0034],\n",
      "        [-0.0134],\n",
      "        [-0.0958],\n",
      "        [ 0.0078],\n",
      "        [-0.0009],\n",
      "        [ 0.0202],\n",
      "        [ 0.0255],\n",
      "        [ 0.0171],\n",
      "        [-0.0198],\n",
      "        [ 0.0126]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1041, 0.1057, 0.1059, 0.1060, 0.1057, 0.1066, 0.1065, 0.1060, 0.1057,\n",
      "        0.1053, 0.1057, 0.1063, 0.1072, 0.1117, 0.1119, 0.1105, 0.1096, 0.1099,\n",
      "        0.1099, 0.1093, 0.1099, 0.1091, 0.1075, 0.1094, 0.1083, 0.1096, 0.1097,\n",
      "        0.1112, 0.1112, 0.1115, 0.1121, 0.1134], device='cuda:0')\n",
      "tensor([[ 0.0179],\n",
      "        [ 0.0298],\n",
      "        [-0.0245],\n",
      "        [-0.0482],\n",
      "        [ 0.0269],\n",
      "        [ 0.0738],\n",
      "        [ 0.1146],\n",
      "        [ 0.0860],\n",
      "        [ 0.0692],\n",
      "        [ 0.0399],\n",
      "        [ 0.0014],\n",
      "        [ 0.0087],\n",
      "        [ 0.0204],\n",
      "        [ 0.0125],\n",
      "        [-0.0249],\n",
      "        [ 0.0934],\n",
      "        [ 0.0079],\n",
      "        [ 0.0577],\n",
      "        [ 0.0142],\n",
      "        [ 0.0132],\n",
      "        [-0.0148],\n",
      "        [ 0.0351],\n",
      "        [ 0.0071],\n",
      "        [-0.0193],\n",
      "        [ 0.0763],\n",
      "        [-0.0638],\n",
      "        [ 0.0582],\n",
      "        [-0.0117],\n",
      "        [-0.0149],\n",
      "        [ 0.0062],\n",
      "        [-0.0855],\n",
      "        [-0.0677]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1153, 0.1156, 0.1173, 0.1170, 0.1179, 0.1170, 0.1189, 0.1198, 0.1209,\n",
      "        0.1209, 0.1180, 0.1221, 0.1235, 0.1224, 0.1218, 0.1229, 0.1233, 0.1232,\n",
      "        0.1232, 0.1209, 0.1223, 0.1227, 0.1240, 0.1235, 0.1229, 0.1208, 0.1209,\n",
      "        0.1201, 0.1214, 0.1180, 0.1184, 0.1186], device='cuda:0')\n",
      "tensor([[ 0.0410],\n",
      "        [-0.0186],\n",
      "        [ 0.1040],\n",
      "        [-0.0184],\n",
      "        [-0.0310],\n",
      "        [ 0.0315],\n",
      "        [-0.0129],\n",
      "        [-0.0065],\n",
      "        [-0.0344],\n",
      "        [-0.0617],\n",
      "        [-0.0186],\n",
      "        [ 0.0132],\n",
      "        [-0.0006],\n",
      "        [ 0.0012],\n",
      "        [-0.0038],\n",
      "        [ 0.1459],\n",
      "        [ 0.1495],\n",
      "        [ 0.0138],\n",
      "        [ 0.0642],\n",
      "        [ 0.0414],\n",
      "        [ 0.0391],\n",
      "        [-0.0021],\n",
      "        [ 0.0052],\n",
      "        [ 0.0432],\n",
      "        [ 0.0294],\n",
      "        [ 0.0439],\n",
      "        [-0.0537],\n",
      "        [-0.0109],\n",
      "        [-0.0254],\n",
      "        [ 0.0035],\n",
      "        [-0.0178],\n",
      "        [ 0.1091]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1201, 0.1196, 0.1195, 0.1207, 0.1196, 0.1193, 0.1201, 0.1212, 0.1198,\n",
      "        0.1214, 0.1224, 0.1236, 0.1252, 0.1233, 0.1223, 0.1224, 0.1196, 0.1176,\n",
      "        0.1162, 0.1162, 0.1143, 0.1122, 0.1131, 0.1124, 0.1125, 0.1103, 0.1084,\n",
      "        0.1034, 0.1024, 0.1025, 0.1026, 0.1012], device='cuda:0')\n",
      "tensor([[-0.0229],\n",
      "        [ 0.0932],\n",
      "        [ 0.0107],\n",
      "        [-0.0344],\n",
      "        [-0.0652],\n",
      "        [-0.0454],\n",
      "        [ 0.0068],\n",
      "        [ 0.0014],\n",
      "        [-0.0031],\n",
      "        [-0.0140],\n",
      "        [-0.0280],\n",
      "        [ 0.0077],\n",
      "        [-0.0249],\n",
      "        [ 0.0197],\n",
      "        [ 0.0186],\n",
      "        [ 0.0426],\n",
      "        [-0.0039],\n",
      "        [ 0.0124],\n",
      "        [-0.0071],\n",
      "        [ 0.0193],\n",
      "        [-0.0290],\n",
      "        [ 0.0036],\n",
      "        [-0.0045],\n",
      "        [ 0.0222],\n",
      "        [ 0.0948],\n",
      "        [-0.0063],\n",
      "        [ 0.0896],\n",
      "        [ 0.0573],\n",
      "        [ 0.0208],\n",
      "        [-0.0336],\n",
      "        [-0.0659],\n",
      "        [-0.0583]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1032, 0.1040, 0.1047, 0.1032, 0.1004, 0.1015, 0.0994, 0.0976, 0.0951,\n",
      "        0.0993, 0.1040, 0.1031, 0.1034, 0.1009, 0.1010, 0.1018, 0.1018, 0.1016,\n",
      "        0.1053, 0.1057, 0.1077, 0.1081, 0.1047, 0.1040, 0.1049, 0.1074, 0.1087,\n",
      "        0.1081, 0.1068, 0.1047, 0.1063, 0.1052], device='cuda:0')\n",
      "tensor([[ 0.0491],\n",
      "        [ 0.0341],\n",
      "        [ 0.0174],\n",
      "        [-0.0179],\n",
      "        [ 0.0382],\n",
      "        [ 0.0036],\n",
      "        [-0.0126],\n",
      "        [-0.0123],\n",
      "        [ 0.0257],\n",
      "        [-0.0138],\n",
      "        [ 0.0135],\n",
      "        [-0.0062],\n",
      "        [-0.0294],\n",
      "        [ 0.0131],\n",
      "        [-0.0356],\n",
      "        [ 0.1079],\n",
      "        [ 0.0789],\n",
      "        [ 0.0199],\n",
      "        [ 0.0290],\n",
      "        [ 0.0427],\n",
      "        [ 0.0339],\n",
      "        [ 0.0834],\n",
      "        [ 0.0372],\n",
      "        [ 0.0363],\n",
      "        [ 0.0044],\n",
      "        [ 0.0324],\n",
      "        [ 0.0073],\n",
      "        [-0.0208],\n",
      "        [-0.0062],\n",
      "        [ 0.0450],\n",
      "        [ 0.0213],\n",
      "        [ 0.0388]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1040, 0.1063, 0.1094, 0.1086, 0.1075, 0.1081, 0.1086, 0.1100, 0.1052,\n",
      "        0.1029, 0.1000, 0.0991, 0.0979, 0.0981, 0.0997, 0.1052, 0.1078, 0.1080,\n",
      "        0.1068, 0.1090, 0.1084, 0.1069, 0.1059, 0.1063, 0.1053, 0.1074, 0.1087,\n",
      "        0.1081, 0.1081, 0.1065, 0.1077, 0.1109], device='cuda:0')\n",
      "tensor([[ 0.0195],\n",
      "        [-0.0057],\n",
      "        [-0.0429],\n",
      "        [ 0.0058],\n",
      "        [-0.0283],\n",
      "        [-0.0117],\n",
      "        [-0.0134],\n",
      "        [ 0.0134],\n",
      "        [ 0.0241],\n",
      "        [ 0.0394],\n",
      "        [ 0.0084],\n",
      "        [ 0.0197],\n",
      "        [-0.0327],\n",
      "        [-0.0773],\n",
      "        [-0.0579],\n",
      "        [ 0.0016],\n",
      "        [ 0.0154],\n",
      "        [ 0.0110],\n",
      "        [ 0.0120],\n",
      "        [ 0.0214],\n",
      "        [-0.0126],\n",
      "        [ 0.0213],\n",
      "        [ 0.0581],\n",
      "        [-0.0090],\n",
      "        [-0.0208],\n",
      "        [ 0.0383],\n",
      "        [ 0.0119],\n",
      "        [-0.0602],\n",
      "        [-0.0077],\n",
      "        [-0.0548],\n",
      "        [ 0.0095],\n",
      "        [ 0.0341]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1142, 0.1130, 0.1148, 0.1137, 0.1149, 0.1162, 0.1146, 0.1155, 0.1137,\n",
      "        0.1152, 0.1148, 0.1134, 0.1130, 0.1149, 0.1146, 0.1162, 0.1161, 0.1124,\n",
      "        0.1136, 0.1146, 0.1140, 0.1158, 0.1140, 0.1121, 0.1124, 0.1148, 0.1139,\n",
      "        0.1150, 0.1152, 0.1152, 0.1148, 0.1149], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0080],\n",
      "        [ 0.0097],\n",
      "        [-0.0339],\n",
      "        [-0.0506],\n",
      "        [-0.0447],\n",
      "        [-0.0344],\n",
      "        [-0.0677],\n",
      "        [ 0.0757],\n",
      "        [ 0.0501],\n",
      "        [ 0.0537],\n",
      "        [ 0.0699],\n",
      "        [ 0.0058],\n",
      "        [-0.0828],\n",
      "        [-0.0096],\n",
      "        [-0.0572],\n",
      "        [ 0.0238],\n",
      "        [-0.0433],\n",
      "        [-0.0392],\n",
      "        [ 0.0401],\n",
      "        [ 0.0750],\n",
      "        [ 0.0064],\n",
      "        [ 0.0568],\n",
      "        [-0.0175],\n",
      "        [ 0.0401],\n",
      "        [-0.0240],\n",
      "        [ 0.0594],\n",
      "        [ 0.0365],\n",
      "        [ 0.1060],\n",
      "        [ 0.0241],\n",
      "        [ 0.0593],\n",
      "        [ 0.0105],\n",
      "        [-0.0187]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1146, 0.1142, 0.1131, 0.1136, 0.1131, 0.1109, 0.1094, 0.1069, 0.1087,\n",
      "        0.1084, 0.1068, 0.1077, 0.1096, 0.1174, 0.1196, 0.1220, 0.1201, 0.1215,\n",
      "        0.1236, 0.1255, 0.1274, 0.1277, 0.1307, 0.1304, 0.1305, 0.1311, 0.1325,\n",
      "        0.1341, 0.1325, 0.1336, 0.1370, 0.1375], device='cuda:0')\n",
      "tensor([[-0.0215],\n",
      "        [ 0.0741],\n",
      "        [ 0.0130],\n",
      "        [ 0.0044],\n",
      "        [ 0.0137],\n",
      "        [-0.0149],\n",
      "        [ 0.1179],\n",
      "        [ 0.0744],\n",
      "        [ 0.1089],\n",
      "        [ 0.0851],\n",
      "        [-0.0735],\n",
      "        [ 0.0042],\n",
      "        [-0.0122],\n",
      "        [-0.0769],\n",
      "        [-0.0468],\n",
      "        [ 0.0336],\n",
      "        [-0.0124],\n",
      "        [-0.0557],\n",
      "        [ 0.0284],\n",
      "        [ 0.0076],\n",
      "        [ 0.0306],\n",
      "        [-0.0015],\n",
      "        [ 0.0371],\n",
      "        [ 0.0244],\n",
      "        [ 0.0179],\n",
      "        [-0.0323],\n",
      "        [ 0.0117],\n",
      "        [ 0.0149],\n",
      "        [-0.0305],\n",
      "        [-0.0061],\n",
      "        [ 0.0645],\n",
      "        [-0.0142]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1397, 0.1401, 0.1429, 0.1455, 0.1435, 0.1407, 0.1381, 0.1385, 0.1339,\n",
      "        0.1353, 0.1328, 0.1354, 0.1350, 0.1384, 0.1376, 0.1372, 0.1357, 0.1332,\n",
      "        0.1307, 0.1332, 0.1320, 0.1302, 0.1317, 0.1167, 0.1155, 0.1128, 0.1125,\n",
      "        0.1148, 0.1152, 0.1140, 0.1152, 0.1133], device='cuda:0')\n",
      "tensor([[-0.1758],\n",
      "        [-0.0634],\n",
      "        [ 0.0197],\n",
      "        [-0.0519],\n",
      "        [-0.0489],\n",
      "        [ 0.0597],\n",
      "        [ 0.0103],\n",
      "        [ 0.0168],\n",
      "        [ 0.0248],\n",
      "        [-0.0211],\n",
      "        [-0.0181],\n",
      "        [ 0.0265],\n",
      "        [ 0.0002],\n",
      "        [ 0.0023],\n",
      "        [-0.0447],\n",
      "        [ 0.0370],\n",
      "        [-0.0234],\n",
      "        [-0.0058],\n",
      "        [ 0.0325],\n",
      "        [ 0.0157],\n",
      "        [-0.0336],\n",
      "        [ 0.0035],\n",
      "        [-0.0192],\n",
      "        [ 0.0532],\n",
      "        [ 0.0266],\n",
      "        [ 0.0068],\n",
      "        [-0.0288],\n",
      "        [ 0.0072],\n",
      "        [ 0.0463],\n",
      "        [-0.0190],\n",
      "        [-0.0075],\n",
      "        [-0.0054]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1145, 0.1143, 0.1148, 0.1137, 0.1142, 0.1121, 0.1121, 0.1114, 0.1088,\n",
      "        0.1069, 0.1097, 0.1105, 0.1103, 0.1100, 0.1088, 0.1087, 0.1086, 0.1083,\n",
      "        0.1075, 0.1046, 0.1024, 0.1035, 0.1057, 0.1031, 0.1028, 0.1010, 0.1032,\n",
      "        0.1057, 0.1028, 0.1057, 0.1059, 0.1021], device='cuda:0')\n",
      "tensor([[-0.0380],\n",
      "        [ 0.0231],\n",
      "        [ 0.0264],\n",
      "        [ 0.0856],\n",
      "        [ 0.0688],\n",
      "        [ 0.0223],\n",
      "        [ 0.0060],\n",
      "        [-0.0608],\n",
      "        [-0.0229],\n",
      "        [ 0.0297],\n",
      "        [-0.0026],\n",
      "        [-0.0590],\n",
      "        [ 0.0579],\n",
      "        [-0.0106],\n",
      "        [ 0.0181],\n",
      "        [ 0.0912],\n",
      "        [ 0.0829],\n",
      "        [-0.0644],\n",
      "        [ 0.0116],\n",
      "        [ 0.0507],\n",
      "        [ 0.0155],\n",
      "        [ 0.0465],\n",
      "        [-0.0364],\n",
      "        [ 0.0294],\n",
      "        [ 0.0378],\n",
      "        [-0.0295],\n",
      "        [-0.0044],\n",
      "        [ 0.0250],\n",
      "        [ 0.0082],\n",
      "        [ 0.0830],\n",
      "        [ 0.0466],\n",
      "        [ 0.0145]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1037, 0.1032, 0.1026, 0.1006, 0.1043, 0.1043, 0.1047, 0.1049, 0.1037,\n",
      "        0.1040, 0.1060, 0.1063, 0.1047, 0.1026, 0.1024, 0.1012, 0.1016, 0.1015,\n",
      "        0.1006, 0.0995, 0.0993, 0.0982, 0.0998, 0.1000, 0.0978, 0.0984, 0.0969,\n",
      "        0.0981, 0.0972, 0.0960, 0.0954, 0.0969], device='cuda:0')\n",
      "tensor([[ 0.0114],\n",
      "        [-0.0444],\n",
      "        [-0.0616],\n",
      "        [ 0.0147],\n",
      "        [-0.0237],\n",
      "        [-0.0338],\n",
      "        [-0.0280],\n",
      "        [-0.0283],\n",
      "        [ 0.0146],\n",
      "        [-0.0213],\n",
      "        [-0.0287],\n",
      "        [-0.0218],\n",
      "        [ 0.0245],\n",
      "        [-0.0407],\n",
      "        [ 0.0260],\n",
      "        [-0.0512],\n",
      "        [ 0.0745],\n",
      "        [ 0.1581],\n",
      "        [ 0.0932],\n",
      "        [ 0.0330],\n",
      "        [ 0.0838],\n",
      "        [-0.0034],\n",
      "        [-0.0586],\n",
      "        [-0.0301],\n",
      "        [-0.0113],\n",
      "        [-0.0088],\n",
      "        [ 0.0157],\n",
      "        [ 0.0160],\n",
      "        [-0.0342],\n",
      "        [-0.0129],\n",
      "        [ 0.0173],\n",
      "        [ 0.0654]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0978, 0.0966, 0.0972, 0.0994, 0.0982, 0.0973, 0.0967, 0.0981, 0.0979,\n",
      "        0.0948, 0.0944, 0.0967, 0.0994, 0.1012, 0.0995, 0.0997, 0.0994, 0.0994,\n",
      "        0.1004, 0.1007, 0.1003, 0.1003, 0.0993, 0.1000, 0.0993, 0.0976, 0.0979,\n",
      "        0.0975, 0.0972, 0.0976, 0.0970, 0.0969], device='cuda:0')\n",
      "tensor([[-0.0427],\n",
      "        [-0.0583],\n",
      "        [ 0.0626],\n",
      "        [ 0.0044],\n",
      "        [ 0.0179],\n",
      "        [-0.0315],\n",
      "        [ 0.0196],\n",
      "        [-0.0652],\n",
      "        [-0.0346],\n",
      "        [ 0.1008],\n",
      "        [ 0.0168],\n",
      "        [ 0.0293],\n",
      "        [-0.0478],\n",
      "        [ 0.0142],\n",
      "        [ 0.0184],\n",
      "        [-0.0316],\n",
      "        [-0.0115],\n",
      "        [ 0.0877],\n",
      "        [ 0.0020],\n",
      "        [ 0.0208],\n",
      "        [ 0.0732],\n",
      "        [ 0.0356],\n",
      "        [ 0.0224],\n",
      "        [ 0.1444],\n",
      "        [ 0.0008],\n",
      "        [ 0.0286],\n",
      "        [-0.0111],\n",
      "        [ 0.0484],\n",
      "        [-0.0111],\n",
      "        [ 0.0404],\n",
      "        [-0.0056],\n",
      "        [ 0.0304]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0947, 0.0929, 0.0938, 0.0936, 0.0922, 0.0928, 0.0931, 0.0932, 0.0923,\n",
      "        0.0935, 0.0951, 0.0964, 0.0972, 0.0967, 0.0981, 0.1000, 0.0984, 0.1004,\n",
      "        0.1035, 0.1022, 0.1031, 0.1046, 0.1052, 0.1046, 0.1038, 0.1043, 0.1057,\n",
      "        0.1047, 0.1046, 0.1015, 0.1031, 0.1019], device='cuda:0')\n",
      "tensor([[ 0.0177],\n",
      "        [ 0.0083],\n",
      "        [-0.0315],\n",
      "        [-0.0036],\n",
      "        [-0.0206],\n",
      "        [-0.0439],\n",
      "        [-0.0043],\n",
      "        [ 0.0453],\n",
      "        [ 0.0005],\n",
      "        [-0.0085],\n",
      "        [ 0.0058],\n",
      "        [ 0.0116],\n",
      "        [-0.0069],\n",
      "        [ 0.0174],\n",
      "        [ 0.0681],\n",
      "        [ 0.0752],\n",
      "        [ 0.0431],\n",
      "        [ 0.0128],\n",
      "        [-0.0079],\n",
      "        [-0.0067],\n",
      "        [ 0.0152],\n",
      "        [-0.0175],\n",
      "        [ 0.0254],\n",
      "        [-0.0252],\n",
      "        [ 0.0246],\n",
      "        [ 0.0513],\n",
      "        [-0.0040],\n",
      "        [ 0.0443],\n",
      "        [-0.0230],\n",
      "        [-0.0124],\n",
      "        [ 0.0275],\n",
      "        [ 0.0284]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1001, 0.0976, 0.0967, 0.0975, 0.0964, 0.0956, 0.0985, 0.0987, 0.1003,\n",
      "        0.1038, 0.1007, 0.0987, 0.0993, 0.0991, 0.0970, 0.0970, 0.0967, 0.0964,\n",
      "        0.0967, 0.0975, 0.0991, 0.0967, 0.0969, 0.0953, 0.0948, 0.0948, 0.0987,\n",
      "        0.0991, 0.0990, 0.0981, 0.0975, 0.0988], device='cuda:0')\n",
      "tensor([[ 0.0146],\n",
      "        [ 0.0846],\n",
      "        [ 0.0809],\n",
      "        [ 0.0553],\n",
      "        [-0.0227],\n",
      "        [-0.0184],\n",
      "        [-0.0427],\n",
      "        [ 0.0567],\n",
      "        [ 0.0242],\n",
      "        [-0.0540],\n",
      "        [-0.0384],\n",
      "        [-0.0034],\n",
      "        [ 0.0559],\n",
      "        [ 0.0001],\n",
      "        [ 0.0196],\n",
      "        [ 0.0031],\n",
      "        [-0.0560],\n",
      "        [-0.0741],\n",
      "        [-0.0387],\n",
      "        [ 0.0352],\n",
      "        [ 0.0118],\n",
      "        [-0.0149],\n",
      "        [ 0.0294],\n",
      "        [-0.0012],\n",
      "        [ 0.0226],\n",
      "        [-0.0056],\n",
      "        [-0.0273],\n",
      "        [-0.0111],\n",
      "        [-0.0262],\n",
      "        [ 0.0445],\n",
      "        [ 0.0608],\n",
      "        [ 0.0480]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0944, 0.0956, 0.0947, 0.0935, 0.0933, 0.0926, 0.0931, 0.0963, 0.0920,\n",
      "        0.0900, 0.0897, 0.0885, 0.0870, 0.0873, 0.0858, 0.0812, 0.0826, 0.0843,\n",
      "        0.0854, 0.0846, 0.0833, 0.0817, 0.0826, 0.0810, 0.0820, 0.0849, 0.0849,\n",
      "        0.0849, 0.0863, 0.0874, 0.0858, 0.0873], device='cuda:0')\n",
      "tensor([[-0.0608],\n",
      "        [-0.0917],\n",
      "        [ 0.0441],\n",
      "        [-0.0035],\n",
      "        [-0.0103],\n",
      "        [-0.0137],\n",
      "        [ 0.0408],\n",
      "        [ 0.0402],\n",
      "        [ 0.0871],\n",
      "        [ 0.0313],\n",
      "        [ 0.0215],\n",
      "        [ 0.0004],\n",
      "        [-0.0341],\n",
      "        [ 0.0488],\n",
      "        [ 0.0621],\n",
      "        [ 0.1332],\n",
      "        [ 0.0178],\n",
      "        [-0.0158],\n",
      "        [-0.0051],\n",
      "        [-0.0184],\n",
      "        [-0.0398],\n",
      "        [ 0.0228],\n",
      "        [-0.0285],\n",
      "        [-0.0543],\n",
      "        [ 0.0351],\n",
      "        [ 0.0801],\n",
      "        [ 0.0252],\n",
      "        [ 0.0486],\n",
      "        [ 0.0219],\n",
      "        [-0.0410],\n",
      "        [ 0.0627],\n",
      "        [-0.0105]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0874, 0.0897, 0.0925, 0.0898, 0.0885, 0.0880, 0.0873, 0.0898, 0.0933,\n",
      "        0.0935, 0.0945, 0.0932, 0.0904, 0.0936, 0.0911, 0.0907, 0.0914, 0.0908,\n",
      "        0.0892, 0.0891, 0.0870, 0.0886, 0.0897, 0.0885, 0.0869, 0.0861, 0.0867,\n",
      "        0.0873, 0.0895, 0.0879, 0.0867, 0.0866], device='cuda:0')\n",
      "tensor([[-0.0772],\n",
      "        [ 0.1108],\n",
      "        [ 0.0688],\n",
      "        [ 0.0054],\n",
      "        [ 0.0136],\n",
      "        [-0.0343],\n",
      "        [-0.0400],\n",
      "        [ 0.0050],\n",
      "        [-0.0208],\n",
      "        [-0.0108],\n",
      "        [-0.0082],\n",
      "        [ 0.0468],\n",
      "        [-0.0472],\n",
      "        [ 0.0218],\n",
      "        [-0.0058],\n",
      "        [ 0.0128],\n",
      "        [ 0.0162],\n",
      "        [ 0.0361],\n",
      "        [ 0.0302],\n",
      "        [-0.0121],\n",
      "        [ 0.0204],\n",
      "        [ 0.0934],\n",
      "        [ 0.1264],\n",
      "        [ 0.0416],\n",
      "        [ 0.0026],\n",
      "        [-0.0211],\n",
      "        [-0.0741],\n",
      "        [ 0.0142],\n",
      "        [-0.0683],\n",
      "        [-0.0065],\n",
      "        [ 0.0582],\n",
      "        [-0.0150]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0866, 0.0867, 0.0869, 0.0863, 0.0849, 0.0849, 0.0843, 0.0833, 0.0840,\n",
      "        0.0849, 0.0839, 0.0830, 0.0827, 0.0839, 0.0845, 0.0843, 0.0860, 0.0866,\n",
      "        0.0855, 0.0842, 0.0840, 0.0821, 0.0824, 0.0818, 0.0814, 0.0812, 0.0801,\n",
      "        0.0790, 0.0792, 0.0793, 0.0786, 0.0779], device='cuda:0')\n",
      "tensor([[ 0.0599],\n",
      "        [-0.0293],\n",
      "        [-0.0918],\n",
      "        [-0.0323],\n",
      "        [-0.0642],\n",
      "        [ 0.0458],\n",
      "        [ 0.0477],\n",
      "        [-0.0449],\n",
      "        [ 0.0027],\n",
      "        [ 0.0661],\n",
      "        [ 0.0438],\n",
      "        [-0.0168],\n",
      "        [-0.0301],\n",
      "        [ 0.0450],\n",
      "        [ 0.0169],\n",
      "        [ 0.0546],\n",
      "        [-0.0145],\n",
      "        [-0.0382],\n",
      "        [-0.0344],\n",
      "        [-0.0011],\n",
      "        [ 0.0548],\n",
      "        [-0.0563],\n",
      "        [ 0.0673],\n",
      "        [ 0.0124],\n",
      "        [ 0.0216],\n",
      "        [ 0.0263],\n",
      "        [-0.0159],\n",
      "        [-0.0031],\n",
      "        [ 0.0607],\n",
      "        [-0.0038],\n",
      "        [-0.0071],\n",
      "        [ 0.0267]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0773, 0.0789, 0.0780, 0.0810, 0.0812, 0.0823, 0.0840, 0.0849, 0.0852,\n",
      "        0.0854, 0.0864, 0.0870, 0.0871, 0.0861, 0.0848, 0.0848, 0.0852, 0.0848,\n",
      "        0.0879, 0.0877, 0.0900, 0.0916, 0.0910, 0.0914, 0.0907, 0.0916, 0.0911,\n",
      "        0.0898, 0.0891, 0.0889, 0.0879, 0.0900], device='cuda:0')\n",
      "tensor([[ 0.0174],\n",
      "        [ 0.0817],\n",
      "        [-0.0173],\n",
      "        [ 0.0589],\n",
      "        [ 0.0216],\n",
      "        [ 0.0065],\n",
      "        [-0.0392],\n",
      "        [ 0.0114],\n",
      "        [-0.0156],\n",
      "        [ 0.0104],\n",
      "        [ 0.0217],\n",
      "        [ 0.0242],\n",
      "        [ 0.0330],\n",
      "        [ 0.0354],\n",
      "        [-0.0525],\n",
      "        [-0.0267],\n",
      "        [-0.0028],\n",
      "        [ 0.0151],\n",
      "        [-0.0291],\n",
      "        [ 0.0230],\n",
      "        [-0.0394],\n",
      "        [ 0.0534],\n",
      "        [ 0.0512],\n",
      "        [-0.0256],\n",
      "        [-0.0268],\n",
      "        [ 0.1172],\n",
      "        [ 0.0347],\n",
      "        [ 0.0471],\n",
      "        [ 0.0650],\n",
      "        [ 0.0168],\n",
      "        [ 0.0618],\n",
      "        [ 0.0070]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0889, 0.0888, 0.0891, 0.0876, 0.0880, 0.0883, 0.0879, 0.0877, 0.0877,\n",
      "        0.0867, 0.0858, 0.0874, 0.0882, 0.0877, 0.0871, 0.0894, 0.0905, 0.0919,\n",
      "        0.0907, 0.0901, 0.0923, 0.0929, 0.0932, 0.0939, 0.0960, 0.0954, 0.0956,\n",
      "        0.0972, 0.0963, 0.0967, 0.0951, 0.0966], device='cuda:0')\n",
      "tensor([[ 0.0826],\n",
      "        [ 0.0121],\n",
      "        [-0.0159],\n",
      "        [-0.0162],\n",
      "        [ 0.0353],\n",
      "        [ 0.0131],\n",
      "        [ 0.0610],\n",
      "        [-0.0289],\n",
      "        [ 0.0138],\n",
      "        [-0.0071],\n",
      "        [ 0.0009],\n",
      "        [ 0.0540],\n",
      "        [ 0.0997],\n",
      "        [-0.0460],\n",
      "        [-0.0156],\n",
      "        [ 0.0664],\n",
      "        [-0.0244],\n",
      "        [-0.0447],\n",
      "        [ 0.0182],\n",
      "        [-0.0249],\n",
      "        [-0.0254],\n",
      "        [-0.0056],\n",
      "        [-0.0341],\n",
      "        [-0.0094],\n",
      "        [-0.0260],\n",
      "        [-0.0523],\n",
      "        [-0.0078],\n",
      "        [-0.0242],\n",
      "        [ 0.0405],\n",
      "        [-0.0663],\n",
      "        [ 0.0105],\n",
      "        [ 0.0150]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0950, 0.0963, 0.0959, 0.0960, 0.0963, 0.0963, 0.0979, 0.0991, 0.0929,\n",
      "        0.0904, 0.0914, 0.0900, 0.0902, 0.0902, 0.0898, 0.0914, 0.0922, 0.0933,\n",
      "        0.0926, 0.0928, 0.0920, 0.0889, 0.0849, 0.0836, 0.0852, 0.0846, 0.0851,\n",
      "        0.0848, 0.0851, 0.0854, 0.0846, 0.0830], device='cuda:0')\n",
      "tensor([[ 0.0193],\n",
      "        [ 0.0299],\n",
      "        [ 0.0188],\n",
      "        [-0.0274],\n",
      "        [ 0.0080],\n",
      "        [-0.0509],\n",
      "        [ 0.0048],\n",
      "        [-0.0033],\n",
      "        [ 0.0012],\n",
      "        [-0.0358],\n",
      "        [ 0.0518],\n",
      "        [-0.0263],\n",
      "        [-0.0330],\n",
      "        [ 0.0533],\n",
      "        [ 0.0192],\n",
      "        [-0.0123],\n",
      "        [ 0.0137],\n",
      "        [-0.0140],\n",
      "        [-0.0182],\n",
      "        [ 0.0040],\n",
      "        [ 0.0593],\n",
      "        [ 0.0707],\n",
      "        [ 0.0674],\n",
      "        [ 0.1097],\n",
      "        [-0.0060],\n",
      "        [ 0.0541],\n",
      "        [ 0.0410],\n",
      "        [ 0.0343],\n",
      "        [ 0.0212],\n",
      "        [ 0.0141],\n",
      "        [ 0.0030],\n",
      "        [-0.0014]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0821, 0.0823, 0.0812, 0.0836, 0.0827, 0.0839, 0.0838, 0.0830, 0.0842,\n",
      "        0.0840, 0.0830, 0.0823, 0.0824, 0.0833, 0.0840, 0.0846, 0.0851, 0.0817,\n",
      "        0.0789, 0.0796, 0.0793, 0.0804, 0.0790, 0.0795, 0.0781, 0.0779, 0.0784,\n",
      "        0.0764, 0.0761, 0.0753, 0.0734, 0.0739], device='cuda:0')\n",
      "tensor([[-3.2356e-02],\n",
      "        [-1.3150e-02],\n",
      "        [ 2.1104e-02],\n",
      "        [ 4.8975e-02],\n",
      "        [ 6.0934e-02],\n",
      "        [-3.4927e-02],\n",
      "        [ 2.9698e-02],\n",
      "        [-6.1457e-02],\n",
      "        [-6.7196e-03],\n",
      "        [ 1.7756e-02],\n",
      "        [-1.2206e-02],\n",
      "        [-1.6426e-04],\n",
      "        [ 1.6868e-01],\n",
      "        [ 1.4058e-01],\n",
      "        [ 7.4076e-02],\n",
      "        [-7.6286e-02],\n",
      "        [ 2.8017e-02],\n",
      "        [-1.0282e-02],\n",
      "        [-3.3190e-02],\n",
      "        [-3.0945e-02],\n",
      "        [ 1.9604e-02],\n",
      "        [-2.6537e-03],\n",
      "        [ 1.0634e-02],\n",
      "        [-1.5255e-02],\n",
      "        [ 3.7072e-02],\n",
      "        [ 2.4996e-02],\n",
      "        [-6.1016e-03],\n",
      "        [ 3.7709e-02],\n",
      "        [ 6.2069e-03],\n",
      "        [-1.3176e-02],\n",
      "        [-5.2258e-03],\n",
      "        [-2.0746e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0749, 0.0733, 0.0745, 0.0734, 0.0734, 0.0737, 0.0728, 0.0668, 0.0643,\n",
      "        0.0616, 0.0615, 0.0616, 0.0616, 0.0624, 0.0604, 0.0584, 0.0600, 0.0587,\n",
      "        0.0597, 0.0621, 0.0624, 0.0613, 0.0585, 0.0590, 0.0604, 0.0585, 0.0575,\n",
      "        0.0564, 0.0573, 0.0573, 0.0566, 0.0553], device='cuda:0')\n",
      "tensor([[-0.0053],\n",
      "        [ 0.0132],\n",
      "        [ 0.0137],\n",
      "        [ 0.0313],\n",
      "        [-0.0010],\n",
      "        [-0.0361],\n",
      "        [ 0.0016],\n",
      "        [-0.0549],\n",
      "        [ 0.0062],\n",
      "        [ 0.0234],\n",
      "        [ 0.0094],\n",
      "        [ 0.1224],\n",
      "        [-0.0666],\n",
      "        [ 0.0253],\n",
      "        [-0.0513],\n",
      "        [-0.0862],\n",
      "        [-0.0276],\n",
      "        [-0.0384],\n",
      "        [-0.0243],\n",
      "        [ 0.0847],\n",
      "        [ 0.0866],\n",
      "        [-0.0040],\n",
      "        [ 0.0864],\n",
      "        [ 0.2034],\n",
      "        [ 0.0265],\n",
      "        [ 0.0140],\n",
      "        [-0.0298],\n",
      "        [ 0.0457],\n",
      "        [-0.0066],\n",
      "        [-0.0349],\n",
      "        [-0.0325],\n",
      "        [ 0.0291]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0531, 0.0542, 0.0554, 0.0573, 0.0579, 0.0587, 0.0613, 0.0607, 0.0609,\n",
      "        0.0601, 0.0598, 0.0585, 0.0579, 0.0547, 0.0536, 0.0544, 0.0550, 0.0470,\n",
      "        0.0420, 0.0433, 0.0414, 0.0384, 0.0418, 0.0412, 0.0430, 0.0418, 0.0395,\n",
      "        0.0399, 0.0402, 0.0399, 0.0384, 0.0374], device='cuda:0')\n",
      "tensor([[ 0.0286],\n",
      "        [-0.0208],\n",
      "        [-0.0353],\n",
      "        [-0.0281],\n",
      "        [ 0.0417],\n",
      "        [-0.0459],\n",
      "        [ 0.0595],\n",
      "        [ 0.0084],\n",
      "        [ 0.0369],\n",
      "        [-0.0210],\n",
      "        [ 0.0230],\n",
      "        [ 0.0007],\n",
      "        [-0.0003],\n",
      "        [ 0.0760],\n",
      "        [ 0.0326],\n",
      "        [ 0.0062],\n",
      "        [ 0.0083],\n",
      "        [-0.0109],\n",
      "        [ 0.3107],\n",
      "        [ 0.0200],\n",
      "        [ 0.0386],\n",
      "        [ 0.0350],\n",
      "        [-0.0018],\n",
      "        [ 0.0283],\n",
      "        [ 0.0116],\n",
      "        [-0.0555],\n",
      "        [-0.0164],\n",
      "        [-0.0374],\n",
      "        [ 0.0511],\n",
      "        [-0.0107],\n",
      "        [-0.0399],\n",
      "        [ 0.0270]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0362, 0.0356, 0.0371, 0.0383, 0.0371, 0.0383, 0.0377, 0.0392, 0.0379,\n",
      "        0.0361, 0.0355, 0.0381, 0.0384, 0.0386, 0.0393, 0.0401, 0.0415, 0.0429,\n",
      "        0.0423, 0.0411, 0.0414, 0.0421, 0.0432, 0.0438, 0.0424, 0.0411, 0.0407,\n",
      "        0.0398, 0.0404, 0.0404, 0.0404, 0.0412], device='cuda:0')\n",
      "tensor([[ 0.0193],\n",
      "        [-0.0459],\n",
      "        [-0.0034],\n",
      "        [-0.0168],\n",
      "        [-0.0055],\n",
      "        [ 0.0094],\n",
      "        [ 0.0172],\n",
      "        [ 0.0848],\n",
      "        [ 0.0431],\n",
      "        [ 0.0658],\n",
      "        [ 0.0326],\n",
      "        [ 0.0969],\n",
      "        [ 0.0108],\n",
      "        [ 0.0396],\n",
      "        [ 0.0512],\n",
      "        [ 0.0350],\n",
      "        [-0.0230],\n",
      "        [-0.0029],\n",
      "        [-0.0121],\n",
      "        [ 0.0228],\n",
      "        [-0.0444],\n",
      "        [-0.0346],\n",
      "        [ 0.0038],\n",
      "        [ 0.0102],\n",
      "        [ 0.0188],\n",
      "        [-0.0336],\n",
      "        [-0.0210],\n",
      "        [-0.0690],\n",
      "        [-0.0096],\n",
      "        [ 0.0465],\n",
      "        [ 0.0944],\n",
      "        [ 0.0162]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0411, 0.0420, 0.0442, 0.0449, 0.0454, 0.0448, 0.0460, 0.0455, 0.0460,\n",
      "        0.0470, 0.0476, 0.0467, 0.0455, 0.0464, 0.0457, 0.0458, 0.0451, 0.0452,\n",
      "        0.0442, 0.0440, 0.0448, 0.0411, 0.0404, 0.0414, 0.0418, 0.0398, 0.0408,\n",
      "        0.0420, 0.0429, 0.0429, 0.0421, 0.0424], device='cuda:0')\n",
      "tensor([[ 0.0289],\n",
      "        [ 0.1713],\n",
      "        [-0.0024],\n",
      "        [ 0.0376],\n",
      "        [ 0.0136],\n",
      "        [-0.0437],\n",
      "        [ 0.0211],\n",
      "        [-0.0154],\n",
      "        [ 0.0742],\n",
      "        [-0.0469],\n",
      "        [ 0.0213],\n",
      "        [-0.0300],\n",
      "        [-0.0040],\n",
      "        [ 0.0193],\n",
      "        [ 0.0170],\n",
      "        [ 0.0078],\n",
      "        [-0.0070],\n",
      "        [-0.0429],\n",
      "        [ 0.0359],\n",
      "        [ 0.0288],\n",
      "        [ 0.0185],\n",
      "        [ 0.0155],\n",
      "        [ 0.0333],\n",
      "        [-0.0260],\n",
      "        [ 0.0216],\n",
      "        [ 0.0038],\n",
      "        [-0.0144],\n",
      "        [-0.0190],\n",
      "        [ 0.0576],\n",
      "        [ 0.0165],\n",
      "        [-0.0133],\n",
      "        [-0.0155]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0401, 0.0410, 0.0390, 0.0386, 0.0383, 0.0386, 0.0389, 0.0405, 0.0387,\n",
      "        0.0380, 0.0371, 0.0379, 0.0379, 0.0396, 0.0384, 0.0381, 0.0389, 0.0389,\n",
      "        0.0390, 0.0377, 0.0381, 0.0384, 0.0384, 0.0374, 0.0368, 0.0373, 0.0370,\n",
      "        0.0386, 0.0393, 0.0389, 0.0379, 0.0395], device='cuda:0')\n",
      "tensor([[ 0.0164],\n",
      "        [ 0.0343],\n",
      "        [-0.0020],\n",
      "        [ 0.0249],\n",
      "        [ 0.0027],\n",
      "        [ 0.0344],\n",
      "        [ 0.0638],\n",
      "        [ 0.0558],\n",
      "        [ 0.0632],\n",
      "        [ 0.0328],\n",
      "        [ 0.0946],\n",
      "        [ 0.0676],\n",
      "        [-0.0063],\n",
      "        [-0.0149],\n",
      "        [ 0.0137],\n",
      "        [-0.0288],\n",
      "        [-0.0220],\n",
      "        [ 0.0309],\n",
      "        [-0.0356],\n",
      "        [-0.0213],\n",
      "        [ 0.0500],\n",
      "        [ 0.0526],\n",
      "        [ 0.0775],\n",
      "        [-0.0349],\n",
      "        [-0.0392],\n",
      "        [ 0.0647],\n",
      "        [-0.0551],\n",
      "        [ 0.0188],\n",
      "        [-0.0042],\n",
      "        [-0.0141],\n",
      "        [-0.0544],\n",
      "        [-0.0333]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0402, 0.0430, 0.0436, 0.0430, 0.0421, 0.0443, 0.0443, 0.0445, 0.0424,\n",
      "        0.0424, 0.0432, 0.0427, 0.0427, 0.0421, 0.0396, 0.0402, 0.0393, 0.0390,\n",
      "        0.0389, 0.0389, 0.0381, 0.0383, 0.0395, 0.0402, 0.0390, 0.0390, 0.0389,\n",
      "        0.0377, 0.0361, 0.0358, 0.0358, 0.0358], device='cuda:0')\n",
      "tensor([[ 9.5572e-05],\n",
      "        [ 2.5261e-02],\n",
      "        [-2.2684e-02],\n",
      "        [ 7.5862e-02],\n",
      "        [ 5.0477e-02],\n",
      "        [-1.2231e-02],\n",
      "        [-7.7527e-03],\n",
      "        [ 1.0501e-02],\n",
      "        [-2.0740e-02],\n",
      "        [ 2.6514e-02],\n",
      "        [ 5.5524e-02],\n",
      "        [ 2.0881e-02],\n",
      "        [ 4.2052e-02],\n",
      "        [ 6.2411e-02],\n",
      "        [-6.6837e-03],\n",
      "        [ 4.2698e-02],\n",
      "        [ 9.2816e-02],\n",
      "        [ 1.6965e-01],\n",
      "        [ 1.7696e-02],\n",
      "        [ 6.5244e-02],\n",
      "        [ 1.6255e-02],\n",
      "        [ 2.0023e-02],\n",
      "        [-4.3407e-03],\n",
      "        [-1.5386e-02],\n",
      "        [-5.2844e-04],\n",
      "        [-3.9986e-02],\n",
      "        [-3.1291e-02],\n",
      "        [ 2.7434e-02],\n",
      "        [ 3.1696e-02],\n",
      "        [-6.5153e-03],\n",
      "        [ 1.7173e-02],\n",
      "        [ 4.2975e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0376, 0.0370, 0.0367, 0.0368, 0.0346, 0.0322, 0.0314, 0.0322, 0.0319,\n",
      "        0.0306, 0.0308, 0.0346, 0.0327, 0.0325, 0.0333, 0.0325, 0.0319, 0.0331,\n",
      "        0.0324, 0.0319, 0.0317, 0.0318, 0.0306, 0.0300, 0.0299, 0.0291, 0.0315,\n",
      "        0.0312, 0.0315, 0.0317, 0.0331, 0.0325], device='cuda:0')\n",
      "tensor([[ 0.0324],\n",
      "        [-0.0078],\n",
      "        [-0.0217],\n",
      "        [ 0.0737],\n",
      "        [-0.0035],\n",
      "        [ 0.0134],\n",
      "        [ 0.0365],\n",
      "        [-0.0250],\n",
      "        [-0.0178],\n",
      "        [ 0.1024],\n",
      "        [ 0.0448],\n",
      "        [ 0.0177],\n",
      "        [ 0.0498],\n",
      "        [ 0.0213],\n",
      "        [ 0.0099],\n",
      "        [-0.0551],\n",
      "        [-0.0747],\n",
      "        [-0.0775],\n",
      "        [-0.0099],\n",
      "        [-0.0194],\n",
      "        [-0.0246],\n",
      "        [ 0.0074],\n",
      "        [-0.0296],\n",
      "        [ 0.0823],\n",
      "        [-0.0577],\n",
      "        [ 0.0985],\n",
      "        [ 0.0453],\n",
      "        [ 0.0350],\n",
      "        [ 0.0610],\n",
      "        [ 0.0192],\n",
      "        [-0.0101],\n",
      "        [ 0.0196]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0327, 0.0327, 0.0328, 0.0334, 0.0348, 0.0349, 0.0350, 0.0348, 0.0345,\n",
      "        0.0331, 0.0331, 0.0324, 0.0325, 0.0321, 0.0322, 0.0321, 0.0319, 0.0306,\n",
      "        0.0305, 0.0302, 0.0302, 0.0300, 0.0300, 0.0300, 0.0299, 0.0303, 0.0325,\n",
      "        0.0330, 0.0324, 0.0327, 0.0327, 0.0330], device='cuda:0')\n",
      "tensor([[-0.0425],\n",
      "        [ 0.0482],\n",
      "        [-0.0569],\n",
      "        [ 0.0264],\n",
      "        [ 0.0456],\n",
      "        [ 0.0188],\n",
      "        [-0.0597],\n",
      "        [ 0.0614],\n",
      "        [ 0.0370],\n",
      "        [-0.0123],\n",
      "        [-0.0437],\n",
      "        [ 0.0304],\n",
      "        [ 0.0617],\n",
      "        [-0.0280],\n",
      "        [ 0.0399],\n",
      "        [-0.0222],\n",
      "        [ 0.1078],\n",
      "        [-0.0115],\n",
      "        [-0.0114],\n",
      "        [-0.0264],\n",
      "        [ 0.0357],\n",
      "        [-0.0766],\n",
      "        [-0.0013],\n",
      "        [ 0.0493],\n",
      "        [ 0.0591],\n",
      "        [-0.0186],\n",
      "        [-0.0219],\n",
      "        [-0.0439],\n",
      "        [ 0.0279],\n",
      "        [-0.0075],\n",
      "        [-0.0131],\n",
      "        [ 0.0493]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0328, 0.0324, 0.0317, 0.0311, 0.0333, 0.0327, 0.0319, 0.0322, 0.0339,\n",
      "        0.0333, 0.0337, 0.0353, 0.0350, 0.0348, 0.0350, 0.0371, 0.0408, 0.0407,\n",
      "        0.0395, 0.0396, 0.0401, 0.0387, 0.0396, 0.0421, 0.0417, 0.0410, 0.0430,\n",
      "        0.0420, 0.0430, 0.0420, 0.0421, 0.0435], device='cuda:0')\n",
      "tensor([[ 0.1095],\n",
      "        [ 0.0341],\n",
      "        [ 0.0569],\n",
      "        [ 0.0460],\n",
      "        [-0.0210],\n",
      "        [ 0.0708],\n",
      "        [-0.0157],\n",
      "        [ 0.0095],\n",
      "        [ 0.0089],\n",
      "        [ 0.0555],\n",
      "        [-0.0204],\n",
      "        [ 0.0476],\n",
      "        [-0.0267],\n",
      "        [-0.0427],\n",
      "        [ 0.0219],\n",
      "        [ 0.0614],\n",
      "        [ 0.0766],\n",
      "        [ 0.0217],\n",
      "        [ 0.0007],\n",
      "        [ 0.0093],\n",
      "        [-0.0039],\n",
      "        [ 0.0267],\n",
      "        [ 0.0191],\n",
      "        [ 0.0274],\n",
      "        [ 0.0149],\n",
      "        [-0.0377],\n",
      "        [ 0.0516],\n",
      "        [ 0.0227],\n",
      "        [ 0.0439],\n",
      "        [ 0.0637],\n",
      "        [-0.0454],\n",
      "        [-0.0390]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0458, 0.0466, 0.0449, 0.0443, 0.0435, 0.0442, 0.0439, 0.0442, 0.0442,\n",
      "        0.0443, 0.0440, 0.0460, 0.0485, 0.0470, 0.0479, 0.0486, 0.0513, 0.0497,\n",
      "        0.0500, 0.0507, 0.0500, 0.0505, 0.0497, 0.0494, 0.0480, 0.0474, 0.0488,\n",
      "        0.0504, 0.0510, 0.0498, 0.0502, 0.0507], device='cuda:0')\n",
      "tensor([[ 0.0098],\n",
      "        [ 0.0463],\n",
      "        [ 0.0496],\n",
      "        [ 0.0034],\n",
      "        [-0.0056],\n",
      "        [ 0.0142],\n",
      "        [ 0.0169],\n",
      "        [ 0.0083],\n",
      "        [ 0.0203],\n",
      "        [ 0.0011],\n",
      "        [-0.0036],\n",
      "        [ 0.0100],\n",
      "        [-0.0298],\n",
      "        [ 0.0544],\n",
      "        [-0.0211],\n",
      "        [ 0.2258],\n",
      "        [ 0.0879],\n",
      "        [-0.0110],\n",
      "        [-0.0458],\n",
      "        [ 0.0164],\n",
      "        [ 0.0327],\n",
      "        [-0.0128],\n",
      "        [-0.0371],\n",
      "        [-0.0623],\n",
      "        [ 0.0120],\n",
      "        [ 0.0225],\n",
      "        [ 0.0642],\n",
      "        [ 0.0556],\n",
      "        [-0.0465],\n",
      "        [-0.0284],\n",
      "        [ 0.0232],\n",
      "        [-0.0361]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0500, 0.0494, 0.0501, 0.0500, 0.0486, 0.0482, 0.0469, 0.0460, 0.0460,\n",
      "        0.0500, 0.0495, 0.0473, 0.0482, 0.0489, 0.0474, 0.0474, 0.0473, 0.0466,\n",
      "        0.0421, 0.0448, 0.0440, 0.0435, 0.0432, 0.0436, 0.0445, 0.0451, 0.0452,\n",
      "        0.0430, 0.0429, 0.0440, 0.0439, 0.0432], device='cuda:0')\n",
      "tensor([[ 0.0111],\n",
      "        [-0.0002],\n",
      "        [-0.0288],\n",
      "        [-0.0692],\n",
      "        [-0.0532],\n",
      "        [-0.0192],\n",
      "        [ 0.0225],\n",
      "        [ 0.0220],\n",
      "        [ 0.0042],\n",
      "        [-0.0341],\n",
      "        [-0.0438],\n",
      "        [-0.0468],\n",
      "        [ 0.1650],\n",
      "        [-0.0005],\n",
      "        [ 0.1119],\n",
      "        [ 0.0512],\n",
      "        [ 0.0730],\n",
      "        [ 0.0268],\n",
      "        [-0.0092],\n",
      "        [ 0.0072],\n",
      "        [ 0.0241],\n",
      "        [ 0.0372],\n",
      "        [ 0.0329],\n",
      "        [-0.0393],\n",
      "        [-0.0472],\n",
      "        [ 0.0351],\n",
      "        [-0.0729],\n",
      "        [ 0.1015],\n",
      "        [ 0.0272],\n",
      "        [ 0.0599],\n",
      "        [-0.0295],\n",
      "        [-0.0245]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0432, 0.0432, 0.0440, 0.0433, 0.0429, 0.0429, 0.0424, 0.0454, 0.0461,\n",
      "        0.0469, 0.0467, 0.0486, 0.0485, 0.0495, 0.0491, 0.0482, 0.0500, 0.0495,\n",
      "        0.0483, 0.0473, 0.0445, 0.0440, 0.0429, 0.0439, 0.0452, 0.0433, 0.0438,\n",
      "        0.0435, 0.0435, 0.0427, 0.0433, 0.0432], device='cuda:0')\n",
      "tensor([[-0.0502],\n",
      "        [-0.0386],\n",
      "        [-0.0643],\n",
      "        [ 0.0246],\n",
      "        [ 0.0330],\n",
      "        [ 0.0514],\n",
      "        [-0.0022],\n",
      "        [ 0.0393],\n",
      "        [ 0.0006],\n",
      "        [ 0.0355],\n",
      "        [-0.0328],\n",
      "        [ 0.2196],\n",
      "        [ 0.2104],\n",
      "        [ 0.0834],\n",
      "        [-0.0223],\n",
      "        [ 0.0227],\n",
      "        [-0.0175],\n",
      "        [ 0.0226],\n",
      "        [-0.0714],\n",
      "        [-0.0406],\n",
      "        [ 0.0430],\n",
      "        [ 0.0090],\n",
      "        [-0.0016],\n",
      "        [-0.0389],\n",
      "        [ 0.0422],\n",
      "        [ 0.0025],\n",
      "        [-0.0387],\n",
      "        [-0.0678],\n",
      "        [ 0.1103],\n",
      "        [ 0.0579],\n",
      "        [ 0.0848],\n",
      "        [ 0.0381]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0426, 0.0443, 0.0433, 0.0438, 0.0438, 0.0424, 0.0497, 0.0501, 0.0507,\n",
      "        0.0498, 0.0482, 0.0486, 0.0492, 0.0497, 0.0489, 0.0482, 0.0474, 0.0480,\n",
      "        0.0492, 0.0483, 0.0483, 0.0486, 0.0498, 0.0531, 0.0525, 0.0532, 0.0541,\n",
      "        0.0536, 0.0553, 0.0559, 0.0563, 0.0559], device='cuda:0')\n",
      "tensor([[ 0.0396],\n",
      "        [ 0.0473],\n",
      "        [ 0.1783],\n",
      "        [-0.0197],\n",
      "        [ 0.0140],\n",
      "        [-0.0086],\n",
      "        [ 0.0068],\n",
      "        [-0.0044],\n",
      "        [-0.0053],\n",
      "        [ 0.0316],\n",
      "        [-0.0255],\n",
      "        [ 0.0369],\n",
      "        [ 0.0091],\n",
      "        [-0.0093],\n",
      "        [ 0.0173],\n",
      "        [ 0.0092],\n",
      "        [-0.0425],\n",
      "        [-0.0054],\n",
      "        [ 0.0377],\n",
      "        [-0.0245],\n",
      "        [ 0.0467],\n",
      "        [ 0.0427],\n",
      "        [-0.0290],\n",
      "        [ 0.0498],\n",
      "        [ 0.0097],\n",
      "        [ 0.0315],\n",
      "        [ 0.0440],\n",
      "        [-0.0129],\n",
      "        [-0.0064],\n",
      "        [-0.0351],\n",
      "        [-0.0617],\n",
      "        [ 0.0387]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0551, 0.0557, 0.0539, 0.0528, 0.0547, 0.0547, 0.0535, 0.0539, 0.0547,\n",
      "        0.0560, 0.0575, 0.0560, 0.0550, 0.0544, 0.0535, 0.0528, 0.0539, 0.0526,\n",
      "        0.0514, 0.0533, 0.0529, 0.0520, 0.0501, 0.0480, 0.0471, 0.0480, 0.0477,\n",
      "        0.0476, 0.0464, 0.0467, 0.0477, 0.0495], device='cuda:0')\n",
      "tensor([[-4.2403e-02],\n",
      "        [ 7.6693e-02],\n",
      "        [ 8.0102e-02],\n",
      "        [-1.2315e-02],\n",
      "        [ 1.3806e-05],\n",
      "        [-1.4244e-02],\n",
      "        [-4.4670e-02],\n",
      "        [ 4.7228e-02],\n",
      "        [-1.8913e-03],\n",
      "        [ 2.0300e-01],\n",
      "        [ 3.8039e-02],\n",
      "        [-2.5318e-02],\n",
      "        [ 6.6086e-02],\n",
      "        [-4.1087e-02],\n",
      "        [-5.9238e-02],\n",
      "        [-2.6778e-02],\n",
      "        [ 1.3106e-02],\n",
      "        [-8.1237e-04],\n",
      "        [-5.2851e-02],\n",
      "        [ 1.3985e-02],\n",
      "        [-6.0228e-02],\n",
      "        [-5.7014e-02],\n",
      "        [ 3.1815e-03],\n",
      "        [-4.3276e-03],\n",
      "        [ 1.4533e-02],\n",
      "        [-4.4258e-02],\n",
      "        [ 1.1590e-03],\n",
      "        [-3.9202e-02],\n",
      "        [ 3.3549e-02],\n",
      "        [ 1.6672e-02],\n",
      "        [ 7.2463e-02],\n",
      "        [ 1.0539e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0479, 0.0479, 0.0464, 0.0467, 0.0544, 0.0532, 0.0542, 0.0544, 0.0545,\n",
      "        0.0542, 0.0538, 0.0550, 0.0542, 0.0551, 0.0553, 0.0544, 0.0554, 0.0569,\n",
      "        0.0564, 0.0570, 0.0560, 0.0567, 0.0570, 0.0573, 0.0590, 0.0612, 0.0607,\n",
      "        0.0606, 0.0603, 0.0626, 0.0634, 0.0626], device='cuda:0')\n",
      "tensor([[ 0.0673],\n",
      "        [ 0.0411],\n",
      "        [ 0.1275],\n",
      "        [ 0.0039],\n",
      "        [ 0.0115],\n",
      "        [-0.0043],\n",
      "        [ 0.0336],\n",
      "        [ 0.0408],\n",
      "        [ 0.0437],\n",
      "        [ 0.1253],\n",
      "        [ 0.0129],\n",
      "        [-0.0261],\n",
      "        [-0.0071],\n",
      "        [ 0.0257],\n",
      "        [ 0.0482],\n",
      "        [ 0.0292],\n",
      "        [-0.0204],\n",
      "        [ 0.0104],\n",
      "        [-0.0069],\n",
      "        [ 0.0377],\n",
      "        [ 0.0602],\n",
      "        [ 0.0301],\n",
      "        [ 0.0307],\n",
      "        [-0.0186],\n",
      "        [ 0.0186],\n",
      "        [ 0.0343],\n",
      "        [-0.0040],\n",
      "        [-0.0387],\n",
      "        [-0.0391],\n",
      "        [-0.0216],\n",
      "        [ 0.0306],\n",
      "        [-0.0432]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0626, 0.0616, 0.0609, 0.0601, 0.0604, 0.0604, 0.0609, 0.0601, 0.0609,\n",
      "        0.0625, 0.0631, 0.0631, 0.0646, 0.0638, 0.0637, 0.0628, 0.0629, 0.0624,\n",
      "        0.0622, 0.0622, 0.0616, 0.0628, 0.0629, 0.0621, 0.0615, 0.0624, 0.0619,\n",
      "        0.0647, 0.0652, 0.0653, 0.0671, 0.0660], device='cuda:0')\n",
      "tensor([[ 0.1419],\n",
      "        [ 0.0064],\n",
      "        [ 0.0991],\n",
      "        [ 0.0718],\n",
      "        [ 0.0418],\n",
      "        [ 0.0102],\n",
      "        [-0.0130],\n",
      "        [-0.0096],\n",
      "        [ 0.1148],\n",
      "        [-0.0386],\n",
      "        [ 0.0530],\n",
      "        [-0.0092],\n",
      "        [ 0.0114],\n",
      "        [-0.0766],\n",
      "        [-0.0217],\n",
      "        [ 0.0449],\n",
      "        [ 0.0211],\n",
      "        [ 0.0107],\n",
      "        [ 0.0032],\n",
      "        [ 0.0424],\n",
      "        [ 0.0965],\n",
      "        [-0.0192],\n",
      "        [ 0.0417],\n",
      "        [ 0.0164],\n",
      "        [-0.0098],\n",
      "        [ 0.0372],\n",
      "        [ 0.0249],\n",
      "        [ 0.0347],\n",
      "        [ 0.0409],\n",
      "        [-0.0321],\n",
      "        [ 0.0053],\n",
      "        [ 0.0337]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0671, 0.0672, 0.0687, 0.0697, 0.0693, 0.0688, 0.0669, 0.0680, 0.0686,\n",
      "        0.0683, 0.0706, 0.0687, 0.0680, 0.0684, 0.0675, 0.0647, 0.0656, 0.0669,\n",
      "        0.0681, 0.0657, 0.0662, 0.0668, 0.0671, 0.0666, 0.0671, 0.0672, 0.0668,\n",
      "        0.0631, 0.0634, 0.0643, 0.0641, 0.0641], device='cuda:0')\n",
      "tensor([[-0.0047],\n",
      "        [ 0.0712],\n",
      "        [-0.0901],\n",
      "        [ 0.0977],\n",
      "        [ 0.0652],\n",
      "        [-0.0185],\n",
      "        [ 0.0818],\n",
      "        [ 0.0092],\n",
      "        [-0.0207],\n",
      "        [-0.0168],\n",
      "        [-0.0434],\n",
      "        [-0.0092],\n",
      "        [ 0.0207],\n",
      "        [ 0.0143],\n",
      "        [ 0.0186],\n",
      "        [-0.0071],\n",
      "        [ 0.0036],\n",
      "        [ 0.0588],\n",
      "        [ 0.0335],\n",
      "        [ 0.0155],\n",
      "        [ 0.0641],\n",
      "        [ 0.0644],\n",
      "        [ 0.0488],\n",
      "        [-0.0031],\n",
      "        [-0.0045],\n",
      "        [ 0.0348],\n",
      "        [-0.0486],\n",
      "        [-0.0157],\n",
      "        [-0.0401],\n",
      "        [ 0.0124],\n",
      "        [ 0.0324],\n",
      "        [ 0.0544]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0643, 0.0628, 0.0650, 0.0650, 0.0653, 0.0649, 0.0635, 0.0652, 0.0641,\n",
      "        0.0631, 0.0637, 0.0640, 0.0635, 0.0653, 0.0643, 0.0677, 0.0675, 0.0675,\n",
      "        0.0684, 0.0669, 0.0686, 0.0675, 0.0678, 0.0686, 0.0681, 0.0694, 0.0699,\n",
      "        0.0712, 0.0705, 0.0705, 0.0709, 0.0722], device='cuda:0')\n",
      "tensor([[ 0.0883],\n",
      "        [ 0.0660],\n",
      "        [ 0.0007],\n",
      "        [ 0.0641],\n",
      "        [ 0.0064],\n",
      "        [ 0.0188],\n",
      "        [ 0.0723],\n",
      "        [ 0.0054],\n",
      "        [ 0.0509],\n",
      "        [ 0.0579],\n",
      "        [ 0.0431],\n",
      "        [ 0.1085],\n",
      "        [ 0.1239],\n",
      "        [-0.0836],\n",
      "        [ 0.0817],\n",
      "        [ 0.0432],\n",
      "        [ 0.0385],\n",
      "        [-0.0209],\n",
      "        [ 0.0819],\n",
      "        [ 0.0489],\n",
      "        [ 0.0224],\n",
      "        [ 0.0081],\n",
      "        [-0.0322],\n",
      "        [-0.0268],\n",
      "        [-0.0296],\n",
      "        [-0.0126],\n",
      "        [ 0.0247],\n",
      "        [ 0.0103],\n",
      "        [ 0.0150],\n",
      "        [-0.0348],\n",
      "        [-0.0513],\n",
      "        [ 0.0211]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0722, 0.0719, 0.0711, 0.0697, 0.0684, 0.0681, 0.0662, 0.0662, 0.0663,\n",
      "        0.0655, 0.0659, 0.0677, 0.0686, 0.0688, 0.0686, 0.0684, 0.0684, 0.0693,\n",
      "        0.0693, 0.0691, 0.0700, 0.0700, 0.0699, 0.0693, 0.0684, 0.0684, 0.0684,\n",
      "        0.0691, 0.0681, 0.0696, 0.0697, 0.0719], device='cuda:0')\n",
      "tensor([[ 0.0478],\n",
      "        [-0.0765],\n",
      "        [-0.0432],\n",
      "        [ 0.0059],\n",
      "        [-0.0436],\n",
      "        [ 0.2217],\n",
      "        [ 0.2378],\n",
      "        [ 0.1174],\n",
      "        [ 0.0673],\n",
      "        [ 0.0024],\n",
      "        [ 0.0248],\n",
      "        [ 0.0820],\n",
      "        [-0.0012],\n",
      "        [-0.0273],\n",
      "        [-0.0323],\n",
      "        [ 0.0258],\n",
      "        [ 0.0259],\n",
      "        [ 0.0398],\n",
      "        [ 0.0257],\n",
      "        [-0.0631],\n",
      "        [ 0.0041],\n",
      "        [-0.0299],\n",
      "        [-0.0524],\n",
      "        [ 0.0214],\n",
      "        [-0.0079],\n",
      "        [-0.0298],\n",
      "        [ 0.0887],\n",
      "        [ 0.0836],\n",
      "        [-0.0326],\n",
      "        [-0.0150],\n",
      "        [-0.0327],\n",
      "        [ 0.0278]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0750, 0.0755, 0.0749, 0.0749, 0.0759, 0.0765, 0.0776, 0.0770, 0.0773,\n",
      "        0.0793, 0.0783, 0.0793, 0.0779, 0.0771, 0.0792, 0.0795, 0.0811, 0.0805,\n",
      "        0.0787, 0.0780, 0.0777, 0.0786, 0.0787, 0.0799, 0.0798, 0.0799, 0.0823,\n",
      "        0.0832, 0.0836, 0.0827, 0.0845, 0.0849], device='cuda:0')\n",
      "tensor([[ 0.0045],\n",
      "        [ 0.0047],\n",
      "        [ 0.0116],\n",
      "        [-0.0293],\n",
      "        [-0.0024],\n",
      "        [ 0.0522],\n",
      "        [ 0.0784],\n",
      "        [ 0.1416],\n",
      "        [ 0.0494],\n",
      "        [ 0.0112],\n",
      "        [ 0.0606],\n",
      "        [ 0.1201],\n",
      "        [ 0.1842],\n",
      "        [ 0.0132],\n",
      "        [ 0.0357],\n",
      "        [-0.0143],\n",
      "        [-0.0103],\n",
      "        [-0.0239],\n",
      "        [-0.0066],\n",
      "        [-0.0163],\n",
      "        [ 0.0118],\n",
      "        [-0.0166],\n",
      "        [-0.0029],\n",
      "        [ 0.0076],\n",
      "        [-0.0294],\n",
      "        [ 0.0263],\n",
      "        [-0.0209],\n",
      "        [ 0.0262],\n",
      "        [-0.0451],\n",
      "        [ 0.0017],\n",
      "        [ 0.0432],\n",
      "        [-0.0407]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0836, 0.0858, 0.0889, 0.0911, 0.0913, 0.0932, 0.0951, 0.0925, 0.0895,\n",
      "        0.0904, 0.0920, 0.0914, 0.0907, 0.0914, 0.0913, 0.0916, 0.0920, 0.0922,\n",
      "        0.0929, 0.0925, 0.0928, 0.0907, 0.0910, 0.0932, 0.0956, 0.0942, 0.0950,\n",
      "        0.0929, 0.0901, 0.0905, 0.0920, 0.0916], device='cuda:0')\n",
      "tensor([[-0.0022],\n",
      "        [ 0.0046],\n",
      "        [-0.0485],\n",
      "        [-0.0374],\n",
      "        [ 0.0096],\n",
      "        [ 0.1093],\n",
      "        [ 0.0274],\n",
      "        [ 0.0431],\n",
      "        [-0.0573],\n",
      "        [ 0.0534],\n",
      "        [ 0.0213],\n",
      "        [ 0.0305],\n",
      "        [ 0.0188],\n",
      "        [-0.0246],\n",
      "        [ 0.0382],\n",
      "        [ 0.0048],\n",
      "        [ 0.1368],\n",
      "        [ 0.0663],\n",
      "        [ 0.1119],\n",
      "        [ 0.0620],\n",
      "        [ 0.0434],\n",
      "        [-0.0419],\n",
      "        [ 0.0207],\n",
      "        [-0.0301],\n",
      "        [ 0.0316],\n",
      "        [-0.0131],\n",
      "        [ 0.0195],\n",
      "        [ 0.0109],\n",
      "        [ 0.0648],\n",
      "        [ 0.0285],\n",
      "        [ 0.0041],\n",
      "        [ 0.0968]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0885, 0.0886, 0.0869, 0.0863, 0.0860, 0.0873, 0.0891, 0.0905, 0.0905,\n",
      "        0.0901, 0.0914, 0.0962, 0.0954, 0.0959, 0.0972, 0.0967, 0.0933, 0.0942,\n",
      "        0.0953, 0.0941, 0.0960, 0.0950, 0.0975, 0.0982, 0.0995, 0.0985, 0.1007,\n",
      "        0.1032, 0.1034, 0.1074, 0.1071, 0.1003], device='cuda:0')\n",
      "tensor([[ 0.0193],\n",
      "        [ 0.0105],\n",
      "        [ 0.1245],\n",
      "        [ 0.0575],\n",
      "        [ 0.0727],\n",
      "        [ 0.0066],\n",
      "        [-0.0058],\n",
      "        [ 0.0426],\n",
      "        [-0.0044],\n",
      "        [ 0.0221],\n",
      "        [ 0.0144],\n",
      "        [-0.0094],\n",
      "        [-0.0293],\n",
      "        [ 0.0190],\n",
      "        [-0.0152],\n",
      "        [ 0.0251],\n",
      "        [-0.0657],\n",
      "        [-0.0766],\n",
      "        [-0.0454],\n",
      "        [ 0.0089],\n",
      "        [-0.0184],\n",
      "        [-0.0384],\n",
      "        [-0.0067],\n",
      "        [ 0.0179],\n",
      "        [ 0.0008],\n",
      "        [ 0.0085],\n",
      "        [ 0.0029],\n",
      "        [ 0.0636],\n",
      "        [ 0.0134],\n",
      "        [ 0.0613],\n",
      "        [-0.0344],\n",
      "        [-0.0032]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1037, 0.1031, 0.1077, 0.1087, 0.1094, 0.1115, 0.1114, 0.1093, 0.1102,\n",
      "        0.1077, 0.1094, 0.1090, 0.1093, 0.1102, 0.1105, 0.1096, 0.1097, 0.1115,\n",
      "        0.1130, 0.1134, 0.1149, 0.1122, 0.1068, 0.1078, 0.1066, 0.1046, 0.1034,\n",
      "        0.1007, 0.1016, 0.1007, 0.1028, 0.1021], device='cuda:0')\n",
      "tensor([[-0.0022],\n",
      "        [ 0.0610],\n",
      "        [ 0.0133],\n",
      "        [ 0.0059],\n",
      "        [ 0.0290],\n",
      "        [-0.0089],\n",
      "        [-0.0166],\n",
      "        [ 0.0115],\n",
      "        [ 0.0086],\n",
      "        [ 0.0246],\n",
      "        [ 0.1204],\n",
      "        [ 0.1682],\n",
      "        [ 0.0512],\n",
      "        [ 0.0736],\n",
      "        [-0.0071],\n",
      "        [ 0.0273],\n",
      "        [ 0.0041],\n",
      "        [-0.0634],\n",
      "        [-0.0145],\n",
      "        [ 0.0176],\n",
      "        [-0.0859],\n",
      "        [ 0.0490],\n",
      "        [-0.0433],\n",
      "        [-0.0128],\n",
      "        [-0.0614],\n",
      "        [ 0.0238],\n",
      "        [-0.0146],\n",
      "        [-0.0344],\n",
      "        [-0.0512],\n",
      "        [-0.0197],\n",
      "        [ 0.1056],\n",
      "        [ 0.0081]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1001, 0.0997, 0.0981, 0.0975, 0.0945, 0.0959, 0.0925, 0.0910, 0.0897,\n",
      "        0.0919, 0.0950, 0.0938, 0.0922, 0.0916, 0.0902, 0.0904, 0.0922, 0.0916,\n",
      "        0.0923, 0.0911, 0.0928, 0.0914, 0.0923, 0.0919, 0.0894, 0.0879, 0.0900,\n",
      "        0.0905, 0.0900, 0.0917, 0.0951, 0.0945], device='cuda:0')\n",
      "tensor([[ 0.0325],\n",
      "        [ 0.0486],\n",
      "        [-0.0437],\n",
      "        [ 0.1660],\n",
      "        [ 0.2158],\n",
      "        [ 0.0464],\n",
      "        [-0.0308],\n",
      "        [ 0.1108],\n",
      "        [ 0.0273],\n",
      "        [ 0.0171],\n",
      "        [ 0.0401],\n",
      "        [-0.0406],\n",
      "        [-0.0331],\n",
      "        [-0.0034],\n",
      "        [-0.0413],\n",
      "        [ 0.0368],\n",
      "        [ 0.0523],\n",
      "        [-0.0208],\n",
      "        [ 0.0728],\n",
      "        [ 0.0184],\n",
      "        [-0.0326],\n",
      "        [-0.0337],\n",
      "        [ 0.0328],\n",
      "        [ 0.0923],\n",
      "        [-0.0552],\n",
      "        [ 0.0440],\n",
      "        [ 0.0344],\n",
      "        [ 0.0804],\n",
      "        [-0.0374],\n",
      "        [-0.0656],\n",
      "        [-0.0945],\n",
      "        [-0.0020]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0967, 0.0933, 0.0976, 0.0964, 0.0942, 0.0939, 0.0947, 0.0967, 0.0956,\n",
      "        0.0951, 0.0984, 0.1006, 0.0994, 0.0973, 0.0962, 0.0969, 0.0957, 0.0957,\n",
      "        0.0933, 0.0935, 0.0936, 0.0931, 0.0905, 0.0923, 0.0932, 0.0939, 0.0939,\n",
      "        0.0953, 0.0954, 0.0948, 0.0926, 0.0942], device='cuda:0')\n",
      "tensor([[ 0.1109],\n",
      "        [ 0.0825],\n",
      "        [-0.0404],\n",
      "        [ 0.0198],\n",
      "        [ 0.0151],\n",
      "        [-0.0523],\n",
      "        [-0.0222],\n",
      "        [-0.0175],\n",
      "        [ 0.0465],\n",
      "        [-0.0329],\n",
      "        [ 0.0222],\n",
      "        [-0.0122],\n",
      "        [ 0.0237],\n",
      "        [-0.0256],\n",
      "        [ 0.0644],\n",
      "        [-0.0107],\n",
      "        [ 0.0204],\n",
      "        [ 0.0561],\n",
      "        [-0.0565],\n",
      "        [ 0.0332],\n",
      "        [ 0.0145],\n",
      "        [-0.0571],\n",
      "        [ 0.0252],\n",
      "        [ 0.0141],\n",
      "        [ 0.0112],\n",
      "        [-0.0674],\n",
      "        [ 0.0041],\n",
      "        [-0.1488],\n",
      "        [ 0.0507],\n",
      "        [ 0.0987],\n",
      "        [ 0.0006],\n",
      "        [-0.0488]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0938, 0.0938, 0.0926, 0.0951, 0.0944, 0.0933, 0.0923, 0.0914, 0.0873,\n",
      "        0.0858, 0.0892, 0.0863, 0.0880, 0.0885, 0.0891, 0.0894, 0.0871, 0.0886,\n",
      "        0.0880, 0.0861, 0.0833, 0.0854, 0.0860, 0.0832, 0.0838, 0.0838, 0.0827,\n",
      "        0.0789, 0.0835, 0.0842, 0.0944, 0.1012], device='cuda:0')\n",
      "tensor([[ 0.1173],\n",
      "        [ 0.0627],\n",
      "        [ 0.0890],\n",
      "        [ 0.1098],\n",
      "        [ 0.3379],\n",
      "        [ 0.0219],\n",
      "        [ 0.0237],\n",
      "        [ 0.1100],\n",
      "        [ 0.0103],\n",
      "        [ 0.0203],\n",
      "        [ 0.0329],\n",
      "        [-0.0075],\n",
      "        [ 0.0173],\n",
      "        [-0.0251],\n",
      "        [-0.0375],\n",
      "        [-0.0007],\n",
      "        [ 0.0511],\n",
      "        [ 0.0294],\n",
      "        [ 0.0281],\n",
      "        [ 0.0122],\n",
      "        [-0.0294],\n",
      "        [-0.0315],\n",
      "        [ 0.0347],\n",
      "        [ 0.0141],\n",
      "        [ 0.0186],\n",
      "        [-0.0021],\n",
      "        [ 0.0102],\n",
      "        [ 0.0191],\n",
      "        [ 0.0019],\n",
      "        [-0.0184],\n",
      "        [ 0.0294],\n",
      "        [ 0.0054]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1015, 0.1024, 0.1071, 0.1037, 0.1044, 0.1065, 0.1090, 0.1088, 0.1094,\n",
      "        0.1102, 0.1133, 0.1162, 0.1137, 0.1148, 0.1148, 0.1168, 0.1149, 0.1156,\n",
      "        0.1196, 0.1201, 0.1214, 0.1227, 0.1273, 0.1291, 0.1282, 0.1328, 0.1311,\n",
      "        0.1255, 0.1202, 0.1179, 0.1212, 0.1189], device='cuda:0')\n",
      "tensor([[-0.0375],\n",
      "        [ 0.0079],\n",
      "        [-0.0406],\n",
      "        [-0.0360],\n",
      "        [-0.0898],\n",
      "        [ 0.0642],\n",
      "        [ 0.0827],\n",
      "        [ 0.0118],\n",
      "        [ 0.0361],\n",
      "        [-0.0187],\n",
      "        [ 0.0135],\n",
      "        [-0.0038],\n",
      "        [ 0.0881],\n",
      "        [ 0.0038],\n",
      "        [ 0.1088],\n",
      "        [-0.0175],\n",
      "        [ 0.0529],\n",
      "        [ 0.0168],\n",
      "        [-0.0266],\n",
      "        [ 0.0121],\n",
      "        [-0.0242],\n",
      "        [-0.0481],\n",
      "        [ 0.0101],\n",
      "        [ 0.1404],\n",
      "        [ 0.0564],\n",
      "        [ 0.0025],\n",
      "        [ 0.0739],\n",
      "        [ 0.0043],\n",
      "        [ 0.0046],\n",
      "        [ 0.0152],\n",
      "        [ 0.0182],\n",
      "        [-0.0732]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1190, 0.1156, 0.1192, 0.1156, 0.1176, 0.1187, 0.1223, 0.1279, 0.1245,\n",
      "        0.1189, 0.1164, 0.1156, 0.1091, 0.1115, 0.1121, 0.1103, 0.1121, 0.1111,\n",
      "        0.1196, 0.1221, 0.1198, 0.1217, 0.1199, 0.1177, 0.1195, 0.1124, 0.1155,\n",
      "        0.1171, 0.1050, 0.1053, 0.1052, 0.1074], device='cuda:0')\n",
      "tensor([[ 0.0217],\n",
      "        [ 0.2085],\n",
      "        [ 0.1095],\n",
      "        [ 0.0148],\n",
      "        [ 0.0331],\n",
      "        [-0.0043],\n",
      "        [-0.0586],\n",
      "        [ 0.0115],\n",
      "        [-0.0211],\n",
      "        [ 0.0125],\n",
      "        [-0.0399],\n",
      "        [-0.0089],\n",
      "        [ 0.0154],\n",
      "        [-0.0282],\n",
      "        [ 0.0173],\n",
      "        [-0.0232],\n",
      "        [-0.0116],\n",
      "        [-0.0457],\n",
      "        [ 0.0038],\n",
      "        [-0.0275],\n",
      "        [ 0.0180],\n",
      "        [ 0.0207],\n",
      "        [ 0.0168],\n",
      "        [ 0.0402],\n",
      "        [ 0.0034],\n",
      "        [-0.0442],\n",
      "        [ 0.0213],\n",
      "        [-0.0175],\n",
      "        [ 0.0853],\n",
      "        [ 0.0368],\n",
      "        [ 0.0402],\n",
      "        [-0.0463]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1071, 0.1068, 0.1086, 0.1080, 0.1090, 0.1080, 0.1081, 0.1081, 0.1084,\n",
      "        0.1071, 0.1057, 0.1057, 0.1071, 0.1063, 0.1078, 0.1090, 0.1094, 0.1090,\n",
      "        0.1117, 0.1131, 0.1118, 0.1111, 0.1097, 0.1091, 0.1086, 0.1069, 0.1074,\n",
      "        0.1068, 0.1052, 0.1057, 0.1046, 0.1003], device='cuda:0')\n",
      "tensor([[-0.0377],\n",
      "        [ 0.0705],\n",
      "        [-0.0818],\n",
      "        [ 0.0059],\n",
      "        [ 0.1002],\n",
      "        [ 0.0461],\n",
      "        [-0.0094],\n",
      "        [ 0.0115],\n",
      "        [ 0.0203],\n",
      "        [ 0.0279],\n",
      "        [-0.0098],\n",
      "        [ 0.0158],\n",
      "        [ 0.0295],\n",
      "        [ 0.0160],\n",
      "        [ 0.0535],\n",
      "        [ 0.0242],\n",
      "        [ 0.0248],\n",
      "        [ 0.0272],\n",
      "        [ 0.0216],\n",
      "        [ 0.0067],\n",
      "        [-0.0312],\n",
      "        [ 0.0703],\n",
      "        [ 0.0166],\n",
      "        [ 0.0095],\n",
      "        [-0.0652],\n",
      "        [ 0.0077],\n",
      "        [-0.0156],\n",
      "        [ 0.0462],\n",
      "        [ 0.1293],\n",
      "        [ 0.0351],\n",
      "        [-0.0375],\n",
      "        [ 0.1216]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1009, 0.1019, 0.1025, 0.1024, 0.1026, 0.1007, 0.1018, 0.1003, 0.1013,\n",
      "        0.0997, 0.0972, 0.0984, 0.0985, 0.0972, 0.0975, 0.0976, 0.1006, 0.0988,\n",
      "        0.0970, 0.0963, 0.0969, 0.0976, 0.0975, 0.0941, 0.0933, 0.0880, 0.0938,\n",
      "        0.0919, 0.0920, 0.0914, 0.0900, 0.0873], device='cuda:0')\n",
      "tensor([[-0.0237],\n",
      "        [-0.0216],\n",
      "        [-0.0648],\n",
      "        [ 0.0751],\n",
      "        [ 0.1277],\n",
      "        [ 0.0456],\n",
      "        [ 0.0599],\n",
      "        [ 0.0230],\n",
      "        [ 0.0223],\n",
      "        [ 0.0693],\n",
      "        [ 0.0579],\n",
      "        [-0.0318],\n",
      "        [ 0.0138],\n",
      "        [-0.0311],\n",
      "        [ 0.0286],\n",
      "        [ 0.0178],\n",
      "        [ 0.0275],\n",
      "        [ 0.0078],\n",
      "        [-0.0211],\n",
      "        [-0.0227],\n",
      "        [-0.0040],\n",
      "        [-0.0200],\n",
      "        [-0.0183],\n",
      "        [-0.0289],\n",
      "        [-0.0794],\n",
      "        [ 0.0292],\n",
      "        [-0.0347],\n",
      "        [ 0.0027],\n",
      "        [-0.0004],\n",
      "        [ 0.0504],\n",
      "        [-0.0083],\n",
      "        [-0.0076]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0891, 0.1031, 0.1034, 0.1044, 0.1075, 0.1077, 0.1074, 0.1093, 0.1097,\n",
      "        0.1102, 0.1137, 0.1148, 0.1134, 0.1131, 0.1099, 0.1121, 0.1117, 0.1106,\n",
      "        0.1106, 0.1112, 0.1133, 0.1137, 0.1142, 0.1136, 0.1127, 0.1165, 0.1167,\n",
      "        0.1158, 0.1168, 0.1161, 0.1143, 0.1171], device='cuda:0')\n",
      "tensor([[-0.0292],\n",
      "        [-0.0238],\n",
      "        [-0.0625],\n",
      "        [ 0.0608],\n",
      "        [ 0.0304],\n",
      "        [ 0.0053],\n",
      "        [-0.0198],\n",
      "        [-0.0378],\n",
      "        [ 0.0248],\n",
      "        [ 0.0143],\n",
      "        [ 0.0163],\n",
      "        [ 0.0919],\n",
      "        [ 0.1146],\n",
      "        [ 0.0302],\n",
      "        [-0.0221],\n",
      "        [-0.0428],\n",
      "        [ 0.0267],\n",
      "        [-0.0424],\n",
      "        [ 0.0283],\n",
      "        [-0.0871],\n",
      "        [ 0.0067],\n",
      "        [ 0.0191],\n",
      "        [-0.0190],\n",
      "        [ 0.0477],\n",
      "        [-0.0265],\n",
      "        [-0.0452],\n",
      "        [ 0.0023],\n",
      "        [-0.0330],\n",
      "        [ 0.0107],\n",
      "        [ 0.0128],\n",
      "        [-0.0525],\n",
      "        [ 0.0519]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1196, 0.1202, 0.1201, 0.1192, 0.1249, 0.1257, 0.1267, 0.1277, 0.1266,\n",
      "        0.1260, 0.1274, 0.1273, 0.1301, 0.1276, 0.1280, 0.1277, 0.1269, 0.1294,\n",
      "        0.1283, 0.1302, 0.1317, 0.1323, 0.1298, 0.1316, 0.1341, 0.1342, 0.1336,\n",
      "        0.1314, 0.1291, 0.1335, 0.1344, 0.1307], device='cuda:0')\n",
      "tensor([[-0.0428],\n",
      "        [ 0.0215],\n",
      "        [ 0.0097],\n",
      "        [ 0.1040],\n",
      "        [ 0.0051],\n",
      "        [ 0.0399],\n",
      "        [ 0.0308],\n",
      "        [ 0.0405],\n",
      "        [-0.0332],\n",
      "        [ 0.0788],\n",
      "        [ 0.0581],\n",
      "        [-0.0439],\n",
      "        [ 0.0131],\n",
      "        [-0.0660],\n",
      "        [ 0.0200],\n",
      "        [ 0.0141],\n",
      "        [ 0.0089],\n",
      "        [-0.0807],\n",
      "        [ 0.0055],\n",
      "        [ 0.0269],\n",
      "        [-0.0030],\n",
      "        [-0.0376],\n",
      "        [ 0.0315],\n",
      "        [ 0.0097],\n",
      "        [-0.0274],\n",
      "        [ 0.0247],\n",
      "        [ 0.0946],\n",
      "        [-0.0503],\n",
      "        [ 0.0622],\n",
      "        [ 0.0514],\n",
      "        [ 0.0274],\n",
      "        [-0.0225]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1333, 0.1311, 0.1301, 0.1311, 0.1291, 0.1300, 0.1331, 0.1313, 0.1328,\n",
      "        0.1345, 0.1382, 0.1387, 0.1394, 0.1395, 0.1381, 0.1398, 0.1424, 0.1519,\n",
      "        0.1540, 0.1627, 0.1609, 0.1627, 0.1679, 0.1669, 0.1673, 0.1674, 0.1689,\n",
      "        0.1732, 0.1728, 0.1720, 0.1679, 0.1645], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0663],\n",
      "        [ 0.0867],\n",
      "        [ 0.0484],\n",
      "        [-0.0313],\n",
      "        [ 0.0497],\n",
      "        [-0.0131],\n",
      "        [-0.0355],\n",
      "        [ 0.0770],\n",
      "        [-0.0125],\n",
      "        [ 0.0301],\n",
      "        [ 0.0282],\n",
      "        [ 0.0153],\n",
      "        [-0.0132],\n",
      "        [ 0.0050],\n",
      "        [-0.0353],\n",
      "        [-0.0102],\n",
      "        [-0.0862],\n",
      "        [ 0.0066],\n",
      "        [-0.0690],\n",
      "        [ 0.0319],\n",
      "        [ 0.0745],\n",
      "        [-0.0177],\n",
      "        [ 0.0190],\n",
      "        [ 0.0599],\n",
      "        [ 0.0437],\n",
      "        [ 0.0124],\n",
      "        [-0.0248],\n",
      "        [ 0.0115],\n",
      "        [-0.0094],\n",
      "        [ 0.0111],\n",
      "        [ 0.0700],\n",
      "        [ 0.0298]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1697, 0.1670, 0.1651, 0.1598, 0.1612, 0.1562, 0.1601, 0.1680, 0.1674,\n",
      "        0.1633, 0.1629, 0.1646, 0.1646, 0.1639, 0.1621, 0.1596, 0.1617, 0.1686,\n",
      "        0.1711, 0.1736, 0.1695, 0.1719, 0.1732, 0.1742, 0.1779, 0.1751, 0.1762,\n",
      "        0.1759, 0.1779, 0.1791, 0.1673, 0.1599], device='cuda:0')\n",
      "tensor([[ 0.0028],\n",
      "        [-0.0160],\n",
      "        [-0.0288],\n",
      "        [ 0.0355],\n",
      "        [-0.0436],\n",
      "        [-0.0034],\n",
      "        [ 0.0070],\n",
      "        [ 0.0714],\n",
      "        [ 0.0080],\n",
      "        [ 0.0691],\n",
      "        [-0.0149],\n",
      "        [ 0.0009],\n",
      "        [-0.0047],\n",
      "        [ 0.0467],\n",
      "        [-0.0508],\n",
      "        [-0.0074],\n",
      "        [-0.0264],\n",
      "        [-0.0094],\n",
      "        [-0.0127],\n",
      "        [-0.0139],\n",
      "        [ 0.0339],\n",
      "        [-0.0652],\n",
      "        [-0.0464],\n",
      "        [-0.0253],\n",
      "        [ 0.0168],\n",
      "        [-0.0150],\n",
      "        [ 0.0183],\n",
      "        [ 0.0385],\n",
      "        [-0.0155],\n",
      "        [ 0.0039],\n",
      "        [-0.0406],\n",
      "        [ 0.0160]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1584, 0.1528, 0.1587, 0.1654, 0.1664, 0.1660, 0.1636, 0.1621, 0.1564,\n",
      "        0.1531, 0.1564, 0.1493, 0.1522, 0.1519, 0.1536, 0.1519, 0.1522, 0.1503,\n",
      "        0.1475, 0.1432, 0.1506, 0.1537, 0.1542, 0.1496, 0.1505, 0.1521, 0.1518,\n",
      "        0.1525, 0.1539, 0.1517, 0.1533, 0.1531], device='cuda:0')\n",
      "tensor([[-0.0702],\n",
      "        [ 0.0658],\n",
      "        [-0.0257],\n",
      "        [ 0.0121],\n",
      "        [ 0.0319],\n",
      "        [-0.0184],\n",
      "        [-0.0118],\n",
      "        [-0.0609],\n",
      "        [-0.0042],\n",
      "        [ 0.0800],\n",
      "        [-0.0490],\n",
      "        [-0.0154],\n",
      "        [-0.0272],\n",
      "        [ 0.0631],\n",
      "        [-0.0412],\n",
      "        [ 0.0423],\n",
      "        [-0.0253],\n",
      "        [ 0.0090],\n",
      "        [-0.0345],\n",
      "        [ 0.0128],\n",
      "        [ 0.0873],\n",
      "        [ 0.0200],\n",
      "        [ 0.0090],\n",
      "        [-0.0246],\n",
      "        [-0.0155],\n",
      "        [-0.0540],\n",
      "        [-0.0030],\n",
      "        [ 0.0263],\n",
      "        [ 0.0789],\n",
      "        [ 0.0029],\n",
      "        [-0.0116],\n",
      "        [ 0.0098]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1518, 0.1494, 0.1503, 0.1455, 0.1453, 0.1435, 0.1424, 0.1372, 0.1422,\n",
      "        0.1412, 0.1463, 0.1425, 0.1428, 0.1422, 0.1387, 0.1356, 0.1333, 0.1372,\n",
      "        0.1421, 0.1379, 0.1378, 0.1382, 0.1419, 0.1435, 0.1431, 0.1434, 0.1457,\n",
      "        0.1429, 0.1460, 0.1488, 0.1621, 0.1587], device='cuda:0')\n",
      "tensor([[ 0.0374],\n",
      "        [-0.0327],\n",
      "        [-0.0142],\n",
      "        [ 0.0936],\n",
      "        [ 0.0365],\n",
      "        [ 0.0116],\n",
      "        [ 0.0437],\n",
      "        [ 0.0398],\n",
      "        [-0.0070],\n",
      "        [ 0.0369],\n",
      "        [ 0.0880],\n",
      "        [-0.0073],\n",
      "        [ 0.0031],\n",
      "        [ 0.0979],\n",
      "        [-0.0099],\n",
      "        [ 0.0683],\n",
      "        [ 0.0309],\n",
      "        [ 0.0356],\n",
      "        [-0.0112],\n",
      "        [ 0.0234],\n",
      "        [ 0.0600],\n",
      "        [-0.0440],\n",
      "        [ 0.0436],\n",
      "        [-0.0425],\n",
      "        [-0.0227],\n",
      "        [-0.0200],\n",
      "        [-0.0161],\n",
      "        [ 0.0371],\n",
      "        [ 0.0138],\n",
      "        [ 0.0233],\n",
      "        [ 0.1073],\n",
      "        [ 0.1491]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1583, 0.1677, 0.1702, 0.1713, 0.1722, 0.1769, 0.1762, 0.1722, 0.1784,\n",
      "        0.1785, 0.1856, 0.1857, 0.1860, 0.1860, 0.1815, 0.1800, 0.1859, 0.1875,\n",
      "        0.1844, 0.1855, 0.1924, 0.1936, 0.1880, 0.1850, 0.1865, 0.1800, 0.1776,\n",
      "        0.1764, 0.1829, 0.1859, 0.1844, 0.1865], device='cuda:0')\n",
      "tensor([[-0.0721],\n",
      "        [ 0.0392],\n",
      "        [ 0.0977],\n",
      "        [-0.0368],\n",
      "        [ 0.0042],\n",
      "        [ 0.0086],\n",
      "        [-0.0111],\n",
      "        [ 0.0127],\n",
      "        [ 0.0110],\n",
      "        [ 0.0254],\n",
      "        [ 0.0138],\n",
      "        [ 0.0023],\n",
      "        [-0.0408],\n",
      "        [-0.0048],\n",
      "        [ 0.0036],\n",
      "        [-0.0268],\n",
      "        [ 0.0121],\n",
      "        [ 0.0375],\n",
      "        [ 0.0149],\n",
      "        [-0.0691],\n",
      "        [-0.0208],\n",
      "        [-0.0254],\n",
      "        [-0.0117],\n",
      "        [ 0.0228],\n",
      "        [-0.0296],\n",
      "        [-0.0224],\n",
      "        [-0.0104],\n",
      "        [ 0.0275],\n",
      "        [ 0.0127],\n",
      "        [ 0.0205],\n",
      "        [ 0.2285],\n",
      "        [ 0.0389]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1888, 0.1909, 0.1915, 0.1930, 0.1909, 0.1924, 0.1930, 0.1880, 0.1976,\n",
      "        0.1977, 0.1948, 0.1962, 0.1939, 0.1976, 0.2014, 0.2046, 0.2039, 0.2069,\n",
      "        0.2079, 0.2069, 0.2069, 0.2057, 0.2074, 0.2113, 0.2160, 0.2275, 0.2257,\n",
      "        0.2240, 0.2290, 0.2353, 0.2334, 0.2287], device='cuda:0')\n",
      "tensor([[ 0.0602],\n",
      "        [ 0.0922],\n",
      "        [-0.0795],\n",
      "        [ 0.0662],\n",
      "        [ 0.0202],\n",
      "        [ 0.0007],\n",
      "        [-0.0095],\n",
      "        [ 0.0085],\n",
      "        [ 0.0401],\n",
      "        [ 0.0082],\n",
      "        [-0.0341],\n",
      "        [ 0.0358],\n",
      "        [ 0.0077],\n",
      "        [ 0.0176],\n",
      "        [ 0.0354],\n",
      "        [-0.0408],\n",
      "        [ 0.0345],\n",
      "        [ 0.0380],\n",
      "        [ 0.1048],\n",
      "        [ 0.0497],\n",
      "        [ 0.0296],\n",
      "        [ 0.0436],\n",
      "        [-0.0262],\n",
      "        [-0.0366],\n",
      "        [-0.0374],\n",
      "        [ 0.0385],\n",
      "        [ 0.0674],\n",
      "        [-0.0656],\n",
      "        [ 0.0908],\n",
      "        [ 0.0057],\n",
      "        [-0.0288],\n",
      "        [-0.0520]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2237, 0.2311, 0.2305, 0.2281, 0.2317, 0.2322, 0.2355, 0.2343, 0.2293,\n",
      "        0.2240, 0.2250, 0.2272, 0.2255, 0.2167, 0.2263, 0.2356, 0.2358, 0.2305,\n",
      "        0.2319, 0.2287, 0.2247, 0.2260, 0.2195, 0.2201, 0.2265, 0.2253, 0.2257,\n",
      "        0.2255, 0.2237, 0.2169, 0.2098, 0.2122], device='cuda:0')\n",
      "tensor([[ 0.0194],\n",
      "        [ 0.0272],\n",
      "        [ 0.0278],\n",
      "        [ 0.0362],\n",
      "        [ 0.0241],\n",
      "        [ 0.0241],\n",
      "        [-0.0948],\n",
      "        [ 0.0273],\n",
      "        [ 0.0268],\n",
      "        [-0.0186],\n",
      "        [ 0.0165],\n",
      "        [ 0.0775],\n",
      "        [ 0.0144],\n",
      "        [ 0.0178],\n",
      "        [ 0.0119],\n",
      "        [ 0.0284],\n",
      "        [-0.0016],\n",
      "        [ 0.0693],\n",
      "        [ 0.0336],\n",
      "        [ 0.0508],\n",
      "        [ 0.0772],\n",
      "        [-0.0102],\n",
      "        [ 0.0197],\n",
      "        [ 0.0080],\n",
      "        [ 0.0046],\n",
      "        [-0.0460],\n",
      "        [-0.0478],\n",
      "        [-0.0110],\n",
      "        [ 0.0137],\n",
      "        [-0.0359],\n",
      "        [ 0.0288],\n",
      "        [-0.0032]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2116, 0.2080, 0.2160, 0.2160, 0.2139, 0.2151, 0.2260, 0.2246, 0.2206,\n",
      "        0.2207, 0.2231, 0.2287, 0.2311, 0.2252, 0.2277, 0.2271, 0.2283, 0.2330,\n",
      "        0.2293, 0.2278, 0.2286, 0.2275, 0.2247, 0.2209, 0.2166, 0.2061, 0.2110,\n",
      "        0.2291, 0.2290, 0.2178, 0.2122, 0.1933], device='cuda:0')\n",
      "tensor([[ 0.0460],\n",
      "        [ 0.0463],\n",
      "        [-0.0107],\n",
      "        [ 0.0311],\n",
      "        [-0.0274],\n",
      "        [-0.0709],\n",
      "        [ 0.0130],\n",
      "        [-0.0127],\n",
      "        [ 0.0170],\n",
      "        [ 0.0300],\n",
      "        [ 0.0118],\n",
      "        [ 0.0152],\n",
      "        [-0.0477],\n",
      "        [-0.0049],\n",
      "        [-0.0640],\n",
      "        [-0.0785],\n",
      "        [-0.1049],\n",
      "        [ 0.0864],\n",
      "        [ 0.0134],\n",
      "        [ 0.0008],\n",
      "        [ 0.0103],\n",
      "        [ 0.0291],\n",
      "        [-0.0003],\n",
      "        [-0.0113],\n",
      "        [ 0.0080],\n",
      "        [ 0.0206],\n",
      "        [-0.0420],\n",
      "        [-0.0806],\n",
      "        [ 0.0817],\n",
      "        [ 0.0600],\n",
      "        [ 0.0436],\n",
      "        [-0.0527]], device='cuda:0', grad_fn=<AddmmBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([0.2154, 0.2128, 0.2070, 0.2133, 0.2207, 0.2215, 0.2234, 0.2194, 0.2157,\n",
      "        0.2114, 0.2145, 0.2089, 0.2148, 0.2204, 0.2252, 0.2219, 0.2241, 0.2281,\n",
      "        0.2300, 0.2243, 0.2343, 0.2399, 0.2393, 0.2466, 0.2423, 0.2414, 0.2387,\n",
      "        0.2458, 0.2473, 0.2414, 0.2322, 0.2207], device='cuda:0')\n",
      "tensor([[ 0.0504],\n",
      "        [-0.0474],\n",
      "        [-0.0347],\n",
      "        [-0.0012],\n",
      "        [-0.0547],\n",
      "        [-0.0266],\n",
      "        [ 0.0230],\n",
      "        [ 0.0121],\n",
      "        [-0.0415],\n",
      "        [-0.0026],\n",
      "        [ 0.0892],\n",
      "        [ 0.0241],\n",
      "        [-0.0166],\n",
      "        [-0.0556],\n",
      "        [-0.0706],\n",
      "        [ 0.0090],\n",
      "        [-0.0258],\n",
      "        [ 0.0099],\n",
      "        [ 0.0275],\n",
      "        [ 0.0897],\n",
      "        [ 0.0096],\n",
      "        [ 0.0334],\n",
      "        [-0.0168],\n",
      "        [-0.0211],\n",
      "        [-0.0182],\n",
      "        [-0.0404],\n",
      "        [ 0.0270],\n",
      "        [ 0.0002],\n",
      "        [ 0.0264],\n",
      "        [ 0.0341],\n",
      "        [-0.0027],\n",
      "        [ 0.0092]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2178, 0.2190, 0.2257, 0.2216, 0.2169, 0.2219, 0.2229, 0.2136, 0.2148,\n",
      "        0.2209, 0.2234, 0.2243, 0.2278, 0.2302, 0.2321, 0.2293, 0.2269, 0.2268,\n",
      "        0.2170, 0.2172, 0.2219, 0.2231, 0.2250, 0.2287, 0.2367, 0.2172, 0.2154,\n",
      "        0.2150, 0.2125, 0.2086, 0.2098, 0.2126], device='cuda:0')\n",
      "tensor([[ 0.0216],\n",
      "        [-0.0361],\n",
      "        [ 0.1016],\n",
      "        [ 0.0246],\n",
      "        [-0.0007],\n",
      "        [ 0.0386],\n",
      "        [ 0.0328],\n",
      "        [ 0.0365],\n",
      "        [ 0.0288],\n",
      "        [ 0.0178],\n",
      "        [ 0.0088],\n",
      "        [ 0.0170],\n",
      "        [ 0.0975],\n",
      "        [ 0.0409],\n",
      "        [ 0.0449],\n",
      "        [ 0.0461],\n",
      "        [ 0.0401],\n",
      "        [ 0.0653],\n",
      "        [ 0.0623],\n",
      "        [ 0.0703],\n",
      "        [-0.0249],\n",
      "        [ 0.0372],\n",
      "        [ 0.0481],\n",
      "        [ 0.0728],\n",
      "        [ 0.0350],\n",
      "        [ 0.0600],\n",
      "        [ 0.0072],\n",
      "        [-0.0915],\n",
      "        [ 0.1005],\n",
      "        [-0.0903],\n",
      "        [-0.0500],\n",
      "        [-0.0402]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2139, 0.2182, 0.2154, 0.2129, 0.2159, 0.2122, 0.2122, 0.2190, 0.2232,\n",
      "        0.2237, 0.2225, 0.2216, 0.2234, 0.2234, 0.2231, 0.2237, 0.2228, 0.2293,\n",
      "        0.2299, 0.2274, 0.2215, 0.2219, 0.2145, 0.2144, 0.2125, 0.2077, 0.2110,\n",
      "        0.2148, 0.2175, 0.2160, 0.2198, 0.2190], device='cuda:0')\n",
      "tensor([[ 0.0733],\n",
      "        [ 0.0547],\n",
      "        [-0.0322],\n",
      "        [-0.0293],\n",
      "        [-0.0181],\n",
      "        [ 0.0058],\n",
      "        [-0.0072],\n",
      "        [ 0.0071],\n",
      "        [ 0.0475],\n",
      "        [-0.0034],\n",
      "        [ 0.0850],\n",
      "        [-0.0454],\n",
      "        [-0.0122],\n",
      "        [-0.0327],\n",
      "        [ 0.0180],\n",
      "        [-0.0256],\n",
      "        [-0.0171],\n",
      "        [-0.0267],\n",
      "        [-0.0072],\n",
      "        [-0.0350],\n",
      "        [-0.0156],\n",
      "        [-0.0165],\n",
      "        [ 0.0219],\n",
      "        [ 0.0367],\n",
      "        [ 0.0221],\n",
      "        [-0.0106],\n",
      "        [-0.0128],\n",
      "        [ 0.0719],\n",
      "        [-0.0333],\n",
      "        [ 0.0096],\n",
      "        [ 0.0567],\n",
      "        [ 0.0755]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2206, 0.2237, 0.2218, 0.2201, 0.2252, 0.2311, 0.2288, 0.2272, 0.2246,\n",
      "        0.2260, 0.2274, 0.2306, 0.2280, 0.2311, 0.2280, 0.2275, 0.2319, 0.2268,\n",
      "        0.2317, 0.2399, 0.2353, 0.2352, 0.2433, 0.2594, 0.2517, 0.2582, 0.2579,\n",
      "        0.2531, 0.2539, 0.2536, 0.2544, 0.2567], device='cuda:0')\n",
      "tensor([[ 0.0285],\n",
      "        [ 0.0318],\n",
      "        [ 0.0099],\n",
      "        [-0.0040],\n",
      "        [-0.0408],\n",
      "        [-0.0173],\n",
      "        [-0.0513],\n",
      "        [ 0.0221],\n",
      "        [ 0.0163],\n",
      "        [ 0.0221],\n",
      "        [ 0.0302],\n",
      "        [ 0.0378],\n",
      "        [ 0.0781],\n",
      "        [ 0.0638],\n",
      "        [ 0.0541],\n",
      "        [ 0.0555],\n",
      "        [ 0.0529],\n",
      "        [ 0.0084],\n",
      "        [-0.0338],\n",
      "        [ 0.0314],\n",
      "        [ 0.0322],\n",
      "        [-0.0047],\n",
      "        [ 0.0221],\n",
      "        [-0.0424],\n",
      "        [ 0.1020],\n",
      "        [-0.0379],\n",
      "        [ 0.1036],\n",
      "        [-0.0726],\n",
      "        [-0.0209],\n",
      "        [ 0.0256],\n",
      "        [ 0.0166],\n",
      "        [ 0.0479]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2562, 0.2590, 0.2576, 0.2573, 0.2641, 0.2625, 0.2632, 0.2686, 0.2778,\n",
      "        0.2758, 0.2750, 0.2759, 0.2724, 0.2727, 0.2687, 0.2665, 0.2647, 0.2643,\n",
      "        0.2582, 0.2575, 0.2536, 0.2497, 0.2548, 0.2615, 0.2613, 0.2624, 0.2576,\n",
      "        0.2547, 0.2553, 0.2458, 0.2405, 0.2429], device='cuda:0')\n",
      "tensor([[ 0.0098],\n",
      "        [ 0.0419],\n",
      "        [ 0.0507],\n",
      "        [ 0.1004],\n",
      "        [ 0.0512],\n",
      "        [-0.0859],\n",
      "        [ 0.1200],\n",
      "        [ 0.0339],\n",
      "        [ 0.0183],\n",
      "        [ 0.0256],\n",
      "        [-0.0167],\n",
      "        [-0.0361],\n",
      "        [ 0.0522],\n",
      "        [ 0.0005],\n",
      "        [-0.0075],\n",
      "        [-0.0187],\n",
      "        [-0.0042],\n",
      "        [ 0.0120],\n",
      "        [ 0.0018],\n",
      "        [-0.0321],\n",
      "        [ 0.0193],\n",
      "        [-0.0190],\n",
      "        [ 0.0098],\n",
      "        [-0.0244],\n",
      "        [ 0.0086],\n",
      "        [ 0.0074],\n",
      "        [ 0.0090],\n",
      "        [ 0.3180],\n",
      "        [-0.0288],\n",
      "        [ 0.1001],\n",
      "        [ 0.0153],\n",
      "        [ 0.0375]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2377, 0.2314, 0.2361, 0.2446, 0.2452, 0.2463, 0.2476, 0.2502, 0.2519,\n",
      "        0.2564, 0.2528, 0.2492, 0.2497, 0.2523, 0.2572, 0.2606, 0.2626, 0.2632,\n",
      "        0.2570, 0.2603, 0.2646, 0.2688, 0.2833, 0.2817, 0.2733, 0.2742, 0.2771,\n",
      "        0.2770, 0.2827, 0.2957, 0.2936, 0.2942], device='cuda:0')\n",
      "tensor([[-1.3515e-05],\n",
      "        [-8.5022e-03],\n",
      "        [-2.3194e-02],\n",
      "        [ 9.8396e-02],\n",
      "        [ 2.5372e-02],\n",
      "        [-2.2266e-02],\n",
      "        [ 1.4998e-03],\n",
      "        [-2.8693e-02],\n",
      "        [-1.4263e-02],\n",
      "        [-4.4100e-02],\n",
      "        [ 1.9414e-02],\n",
      "        [-2.4444e-03],\n",
      "        [ 2.4131e-02],\n",
      "        [-3.0364e-02],\n",
      "        [-1.0068e-02],\n",
      "        [-3.4128e-02],\n",
      "        [-4.3159e-02],\n",
      "        [-4.8127e-02],\n",
      "        [-1.8805e-02],\n",
      "        [ 5.1155e-03],\n",
      "        [-4.3386e-02],\n",
      "        [-4.1055e-02],\n",
      "        [ 2.6656e-02],\n",
      "        [ 2.1966e-03],\n",
      "        [-1.7530e-02],\n",
      "        [ 3.4199e-02],\n",
      "        [ 6.8945e-02],\n",
      "        [ 3.9653e-02],\n",
      "        [ 7.7095e-02],\n",
      "        [ 1.9367e-02],\n",
      "        [-1.0929e-02],\n",
      "        [-3.3678e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2802, 0.2848, 0.2871, 0.2857, 0.2874, 0.2842, 0.2830, 0.2787, 0.2768,\n",
      "        0.2762, 0.2851, 0.2876, 0.2832, 0.2827, 0.2843, 0.2840, 0.2898, 0.2765,\n",
      "        0.2702, 0.2467, 0.2593, 0.2653, 0.2683, 0.2626, 0.2781, 0.2724, 0.2700,\n",
      "        0.2796, 0.2857, 0.2877, 0.2889, 0.2801], device='cuda:0')\n",
      "tensor([[-0.0025],\n",
      "        [ 0.0136],\n",
      "        [ 0.0187],\n",
      "        [ 0.0268],\n",
      "        [ 0.0143],\n",
      "        [-0.0277],\n",
      "        [ 0.0045],\n",
      "        [-0.0215],\n",
      "        [-0.0577],\n",
      "        [-0.0312],\n",
      "        [-0.0020],\n",
      "        [-0.0006],\n",
      "        [-0.0201],\n",
      "        [-0.0103],\n",
      "        [ 0.0154],\n",
      "        [ 0.0187],\n",
      "        [ 0.0742],\n",
      "        [-0.0131],\n",
      "        [-0.0089],\n",
      "        [-0.0268],\n",
      "        [ 0.0468],\n",
      "        [ 0.0279],\n",
      "        [ 0.0281],\n",
      "        [ 0.0091],\n",
      "        [ 0.0757],\n",
      "        [ 0.0710],\n",
      "        [ 0.0252],\n",
      "        [ 0.0867],\n",
      "        [ 0.1562],\n",
      "        [-0.0241],\n",
      "        [-0.0510],\n",
      "        [ 0.0345]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2752, 0.2835, 0.2824, 0.2926, 0.2891, 0.2960, 0.2963, 0.2911, 0.2842,\n",
      "        0.2768, 0.2755, 0.2647, 0.2624, 0.2659, 0.2724, 0.2814, 0.2898, 0.2835,\n",
      "        0.2889, 0.3031, 0.3018, 0.3099, 0.3063, 0.3177, 0.3156, 0.3150, 0.3186,\n",
      "        0.3217, 0.3260, 0.3320, 0.3314, 0.3311], device='cuda:0')\n",
      "tensor([[ 0.0543],\n",
      "        [ 0.0392],\n",
      "        [ 0.0270],\n",
      "        [ 0.0629],\n",
      "        [ 0.0638],\n",
      "        [ 0.0072],\n",
      "        [-0.0162],\n",
      "        [ 0.0178],\n",
      "        [ 0.0137],\n",
      "        [-0.0276],\n",
      "        [-0.0358],\n",
      "        [ 0.0204],\n",
      "        [-0.0454],\n",
      "        [ 0.0047],\n",
      "        [ 0.0638],\n",
      "        [-0.0351],\n",
      "        [-0.0303],\n",
      "        [ 0.0319],\n",
      "        [ 0.0303],\n",
      "        [-0.0052],\n",
      "        [-0.0283],\n",
      "        [-0.0180],\n",
      "        [-0.0054],\n",
      "        [ 0.0528],\n",
      "        [ 0.0773],\n",
      "        [ 0.1322],\n",
      "        [-0.0901],\n",
      "        [-0.0505],\n",
      "        [-0.0528],\n",
      "        [-0.1077],\n",
      "        [ 0.0511],\n",
      "        [-0.0743]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3288, 0.3300, 0.3326, 0.3348, 0.3382, 0.3491, 0.3518, 0.3536, 0.3525,\n",
      "        0.3571, 0.3539, 0.3562, 0.3552, 0.3589, 0.3741, 0.3710, 0.3745, 0.3822,\n",
      "        0.3707, 0.3819, 0.3762, 0.3669, 0.3686, 0.3756, 0.3779, 0.3809, 0.3704,\n",
      "        0.3775, 0.3654, 0.3704, 0.3689, 0.3729], device='cuda:0')\n",
      "tensor([[-0.0114],\n",
      "        [ 0.0032],\n",
      "        [-0.0146],\n",
      "        [-0.0085],\n",
      "        [-0.0322],\n",
      "        [-0.0136],\n",
      "        [ 0.0349],\n",
      "        [ 0.0370],\n",
      "        [ 0.0792],\n",
      "        [ 0.0514],\n",
      "        [ 0.0305],\n",
      "        [ 0.0198],\n",
      "        [-0.0159],\n",
      "        [-0.0477],\n",
      "        [ 0.0111],\n",
      "        [ 0.0179],\n",
      "        [-0.0102],\n",
      "        [-0.0478],\n",
      "        [ 0.0211],\n",
      "        [ 0.0159],\n",
      "        [-0.0322],\n",
      "        [ 0.0404],\n",
      "        [-0.0006],\n",
      "        [ 0.0310],\n",
      "        [-0.0023],\n",
      "        [ 0.0103],\n",
      "        [ 0.0241],\n",
      "        [ 0.0756],\n",
      "        [-0.0276],\n",
      "        [-0.0098],\n",
      "        [ 0.0165],\n",
      "        [ 0.1228]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3859, 0.3973, 0.4111, 0.4176, 0.4246, 0.4277, 0.4226, 0.4218, 0.4162,\n",
      "        0.4129, 0.4285, 0.4265, 0.4299, 0.4237, 0.4277, 0.4178, 0.4188, 0.4073,\n",
      "        0.4175, 0.4347, 0.4401, 0.4460, 0.4052, 0.4105, 0.4191, 0.4018, 0.4027,\n",
      "        0.4135, 0.4052, 0.3981, 0.3946, 0.3812], device='cuda:0')\n",
      "tensor([[-0.0586],\n",
      "        [-0.0564],\n",
      "        [-0.0360],\n",
      "        [ 0.0178],\n",
      "        [-0.0329],\n",
      "        [ 0.0695],\n",
      "        [ 0.1220],\n",
      "        [-0.0033],\n",
      "        [-0.0235],\n",
      "        [-0.0184],\n",
      "        [ 0.0448],\n",
      "        [-0.0371],\n",
      "        [ 0.0030],\n",
      "        [-0.0060],\n",
      "        [-0.0131],\n",
      "        [ 0.0012],\n",
      "        [ 0.0080],\n",
      "        [-0.0254],\n",
      "        [ 0.0338],\n",
      "        [ 0.0510],\n",
      "        [ 0.0772],\n",
      "        [-0.0109],\n",
      "        [-0.0266],\n",
      "        [ 0.0207],\n",
      "        [ 0.0259],\n",
      "        [ 0.0564],\n",
      "        [ 0.0638],\n",
      "        [ 0.0062],\n",
      "        [ 0.0822],\n",
      "        [-0.0202],\n",
      "        [ 0.0177],\n",
      "        [-0.0257]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3728, 0.3751, 0.3651, 0.3795, 0.4023, 0.3887, 0.3881, 0.3834, 0.3922,\n",
      "        0.3860, 0.4009, 0.3986, 0.3911, 0.3908, 0.3816, 0.3784, 0.3769, 0.3745,\n",
      "        0.3846, 0.4020, 0.4032, 0.4110, 0.4094, 0.4126, 0.4011, 0.4105, 0.4082,\n",
      "        0.4012, 0.4002, 0.3788, 0.3751, 0.3713], device='cuda:0')\n",
      "tensor([[ 0.0115],\n",
      "        [ 0.0430],\n",
      "        [-0.0442],\n",
      "        [ 0.0601],\n",
      "        [ 0.0441],\n",
      "        [ 0.0245],\n",
      "        [ 0.0004],\n",
      "        [ 0.0217],\n",
      "        [-0.0447],\n",
      "        [-0.0701],\n",
      "        [ 0.0284],\n",
      "        [-0.0254],\n",
      "        [-0.0445],\n",
      "        [ 0.0048],\n",
      "        [ 0.0289],\n",
      "        [ 0.0451],\n",
      "        [ 0.0037],\n",
      "        [-0.0011],\n",
      "        [ 0.0217],\n",
      "        [-0.0117],\n",
      "        [-0.0752],\n",
      "        [ 0.0086],\n",
      "        [ 0.0901],\n",
      "        [ 0.0493],\n",
      "        [-0.0230],\n",
      "        [-0.0966],\n",
      "        [ 0.0627],\n",
      "        [ 0.1709],\n",
      "        [ 0.0240],\n",
      "        [ 0.1068],\n",
      "        [ 0.0288],\n",
      "        [ 0.0632]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3810, 0.3853, 0.3878, 0.4008, 0.4024, 0.3993, 0.3987, 0.4151, 0.4129,\n",
      "        0.4212, 0.4224, 0.4207, 0.4139, 0.4058, 0.4043, 0.4005, 0.3831, 0.3745,\n",
      "        0.3816, 0.3866, 0.4401, 0.4525, 0.4764, 0.4814, 0.4649, 0.4644, 0.4747,\n",
      "        0.4820, 0.4814, 0.4817, 0.4749, 0.4938], device='cuda:0')\n",
      "tensor([[ 0.0385],\n",
      "        [-0.0178],\n",
      "        [ 0.0203],\n",
      "        [-0.0183],\n",
      "        [-0.0195],\n",
      "        [-0.0113],\n",
      "        [ 0.0122],\n",
      "        [ 0.0530],\n",
      "        [ 0.1561],\n",
      "        [ 0.1107],\n",
      "        [ 0.0695],\n",
      "        [-0.0107],\n",
      "        [-0.0110],\n",
      "        [ 0.0370],\n",
      "        [ 0.0104],\n",
      "        [-0.0545],\n",
      "        [-0.0663],\n",
      "        [ 0.0536],\n",
      "        [ 0.0109],\n",
      "        [ 0.0523],\n",
      "        [ 0.0241],\n",
      "        [-0.0810],\n",
      "        [-0.0102],\n",
      "        [-0.0515],\n",
      "        [-0.0221],\n",
      "        [-0.0129],\n",
      "        [ 0.0010],\n",
      "        [ 0.0624],\n",
      "        [ 0.0420],\n",
      "        [ 0.0452],\n",
      "        [-0.0453],\n",
      "        [-0.0256]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4970, 0.5026, 0.5133, 0.5617, 0.5457, 0.5416, 0.5440, 0.5378, 0.5307,\n",
      "        0.5248, 0.5091, 0.5031, 0.5387, 0.5286, 0.5286, 0.5097, 0.5180, 0.5142,\n",
      "        0.5286, 0.5499, 0.5316, 0.5333, 0.5251, 0.5207, 0.5263, 0.5280, 0.5508,\n",
      "        0.5484, 0.5511, 0.5700, 0.5635, 0.5614], device='cuda:0')\n",
      "tensor([[-0.0045],\n",
      "        [ 0.1047],\n",
      "        [ 0.0292],\n",
      "        [ 0.0701],\n",
      "        [-0.0014],\n",
      "        [ 0.0320],\n",
      "        [-0.0524],\n",
      "        [-0.0048],\n",
      "        [-0.0083],\n",
      "        [ 0.0453],\n",
      "        [ 0.1415],\n",
      "        [ 0.0337],\n",
      "        [ 0.0217],\n",
      "        [ 0.0751],\n",
      "        [ 0.0429],\n",
      "        [ 0.0888],\n",
      "        [ 0.0437],\n",
      "        [-0.0115],\n",
      "        [ 0.0554],\n",
      "        [ 0.0636],\n",
      "        [-0.0059],\n",
      "        [-0.0342],\n",
      "        [ 0.0407],\n",
      "        [ 0.0416],\n",
      "        [ 0.1243],\n",
      "        [ 0.1031],\n",
      "        [ 0.0005],\n",
      "        [ 0.0295],\n",
      "        [ 0.0484],\n",
      "        [-0.0574],\n",
      "        [-0.0436],\n",
      "        [ 0.0470]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5596, 0.5623, 0.5596, 0.5694, 0.5912, 0.5995, 0.6054, 0.5995, 0.6080,\n",
      "        0.6136, 0.6296, 0.6316, 0.6319, 0.6290, 0.6246, 0.6243, 0.6166, 0.5865,\n",
      "        0.5900, 0.5658, 0.5702, 0.5617, 0.5770, 0.5871, 0.5729, 0.5744, 0.5581,\n",
      "        0.5446, 0.5404, 0.5626, 0.5640, 0.5578], device='cuda:0')\n",
      "tensor([[ 0.1156],\n",
      "        [-0.0461],\n",
      "        [ 0.0425],\n",
      "        [ 0.0402],\n",
      "        [-0.0232],\n",
      "        [ 0.0292],\n",
      "        [-0.0536],\n",
      "        [ 0.0078],\n",
      "        [-0.0190],\n",
      "        [-0.0265],\n",
      "        [ 0.1094],\n",
      "        [-0.0060],\n",
      "        [ 0.0160],\n",
      "        [-0.0151],\n",
      "        [ 0.0071],\n",
      "        [ 0.0591],\n",
      "        [ 0.0185],\n",
      "        [-0.0179],\n",
      "        [-0.0060],\n",
      "        [-0.0337],\n",
      "        [ 0.0315],\n",
      "        [-0.0213],\n",
      "        [ 0.0381],\n",
      "        [ 0.0271],\n",
      "        [ 0.1449],\n",
      "        [-0.0103],\n",
      "        [ 0.0984],\n",
      "        [ 0.0950],\n",
      "        [ 0.0075],\n",
      "        [ 0.0357],\n",
      "        [-0.0186],\n",
      "        [-0.0688]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5443, 0.5632, 0.5528, 0.5635, 0.5823, 0.5877, 0.5658, 0.5614, 0.5558,\n",
      "        0.5685, 0.5570, 0.5587, 0.5614, 0.5664, 0.5626, 0.5691, 0.5818, 0.5753,\n",
      "        0.5894, 0.6042, 0.5983, 0.6172, 0.6184, 0.6060, 0.6104, 0.6039, 0.5947,\n",
      "        0.5729, 0.5953, 0.5812, 0.5720, 0.5570], device='cuda:0')\n",
      "tensor([[ 0.0060],\n",
      "        [ 0.0592],\n",
      "        [-0.1033],\n",
      "        [-0.0009],\n",
      "        [ 0.0418],\n",
      "        [-0.0004],\n",
      "        [-0.0148],\n",
      "        [ 0.0179],\n",
      "        [-0.0052],\n",
      "        [-0.0306],\n",
      "        [ 0.0147],\n",
      "        [ 0.0303],\n",
      "        [ 0.0515],\n",
      "        [ 0.0138],\n",
      "        [ 0.0305],\n",
      "        [ 0.0742],\n",
      "        [-0.0374],\n",
      "        [-0.0073],\n",
      "        [-0.0193],\n",
      "        [-0.0081],\n",
      "        [-0.0252],\n",
      "        [ 0.0381],\n",
      "        [ 0.0010],\n",
      "        [ 0.0079],\n",
      "        [-0.1262],\n",
      "        [ 0.0605],\n",
      "        [ 0.0778],\n",
      "        [-0.0254],\n",
      "        [ 0.0308],\n",
      "        [ 0.0396],\n",
      "        [-0.0258],\n",
      "        [ 0.0412]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5711, 0.5617, 0.5640, 0.5478, 0.5522, 0.5369, 0.5469, 0.5570, 0.5437,\n",
      "        0.5304, 0.5168, 0.5204, 0.5003, 0.4770, 0.4861, 0.4902, 0.4861, 0.4867,\n",
      "        0.4861, 0.4105, 0.4244, 0.4241, 0.4318, 0.4200, 0.4291, 0.4448, 0.4377,\n",
      "        0.4285, 0.4265, 0.4132, 0.4070, 0.4244], device='cuda:0')\n",
      "tensor([[-0.0429],\n",
      "        [-0.0665],\n",
      "        [ 0.0663],\n",
      "        [ 0.0555],\n",
      "        [-0.0553],\n",
      "        [-0.0431],\n",
      "        [-0.0228],\n",
      "        [-0.0363],\n",
      "        [ 0.0705],\n",
      "        [-0.0304],\n",
      "        [ 0.0346],\n",
      "        [ 0.0392],\n",
      "        [-0.0195],\n",
      "        [ 0.0615],\n",
      "        [ 0.1008],\n",
      "        [ 0.0723],\n",
      "        [ 0.1410],\n",
      "        [ 0.0330],\n",
      "        [-0.0279],\n",
      "        [ 0.0846],\n",
      "        [-0.0265],\n",
      "        [-0.0492],\n",
      "        [ 0.0461],\n",
      "        [ 0.0597],\n",
      "        [ 0.0359],\n",
      "        [ 0.0867],\n",
      "        [ 0.0237],\n",
      "        [ 0.0511],\n",
      "        [-0.0263],\n",
      "        [ 0.0738],\n",
      "        [ 0.1376],\n",
      "        [-0.0018]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4229, 0.4389, 0.4294, 0.4336, 0.4250, 0.4277, 0.4235, 0.4436, 0.4716,\n",
      "        0.4902, 0.4817, 0.4743, 0.4767, 0.4728, 0.4675, 0.4692, 0.4779, 0.5091,\n",
      "        0.5286, 0.5316, 0.5394, 0.5162, 0.4956, 0.4989, 0.4967, 0.4861, 0.4964,\n",
      "        0.5003, 0.4965, 0.5009, 0.4908, 0.4938], device='cuda:0')\n",
      "tensor([[ 0.0197],\n",
      "        [-0.0018],\n",
      "        [-0.0008],\n",
      "        [-0.0012],\n",
      "        [ 0.0248],\n",
      "        [ 0.0207],\n",
      "        [ 0.0009],\n",
      "        [-0.0252],\n",
      "        [-0.0451],\n",
      "        [ 0.0437],\n",
      "        [ 0.0491],\n",
      "        [ 0.0174],\n",
      "        [ 0.0286],\n",
      "        [ 0.0043],\n",
      "        [ 0.0661],\n",
      "        [ 0.0647],\n",
      "        [ 0.0397],\n",
      "        [-0.0204],\n",
      "        [ 0.0301],\n",
      "        [ 0.0970],\n",
      "        [ 0.0375],\n",
      "        [ 0.0696],\n",
      "        [ 0.0153],\n",
      "        [ 0.0044],\n",
      "        [-0.0457],\n",
      "        [-0.0219],\n",
      "        [ 0.0476],\n",
      "        [ 0.0471],\n",
      "        [ 0.0055],\n",
      "        [ 0.0041],\n",
      "        [ 0.0007],\n",
      "        [-0.0415]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4991, 0.4994, 0.4956, 0.4944, 0.4902, 0.5286, 0.5100, 0.5286, 0.5192,\n",
      "        0.5168, 0.5381, 0.5428, 0.5452, 0.5392, 0.5457, 0.5274, 0.5452, 0.5428,\n",
      "        0.5546, 0.5546, 0.5434, 0.5322, 0.5168, 0.5077, 0.5109, 0.5003, 0.5168,\n",
      "        0.5339, 0.5269, 0.5198, 0.5419, 0.5351], device='cuda:0')\n",
      "tensor([[ 0.0248],\n",
      "        [ 0.0209],\n",
      "        [ 0.0077],\n",
      "        [ 0.0051],\n",
      "        [-0.0158],\n",
      "        [-0.0156],\n",
      "        [-0.0158],\n",
      "        [ 0.0169],\n",
      "        [ 0.0374],\n",
      "        [-0.0330],\n",
      "        [-0.0753],\n",
      "        [ 0.0028],\n",
      "        [ 0.0535],\n",
      "        [-0.0043],\n",
      "        [-0.0157],\n",
      "        [ 0.0646],\n",
      "        [-0.0207],\n",
      "        [ 0.0549],\n",
      "        [-0.0679],\n",
      "        [ 0.0026],\n",
      "        [ 0.0289],\n",
      "        [ 0.0262],\n",
      "        [-0.0126],\n",
      "        [ 0.0665],\n",
      "        [ 0.0827],\n",
      "        [-0.0150],\n",
      "        [ 0.1321],\n",
      "        [ 0.0788],\n",
      "        [-0.0155],\n",
      "        [ 0.0815],\n",
      "        [ 0.1392],\n",
      "        [-0.1014]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5434, 0.5257, 0.5289, 0.5339, 0.5274, 0.5322, 0.5121, 0.5050, 0.4944,\n",
      "        0.5026, 0.4908, 0.4743, 0.4660, 0.4542, 0.4678, 0.4908, 0.4675, 0.4672,\n",
      "        0.4826, 0.4908, 0.4778, 0.4894, 0.4938, 0.4861, 0.4956, 0.5003, 0.5133,\n",
      "        0.5168, 0.5204, 0.5251, 0.5505, 0.5800], device='cuda:0')\n",
      "tensor([[ 0.0092],\n",
      "        [ 0.0245],\n",
      "        [ 0.0283],\n",
      "        [ 0.0784],\n",
      "        [ 0.1058],\n",
      "        [ 0.0333],\n",
      "        [ 0.0278],\n",
      "        [ 0.0163],\n",
      "        [-0.0209],\n",
      "        [ 0.0219],\n",
      "        [ 0.0749],\n",
      "        [-0.0173],\n",
      "        [-0.0154],\n",
      "        [ 0.0304],\n",
      "        [-0.0307],\n",
      "        [ 0.0326],\n",
      "        [-0.0002],\n",
      "        [ 0.0095],\n",
      "        [-0.0339],\n",
      "        [ 0.0260],\n",
      "        [ 0.0211],\n",
      "        [-0.0462],\n",
      "        [-0.0591],\n",
      "        [ 0.0121],\n",
      "        [-0.0355],\n",
      "        [ 0.0431],\n",
      "        [ 0.0015],\n",
      "        [ 0.0019],\n",
      "        [ 0.0425],\n",
      "        [-0.0317],\n",
      "        [ 0.0213],\n",
      "        [-0.0324]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5593, 0.5428, 0.5605, 0.5398, 0.5570, 0.5531, 0.5711, 0.5605, 0.5623,\n",
      "        0.5576, 0.5446, 0.5180, 0.5032, 0.4767, 0.5091, 0.5074, 0.4767, 0.4719,\n",
      "        0.4838, 0.5121, 0.5026, 0.5032, 0.5074, 0.5097, 0.5068, 0.4914, 0.4891,\n",
      "        0.4902, 0.4991, 0.4956, 0.4672, 0.4740], device='cuda:0')\n",
      "tensor([[-0.0350],\n",
      "        [ 0.0309],\n",
      "        [-0.0315],\n",
      "        [ 0.0403],\n",
      "        [ 0.0328],\n",
      "        [ 0.0356],\n",
      "        [ 0.1001],\n",
      "        [-0.0327],\n",
      "        [ 0.0230],\n",
      "        [-0.0121],\n",
      "        [-0.0475],\n",
      "        [ 0.0694],\n",
      "        [-0.0268],\n",
      "        [ 0.0644],\n",
      "        [-0.0190],\n",
      "        [-0.0259],\n",
      "        [ 0.0088],\n",
      "        [-0.0096],\n",
      "        [ 0.0115],\n",
      "        [-0.0100],\n",
      "        [ 0.0124],\n",
      "        [ 0.0100],\n",
      "        [ 0.0942],\n",
      "        [ 0.1467],\n",
      "        [ 0.0127],\n",
      "        [ 0.0600],\n",
      "        [ 0.0472],\n",
      "        [ 0.0110],\n",
      "        [ 0.0034],\n",
      "        [ 0.0565],\n",
      "        [-0.0242],\n",
      "        [ 0.0386]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4740, 0.4728, 0.4956, 0.4902, 0.4817, 0.4835, 0.4967, 0.4879, 0.4985,\n",
      "        0.4838, 0.4858, 0.5047, 0.4876, 0.4814, 0.4947, 0.5136, 0.5115, 0.5522,\n",
      "        0.5463, 0.5460, 0.5421, 0.5443, 0.5286, 0.5325, 0.5156, 0.5493, 0.5304,\n",
      "        0.5215, 0.5088, 0.5091, 0.5211, 0.4991], device='cuda:0')\n",
      "tensor([[ 0.0072],\n",
      "        [ 0.0097],\n",
      "        [ 0.0105],\n",
      "        [-0.0735],\n",
      "        [-0.0059],\n",
      "        [-0.0378],\n",
      "        [ 0.0340],\n",
      "        [ 0.0318],\n",
      "        [ 0.0054],\n",
      "        [ 0.0981],\n",
      "        [-0.0187],\n",
      "        [ 0.0612],\n",
      "        [-0.0316],\n",
      "        [ 0.0698],\n",
      "        [-0.0142],\n",
      "        [-0.0311],\n",
      "        [-0.0464],\n",
      "        [ 0.0186],\n",
      "        [-0.0155],\n",
      "        [ 0.0298],\n",
      "        [ 0.1391],\n",
      "        [ 0.1412],\n",
      "        [ 0.0731],\n",
      "        [ 0.0159],\n",
      "        [ 0.0151],\n",
      "        [-0.0118],\n",
      "        [ 0.0187],\n",
      "        [-0.0163],\n",
      "        [-0.0493],\n",
      "        [-0.0374],\n",
      "        [ 0.0473],\n",
      "        [ 0.0126]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5181, 0.5192, 0.4982, 0.4979, 0.4767, 0.4590, 0.4770, 0.4687, 0.4625,\n",
      "        0.4749, 0.4719, 0.4716, 0.4790, 0.4687, 0.4944, 0.5345, 0.5227, 0.5121,\n",
      "        0.5097, 0.4997, 0.5018, 0.5088, 0.5109, 0.5026, 0.5204, 0.5286, 0.5280,\n",
      "        0.5301, 0.5422, 0.5416, 0.5463, 0.5505], device='cuda:0')\n",
      "tensor([[ 0.0566],\n",
      "        [ 0.0971],\n",
      "        [ 0.0012],\n",
      "        [ 0.0366],\n",
      "        [ 0.0260],\n",
      "        [ 0.0187],\n",
      "        [ 0.0310],\n",
      "        [ 0.0311],\n",
      "        [ 0.0402],\n",
      "        [-0.0122],\n",
      "        [ 0.0390],\n",
      "        [-0.0039],\n",
      "        [ 0.0111],\n",
      "        [-0.0084],\n",
      "        [ 0.0958],\n",
      "        [ 0.1030],\n",
      "        [ 0.0315],\n",
      "        [ 0.0632],\n",
      "        [ 0.0175],\n",
      "        [ 0.0495],\n",
      "        [-0.0174],\n",
      "        [-0.0092],\n",
      "        [-0.0362],\n",
      "        [-0.0480],\n",
      "        [-0.0023],\n",
      "        [ 0.1189],\n",
      "        [ 0.0118],\n",
      "        [ 0.0862],\n",
      "        [ 0.0264],\n",
      "        [-0.0298],\n",
      "        [-0.0983],\n",
      "        [-0.0370]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5629, 0.5570, 0.5587, 0.5593, 0.5496, 0.5543, 0.5540, 0.5629, 0.5702,\n",
      "        0.5900, 0.6018, 0.6083, 0.5962, 0.6043, 0.6119, 0.6004, 0.6015, 0.6107,\n",
      "        0.5924, 0.5688, 0.5711, 0.5838, 0.5800, 0.5711, 0.5629, 0.5708, 0.5700,\n",
      "        0.5546, 0.5658, 0.5617, 0.5434, 0.5381], device='cuda:0')\n",
      "tensor([[ 0.0058],\n",
      "        [ 0.0277],\n",
      "        [-0.0288],\n",
      "        [-0.0292],\n",
      "        [ 0.0222],\n",
      "        [-0.0032],\n",
      "        [-0.0083],\n",
      "        [-0.0270],\n",
      "        [ 0.0271],\n",
      "        [ 0.0085],\n",
      "        [ 0.0158],\n",
      "        [ 0.0192],\n",
      "        [-0.0239],\n",
      "        [ 0.0092],\n",
      "        [ 0.0167],\n",
      "        [ 0.0041],\n",
      "        [-0.0846],\n",
      "        [-0.0133],\n",
      "        [ 0.0678],\n",
      "        [-0.0144],\n",
      "        [ 0.0025],\n",
      "        [ 0.0433],\n",
      "        [ 0.0159],\n",
      "        [-0.0009],\n",
      "        [-0.0121],\n",
      "        [ 0.0174],\n",
      "        [-0.0171],\n",
      "        [ 0.0256],\n",
      "        [-0.0170],\n",
      "        [ 0.0306],\n",
      "        [ 0.0625],\n",
      "        [-0.0543]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5251, 0.5127, 0.5372, 0.5029, 0.5209, 0.5153, 0.5286, 0.5378, 0.5233,\n",
      "        0.5097, 0.4678, 0.4959, 0.5056, 0.5145, 0.4315, 0.4362, 0.4283, 0.4194,\n",
      "        0.4126, 0.3943, 0.4188, 0.4232, 0.4215, 0.4460, 0.4463, 0.4622, 0.4536,\n",
      "        0.4545, 0.4640, 0.4531, 0.4504, 0.4200], device='cuda:0')\n",
      "tensor([[ 0.0668],\n",
      "        [ 0.0651],\n",
      "        [ 0.0870],\n",
      "        [ 0.0258],\n",
      "        [-0.0516],\n",
      "        [-0.0133],\n",
      "        [-0.0276],\n",
      "        [-0.0176],\n",
      "        [-0.0515],\n",
      "        [ 0.1316],\n",
      "        [ 0.0361],\n",
      "        [-0.0133],\n",
      "        [-0.0361],\n",
      "        [-0.0360],\n",
      "        [-0.0453],\n",
      "        [ 0.0473],\n",
      "        [ 0.0080],\n",
      "        [ 0.0627],\n",
      "        [ 0.0100],\n",
      "        [ 0.0016],\n",
      "        [ 0.0175],\n",
      "        [-0.0230],\n",
      "        [-0.0048],\n",
      "        [ 0.0102],\n",
      "        [ 0.0017],\n",
      "        [-0.0667],\n",
      "        [-0.0324],\n",
      "        [ 0.0321],\n",
      "        [ 0.0122],\n",
      "        [ 0.0288],\n",
      "        [-0.0422],\n",
      "        [ 0.1034]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4409, 0.4507, 0.4501, 0.4448, 0.4622, 0.4684, 0.4460, 0.4460, 0.4528,\n",
      "        0.4457, 0.4430, 0.4522, 0.4224, 0.4324, 0.4454, 0.4690, 0.4377, 0.4206,\n",
      "        0.4389, 0.4294, 0.4241, 0.4117, 0.4173, 0.3955, 0.4082, 0.4064, 0.3869,\n",
      "        0.3660, 0.4011, 0.3813, 0.3807, 0.3834], device='cuda:0')\n",
      "tensor([[ 0.0341],\n",
      "        [ 0.0011],\n",
      "        [ 0.0668],\n",
      "        [ 0.1037],\n",
      "        [ 0.0152],\n",
      "        [ 0.0620],\n",
      "        [-0.0354],\n",
      "        [ 0.0270],\n",
      "        [-0.0018],\n",
      "        [-0.0152],\n",
      "        [-0.0010],\n",
      "        [ 0.0345],\n",
      "        [-0.0030],\n",
      "        [ 0.0147],\n",
      "        [ 0.0111],\n",
      "        [ 0.0200],\n",
      "        [ 0.0181],\n",
      "        [ 0.1430],\n",
      "        [ 0.1133],\n",
      "        [ 0.1423],\n",
      "        [ 0.1604],\n",
      "        [ 0.0043],\n",
      "        [-0.0559],\n",
      "        [ 0.0431],\n",
      "        [-0.0620],\n",
      "        [ 0.0458],\n",
      "        [-0.0575],\n",
      "        [-0.0563],\n",
      "        [-0.0500],\n",
      "        [-0.0627],\n",
      "        [-0.0279],\n",
      "        [ 0.0288]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3822, 0.3813, 0.4277, 0.4209, 0.4247, 0.4226, 0.4179, 0.4221, 0.4232,\n",
      "        0.4238, 0.4188, 0.4374, 0.4923, 0.5062, 0.4935, 0.4959, 0.5023, 0.5038,\n",
      "        0.5201, 0.5238, 0.5315, 0.5097, 0.5194, 0.5016, 0.5108, 0.5201, 0.5329,\n",
      "        0.5196, 0.5097, 0.5234, 0.5180, 0.5244], device='cuda:0')\n",
      "tensor([[-0.1656],\n",
      "        [ 0.0577],\n",
      "        [ 0.0080],\n",
      "        [ 0.0142],\n",
      "        [-0.0026],\n",
      "        [ 0.0354],\n",
      "        [ 0.0297],\n",
      "        [ 0.0046],\n",
      "        [ 0.0273],\n",
      "        [-0.0277],\n",
      "        [-0.0654],\n",
      "        [-0.0760],\n",
      "        [-0.0208],\n",
      "        [ 0.0091],\n",
      "        [ 0.0010],\n",
      "        [ 0.0279],\n",
      "        [-0.0289],\n",
      "        [-0.0055],\n",
      "        [ 0.0082],\n",
      "        [ 0.0170],\n",
      "        [ 0.0219],\n",
      "        [ 0.0071],\n",
      "        [ 0.0041],\n",
      "        [ 0.0032],\n",
      "        [ 0.0245],\n",
      "        [ 0.0065],\n",
      "        [-0.0115],\n",
      "        [ 0.0036],\n",
      "        [-0.0199],\n",
      "        [-0.0148],\n",
      "        [ 0.0045],\n",
      "        [ 0.0402]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5323, 0.5239, 0.5074, 0.4885, 0.4951, 0.4719, 0.4781, 0.4653, 0.4526,\n",
      "        0.4816, 0.4639, 0.4762, 0.4814, 0.4887, 0.4836, 0.4497, 0.4317, 0.4454,\n",
      "        0.4292, 0.4321, 0.4063, 0.4181, 0.3978, 0.4015, 0.4016, 0.4224, 0.4313,\n",
      "        0.4507, 0.4266, 0.4296, 0.4350, 0.4278], device='cuda:0')\n",
      "tensor([[-0.0018],\n",
      "        [ 0.0387],\n",
      "        [ 0.0038],\n",
      "        [-0.0179],\n",
      "        [-0.0055],\n",
      "        [-0.0388],\n",
      "        [ 0.0447],\n",
      "        [-0.0093],\n",
      "        [ 0.0228],\n",
      "        [ 0.0406],\n",
      "        [ 0.0082],\n",
      "        [-0.0186],\n",
      "        [ 0.0036],\n",
      "        [-0.0189],\n",
      "        [-0.0515],\n",
      "        [ 0.1256],\n",
      "        [ 0.1385],\n",
      "        [ 0.0415],\n",
      "        [ 0.0568],\n",
      "        [ 0.0327],\n",
      "        [ 0.0175],\n",
      "        [ 0.0109],\n",
      "        [-0.0279],\n",
      "        [-0.0442],\n",
      "        [-0.0113],\n",
      "        [ 0.0410],\n",
      "        [ 0.0327],\n",
      "        [ 0.0170],\n",
      "        [ 0.0675],\n",
      "        [ 0.0543],\n",
      "        [-0.0507],\n",
      "        [-0.0700]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4077, 0.4153, 0.4446, 0.4434, 0.4342, 0.4486, 0.4409, 0.4351, 0.4377,\n",
      "        0.4516, 0.4838, 0.5214, 0.5231, 0.5097, 0.5129, 0.5232, 0.5179, 0.5296,\n",
      "        0.5246, 0.5405, 0.5258, 0.5178, 0.5280, 0.5282, 0.5367, 0.5333, 0.5248,\n",
      "        0.5088, 0.5124, 0.5172, 0.5277, 0.5242], device='cuda:0')\n",
      "tensor([[ 0.0127],\n",
      "        [-0.0158],\n",
      "        [ 0.0440],\n",
      "        [-0.0098],\n",
      "        [-0.0439],\n",
      "        [ 0.0207],\n",
      "        [-0.0286],\n",
      "        [ 0.0700],\n",
      "        [ 0.0262],\n",
      "        [ 0.0683],\n",
      "        [ 0.0233],\n",
      "        [ 0.0166],\n",
      "        [ 0.1131],\n",
      "        [-0.0200],\n",
      "        [ 0.0779],\n",
      "        [-0.0617],\n",
      "        [-0.0248],\n",
      "        [ 0.0949],\n",
      "        [ 0.0333],\n",
      "        [-0.0006],\n",
      "        [ 0.0540],\n",
      "        [ 0.0525],\n",
      "        [ 0.0601],\n",
      "        [ 0.0183],\n",
      "        [ 0.0261],\n",
      "        [-0.0329],\n",
      "        [-0.0137],\n",
      "        [-0.0095],\n",
      "        [ 0.0662],\n",
      "        [ 0.0226],\n",
      "        [ 0.0660],\n",
      "        [-0.0147]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5354, 0.5430, 0.5381, 0.5352, 0.5456, 0.5371, 0.5252, 0.5128, 0.5088,\n",
      "        0.5139, 0.5175, 0.5332, 0.5357, 0.5345, 0.5291, 0.5350, 0.5345, 0.5312,\n",
      "        0.5274, 0.5173, 0.5205, 0.5231, 0.5149, 0.5126, 0.5138, 0.5128, 0.5146,\n",
      "        0.5169, 0.5244, 0.5168, 0.5208, 0.5144], device='cuda:0')\n",
      "tensor([[-0.0103],\n",
      "        [ 0.0675],\n",
      "        [ 0.0290],\n",
      "        [-0.0102],\n",
      "        [-0.0201],\n",
      "        [-0.0366],\n",
      "        [ 0.0202],\n",
      "        [ 0.0194],\n",
      "        [ 0.1389],\n",
      "        [ 0.1005],\n",
      "        [-0.0297],\n",
      "        [ 0.0087],\n",
      "        [-0.0404],\n",
      "        [ 0.0215],\n",
      "        [ 0.0144],\n",
      "        [ 0.0635],\n",
      "        [ 0.0152],\n",
      "        [ 0.0137],\n",
      "        [ 0.0056],\n",
      "        [ 0.0026],\n",
      "        [ 0.1248],\n",
      "        [ 0.0065],\n",
      "        [-0.0339],\n",
      "        [-0.0046],\n",
      "        [ 0.0367],\n",
      "        [ 0.0909],\n",
      "        [ 0.1092],\n",
      "        [ 0.0344],\n",
      "        [ 0.0281],\n",
      "        [-0.0093],\n",
      "        [ 0.0365],\n",
      "        [ 0.0255]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5102, 0.4838, 0.4753, 0.4623, 0.4712, 0.4873, 0.4933, 0.4900, 0.4933,\n",
      "        0.4733, 0.4719, 0.4800, 0.4807, 0.4744, 0.4761, 0.4814, 0.4753, 0.4807,\n",
      "        0.4777, 0.4864, 0.4946, 0.4917, 0.4838, 0.4826, 0.4728, 0.4723, 0.4764,\n",
      "        0.4807, 0.4823, 0.4767, 0.4802, 0.4747], device='cuda:0')\n",
      "tensor([[-0.0385],\n",
      "        [ 0.0373],\n",
      "        [ 0.0167],\n",
      "        [-0.0174],\n",
      "        [ 0.0328],\n",
      "        [ 0.0081],\n",
      "        [-0.0037],\n",
      "        [ 0.0455],\n",
      "        [-0.0166],\n",
      "        [ 0.0487],\n",
      "        [ 0.0675],\n",
      "        [ 0.0957],\n",
      "        [ 0.0135],\n",
      "        [ 0.0635],\n",
      "        [ 0.0541],\n",
      "        [-0.0353],\n",
      "        [ 0.0221],\n",
      "        [-0.0246],\n",
      "        [-0.0318],\n",
      "        [-0.0102],\n",
      "        [ 0.0892],\n",
      "        [ 0.0386],\n",
      "        [ 0.0013],\n",
      "        [-0.0095],\n",
      "        [ 0.0437],\n",
      "        [ 0.0471],\n",
      "        [ 0.0084],\n",
      "        [-0.0163],\n",
      "        [-0.0897],\n",
      "        [ 0.0862],\n",
      "        [-0.0169],\n",
      "        [-0.0098]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4724, 0.4620, 0.4718, 0.4672, 0.4861, 0.4855, 0.4764, 0.4726, 0.4548,\n",
      "        0.4528, 0.4601, 0.4547, 0.4436, 0.4369, 0.4364, 0.4216, 0.4360, 0.4342,\n",
      "        0.4219, 0.4082, 0.4285, 0.4268, 0.4120, 0.4058, 0.4139, 0.4186, 0.4236,\n",
      "        0.4386, 0.4403, 0.4437, 0.4460, 0.4395], device='cuda:0')\n",
      "tensor([[ 0.0441],\n",
      "        [ 0.0335],\n",
      "        [ 0.0355],\n",
      "        [ 0.0569],\n",
      "        [ 0.0197],\n",
      "        [ 0.0121],\n",
      "        [ 0.0208],\n",
      "        [ 0.0261],\n",
      "        [ 0.0451],\n",
      "        [ 0.0312],\n",
      "        [ 0.1625],\n",
      "        [ 0.0052],\n",
      "        [-0.0020],\n",
      "        [-0.0070],\n",
      "        [ 0.0083],\n",
      "        [ 0.0391],\n",
      "        [ 0.0766],\n",
      "        [ 0.0314],\n",
      "        [-0.0323],\n",
      "        [ 0.0167],\n",
      "        [-0.0242],\n",
      "        [-0.0699],\n",
      "        [-0.0281],\n",
      "        [-0.0291],\n",
      "        [ 0.0134],\n",
      "        [ 0.0098],\n",
      "        [-0.0375],\n",
      "        [-0.0511],\n",
      "        [-0.0436],\n",
      "        [-0.0006],\n",
      "        [ 0.0113],\n",
      "        [ 0.0287]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4401, 0.4502, 0.4570, 0.4625, 0.4618, 0.4667, 0.4590, 0.4656, 0.4778,\n",
      "        0.4805, 0.4935, 0.5034, 0.5058, 0.4938, 0.4939, 0.4912, 0.4998, 0.4979,\n",
      "        0.5001, 0.5173, 0.5185, 0.5183, 0.5196, 0.5232, 0.5319, 0.5208, 0.5227,\n",
      "        0.5215, 0.5239, 0.5260, 0.5208, 0.5256], device='cuda:0')\n",
      "tensor([[ 0.0259],\n",
      "        [-0.0212],\n",
      "        [-0.0916],\n",
      "        [-0.0057],\n",
      "        [ 0.0112],\n",
      "        [-0.0014],\n",
      "        [-0.0118],\n",
      "        [ 0.0286],\n",
      "        [-0.0393],\n",
      "        [ 0.0439],\n",
      "        [ 0.0624],\n",
      "        [-0.0291],\n",
      "        [ 0.2290],\n",
      "        [ 0.0803],\n",
      "        [ 0.0524],\n",
      "        [-0.0008],\n",
      "        [ 0.0762],\n",
      "        [ 0.0427],\n",
      "        [-0.0164],\n",
      "        [ 0.0556],\n",
      "        [-0.0367],\n",
      "        [-0.0176],\n",
      "        [ 0.0434],\n",
      "        [ 0.0337],\n",
      "        [ 0.0260],\n",
      "        [ 0.0215],\n",
      "        [-0.0513],\n",
      "        [-0.0468],\n",
      "        [-0.0342],\n",
      "        [ 0.0669],\n",
      "        [ 0.0594],\n",
      "        [ 0.0345]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5302, 0.5201, 0.5104, 0.5212, 0.5267, 0.5198, 0.5316, 0.5541, 0.5482,\n",
      "        0.5494, 0.5459, 0.5546, 0.5626, 0.5487, 0.5527, 0.5538, 0.5579, 0.5659,\n",
      "        0.5603, 0.5570, 0.5544, 0.5589, 0.5640, 0.5612, 0.5520, 0.5546, 0.5648,\n",
      "        0.5740, 0.5666, 0.5697, 0.5687, 0.5576], device='cuda:0')\n",
      "tensor([[-0.0115],\n",
      "        [ 0.0468],\n",
      "        [ 0.0037],\n",
      "        [ 0.0205],\n",
      "        [ 0.0197],\n",
      "        [-0.0523],\n",
      "        [ 0.0801],\n",
      "        [-0.0124],\n",
      "        [ 0.0744],\n",
      "        [ 0.0465],\n",
      "        [ 0.0104],\n",
      "        [ 0.0055],\n",
      "        [ 0.1105],\n",
      "        [ 0.0251],\n",
      "        [ 0.0476],\n",
      "        [ 0.0548],\n",
      "        [-0.0329],\n",
      "        [ 0.0368],\n",
      "        [ 0.0110],\n",
      "        [ 0.0308],\n",
      "        [-0.0183],\n",
      "        [-0.0115],\n",
      "        [-0.0095],\n",
      "        [-0.0166],\n",
      "        [-0.0073],\n",
      "        [-0.0122],\n",
      "        [-0.0041],\n",
      "        [-0.0170],\n",
      "        [ 0.0675],\n",
      "        [ 0.1270],\n",
      "        [ 0.0934],\n",
      "        [ 0.0573]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5490, 0.5383, 0.5421, 0.5352, 0.5470, 0.5204, 0.5026, 0.4904, 0.4942,\n",
      "        0.4969, 0.4915, 0.4672, 0.4793, 0.4903, 0.4908, 0.4852, 0.4828, 0.4844,\n",
      "        0.4715, 0.4766, 0.4879, 0.4841, 0.4912, 0.4903, 0.4667, 0.4592, 0.4498,\n",
      "        0.4360, 0.4457, 0.4450, 0.4396, 0.4428], device='cuda:0')\n",
      "tensor([[ 0.0902],\n",
      "        [ 0.0261],\n",
      "        [-0.0318],\n",
      "        [-0.0635],\n",
      "        [-0.0384],\n",
      "        [-0.0185],\n",
      "        [ 0.0230],\n",
      "        [ 0.0292],\n",
      "        [ 0.0783],\n",
      "        [ 0.1235],\n",
      "        [ 0.0789],\n",
      "        [ 0.0225],\n",
      "        [ 0.0442],\n",
      "        [ 0.0045],\n",
      "        [ 0.0571],\n",
      "        [ 0.0334],\n",
      "        [ 0.0039],\n",
      "        [-0.0133],\n",
      "        [-0.0302],\n",
      "        [ 0.0316],\n",
      "        [ 0.0104],\n",
      "        [-0.0066],\n",
      "        [-0.0261],\n",
      "        [-0.0179],\n",
      "        [ 0.0602],\n",
      "        [ 0.0197],\n",
      "        [-0.0125],\n",
      "        [ 0.0314],\n",
      "        [ 0.0752],\n",
      "        [-0.0275],\n",
      "        [-0.0030],\n",
      "        [ 0.0114]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4442, 0.4673, 0.4809, 0.4798, 0.4828, 0.4706, 0.4771, 0.4778, 0.4932,\n",
      "        0.4870, 0.4842, 0.4851, 0.4830, 0.4884, 0.4790, 0.4851, 0.4795, 0.4699,\n",
      "        0.4667, 0.4691, 0.4719, 0.4666, 0.4575, 0.4529, 0.4570, 0.4401, 0.3936,\n",
      "        0.3951, 0.4011, 0.3784, 0.3850, 0.3839], device='cuda:0')\n",
      "tensor([[ 0.0968],\n",
      "        [ 0.0744],\n",
      "        [ 0.1577],\n",
      "        [-0.0336],\n",
      "        [ 0.0398],\n",
      "        [-0.0097],\n",
      "        [-0.0549],\n",
      "        [ 0.0755],\n",
      "        [ 0.0269],\n",
      "        [-0.0091],\n",
      "        [ 0.0045],\n",
      "        [ 0.0082],\n",
      "        [-0.0522],\n",
      "        [-0.0102],\n",
      "        [-0.0150],\n",
      "        [ 0.0248],\n",
      "        [ 0.0625],\n",
      "        [-0.0231],\n",
      "        [ 0.0329],\n",
      "        [-0.0109],\n",
      "        [ 0.0036],\n",
      "        [-0.0010],\n",
      "        [ 0.0250],\n",
      "        [ 0.0016],\n",
      "        [ 0.0251],\n",
      "        [ 0.2358],\n",
      "        [ 0.1382],\n",
      "        [ 0.0766],\n",
      "        [ 0.0253],\n",
      "        [ 0.0406],\n",
      "        [-0.0041],\n",
      "        [ 0.0448]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3879, 0.3813, 0.4009, 0.4011, 0.3960, 0.3932, 0.3893, 0.3903, 0.3808,\n",
      "        0.3770, 0.3763, 0.3789, 0.3768, 0.3670, 0.3397, 0.3421, 0.3702, 0.3583,\n",
      "        0.3571, 0.3689, 0.3845, 0.3798, 0.3843, 0.3855, 0.3796, 0.3749, 0.3775,\n",
      "        0.3791, 0.3732, 0.3684, 0.3661, 0.3692], device='cuda:0')\n",
      "tensor([[ 0.0003],\n",
      "        [-0.0327],\n",
      "        [ 0.0240],\n",
      "        [-0.0191],\n",
      "        [-0.0222],\n",
      "        [-0.0608],\n",
      "        [-0.0335],\n",
      "        [ 0.0219],\n",
      "        [-0.0272],\n",
      "        [-0.0416],\n",
      "        [ 0.0459],\n",
      "        [-0.0161],\n",
      "        [-0.0336],\n",
      "        [-0.0389],\n",
      "        [-0.0330],\n",
      "        [-0.0330],\n",
      "        [ 0.0277],\n",
      "        [-0.0375],\n",
      "        [-0.0293],\n",
      "        [ 0.0705],\n",
      "        [ 0.0354],\n",
      "        [ 0.0415],\n",
      "        [ 0.0572],\n",
      "        [-0.0290],\n",
      "        [-0.0226],\n",
      "        [ 0.0268],\n",
      "        [ 0.0484],\n",
      "        [ 0.0513],\n",
      "        [ 0.0630],\n",
      "        [ 0.0860],\n",
      "        [ 0.0399],\n",
      "        [ 0.1853]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3607, 0.3497, 0.3553, 0.3612, 0.3570, 0.3506, 0.3435, 0.3373, 0.3333,\n",
      "        0.3378, 0.3405, 0.3451, 0.3394, 0.3272, 0.3188, 0.3055, 0.3099, 0.3047,\n",
      "        0.3116, 0.3203, 0.3208, 0.3000, 0.3046, 0.3138, 0.3279, 0.3175, 0.3098,\n",
      "        0.3055, 0.3086, 0.3076, 0.3161, 0.3067], device='cuda:0')\n",
      "tensor([[ 0.0235],\n",
      "        [ 0.0084],\n",
      "        [-0.0710],\n",
      "        [ 0.0411],\n",
      "        [ 0.0371],\n",
      "        [ 0.0226],\n",
      "        [ 0.0534],\n",
      "        [ 0.0432],\n",
      "        [ 0.0100],\n",
      "        [-0.0326],\n",
      "        [-0.0035],\n",
      "        [ 0.0806],\n",
      "        [ 0.0529],\n",
      "        [ 0.0661],\n",
      "        [-0.0199],\n",
      "        [ 0.0462],\n",
      "        [-0.0133],\n",
      "        [-0.0272],\n",
      "        [ 0.0973],\n",
      "        [-0.0702],\n",
      "        [ 0.0638],\n",
      "        [ 0.0294],\n",
      "        [-0.0435],\n",
      "        [ 0.0238],\n",
      "        [-0.0037],\n",
      "        [ 0.0394],\n",
      "        [ 0.0941],\n",
      "        [ 0.1216],\n",
      "        [ 0.0241],\n",
      "        [-0.0015],\n",
      "        [ 0.0931],\n",
      "        [-0.0069]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3146, 0.3210, 0.3208, 0.3043, 0.2974, 0.3092, 0.3083, 0.2944, 0.3169,\n",
      "        0.3198, 0.3132, 0.3031, 0.3013, 0.2924, 0.3014, 0.3074, 0.3190, 0.3200,\n",
      "        0.3197, 0.3203, 0.3346, 0.3421, 0.3555, 0.3703, 0.3646, 0.3633, 0.3680,\n",
      "        0.3605, 0.3558, 0.3490, 0.3400, 0.3426], device='cuda:0')\n",
      "tensor([[ 0.1067],\n",
      "        [ 0.0329],\n",
      "        [-0.0391],\n",
      "        [ 0.0413],\n",
      "        [ 0.0071],\n",
      "        [ 0.0349],\n",
      "        [-0.0439],\n",
      "        [-0.0100],\n",
      "        [ 0.0161],\n",
      "        [-0.0314],\n",
      "        [-0.0281],\n",
      "        [ 0.0275],\n",
      "        [-0.0208],\n",
      "        [-0.0378],\n",
      "        [ 0.0091],\n",
      "        [-0.0138],\n",
      "        [-0.0146],\n",
      "        [ 0.0580],\n",
      "        [ 0.0047],\n",
      "        [ 0.0409],\n",
      "        [ 0.0694],\n",
      "        [-0.0407],\n",
      "        [ 0.0496],\n",
      "        [ 0.0107],\n",
      "        [-0.0300],\n",
      "        [ 0.0558],\n",
      "        [ 0.0553],\n",
      "        [ 0.0722],\n",
      "        [-0.0122],\n",
      "        [ 0.0226],\n",
      "        [ 0.0248],\n",
      "        [ 0.0957]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3368, 0.3225, 0.3290, 0.3217, 0.3265, 0.3326, 0.3378, 0.3312, 0.3202,\n",
      "        0.3232, 0.3223, 0.3196, 0.3092, 0.2868, 0.2826, 0.2800, 0.2629, 0.2783,\n",
      "        0.2737, 0.2658, 0.2561, 0.2696, 0.2624, 0.2641, 0.2481, 0.2493, 0.2502,\n",
      "        0.2408, 0.2527, 0.2826, 0.2803, 0.3042], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0875],\n",
      "        [ 0.0460],\n",
      "        [-0.0096],\n",
      "        [-0.0214],\n",
      "        [ 0.0212],\n",
      "        [ 0.1421],\n",
      "        [ 0.0402],\n",
      "        [ 0.0205],\n",
      "        [ 0.0675],\n",
      "        [ 0.1121],\n",
      "        [ 0.0853],\n",
      "        [ 0.0212],\n",
      "        [-0.0257],\n",
      "        [-0.0222],\n",
      "        [ 0.0399],\n",
      "        [ 0.0220],\n",
      "        [ 0.0365],\n",
      "        [ 0.0219],\n",
      "        [ 0.0134],\n",
      "        [ 0.0311],\n",
      "        [ 0.0188],\n",
      "        [ 0.0052],\n",
      "        [ 0.0521],\n",
      "        [-0.0087],\n",
      "        [ 0.0222],\n",
      "        [-0.0415],\n",
      "        [-0.0310],\n",
      "        [-0.0252],\n",
      "        [-0.0641],\n",
      "        [ 0.0515],\n",
      "        [-0.0003],\n",
      "        [-0.0130]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2873, 0.3217, 0.3314, 0.3376, 0.3326, 0.3331, 0.3213, 0.3329, 0.3423,\n",
      "        0.3432, 0.3523, 0.3536, 0.3605, 0.3704, 0.3665, 0.3659, 0.3536, 0.3472,\n",
      "        0.3458, 0.3546, 0.3555, 0.3620, 0.3586, 0.3547, 0.3509, 0.3662, 0.3817,\n",
      "        0.3795, 0.3879, 0.3825, 0.3950, 0.3913], device='cuda:0')\n",
      "tensor([[ 0.0669],\n",
      "        [ 0.1306],\n",
      "        [ 0.0583],\n",
      "        [ 0.1262],\n",
      "        [ 0.0017],\n",
      "        [ 0.0321],\n",
      "        [-0.0275],\n",
      "        [ 0.0155],\n",
      "        [ 0.0555],\n",
      "        [ 0.0329],\n",
      "        [-0.0565],\n",
      "        [ 0.0323],\n",
      "        [ 0.0539],\n",
      "        [ 0.0239],\n",
      "        [ 0.0481],\n",
      "        [ 0.0316],\n",
      "        [ 0.0236],\n",
      "        [-0.0429],\n",
      "        [ 0.0382],\n",
      "        [ 0.0193],\n",
      "        [ 0.0245],\n",
      "        [ 0.0200],\n",
      "        [ 0.0218],\n",
      "        [-0.0683],\n",
      "        [ 0.0654],\n",
      "        [-0.0209],\n",
      "        [ 0.0051],\n",
      "        [-0.0145],\n",
      "        [ 0.0974],\n",
      "        [ 0.1047],\n",
      "        [ 0.0560],\n",
      "        [ 0.0530]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3931, 0.3832, 0.3760, 0.3730, 0.3695, 0.3567, 0.3624, 0.3654, 0.3594,\n",
      "        0.3586, 0.3662, 0.3601, 0.3545, 0.3523, 0.3576, 0.3598, 0.3575, 0.3515,\n",
      "        0.3461, 0.3409, 0.3468, 0.3613, 0.3664, 0.3755, 0.3869, 0.3784, 0.3916,\n",
      "        0.3949, 0.3941, 0.3991, 0.3944, 0.3872], device='cuda:0')\n",
      "tensor([[ 0.1127],\n",
      "        [ 0.0321],\n",
      "        [ 0.0690],\n",
      "        [ 0.0995],\n",
      "        [ 0.0477],\n",
      "        [ 0.1021],\n",
      "        [ 0.0214],\n",
      "        [ 0.0989],\n",
      "        [ 0.0386],\n",
      "        [-0.0649],\n",
      "        [-0.0111],\n",
      "        [ 0.0091],\n",
      "        [ 0.0176],\n",
      "        [ 0.0374],\n",
      "        [ 0.0125],\n",
      "        [-0.0299],\n",
      "        [ 0.0061],\n",
      "        [-0.0259],\n",
      "        [-0.0335],\n",
      "        [ 0.0313],\n",
      "        [ 0.0405],\n",
      "        [ 0.0148],\n",
      "        [-0.0250],\n",
      "        [-0.0144],\n",
      "        [-0.0030],\n",
      "        [-0.0021],\n",
      "        [ 0.0236],\n",
      "        [ 0.0126],\n",
      "        [ 0.1676],\n",
      "        [ 0.0060],\n",
      "        [ 0.0603],\n",
      "        [-0.0100]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3647, 0.3611, 0.3572, 0.3635, 0.3538, 0.3511, 0.3591, 0.3601, 0.3506,\n",
      "        0.3501, 0.3500, 0.3448, 0.3456, 0.3468, 0.3449, 0.3487, 0.3463, 0.3421,\n",
      "        0.3390, 0.3465, 0.3554, 0.3563, 0.3546, 0.3584, 0.3518, 0.3542, 0.3463,\n",
      "        0.3457, 0.3489, 0.3460, 0.3430, 0.3479], device='cuda:0')\n",
      "tensor([[ 0.0210],\n",
      "        [-0.0123],\n",
      "        [-0.0195],\n",
      "        [ 0.0007],\n",
      "        [-0.0313],\n",
      "        [-0.0165],\n",
      "        [ 0.0170],\n",
      "        [ 0.0250],\n",
      "        [ 0.0504],\n",
      "        [ 0.0644],\n",
      "        [-0.0012],\n",
      "        [-0.0125],\n",
      "        [ 0.1642],\n",
      "        [ 0.0564],\n",
      "        [ 0.0303],\n",
      "        [ 0.0227],\n",
      "        [ 0.0674],\n",
      "        [ 0.0265],\n",
      "        [ 0.0588],\n",
      "        [-0.0230],\n",
      "        [ 0.0068],\n",
      "        [-0.0440],\n",
      "        [ 0.0059],\n",
      "        [-0.0543],\n",
      "        [-0.0495],\n",
      "        [ 0.0005],\n",
      "        [ 0.0379],\n",
      "        [-0.0260],\n",
      "        [-0.0802],\n",
      "        [ 0.0472],\n",
      "        [ 0.0140],\n",
      "        [-0.0140]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3447, 0.3487, 0.3383, 0.3366, 0.3358, 0.3513, 0.3539, 0.3702, 0.3703,\n",
      "        0.3680, 0.3690, 0.3817, 0.3692, 0.3749, 0.3659, 0.3654, 0.3626, 0.3512,\n",
      "        0.3526, 0.3655, 0.3676, 0.3623, 0.3608, 0.3589, 0.3525, 0.3539, 0.3527,\n",
      "        0.3589, 0.3718, 0.3722, 0.3787, 0.3745], device='cuda:0')\n",
      "tensor([[ 0.0620],\n",
      "        [ 0.0446],\n",
      "        [ 0.0623],\n",
      "        [ 0.1030],\n",
      "        [ 0.0136],\n",
      "        [ 0.1554],\n",
      "        [ 0.0052],\n",
      "        [-0.0236],\n",
      "        [-0.0186],\n",
      "        [ 0.0194],\n",
      "        [ 0.0111],\n",
      "        [ 0.0628],\n",
      "        [ 0.0359],\n",
      "        [ 0.0179],\n",
      "        [-0.0208],\n",
      "        [ 0.0039],\n",
      "        [ 0.0233],\n",
      "        [ 0.0012],\n",
      "        [-0.0113]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3852, 0.3857, 0.3831, 0.3769, 0.3828, 0.3853, 0.3817, 0.3864, 0.3943,\n",
      "        0.3894, 0.3941, 0.3901, 0.3872, 0.3942, 0.4011, 0.4057, 0.3997, 0.4053,\n",
      "        0.4010], device='cuda:0')\n",
      "tensor([[ 0.0325],\n",
      "        [ 0.0333],\n",
      "        [ 0.0255],\n",
      "        [-0.0257],\n",
      "        [ 0.0221],\n",
      "        [ 0.0744],\n",
      "        [-0.0143],\n",
      "        [ 0.0365],\n",
      "        [-0.0393],\n",
      "        [-0.0445],\n",
      "        [ 0.1155],\n",
      "        [-0.0083],\n",
      "        [ 0.0091],\n",
      "        [ 0.0333],\n",
      "        [-0.0470],\n",
      "        [ 0.0314],\n",
      "        [ 0.0223],\n",
      "        [ 0.0402],\n",
      "        [ 0.0285],\n",
      "        [ 0.0192],\n",
      "        [ 0.0371],\n",
      "        [ 0.0040],\n",
      "        [ 0.0233],\n",
      "        [ 0.0235],\n",
      "        [ 0.0320],\n",
      "        [ 0.0178],\n",
      "        [ 0.0926],\n",
      "        [-0.0322],\n",
      "        [-0.0548],\n",
      "        [ 0.0090],\n",
      "        [-0.0094],\n",
      "        [ 0.0527]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0147, 0.0146, 0.0143, 0.0138, 0.0130, 0.0129, 0.0135, 0.0135, 0.0135,\n",
      "        0.0137, 0.0132, 0.0129, 0.0134, 0.0133, 0.0135, 0.0134, 0.0134, 0.0134,\n",
      "        0.0134, 0.0130, 0.0122, 0.0113, 0.0093, 0.0098, 0.0105, 0.0111, 0.0113,\n",
      "        0.0107, 0.0097, 0.0091, 0.0093, 0.0088], device='cuda:0')\n",
      "tensor([[ 0.0045],\n",
      "        [ 0.0474],\n",
      "        [-0.0020],\n",
      "        [-0.0492],\n",
      "        [-0.0050],\n",
      "        [-0.0015],\n",
      "        [ 0.0651],\n",
      "        [ 0.0520],\n",
      "        [ 0.0571],\n",
      "        [ 0.0514],\n",
      "        [ 0.0052],\n",
      "        [ 0.0190],\n",
      "        [ 0.0236],\n",
      "        [ 0.1034],\n",
      "        [-0.0140],\n",
      "        [-0.0736],\n",
      "        [ 0.0091],\n",
      "        [ 0.0743],\n",
      "        [ 0.0558],\n",
      "        [-0.0033],\n",
      "        [-0.0322],\n",
      "        [ 0.0314],\n",
      "        [-0.0089],\n",
      "        [ 0.0185],\n",
      "        [ 0.0121],\n",
      "        [ 0.0300],\n",
      "        [ 0.0650],\n",
      "        [-0.0192],\n",
      "        [ 0.0033],\n",
      "        [ 0.0363],\n",
      "        [ 0.0886],\n",
      "        [ 0.0723]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0094, 0.0092, 0.0095, 0.0090, 0.0092, 0.0091, 0.0081, 0.0069, 0.0058,\n",
      "        0.0058, 0.0035, 0.0048, 0.0054, 0.0050, 0.0034, 0.0037, 0.0037, 0.0040,\n",
      "        0.0041, 0.0033, 0.0018, 0.0010, 0.0000, 0.0017, 0.0015, 0.0019, 0.0014,\n",
      "        0.0006, 0.0009, 0.0017, 0.0009, 0.0017], device='cuda:0')\n",
      "tensor([[-0.0885],\n",
      "        [ 0.1240],\n",
      "        [-0.0124],\n",
      "        [-0.0204],\n",
      "        [ 0.0240],\n",
      "        [ 0.0675],\n",
      "        [ 0.0137],\n",
      "        [ 0.0007],\n",
      "        [-0.0108],\n",
      "        [ 0.0569],\n",
      "        [ 0.0284],\n",
      "        [-0.0042],\n",
      "        [ 0.0134],\n",
      "        [ 0.0966],\n",
      "        [ 0.0463],\n",
      "        [ 0.0911],\n",
      "        [ 0.0624],\n",
      "        [-0.0030],\n",
      "        [-0.0172],\n",
      "        [-0.0474],\n",
      "        [ 0.0097],\n",
      "        [-0.0141],\n",
      "        [-0.0411],\n",
      "        [ 0.0328],\n",
      "        [ 0.0234],\n",
      "        [-0.0318],\n",
      "        [ 0.0415],\n",
      "        [-0.0244],\n",
      "        [-0.0399],\n",
      "        [ 0.0182],\n",
      "        [-0.0395],\n",
      "        [ 0.1138]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0024, 0.0021, 0.0028, 0.0029, 0.0028, 0.0025, 0.0028, 0.0033, 0.0043,\n",
      "        0.0046, 0.0044, 0.0048, 0.0040, 0.0037, 0.0039, 0.0042, 0.0042, 0.0036,\n",
      "        0.0039, 0.0040, 0.0044, 0.0051, 0.0051, 0.0044, 0.0050, 0.0050, 0.0047,\n",
      "        0.0042, 0.0048, 0.0044, 0.0044, 0.0046], device='cuda:0')\n",
      "tensor([[ 0.0172],\n",
      "        [ 0.0190],\n",
      "        [ 0.0121],\n",
      "        [ 0.0257],\n",
      "        [ 0.0066],\n",
      "        [ 0.0319],\n",
      "        [ 0.0270],\n",
      "        [ 0.0090],\n",
      "        [ 0.0173],\n",
      "        [ 0.0106],\n",
      "        [ 0.0171],\n",
      "        [ 0.0311],\n",
      "        [ 0.1736],\n",
      "        [ 0.0236],\n",
      "        [ 0.0222],\n",
      "        [ 0.0177],\n",
      "        [ 0.0960],\n",
      "        [ 0.0723],\n",
      "        [-0.0198],\n",
      "        [ 0.0063],\n",
      "        [-0.0107],\n",
      "        [ 0.0401],\n",
      "        [ 0.0055],\n",
      "        [ 0.0033],\n",
      "        [-0.0134],\n",
      "        [-0.0173],\n",
      "        [-0.0040],\n",
      "        [ 0.0026],\n",
      "        [ 0.0474],\n",
      "        [ 0.0370],\n",
      "        [-0.0268],\n",
      "        [-0.0283]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0050, 0.0051, 0.0051, 0.0053, 0.0055, 0.0055, 0.0065, 0.0066, 0.0065,\n",
      "        0.0064, 0.0055, 0.0054, 0.0051, 0.0057, 0.0051, 0.0048, 0.0052, 0.0048,\n",
      "        0.0049, 0.0048, 0.0049, 0.0049, 0.0052, 0.0056, 0.0054, 0.0051, 0.0048,\n",
      "        0.0045, 0.0035, 0.0040, 0.0031, 0.0028], device='cuda:0')\n",
      "tensor([[-0.0267],\n",
      "        [ 0.0126],\n",
      "        [ 0.0678],\n",
      "        [ 0.0367],\n",
      "        [ 0.0736],\n",
      "        [-0.0628],\n",
      "        [ 0.0380],\n",
      "        [ 0.0495],\n",
      "        [ 0.0296],\n",
      "        [ 0.0388],\n",
      "        [ 0.0164],\n",
      "        [ 0.0833],\n",
      "        [ 0.0431],\n",
      "        [ 0.0263],\n",
      "        [ 0.0412],\n",
      "        [ 0.0199],\n",
      "        [ 0.0307],\n",
      "        [-0.0357],\n",
      "        [ 0.0421],\n",
      "        [ 0.0058],\n",
      "        [ 0.0273],\n",
      "        [ 0.0345],\n",
      "        [-0.0405],\n",
      "        [ 0.0547],\n",
      "        [ 0.0475],\n",
      "        [ 0.0056],\n",
      "        [ 0.0450],\n",
      "        [ 0.0069],\n",
      "        [ 0.0214],\n",
      "        [ 0.0093],\n",
      "        [-0.0494],\n",
      "        [ 0.1508]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0030, 0.0022, 0.0028, 0.0027, 0.0033, 0.0034, 0.0034, 0.0038, 0.0033,\n",
      "        0.0031, 0.0031, 0.0038, 0.0032, 0.0035, 0.0031, 0.0027, 0.0023, 0.0015,\n",
      "        0.0021, 0.0020, 0.0016, 0.0024, 0.0029, 0.0025, 0.0029, 0.0032, 0.0035,\n",
      "        0.0035, 0.0031, 0.0035, 0.0043, 0.0038], device='cuda:0')\n",
      "tensor([[ 0.0450],\n",
      "        [-0.0238],\n",
      "        [ 0.0127],\n",
      "        [ 0.0215],\n",
      "        [ 0.0173],\n",
      "        [ 0.0579],\n",
      "        [ 0.0218],\n",
      "        [ 0.0686],\n",
      "        [ 0.0258],\n",
      "        [ 0.0215],\n",
      "        [ 0.0156],\n",
      "        [ 0.0673],\n",
      "        [ 0.0320],\n",
      "        [ 0.0064],\n",
      "        [ 0.0515],\n",
      "        [-0.0063],\n",
      "        [ 0.0576],\n",
      "        [-0.0001],\n",
      "        [-0.0077],\n",
      "        [ 0.0080],\n",
      "        [-0.0581],\n",
      "        [ 0.0059],\n",
      "        [-0.0192],\n",
      "        [ 0.0607],\n",
      "        [ 0.0587],\n",
      "        [-0.0160],\n",
      "        [ 0.0973],\n",
      "        [ 0.0093],\n",
      "        [-0.0161],\n",
      "        [ 0.0269],\n",
      "        [ 0.0390],\n",
      "        [-0.0084]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0043, 0.0042, 0.0046, 0.0042, 0.0044, 0.0045, 0.0052, 0.0052, 0.0056,\n",
      "        0.0058, 0.0060, 0.0058, 0.0054, 0.0059, 0.0058, 0.0058, 0.0058, 0.0052,\n",
      "        0.0051, 0.0055, 0.0052, 0.0053, 0.0050, 0.0048, 0.0054, 0.0054, 0.0050,\n",
      "        0.0055, 0.0055, 0.0054, 0.0054, 0.0053], device='cuda:0')\n",
      "tensor([[-0.0097],\n",
      "        [ 0.0315],\n",
      "        [-0.0246],\n",
      "        [-0.0231],\n",
      "        [ 0.0567],\n",
      "        [ 0.0793],\n",
      "        [-0.0105],\n",
      "        [ 0.0223],\n",
      "        [ 0.0305],\n",
      "        [ 0.0313],\n",
      "        [ 0.0480],\n",
      "        [ 0.0322],\n",
      "        [-0.0002],\n",
      "        [ 0.1121],\n",
      "        [ 0.0885],\n",
      "        [ 0.0504],\n",
      "        [ 0.0293],\n",
      "        [ 0.0128],\n",
      "        [ 0.0538],\n",
      "        [ 0.0411],\n",
      "        [-0.0081],\n",
      "        [ 0.0057],\n",
      "        [-0.0025],\n",
      "        [ 0.0554],\n",
      "        [-0.0052],\n",
      "        [ 0.0196],\n",
      "        [ 0.0217],\n",
      "        [ 0.0288],\n",
      "        [ 0.0725],\n",
      "        [ 0.0395],\n",
      "        [ 0.0048],\n",
      "        [-0.0040]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0050, 0.0057, 0.0057, 0.0055, 0.0061, 0.0062, 0.0063, 0.0064, 0.0068,\n",
      "        0.0069, 0.0065, 0.0068, 0.0067, 0.0068, 0.0068, 0.0068, 0.0069, 0.0071,\n",
      "        0.0075, 0.0073, 0.0071, 0.0074, 0.0074, 0.0072, 0.0072, 0.0071, 0.0071,\n",
      "        0.0072, 0.0070, 0.0071, 0.0070, 0.0070], device='cuda:0')\n",
      "tensor([[ 0.0389],\n",
      "        [-0.0054],\n",
      "        [ 0.0885],\n",
      "        [ 0.0203],\n",
      "        [ 0.0324],\n",
      "        [-0.0222],\n",
      "        [-0.0133],\n",
      "        [ 0.0279],\n",
      "        [ 0.0224],\n",
      "        [ 0.0715],\n",
      "        [ 0.0934],\n",
      "        [ 0.1169],\n",
      "        [-0.0020],\n",
      "        [ 0.0022],\n",
      "        [-0.0441],\n",
      "        [ 0.0368],\n",
      "        [-0.0123],\n",
      "        [-0.0111],\n",
      "        [ 0.0348],\n",
      "        [-0.0849],\n",
      "        [-0.0087],\n",
      "        [-0.0207],\n",
      "        [ 0.0196],\n",
      "        [ 0.0249],\n",
      "        [ 0.0222],\n",
      "        [ 0.0154],\n",
      "        [ 0.0199],\n",
      "        [ 0.0279],\n",
      "        [ 0.0632],\n",
      "        [ 0.0364],\n",
      "        [ 0.0579],\n",
      "        [ 0.1239]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0071, 0.0070, 0.0068, 0.0066, 0.0066, 0.0062, 0.0063, 0.0063, 0.0059,\n",
      "        0.0057, 0.0061, 0.0060, 0.0062, 0.0065, 0.0065, 0.0064, 0.0064, 0.0065,\n",
      "        0.0065, 0.0068, 0.0065, 0.0065, 0.0068, 0.0066, 0.0068, 0.0068, 0.0069,\n",
      "        0.0072, 0.0072, 0.0072, 0.0072, 0.0070], device='cuda:0')\n",
      "tensor([[ 0.0362],\n",
      "        [-0.0315],\n",
      "        [-0.0379],\n",
      "        [-0.0171],\n",
      "        [ 0.0723],\n",
      "        [-0.0260],\n",
      "        [ 0.0130],\n",
      "        [ 0.1184],\n",
      "        [ 0.0495],\n",
      "        [ 0.0401],\n",
      "        [ 0.0950],\n",
      "        [ 0.0662],\n",
      "        [ 0.0235],\n",
      "        [ 0.0312],\n",
      "        [-0.0225],\n",
      "        [-0.0200],\n",
      "        [ 0.0189],\n",
      "        [ 0.0179],\n",
      "        [ 0.0595],\n",
      "        [ 0.0187],\n",
      "        [ 0.1091],\n",
      "        [ 0.0658],\n",
      "        [ 0.0199],\n",
      "        [ 0.0377],\n",
      "        [ 0.0226],\n",
      "        [ 0.0153],\n",
      "        [ 0.0919],\n",
      "        [ 0.1502],\n",
      "        [ 0.1002],\n",
      "        [ 0.0550],\n",
      "        [-0.0091],\n",
      "        [ 0.0307]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([19])) that is different to the input size (torch.Size([19, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0073, 0.0077, 0.0086, 0.0090, 0.0087, 0.0086, 0.0088, 0.0088, 0.0086,\n",
      "        0.0085, 0.0085, 0.0091, 0.0095, 0.0098, 0.0099, 0.0100, 0.0103, 0.0102,\n",
      "        0.0099, 0.0100, 0.0102, 0.0100, 0.0096, 0.0097, 0.0103, 0.0104, 0.0106,\n",
      "        0.0104, 0.0104, 0.0105, 0.0103, 0.0101], device='cuda:0')\n",
      "tensor([[ 0.0048],\n",
      "        [ 0.0392],\n",
      "        [ 0.0140],\n",
      "        [-0.0073],\n",
      "        [-0.0484],\n",
      "        [ 0.0605],\n",
      "        [ 0.0188],\n",
      "        [-0.0065],\n",
      "        [ 0.0132],\n",
      "        [ 0.0052],\n",
      "        [ 0.0290],\n",
      "        [ 0.0074],\n",
      "        [ 0.0170],\n",
      "        [ 0.0321],\n",
      "        [ 0.0327],\n",
      "        [ 0.0867],\n",
      "        [ 0.0441],\n",
      "        [ 0.0324],\n",
      "        [-0.0034],\n",
      "        [-0.0325],\n",
      "        [ 0.0079],\n",
      "        [ 0.0287],\n",
      "        [ 0.0333],\n",
      "        [ 0.0102],\n",
      "        [ 0.0106],\n",
      "        [-0.0077],\n",
      "        [ 0.0460],\n",
      "        [ 0.0271],\n",
      "        [ 0.0703],\n",
      "        [ 0.0034],\n",
      "        [-0.0409],\n",
      "        [ 0.1296]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0099, 0.0101, 0.0101, 0.0100, 0.0099, 0.0096, 0.0097, 0.0103, 0.0108,\n",
      "        0.0105, 0.0106, 0.0103, 0.0103, 0.0102, 0.0098, 0.0100, 0.0102, 0.0099,\n",
      "        0.0099, 0.0097, 0.0096, 0.0095, 0.0094, 0.0094, 0.0090, 0.0089, 0.0084,\n",
      "        0.0081, 0.0082, 0.0076, 0.0083, 0.0085], device='cuda:0')\n",
      "tensor([[-0.0513],\n",
      "        [ 0.1146],\n",
      "        [ 0.0961],\n",
      "        [-0.0017],\n",
      "        [ 0.0272],\n",
      "        [ 0.0118],\n",
      "        [-0.0159],\n",
      "        [-0.0579],\n",
      "        [ 0.0015],\n",
      "        [-0.0011],\n",
      "        [ 0.0168],\n",
      "        [ 0.0255],\n",
      "        [-0.0014],\n",
      "        [-0.0010],\n",
      "        [ 0.0050],\n",
      "        [ 0.0217],\n",
      "        [-0.0102],\n",
      "        [-0.0436],\n",
      "        [ 0.0530],\n",
      "        [ 0.0016],\n",
      "        [ 0.0128],\n",
      "        [ 0.0363],\n",
      "        [ 0.1207],\n",
      "        [ 0.0636],\n",
      "        [ 0.0135],\n",
      "        [ 0.0264],\n",
      "        [ 0.0189],\n",
      "        [ 0.0876],\n",
      "        [ 0.0203],\n",
      "        [ 0.0150],\n",
      "        [ 0.0256],\n",
      "        [ 0.0724]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0088, 0.0082, 0.0085, 0.0082, 0.0081, 0.0079, 0.0080, 0.0081, 0.0080,\n",
      "        0.0078, 0.0078, 0.0077, 0.0076, 0.0077, 0.0077, 0.0079, 0.0080, 0.0086,\n",
      "        0.0081, 0.0081, 0.0079, 0.0083, 0.0085, 0.0083, 0.0084, 0.0087, 0.0088,\n",
      "        0.0093, 0.0095, 0.0093, 0.0092, 0.0092], device='cuda:0')\n",
      "tensor([[ 0.0825],\n",
      "        [ 0.0964],\n",
      "        [ 0.0555],\n",
      "        [ 0.0208],\n",
      "        [ 0.0263],\n",
      "        [ 0.0196],\n",
      "        [ 0.0590],\n",
      "        [-0.0068],\n",
      "        [-0.0206],\n",
      "        [ 0.0378],\n",
      "        [ 0.1156],\n",
      "        [-0.0322],\n",
      "        [ 0.0246],\n",
      "        [ 0.0514],\n",
      "        [-0.0063],\n",
      "        [ 0.0250],\n",
      "        [ 0.0214],\n",
      "        [ 0.0749],\n",
      "        [ 0.0840],\n",
      "        [ 0.0395],\n",
      "        [ 0.0183],\n",
      "        [ 0.0185],\n",
      "        [-0.0239],\n",
      "        [ 0.0282],\n",
      "        [-0.0056],\n",
      "        [ 0.0289],\n",
      "        [ 0.0594],\n",
      "        [-0.0044],\n",
      "        [ 0.0398],\n",
      "        [ 0.0290],\n",
      "        [ 0.0304],\n",
      "        [ 0.0374]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0088, 0.0090, 0.0092, 0.0090, 0.0091, 0.0086, 0.0087, 0.0086, 0.0087,\n",
      "        0.0089, 0.0089, 0.0091, 0.0096, 0.0095, 0.0096, 0.0095, 0.0095, 0.0094,\n",
      "        0.0094, 0.0094, 0.0091, 0.0093, 0.0095, 0.0094, 0.0099, 0.0096, 0.0091,\n",
      "        0.0090, 0.0092, 0.0091, 0.0090, 0.0095], device='cuda:0')\n",
      "tensor([[-2.5496e-02],\n",
      "        [-1.2599e-02],\n",
      "        [ 3.6815e-02],\n",
      "        [ 1.2033e-02],\n",
      "        [-2.3497e-02],\n",
      "        [-1.1545e-03],\n",
      "        [ 1.0843e-02],\n",
      "        [ 7.2855e-02],\n",
      "        [ 4.3762e-02],\n",
      "        [ 2.5753e-03],\n",
      "        [ 4.4624e-03],\n",
      "        [ 4.9939e-02],\n",
      "        [ 2.4773e-02],\n",
      "        [ 1.2774e-01],\n",
      "        [ 1.0671e-01],\n",
      "        [ 9.2496e-02],\n",
      "        [ 1.8635e-02],\n",
      "        [ 4.3939e-02],\n",
      "        [-6.1385e-05],\n",
      "        [-6.4090e-02],\n",
      "        [-2.1359e-02],\n",
      "        [ 2.8986e-02],\n",
      "        [ 3.1485e-02],\n",
      "        [ 3.4009e-02],\n",
      "        [ 1.1612e-02],\n",
      "        [ 1.8445e-02],\n",
      "        [-6.1820e-02],\n",
      "        [ 5.1903e-02],\n",
      "        [-8.3870e-03],\n",
      "        [ 3.6787e-02],\n",
      "        [ 4.7223e-02],\n",
      "        [-1.5515e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0098, 0.0103, 0.0099, 0.0099, 0.0100, 0.0103, 0.0107, 0.0108, 0.0116,\n",
      "        0.0117, 0.0119, 0.0118, 0.0113, 0.0111, 0.0113, 0.0118, 0.0120, 0.0117,\n",
      "        0.0112, 0.0118, 0.0115, 0.0112, 0.0110, 0.0111, 0.0112, 0.0114, 0.0115,\n",
      "        0.0116, 0.0114, 0.0113, 0.0110, 0.0105], device='cuda:0')\n",
      "tensor([[ 0.0137],\n",
      "        [ 0.0264],\n",
      "        [ 0.0270],\n",
      "        [ 0.0043],\n",
      "        [ 0.1242],\n",
      "        [-0.0221],\n",
      "        [ 0.0347],\n",
      "        [ 0.0238],\n",
      "        [ 0.0355],\n",
      "        [ 0.0352],\n",
      "        [ 0.0335],\n",
      "        [ 0.0517],\n",
      "        [ 0.0202],\n",
      "        [ 0.0144],\n",
      "        [ 0.0366],\n",
      "        [ 0.0377],\n",
      "        [ 0.0044],\n",
      "        [-0.0176],\n",
      "        [ 0.0099],\n",
      "        [-0.0442],\n",
      "        [ 0.0253],\n",
      "        [ 0.0745],\n",
      "        [ 0.0264],\n",
      "        [ 0.0112],\n",
      "        [ 0.0303],\n",
      "        [ 0.0270],\n",
      "        [-0.0146],\n",
      "        [ 0.0310],\n",
      "        [ 0.0154],\n",
      "        [ 0.0509],\n",
      "        [ 0.0064],\n",
      "        [ 0.0009]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0105, 0.0100, 0.0100, 0.0104, 0.0108, 0.0113, 0.0117, 0.0116, 0.0111,\n",
      "        0.0114, 0.0112, 0.0112, 0.0110, 0.0110, 0.0107, 0.0107, 0.0107, 0.0112,\n",
      "        0.0112, 0.0111, 0.0112, 0.0111, 0.0112, 0.0116, 0.0118, 0.0122, 0.0127,\n",
      "        0.0133, 0.0128, 0.0129, 0.0127, 0.0130], device='cuda:0')\n",
      "tensor([[ 0.1396],\n",
      "        [ 0.0522],\n",
      "        [ 0.0145],\n",
      "        [ 0.0073],\n",
      "        [ 0.0028],\n",
      "        [ 0.0558],\n",
      "        [ 0.0161],\n",
      "        [ 0.0392],\n",
      "        [-0.0127],\n",
      "        [ 0.0272],\n",
      "        [ 0.0994],\n",
      "        [ 0.0203],\n",
      "        [ 0.0047],\n",
      "        [ 0.0640],\n",
      "        [ 0.0763],\n",
      "        [ 0.0363],\n",
      "        [ 0.0521],\n",
      "        [ 0.0811],\n",
      "        [-0.0172],\n",
      "        [-0.1328],\n",
      "        [-0.0191],\n",
      "        [ 0.0571],\n",
      "        [ 0.0054],\n",
      "        [ 0.0125],\n",
      "        [ 0.0118],\n",
      "        [-0.0407],\n",
      "        [-0.0195],\n",
      "        [ 0.0369],\n",
      "        [ 0.0239],\n",
      "        [ 0.0167],\n",
      "        [ 0.0172],\n",
      "        [-0.0047]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0140, 0.0143, 0.0145, 0.0144, 0.0161, 0.0154, 0.0156, 0.0155, 0.0149,\n",
      "        0.0152, 0.0153, 0.0151, 0.0147, 0.0144, 0.0137, 0.0140, 0.0149, 0.0148,\n",
      "        0.0147, 0.0145, 0.0145, 0.0145, 0.0147, 0.0149, 0.0151, 0.0156, 0.0157,\n",
      "        0.0156, 0.0156, 0.0156, 0.0157, 0.0158], device='cuda:0')\n",
      "tensor([[ 0.0248],\n",
      "        [ 0.0468],\n",
      "        [ 0.0164],\n",
      "        [-0.0089],\n",
      "        [ 0.0030],\n",
      "        [-0.0061],\n",
      "        [ 0.0830],\n",
      "        [ 0.0109],\n",
      "        [ 0.0081],\n",
      "        [ 0.0441],\n",
      "        [-0.0193],\n",
      "        [-0.0382],\n",
      "        [-0.0087],\n",
      "        [ 0.0219],\n",
      "        [ 0.0005],\n",
      "        [ 0.0099],\n",
      "        [ 0.0155],\n",
      "        [ 0.1488],\n",
      "        [ 0.0781],\n",
      "        [ 0.0472],\n",
      "        [ 0.0465],\n",
      "        [ 0.0174],\n",
      "        [ 0.0716],\n",
      "        [ 0.0211],\n",
      "        [ 0.0495],\n",
      "        [ 0.0751],\n",
      "        [ 0.0202],\n",
      "        [ 0.0156],\n",
      "        [ 0.0469],\n",
      "        [ 0.0322],\n",
      "        [ 0.0365],\n",
      "        [ 0.0329]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0166, 0.0170, 0.0164, 0.0166, 0.0163, 0.0162, 0.0159, 0.0162, 0.0165,\n",
      "        0.0165, 0.0165, 0.0170, 0.0176, 0.0178, 0.0175, 0.0175, 0.0172, 0.0171,\n",
      "        0.0169, 0.0173, 0.0174, 0.0177, 0.0178, 0.0178, 0.0182, 0.0182, 0.0184,\n",
      "        0.0184, 0.0183, 0.0178, 0.0175, 0.0176], device='cuda:0')\n",
      "tensor([[ 0.0648],\n",
      "        [ 0.0570],\n",
      "        [-0.0036],\n",
      "        [-0.0164],\n",
      "        [ 0.0521],\n",
      "        [ 0.0531],\n",
      "        [-0.0139],\n",
      "        [ 0.0268],\n",
      "        [-0.0062],\n",
      "        [-0.0092],\n",
      "        [-0.0110],\n",
      "        [ 0.0112],\n",
      "        [-0.0015],\n",
      "        [ 0.0571],\n",
      "        [ 0.0113],\n",
      "        [-0.0279],\n",
      "        [ 0.0065],\n",
      "        [ 0.0260],\n",
      "        [-0.0389],\n",
      "        [ 0.0149],\n",
      "        [ 0.0415],\n",
      "        [ 0.0065],\n",
      "        [ 0.0164],\n",
      "        [ 0.0416],\n",
      "        [ 0.0735],\n",
      "        [-0.0031],\n",
      "        [-0.0080],\n",
      "        [ 0.0057],\n",
      "        [ 0.0241],\n",
      "        [ 0.0205],\n",
      "        [ 0.0348],\n",
      "        [ 0.0725]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0183, 0.0179, 0.0176, 0.0175, 0.0174, 0.0176, 0.0174, 0.0179, 0.0181,\n",
      "        0.0175, 0.0174, 0.0173, 0.0175, 0.0170, 0.0166, 0.0172, 0.0175, 0.0176,\n",
      "        0.0175, 0.0175, 0.0175, 0.0175, 0.0177, 0.0177, 0.0175, 0.0177, 0.0180,\n",
      "        0.0184, 0.0189, 0.0192, 0.0194, 0.0188], device='cuda:0')\n",
      "tensor([[ 0.0806],\n",
      "        [ 0.1341],\n",
      "        [ 0.0599],\n",
      "        [ 0.1255],\n",
      "        [ 0.0849],\n",
      "        [-0.0150],\n",
      "        [-0.0017],\n",
      "        [-0.0278],\n",
      "        [ 0.0513],\n",
      "        [ 0.0442],\n",
      "        [-0.0416],\n",
      "        [ 0.0759],\n",
      "        [-0.0970],\n",
      "        [-0.0411],\n",
      "        [ 0.0481],\n",
      "        [ 0.0213],\n",
      "        [-0.0184],\n",
      "        [ 0.0336],\n",
      "        [ 0.0333],\n",
      "        [-0.0016],\n",
      "        [-0.0070],\n",
      "        [ 0.0571],\n",
      "        [ 0.0194],\n",
      "        [ 0.0207],\n",
      "        [ 0.0207],\n",
      "        [ 0.0425],\n",
      "        [-0.0053],\n",
      "        [ 0.0067],\n",
      "        [-0.0138],\n",
      "        [-0.0120],\n",
      "        [ 0.0038],\n",
      "        [ 0.0394]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0187, 0.0182, 0.0185, 0.0180, 0.0182, 0.0177, 0.0171, 0.0173, 0.0170,\n",
      "        0.0177, 0.0175, 0.0176, 0.0179, 0.0182, 0.0185, 0.0187, 0.0183, 0.0185,\n",
      "        0.0186, 0.0184, 0.0186, 0.0186, 0.0184, 0.0183, 0.0183, 0.0186, 0.0188,\n",
      "        0.0191, 0.0194, 0.0192, 0.0191, 0.0187], device='cuda:0')\n",
      "tensor([[ 0.1783],\n",
      "        [ 0.0797],\n",
      "        [ 0.1342],\n",
      "        [ 0.1090],\n",
      "        [ 0.0376],\n",
      "        [ 0.0065],\n",
      "        [-0.0372],\n",
      "        [-0.0115],\n",
      "        [-0.0149],\n",
      "        [-0.0124],\n",
      "        [ 0.0388],\n",
      "        [ 0.0346],\n",
      "        [ 0.0230],\n",
      "        [ 0.0106],\n",
      "        [ 0.0529],\n",
      "        [-0.0205],\n",
      "        [ 0.0923],\n",
      "        [ 0.0275],\n",
      "        [ 0.0075],\n",
      "        [ 0.0390],\n",
      "        [-0.0082],\n",
      "        [ 0.0884],\n",
      "        [ 0.0282],\n",
      "        [-0.0252],\n",
      "        [ 0.0340],\n",
      "        [ 0.0579],\n",
      "        [-0.0361],\n",
      "        [ 0.0381],\n",
      "        [ 0.0216],\n",
      "        [ 0.0252],\n",
      "        [ 0.0250],\n",
      "        [ 0.0172]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0186, 0.0179, 0.0183, 0.0184, 0.0184, 0.0180, 0.0179, 0.0178, 0.0177,\n",
      "        0.0172, 0.0171, 0.0170, 0.0173, 0.0171, 0.0171, 0.0169, 0.0157, 0.0162,\n",
      "        0.0157, 0.0161, 0.0161, 0.0158, 0.0160, 0.0164, 0.0159, 0.0160, 0.0160,\n",
      "        0.0156, 0.0149, 0.0153, 0.0150, 0.0145], device='cuda:0')\n",
      "tensor([[ 0.0393],\n",
      "        [ 0.0481],\n",
      "        [-0.0065],\n",
      "        [ 0.0306],\n",
      "        [ 0.0723],\n",
      "        [ 0.0575],\n",
      "        [-0.0200],\n",
      "        [-0.0129],\n",
      "        [ 0.0507],\n",
      "        [ 0.0499],\n",
      "        [ 0.0869],\n",
      "        [ 0.0416],\n",
      "        [ 0.0284],\n",
      "        [-0.0070],\n",
      "        [ 0.0113],\n",
      "        [ 0.0984],\n",
      "        [ 0.1072],\n",
      "        [ 0.0936],\n",
      "        [ 0.1230],\n",
      "        [ 0.0319],\n",
      "        [ 0.0846],\n",
      "        [ 0.0067],\n",
      "        [ 0.0190],\n",
      "        [ 0.0452],\n",
      "        [ 0.0490],\n",
      "        [ 0.0196],\n",
      "        [ 0.0738],\n",
      "        [ 0.0328],\n",
      "        [ 0.0950],\n",
      "        [ 0.0165],\n",
      "        [ 0.0460],\n",
      "        [ 0.0378]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0144, 0.0146, 0.0152, 0.0154, 0.0154, 0.0155, 0.0157, 0.0157, 0.0154,\n",
      "        0.0150, 0.0143, 0.0142, 0.0132, 0.0135, 0.0143, 0.0149, 0.0142, 0.0143,\n",
      "        0.0142, 0.0146, 0.0147, 0.0153, 0.0150, 0.0152, 0.0151, 0.0150, 0.0148,\n",
      "        0.0146, 0.0142, 0.0142, 0.0145, 0.0147], device='cuda:0')\n",
      "tensor([[-0.0033],\n",
      "        [ 0.0114],\n",
      "        [-0.0501],\n",
      "        [ 0.0054],\n",
      "        [-0.0104],\n",
      "        [ 0.0304],\n",
      "        [-0.0050],\n",
      "        [ 0.0118],\n",
      "        [ 0.0038],\n",
      "        [ 0.0070],\n",
      "        [ 0.0304],\n",
      "        [ 0.0110],\n",
      "        [ 0.0166],\n",
      "        [ 0.0022],\n",
      "        [ 0.1196],\n",
      "        [-0.0346],\n",
      "        [ 0.0085],\n",
      "        [ 0.0417],\n",
      "        [ 0.0015],\n",
      "        [-0.0048],\n",
      "        [ 0.0303],\n",
      "        [ 0.0538],\n",
      "        [ 0.0351],\n",
      "        [ 0.0430],\n",
      "        [ 0.0305],\n",
      "        [-0.0058],\n",
      "        [ 0.0176],\n",
      "        [ 0.0334],\n",
      "        [ 0.0012],\n",
      "        [ 0.2382],\n",
      "        [ 0.1858],\n",
      "        [ 0.0519]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0144, 0.0139, 0.0139, 0.0142, 0.0147, 0.0144, 0.0141, 0.0141, 0.0140,\n",
      "        0.0139, 0.0134, 0.0135, 0.0137, 0.0138, 0.0138, 0.0136, 0.0136, 0.0137,\n",
      "        0.0137, 0.0137, 0.0137, 0.0137, 0.0138, 0.0143, 0.0147, 0.0147, 0.0139,\n",
      "        0.0139, 0.0142, 0.0140, 0.0137, 0.0136], device='cuda:0')\n",
      "tensor([[ 2.3515e-02],\n",
      "        [ 2.1130e-02],\n",
      "        [ 3.0782e-02],\n",
      "        [ 8.3999e-04],\n",
      "        [ 3.7390e-02],\n",
      "        [ 2.7809e-02],\n",
      "        [ 1.1944e-01],\n",
      "        [-1.3619e-01],\n",
      "        [-1.1745e-02],\n",
      "        [ 4.4184e-02],\n",
      "        [ 3.5845e-03],\n",
      "        [ 3.7137e-02],\n",
      "        [-2.8349e-05],\n",
      "        [ 1.0481e-02],\n",
      "        [-6.1616e-03],\n",
      "        [ 2.0411e-02],\n",
      "        [-1.3380e-02],\n",
      "        [ 1.1845e-02],\n",
      "        [ 2.5964e-02],\n",
      "        [ 6.3192e-02],\n",
      "        [-2.2458e-02],\n",
      "        [ 1.2102e-02],\n",
      "        [ 6.3791e-02],\n",
      "        [ 2.8079e-02],\n",
      "        [ 2.8796e-02],\n",
      "        [-6.8293e-03],\n",
      "        [ 3.9685e-02],\n",
      "        [ 3.3396e-02],\n",
      "        [ 2.3555e-02],\n",
      "        [ 2.5563e-02],\n",
      "        [-2.4401e-02],\n",
      "        [ 2.4930e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0135, 0.0132, 0.0128, 0.0128, 0.0132, 0.0136, 0.0135, 0.0128, 0.0128,\n",
      "        0.0129, 0.0133, 0.0131, 0.0131, 0.0131, 0.0132, 0.0134, 0.0134, 0.0133,\n",
      "        0.0131, 0.0133, 0.0132, 0.0130, 0.0131, 0.0130, 0.0126, 0.0125, 0.0129,\n",
      "        0.0136, 0.0142, 0.0140, 0.0140, 0.0141], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0172],\n",
      "        [ 0.0227],\n",
      "        [ 0.0046],\n",
      "        [ 0.0279],\n",
      "        [ 0.0050],\n",
      "        [ 0.0335],\n",
      "        [ 0.0282],\n",
      "        [ 0.0764],\n",
      "        [-0.0126],\n",
      "        [-0.0021],\n",
      "        [ 0.0546],\n",
      "        [ 0.0467],\n",
      "        [ 0.0657],\n",
      "        [-0.0276],\n",
      "        [ 0.0109],\n",
      "        [ 0.0290],\n",
      "        [ 0.0576],\n",
      "        [ 0.0044],\n",
      "        [ 0.0041],\n",
      "        [ 0.0696],\n",
      "        [-0.0115],\n",
      "        [-0.0121],\n",
      "        [-0.0132],\n",
      "        [ 0.0381],\n",
      "        [-0.0503],\n",
      "        [-0.0007],\n",
      "        [ 0.0939],\n",
      "        [-0.0749],\n",
      "        [-0.0888],\n",
      "        [ 0.0148],\n",
      "        [ 0.0087],\n",
      "        [ 0.0003]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0144, 0.0150, 0.0154, 0.0157, 0.0157, 0.0156, 0.0159, 0.0158, 0.0156,\n",
      "        0.0160, 0.0161, 0.0160, 0.0158, 0.0157, 0.0155, 0.0161, 0.0158, 0.0154,\n",
      "        0.0159, 0.0153, 0.0154, 0.0154, 0.0148, 0.0146, 0.0148, 0.0156, 0.0160,\n",
      "        0.0160, 0.0161, 0.0165, 0.0166, 0.0166], device='cuda:0')\n",
      "tensor([[ 7.4245e-02],\n",
      "        [-9.8284e-05],\n",
      "        [ 2.6301e-02],\n",
      "        [ 6.8102e-02],\n",
      "        [ 1.3462e-02],\n",
      "        [ 8.3165e-02],\n",
      "        [ 3.5511e-02],\n",
      "        [ 4.1469e-02],\n",
      "        [-2.0752e-02],\n",
      "        [ 2.2726e-02],\n",
      "        [ 7.3616e-03],\n",
      "        [ 2.7163e-02],\n",
      "        [ 4.2071e-02],\n",
      "        [-1.1728e-02],\n",
      "        [-4.8639e-03],\n",
      "        [ 3.5066e-02],\n",
      "        [ 1.3980e-02],\n",
      "        [ 3.4957e-02],\n",
      "        [ 3.2304e-02],\n",
      "        [ 3.7429e-02],\n",
      "        [-2.6034e-03],\n",
      "        [ 8.4591e-02],\n",
      "        [-2.6412e-02],\n",
      "        [ 4.0178e-02],\n",
      "        [ 1.9485e-02],\n",
      "        [ 5.2145e-02],\n",
      "        [-3.3359e-02],\n",
      "        [ 4.6746e-02],\n",
      "        [-2.0511e-02],\n",
      "        [ 1.0170e-02],\n",
      "        [-1.5806e-02],\n",
      "        [-2.8894e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0166, 0.0164, 0.0161, 0.0163, 0.0165, 0.0170, 0.0167, 0.0169, 0.0173,\n",
      "        0.0175, 0.0173, 0.0172, 0.0173, 0.0172, 0.0172, 0.0170, 0.0169, 0.0166,\n",
      "        0.0161, 0.0165, 0.0165, 0.0165, 0.0166, 0.0167, 0.0169, 0.0167, 0.0166,\n",
      "        0.0168, 0.0177, 0.0177, 0.0179, 0.0179], device='cuda:0')\n",
      "tensor([[ 0.0360],\n",
      "        [ 0.0951],\n",
      "        [ 0.0820],\n",
      "        [-0.0217],\n",
      "        [-0.0183],\n",
      "        [ 0.0516],\n",
      "        [ 0.0467],\n",
      "        [ 0.0737],\n",
      "        [ 0.0455],\n",
      "        [ 0.0632],\n",
      "        [ 0.0185],\n",
      "        [ 0.0302],\n",
      "        [ 0.0003],\n",
      "        [ 0.0176],\n",
      "        [ 0.0372],\n",
      "        [ 0.0286],\n",
      "        [ 0.0240],\n",
      "        [ 0.0171],\n",
      "        [ 0.0233],\n",
      "        [ 0.0627],\n",
      "        [-0.0193],\n",
      "        [-0.0303],\n",
      "        [-0.0113],\n",
      "        [ 0.0248],\n",
      "        [-0.0151],\n",
      "        [ 0.0396],\n",
      "        [-0.0376],\n",
      "        [-0.0205],\n",
      "        [ 0.0460],\n",
      "        [ 0.0001],\n",
      "        [ 0.0955],\n",
      "        [ 0.0144]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0179, 0.0184, 0.0184, 0.0182, 0.0185, 0.0185, 0.0184, 0.0184, 0.0184,\n",
      "        0.0185, 0.0189, 0.0188, 0.0189, 0.0189, 0.0193, 0.0189, 0.0184, 0.0185,\n",
      "        0.0189, 0.0188, 0.0186, 0.0181, 0.0182, 0.0184, 0.0180, 0.0176, 0.0169,\n",
      "        0.0178, 0.0175, 0.0175, 0.0184, 0.0176], device='cuda:0')\n",
      "tensor([[-0.0032],\n",
      "        [ 0.0112],\n",
      "        [ 0.0051],\n",
      "        [ 0.0216],\n",
      "        [ 0.0456],\n",
      "        [ 0.0167],\n",
      "        [ 0.0273],\n",
      "        [ 0.0602],\n",
      "        [-0.0207],\n",
      "        [ 0.0085],\n",
      "        [ 0.0327],\n",
      "        [ 0.0068],\n",
      "        [-0.0215],\n",
      "        [ 0.0333],\n",
      "        [ 0.0005],\n",
      "        [ 0.0098],\n",
      "        [ 0.0600],\n",
      "        [ 0.0226],\n",
      "        [ 0.0574],\n",
      "        [-0.0071],\n",
      "        [ 0.0035],\n",
      "        [ 0.0114],\n",
      "        [-0.0258],\n",
      "        [ 0.1789],\n",
      "        [ 0.0166],\n",
      "        [ 0.0226],\n",
      "        [ 0.0338],\n",
      "        [ 0.0197],\n",
      "        [ 0.0300],\n",
      "        [ 0.0256],\n",
      "        [ 0.0461],\n",
      "        [ 0.0116]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0181, 0.0178, 0.0181, 0.0180, 0.0176, 0.0168, 0.0164, 0.0165, 0.0163,\n",
      "        0.0168, 0.0167, 0.0172, 0.0171, 0.0170, 0.0168, 0.0167, 0.0166, 0.0159,\n",
      "        0.0156, 0.0162, 0.0168, 0.0170, 0.0173, 0.0170, 0.0168, 0.0175, 0.0177,\n",
      "        0.0175, 0.0174, 0.0177, 0.0179, 0.0181], device='cuda:0')\n",
      "tensor([[-0.0229],\n",
      "        [ 0.0053],\n",
      "        [ 0.0451],\n",
      "        [ 0.0043],\n",
      "        [ 0.0004],\n",
      "        [ 0.0032],\n",
      "        [ 0.0900],\n",
      "        [ 0.1385],\n",
      "        [ 0.0540],\n",
      "        [ 0.0364],\n",
      "        [-0.0290],\n",
      "        [ 0.0618],\n",
      "        [-0.0043],\n",
      "        [-0.0246],\n",
      "        [ 0.0867],\n",
      "        [ 0.0143],\n",
      "        [ 0.0593],\n",
      "        [ 0.0988],\n",
      "        [-0.0005],\n",
      "        [ 0.0123],\n",
      "        [ 0.0169],\n",
      "        [ 0.0066],\n",
      "        [ 0.0094],\n",
      "        [ 0.0158],\n",
      "        [-0.0200],\n",
      "        [-0.0013],\n",
      "        [ 0.0298],\n",
      "        [ 0.0549],\n",
      "        [ 0.0279],\n",
      "        [-0.0199],\n",
      "        [-0.0042],\n",
      "        [ 0.0367]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0181, 0.0174, 0.0172, 0.0170, 0.0174, 0.0174, 0.0173, 0.0178, 0.0182,\n",
      "        0.0184, 0.0182, 0.0185, 0.0189, 0.0186, 0.0188, 0.0188, 0.0187, 0.0188,\n",
      "        0.0193, 0.0195, 0.0195, 0.0194, 0.0195, 0.0193, 0.0195, 0.0197, 0.0202,\n",
      "        0.0200, 0.0200, 0.0201, 0.0201, 0.0200], device='cuda:0')\n",
      "tensor([[ 0.0133],\n",
      "        [ 0.0613],\n",
      "        [ 0.0205],\n",
      "        [ 0.0318],\n",
      "        [ 0.0143],\n",
      "        [-0.0115],\n",
      "        [-0.0071],\n",
      "        [ 0.0192],\n",
      "        [ 0.0201],\n",
      "        [ 0.0429],\n",
      "        [ 0.0137],\n",
      "        [ 0.0270],\n",
      "        [ 0.0441],\n",
      "        [ 0.0190],\n",
      "        [-0.0070],\n",
      "        [-0.0059],\n",
      "        [ 0.1251],\n",
      "        [ 0.0298],\n",
      "        [ 0.0167],\n",
      "        [-0.0019],\n",
      "        [-0.0345],\n",
      "        [-0.0199],\n",
      "        [ 0.0138],\n",
      "        [ 0.0210],\n",
      "        [ 0.0166],\n",
      "        [ 0.0915],\n",
      "        [ 0.0964],\n",
      "        [ 0.0210],\n",
      "        [-0.0148],\n",
      "        [-0.0118],\n",
      "        [ 0.0434],\n",
      "        [-0.0212]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0201, 0.0202, 0.0204, 0.0203, 0.0202, 0.0204, 0.0204, 0.0210, 0.0208,\n",
      "        0.0208, 0.0210, 0.0213, 0.0210, 0.0212, 0.0214, 0.0213, 0.0210, 0.0213,\n",
      "        0.0211, 0.0210, 0.0211, 0.0206, 0.0208, 0.0210, 0.0212, 0.0210, 0.0213,\n",
      "        0.0216, 0.0213, 0.0213, 0.0213, 0.0215], device='cuda:0')\n",
      "tensor([[ 0.0554],\n",
      "        [ 0.0145],\n",
      "        [-0.0237],\n",
      "        [ 0.0017],\n",
      "        [ 0.0023],\n",
      "        [ 0.0078],\n",
      "        [-0.0187],\n",
      "        [ 0.0452],\n",
      "        [ 0.0564],\n",
      "        [ 0.0206],\n",
      "        [-0.0019],\n",
      "        [-0.0017],\n",
      "        [ 0.0112],\n",
      "        [ 0.0250],\n",
      "        [ 0.0161],\n",
      "        [ 0.0019],\n",
      "        [ 0.0669],\n",
      "        [ 0.0404],\n",
      "        [-0.0023],\n",
      "        [ 0.0374],\n",
      "        [ 0.0111],\n",
      "        [ 0.0421],\n",
      "        [ 0.0661],\n",
      "        [ 0.0148],\n",
      "        [ 0.0522],\n",
      "        [ 0.0323],\n",
      "        [-0.0050],\n",
      "        [ 0.0161],\n",
      "        [ 0.0331],\n",
      "        [-0.0260],\n",
      "        [-0.0778],\n",
      "        [-0.0330]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0217, 0.0218, 0.0223, 0.0223, 0.0224, 0.0223, 0.0220, 0.0225, 0.0226,\n",
      "        0.0227, 0.0227, 0.0228, 0.0230, 0.0230, 0.0231, 0.0226, 0.0227, 0.0228,\n",
      "        0.0231, 0.0231, 0.0235, 0.0237, 0.0234, 0.0234, 0.0233, 0.0229, 0.0229,\n",
      "        0.0229, 0.0223, 0.0221, 0.0213, 0.0202], device='cuda:0')\n",
      "tensor([[ 0.0872],\n",
      "        [-0.0287],\n",
      "        [-0.0021],\n",
      "        [-0.0562],\n",
      "        [ 0.1546],\n",
      "        [ 0.0327],\n",
      "        [-0.0605],\n",
      "        [ 0.0046],\n",
      "        [-0.0103],\n",
      "        [ 0.1507],\n",
      "        [ 0.0833],\n",
      "        [ 0.1273],\n",
      "        [-0.0174],\n",
      "        [ 0.0142],\n",
      "        [-0.0283],\n",
      "        [-0.0025],\n",
      "        [-0.0065],\n",
      "        [ 0.0115],\n",
      "        [ 0.0741],\n",
      "        [ 0.0185],\n",
      "        [ 0.0177],\n",
      "        [ 0.0221],\n",
      "        [-0.0040],\n",
      "        [ 0.0399],\n",
      "        [ 0.0135],\n",
      "        [ 0.0311],\n",
      "        [ 0.0098],\n",
      "        [ 0.0182],\n",
      "        [ 0.0354],\n",
      "        [ 0.0508],\n",
      "        [ 0.0603],\n",
      "        [ 0.0518]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0206, 0.0202, 0.0208, 0.0210, 0.0213, 0.0215, 0.0214, 0.0206, 0.0197,\n",
      "        0.0200, 0.0200, 0.0202, 0.0206, 0.0205, 0.0200, 0.0201, 0.0203, 0.0199,\n",
      "        0.0201, 0.0200, 0.0196, 0.0195, 0.0197, 0.0199, 0.0199, 0.0198, 0.0199,\n",
      "        0.0197, 0.0200, 0.0198, 0.0195, 0.0188], device='cuda:0')\n",
      "tensor([[-3.6520e-02],\n",
      "        [ 4.2800e-02],\n",
      "        [-1.1066e-02],\n",
      "        [-1.6657e-02],\n",
      "        [ 1.3616e-01],\n",
      "        [ 4.8839e-03],\n",
      "        [ 8.3497e-02],\n",
      "        [ 2.6421e-02],\n",
      "        [ 2.7796e-02],\n",
      "        [ 1.4451e-01],\n",
      "        [ 1.2123e-01],\n",
      "        [ 2.0791e-02],\n",
      "        [ 1.8938e-02],\n",
      "        [-5.8836e-03],\n",
      "        [-2.6475e-02],\n",
      "        [-4.5420e-02],\n",
      "        [ 4.4400e-02],\n",
      "        [ 8.2235e-03],\n",
      "        [ 8.3754e-03],\n",
      "        [ 9.4132e-02],\n",
      "        [ 1.0128e-01],\n",
      "        [ 1.2094e-01],\n",
      "        [ 1.2682e-01],\n",
      "        [ 2.1221e-02],\n",
      "        [ 2.8614e-02],\n",
      "        [ 2.0518e-02],\n",
      "        [-2.8604e-02],\n",
      "        [-5.2997e-02],\n",
      "        [-1.0959e-04],\n",
      "        [ 1.0940e-02],\n",
      "        [ 5.0189e-02],\n",
      "        [ 4.3260e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0184, 0.0188, 0.0194, 0.0196, 0.0208, 0.0206, 0.0203, 0.0199, 0.0198,\n",
      "        0.0195, 0.0193, 0.0198, 0.0199, 0.0203, 0.0207, 0.0211, 0.0214, 0.0220,\n",
      "        0.0216, 0.0211, 0.0215, 0.0212, 0.0211, 0.0209, 0.0206, 0.0206, 0.0210,\n",
      "        0.0213, 0.0205, 0.0201, 0.0203, 0.0204], device='cuda:0')\n",
      "tensor([[ 0.0187],\n",
      "        [-0.0029],\n",
      "        [ 0.0613],\n",
      "        [ 0.0488],\n",
      "        [ 0.0619],\n",
      "        [ 0.0208],\n",
      "        [ 0.0405],\n",
      "        [ 0.0034],\n",
      "        [-0.0055],\n",
      "        [ 0.0251],\n",
      "        [-0.0246],\n",
      "        [ 0.0461],\n",
      "        [-0.0117],\n",
      "        [ 0.0012],\n",
      "        [-0.0128],\n",
      "        [ 0.0010],\n",
      "        [ 0.0125],\n",
      "        [ 0.0221],\n",
      "        [ 0.0137],\n",
      "        [ 0.1627],\n",
      "        [ 0.0642],\n",
      "        [ 0.0149],\n",
      "        [ 0.0495],\n",
      "        [-0.0300],\n",
      "        [-0.0266],\n",
      "        [ 0.0015],\n",
      "        [ 0.0220],\n",
      "        [ 0.0515],\n",
      "        [ 0.0094],\n",
      "        [ 0.0981],\n",
      "        [ 0.0084],\n",
      "        [ 0.0673]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0199, 0.0199, 0.0206, 0.0204, 0.0201, 0.0201, 0.0200, 0.0203, 0.0201,\n",
      "        0.0200, 0.0208, 0.0210, 0.0210, 0.0214, 0.0221, 0.0217, 0.0216, 0.0210,\n",
      "        0.0213, 0.0217, 0.0220, 0.0224, 0.0225, 0.0232, 0.0240, 0.0232, 0.0234,\n",
      "        0.0248, 0.0243, 0.0238, 0.0236, 0.0239], device='cuda:0')\n",
      "tensor([[ 0.0869],\n",
      "        [ 0.0161],\n",
      "        [ 0.0151],\n",
      "        [ 0.0313],\n",
      "        [ 0.0360],\n",
      "        [-0.0267],\n",
      "        [ 0.0196],\n",
      "        [-0.0220],\n",
      "        [ 0.0510],\n",
      "        [ 0.0753],\n",
      "        [-0.0007],\n",
      "        [ 0.0168],\n",
      "        [ 0.0460],\n",
      "        [ 0.0045],\n",
      "        [-0.0097],\n",
      "        [-0.0269],\n",
      "        [-0.0514],\n",
      "        [ 0.0329],\n",
      "        [ 0.0876],\n",
      "        [ 0.0835],\n",
      "        [-0.0234],\n",
      "        [ 0.0008],\n",
      "        [-0.0139],\n",
      "        [ 0.0407],\n",
      "        [ 0.0482],\n",
      "        [-0.0098],\n",
      "        [ 0.0330],\n",
      "        [ 0.0606],\n",
      "        [ 0.1299],\n",
      "        [ 0.0433],\n",
      "        [ 0.0156],\n",
      "        [ 0.0336]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0244, 0.0244, 0.0233, 0.0244, 0.0249, 0.0244, 0.0246, 0.0248, 0.0246,\n",
      "        0.0239, 0.0231, 0.0225, 0.0217, 0.0220, 0.0225, 0.0220, 0.0216, 0.0217,\n",
      "        0.0214, 0.0224, 0.0235, 0.0233, 0.0242, 0.0248, 0.0245, 0.0246, 0.0245,\n",
      "        0.0236, 0.0226, 0.0217, 0.0213, 0.0205], device='cuda:0')\n",
      "tensor([[-0.0173],\n",
      "        [-0.0077],\n",
      "        [ 0.0438],\n",
      "        [ 0.0431],\n",
      "        [ 0.0444],\n",
      "        [-0.0905],\n",
      "        [ 0.0518],\n",
      "        [ 0.0145],\n",
      "        [ 0.0438],\n",
      "        [ 0.0010],\n",
      "        [ 0.0112],\n",
      "        [ 0.0073],\n",
      "        [ 0.0063],\n",
      "        [ 0.0960],\n",
      "        [ 0.0579],\n",
      "        [ 0.0196],\n",
      "        [ 0.1565],\n",
      "        [ 0.0515],\n",
      "        [ 0.0301],\n",
      "        [ 0.0100],\n",
      "        [-0.0169],\n",
      "        [ 0.0531],\n",
      "        [ 0.0196],\n",
      "        [ 0.0097],\n",
      "        [ 0.0162],\n",
      "        [ 0.0654],\n",
      "        [ 0.0937],\n",
      "        [ 0.0448],\n",
      "        [ 0.0326],\n",
      "        [ 0.0316],\n",
      "        [-0.0342],\n",
      "        [ 0.0340]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0202, 0.0208, 0.0219, 0.0219, 0.0215, 0.0216, 0.0212, 0.0216, 0.0229,\n",
      "        0.0235, 0.0236, 0.0235, 0.0228, 0.0226, 0.0221, 0.0222, 0.0218, 0.0221,\n",
      "        0.0226, 0.0225, 0.0230, 0.0234, 0.0229, 0.0228, 0.0228, 0.0222, 0.0226,\n",
      "        0.0230, 0.0230, 0.0224, 0.0220, 0.0226], device='cuda:0')\n",
      "tensor([[ 0.0961],\n",
      "        [ 0.0726],\n",
      "        [ 0.0405],\n",
      "        [ 0.0381],\n",
      "        [ 0.0636],\n",
      "        [ 0.0399],\n",
      "        [-0.0394],\n",
      "        [ 0.0110],\n",
      "        [ 0.0191],\n",
      "        [-0.0219],\n",
      "        [ 0.0785],\n",
      "        [-0.0110],\n",
      "        [-0.0092],\n",
      "        [ 0.0230],\n",
      "        [ 0.0183],\n",
      "        [ 0.0275],\n",
      "        [ 0.0452],\n",
      "        [ 0.0480],\n",
      "        [ 0.0225],\n",
      "        [ 0.0199],\n",
      "        [ 0.0628],\n",
      "        [ 0.0200],\n",
      "        [ 0.0502],\n",
      "        [ 0.0566],\n",
      "        [ 0.0342],\n",
      "        [-0.0094],\n",
      "        [-0.0379],\n",
      "        [ 0.0809],\n",
      "        [ 0.0359],\n",
      "        [ 0.0320],\n",
      "        [-0.0452],\n",
      "        [-0.0783]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0226, 0.0218, 0.0217, 0.0219, 0.0213, 0.0210, 0.0199, 0.0200, 0.0206,\n",
      "        0.0213, 0.0212, 0.0212, 0.0209, 0.0206, 0.0209, 0.0220, 0.0218, 0.0213,\n",
      "        0.0211, 0.0203, 0.0203, 0.0196, 0.0196, 0.0195, 0.0190, 0.0179, 0.0170,\n",
      "        0.0184, 0.0186, 0.0186, 0.0185, 0.0182], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0509],\n",
      "        [-0.0157],\n",
      "        [ 0.0230],\n",
      "        [ 0.0582],\n",
      "        [ 0.0341],\n",
      "        [-0.0428],\n",
      "        [-0.0294],\n",
      "        [ 0.0393],\n",
      "        [ 0.0289],\n",
      "        [ 0.0109],\n",
      "        [ 0.0320],\n",
      "        [ 0.1396],\n",
      "        [ 0.0192],\n",
      "        [ 0.0691],\n",
      "        [ 0.0182],\n",
      "        [-0.0300],\n",
      "        [ 0.0263],\n",
      "        [ 0.0391],\n",
      "        [ 0.0010],\n",
      "        [ 0.0305],\n",
      "        [ 0.0202],\n",
      "        [-0.0067],\n",
      "        [ 0.0348],\n",
      "        [ 0.0417],\n",
      "        [ 0.0036],\n",
      "        [ 0.0480],\n",
      "        [ 0.0436],\n",
      "        [ 0.1173],\n",
      "        [ 0.0052],\n",
      "        [ 0.0245],\n",
      "        [ 0.0636],\n",
      "        [ 0.1283]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0179, 0.0172, 0.0179, 0.0186, 0.0184, 0.0189, 0.0203, 0.0196, 0.0196,\n",
      "        0.0188, 0.0180, 0.0184, 0.0184, 0.0193, 0.0194, 0.0184, 0.0180, 0.0182,\n",
      "        0.0174, 0.0173, 0.0173, 0.0168, 0.0153, 0.0172, 0.0167, 0.0177, 0.0182,\n",
      "        0.0180, 0.0181, 0.0191, 0.0182, 0.0183], device='cuda:0')\n",
      "tensor([[ 0.0566],\n",
      "        [-0.0054],\n",
      "        [ 0.0329],\n",
      "        [-0.0051],\n",
      "        [ 0.0689],\n",
      "        [ 0.0242],\n",
      "        [-0.0062],\n",
      "        [ 0.0274],\n",
      "        [-0.0082],\n",
      "        [ 0.0412],\n",
      "        [-0.0134],\n",
      "        [ 0.0335],\n",
      "        [ 0.0140],\n",
      "        [ 0.0816],\n",
      "        [ 0.0123],\n",
      "        [ 0.0355],\n",
      "        [ 0.0603],\n",
      "        [ 0.0106],\n",
      "        [ 0.0300],\n",
      "        [-0.0021],\n",
      "        [ 0.0058],\n",
      "        [ 0.0316],\n",
      "        [ 0.0263],\n",
      "        [-0.0092],\n",
      "        [-0.0111],\n",
      "        [-0.0162],\n",
      "        [ 0.1723],\n",
      "        [ 0.0298],\n",
      "        [-0.0220],\n",
      "        [ 0.0279],\n",
      "        [ 0.0053],\n",
      "        [ 0.0914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0188, 0.0188, 0.0196, 0.0196, 0.0201, 0.0203, 0.0199, 0.0209, 0.0214,\n",
      "        0.0213, 0.0216, 0.0219, 0.0220, 0.0224, 0.0223, 0.0220, 0.0224, 0.0231,\n",
      "        0.0229, 0.0226, 0.0218, 0.0218, 0.0228, 0.0240, 0.0245, 0.0248, 0.0251,\n",
      "        0.0244, 0.0241, 0.0247, 0.0251, 0.0258], device='cuda:0')\n",
      "tensor([[ 0.0238],\n",
      "        [ 0.0263],\n",
      "        [-0.0122],\n",
      "        [-0.0199],\n",
      "        [-0.0129],\n",
      "        [ 0.0805],\n",
      "        [ 0.0009],\n",
      "        [ 0.0542],\n",
      "        [ 0.0383],\n",
      "        [-0.0038],\n",
      "        [ 0.0369],\n",
      "        [ 0.0592],\n",
      "        [ 0.0789],\n",
      "        [ 0.0783],\n",
      "        [ 0.0806],\n",
      "        [-0.0227],\n",
      "        [-0.0314],\n",
      "        [ 0.0805],\n",
      "        [ 0.0102],\n",
      "        [-0.0174],\n",
      "        [-0.0211],\n",
      "        [ 0.0325],\n",
      "        [ 0.0480],\n",
      "        [-0.0106],\n",
      "        [ 0.0445],\n",
      "        [ 0.0113],\n",
      "        [ 0.0864],\n",
      "        [ 0.0866],\n",
      "        [-0.0130],\n",
      "        [ 0.1219],\n",
      "        [ 0.0372],\n",
      "        [ 0.0603]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0260, 0.0252, 0.0257, 0.0259, 0.0258, 0.0248, 0.0246, 0.0244, 0.0248,\n",
      "        0.0247, 0.0244, 0.0241, 0.0239, 0.0241, 0.0243, 0.0246, 0.0243, 0.0238,\n",
      "        0.0242, 0.0254, 0.0263, 0.0267, 0.0273, 0.0270, 0.0275, 0.0261, 0.0265,\n",
      "        0.0269, 0.0268, 0.0268, 0.0277, 0.0279], device='cuda:0')\n",
      "tensor([[ 0.0170],\n",
      "        [-0.0063],\n",
      "        [-0.0229],\n",
      "        [ 0.0404],\n",
      "        [ 0.0352],\n",
      "        [ 0.0215],\n",
      "        [ 0.0075],\n",
      "        [ 0.0336],\n",
      "        [ 0.0178],\n",
      "        [-0.0115],\n",
      "        [-0.0391],\n",
      "        [ 0.0066],\n",
      "        [-0.0106],\n",
      "        [ 0.0789],\n",
      "        [ 0.0514],\n",
      "        [ 0.0321],\n",
      "        [ 0.0497],\n",
      "        [ 0.0521],\n",
      "        [ 0.1449],\n",
      "        [-0.0249],\n",
      "        [ 0.1286],\n",
      "        [ 0.0763],\n",
      "        [ 0.0300],\n",
      "        [ 0.0419],\n",
      "        [ 0.0529],\n",
      "        [ 0.0908],\n",
      "        [-0.0165],\n",
      "        [-0.0403],\n",
      "        [ 0.0169],\n",
      "        [ 0.0377],\n",
      "        [ 0.0349],\n",
      "        [ 0.0402]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0275, 0.0276, 0.0281, 0.0285, 0.0279, 0.0271, 0.0275, 0.0278, 0.0277,\n",
      "        0.0277, 0.0291, 0.0296, 0.0296, 0.0303, 0.0312, 0.0319, 0.0311, 0.0309,\n",
      "        0.0307, 0.0308, 0.0306, 0.0309, 0.0299, 0.0315, 0.0327, 0.0328, 0.0327,\n",
      "        0.0327, 0.0326, 0.0323, 0.0323, 0.0327], device='cuda:0')\n",
      "tensor([[ 0.1439],\n",
      "        [ 0.0590],\n",
      "        [-0.0128],\n",
      "        [-0.0040],\n",
      "        [-0.0142],\n",
      "        [ 0.0072],\n",
      "        [ 0.0327],\n",
      "        [ 0.0226],\n",
      "        [ 0.0279],\n",
      "        [ 0.0377],\n",
      "        [ 0.0267],\n",
      "        [ 0.0246],\n",
      "        [ 0.0166],\n",
      "        [ 0.0252],\n",
      "        [ 0.0715],\n",
      "        [ 0.0537],\n",
      "        [ 0.0898],\n",
      "        [ 0.0547],\n",
      "        [-0.0304],\n",
      "        [ 0.0041],\n",
      "        [-0.0048],\n",
      "        [ 0.0068],\n",
      "        [ 0.0399],\n",
      "        [-0.0545],\n",
      "        [ 0.0518],\n",
      "        [-0.0240],\n",
      "        [ 0.0385],\n",
      "        [ 0.0224],\n",
      "        [ 0.0074],\n",
      "        [-0.0042],\n",
      "        [ 0.0421],\n",
      "        [-0.0112]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0328, 0.0321, 0.0329, 0.0339, 0.0339, 0.0332, 0.0332, 0.0332, 0.0345,\n",
      "        0.0352, 0.0348, 0.0347, 0.0347, 0.0340, 0.0327, 0.0328, 0.0332, 0.0343,\n",
      "        0.0335, 0.0328, 0.0339, 0.0335, 0.0346, 0.0349, 0.0348, 0.0351, 0.0359,\n",
      "        0.0361, 0.0360, 0.0366, 0.0376, 0.0373], device='cuda:0')\n",
      "tensor([[ 0.0402],\n",
      "        [ 0.0404],\n",
      "        [ 0.0490],\n",
      "        [ 0.1207],\n",
      "        [ 0.0551],\n",
      "        [ 0.0359],\n",
      "        [ 0.1199],\n",
      "        [-0.0123],\n",
      "        [-0.0446],\n",
      "        [ 0.0053],\n",
      "        [-0.0072],\n",
      "        [ 0.1175],\n",
      "        [-0.0023],\n",
      "        [-0.0067],\n",
      "        [ 0.0084],\n",
      "        [-0.0264],\n",
      "        [-0.0019],\n",
      "        [ 0.0927],\n",
      "        [ 0.0250],\n",
      "        [ 0.0041],\n",
      "        [ 0.0120],\n",
      "        [ 0.0441],\n",
      "        [-0.0143],\n",
      "        [ 0.0055],\n",
      "        [-0.0070],\n",
      "        [ 0.0016],\n",
      "        [ 0.0168],\n",
      "        [ 0.0237],\n",
      "        [-0.0259],\n",
      "        [ 0.0021],\n",
      "        [ 0.0317],\n",
      "        [ 0.0225]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0394, 0.0394, 0.0377, 0.0377, 0.0377, 0.0376, 0.0375, 0.0368, 0.0352,\n",
      "        0.0358, 0.0359, 0.0359, 0.0355, 0.0367, 0.0368, 0.0369, 0.0365, 0.0365,\n",
      "        0.0356, 0.0356, 0.0366, 0.0362, 0.0362, 0.0358, 0.0369, 0.0361, 0.0357,\n",
      "        0.0371, 0.0374, 0.0378, 0.0381, 0.0383], device='cuda:0')\n",
      "tensor([[ 0.0446],\n",
      "        [ 0.0441],\n",
      "        [-0.0077],\n",
      "        [ 0.0112],\n",
      "        [ 0.0053],\n",
      "        [ 0.0150],\n",
      "        [ 0.1767],\n",
      "        [ 0.1049],\n",
      "        [ 0.0641],\n",
      "        [ 0.0213],\n",
      "        [ 0.0487],\n",
      "        [-0.0236],\n",
      "        [ 0.0197],\n",
      "        [-0.0390],\n",
      "        [ 0.0133],\n",
      "        [ 0.0091],\n",
      "        [ 0.0145],\n",
      "        [ 0.0663],\n",
      "        [-0.0118],\n",
      "        [ 0.0317],\n",
      "        [-0.0106],\n",
      "        [ 0.0111],\n",
      "        [ 0.0222],\n",
      "        [ 0.0021],\n",
      "        [ 0.0270],\n",
      "        [ 0.0080],\n",
      "        [ 0.0128],\n",
      "        [-0.0165],\n",
      "        [ 0.0486],\n",
      "        [ 0.0246],\n",
      "        [ 0.0113],\n",
      "        [ 0.0340]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0388, 0.0397, 0.0397, 0.0397, 0.0395, 0.0395, 0.0394, 0.0394, 0.0400,\n",
      "        0.0410, 0.0402, 0.0397, 0.0397, 0.0395, 0.0397, 0.0400, 0.0399, 0.0399,\n",
      "        0.0402, 0.0405, 0.0401, 0.0402, 0.0401, 0.0402, 0.0401, 0.0393, 0.0395,\n",
      "        0.0396, 0.0392, 0.0387, 0.0397, 0.0404], device='cuda:0')\n",
      "tensor([[ 0.0249],\n",
      "        [ 0.0252],\n",
      "        [-0.0306],\n",
      "        [ 0.0470],\n",
      "        [ 0.0712],\n",
      "        [ 0.0653],\n",
      "        [ 0.0201],\n",
      "        [ 0.1354],\n",
      "        [ 0.0414],\n",
      "        [-0.0042],\n",
      "        [ 0.0853],\n",
      "        [ 0.0117],\n",
      "        [-0.0097],\n",
      "        [ 0.0444],\n",
      "        [ 0.0606],\n",
      "        [ 0.0606],\n",
      "        [ 0.1545],\n",
      "        [ 0.0897],\n",
      "        [ 0.0336],\n",
      "        [ 0.0334],\n",
      "        [ 0.0071],\n",
      "        [ 0.0355],\n",
      "        [-0.0138],\n",
      "        [-0.0031],\n",
      "        [ 0.0502],\n",
      "        [-0.0465],\n",
      "        [ 0.0883],\n",
      "        [ 0.0188],\n",
      "        [ 0.0010],\n",
      "        [ 0.0171],\n",
      "        [ 0.0832],\n",
      "        [ 0.0218]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0405, 0.0407, 0.0415, 0.0409, 0.0407, 0.0409, 0.0409, 0.0410, 0.0404,\n",
      "        0.0392, 0.0388, 0.0385, 0.0386, 0.0391, 0.0388, 0.0395, 0.0395, 0.0391,\n",
      "        0.0393, 0.0388, 0.0381, 0.0381, 0.0387, 0.0389, 0.0397, 0.0398, 0.0400,\n",
      "        0.0403, 0.0401, 0.0402, 0.0413, 0.0418], device='cuda:0')\n",
      "tensor([[-0.0262],\n",
      "        [ 0.0456],\n",
      "        [ 0.0731],\n",
      "        [-0.0050],\n",
      "        [ 0.0340],\n",
      "        [-0.0231],\n",
      "        [ 0.0462],\n",
      "        [ 0.0421],\n",
      "        [-0.0248],\n",
      "        [-0.0055],\n",
      "        [ 0.0706],\n",
      "        [ 0.0358],\n",
      "        [ 0.0698],\n",
      "        [ 0.0577],\n",
      "        [ 0.0751],\n",
      "        [ 0.1051],\n",
      "        [ 0.0229],\n",
      "        [ 0.0528],\n",
      "        [-0.0237],\n",
      "        [ 0.0761],\n",
      "        [-0.0082],\n",
      "        [ 0.0312],\n",
      "        [ 0.0088],\n",
      "        [ 0.0536],\n",
      "        [ 0.0280],\n",
      "        [ 0.0484],\n",
      "        [-0.0148],\n",
      "        [-0.0272],\n",
      "        [-0.0134],\n",
      "        [ 0.0266],\n",
      "        [-0.0134],\n",
      "        [-0.0410]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0418, 0.0411, 0.0411, 0.0414, 0.0418, 0.0414, 0.0446, 0.0448, 0.0460,\n",
      "        0.0451, 0.0454, 0.0457, 0.0455, 0.0448, 0.0456, 0.0456, 0.0478, 0.0478,\n",
      "        0.0482, 0.0480, 0.0492, 0.0492, 0.0499, 0.0496, 0.0487, 0.0498, 0.0506,\n",
      "        0.0513, 0.0505, 0.0504, 0.0503, 0.0509], device='cuda:0')\n",
      "tensor([[ 0.0556],\n",
      "        [ 0.0694],\n",
      "        [ 0.0802],\n",
      "        [ 0.0081],\n",
      "        [-0.0049],\n",
      "        [-0.0067],\n",
      "        [-0.0095],\n",
      "        [-0.0095],\n",
      "        [ 0.0476],\n",
      "        [ 0.0575],\n",
      "        [ 0.0500],\n",
      "        [-0.0412],\n",
      "        [ 0.1424],\n",
      "        [ 0.0341],\n",
      "        [-0.0274],\n",
      "        [ 0.0504],\n",
      "        [ 0.0180],\n",
      "        [ 0.0192],\n",
      "        [ 0.1080],\n",
      "        [ 0.0260],\n",
      "        [ 0.0087],\n",
      "        [ 0.0619],\n",
      "        [ 0.0644],\n",
      "        [ 0.0289],\n",
      "        [ 0.0312],\n",
      "        [ 0.0176],\n",
      "        [-0.0245],\n",
      "        [ 0.0308],\n",
      "        [ 0.0081],\n",
      "        [ 0.0531],\n",
      "        [ 0.0064],\n",
      "        [ 0.0258]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0513, 0.0512, 0.0508, 0.0497, 0.0495, 0.0492, 0.0493, 0.0488, 0.0492,\n",
      "        0.0500, 0.0504, 0.0500, 0.0510, 0.0528, 0.0535, 0.0516, 0.0537, 0.0531,\n",
      "        0.0532, 0.0536, 0.0532, 0.0532, 0.0530, 0.0535, 0.0551, 0.0550, 0.0554,\n",
      "        0.0563, 0.0568, 0.0570, 0.0564, 0.0567], device='cuda:0')\n",
      "tensor([[ 0.0740],\n",
      "        [ 0.1834],\n",
      "        [ 0.0752],\n",
      "        [ 0.0762],\n",
      "        [ 0.0531],\n",
      "        [ 0.0424],\n",
      "        [ 0.0161],\n",
      "        [-0.0317],\n",
      "        [ 0.0608],\n",
      "        [ 0.0884],\n",
      "        [-0.0005],\n",
      "        [ 0.0914],\n",
      "        [ 0.0264],\n",
      "        [-0.0031],\n",
      "        [ 0.0024],\n",
      "        [ 0.0227],\n",
      "        [ 0.0046],\n",
      "        [ 0.0298],\n",
      "        [-0.0214],\n",
      "        [ 0.1058],\n",
      "        [-0.0254],\n",
      "        [-0.0244],\n",
      "        [ 0.0339],\n",
      "        [ 0.0008],\n",
      "        [ 0.0154],\n",
      "        [ 0.0467],\n",
      "        [ 0.0466],\n",
      "        [ 0.0274],\n",
      "        [ 0.0370],\n",
      "        [ 0.0322],\n",
      "        [-0.0292],\n",
      "        [ 0.0055]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0572, 0.0560, 0.0537, 0.0536, 0.0545, 0.0542, 0.0532, 0.0535, 0.0545,\n",
      "        0.0545, 0.0548, 0.0532, 0.0523, 0.0502, 0.0508, 0.0513, 0.0514, 0.0520,\n",
      "        0.0526, 0.0535, 0.0543, 0.0535, 0.0535, 0.0541, 0.0541, 0.0524, 0.0543,\n",
      "        0.0532, 0.0536, 0.0538, 0.0533, 0.0527], device='cuda:0')\n",
      "tensor([[ 0.0108],\n",
      "        [ 0.0353],\n",
      "        [ 0.0462],\n",
      "        [ 0.0299],\n",
      "        [ 0.0527],\n",
      "        [-0.0004],\n",
      "        [ 0.0490],\n",
      "        [-0.0110],\n",
      "        [ 0.0776],\n",
      "        [-0.0146],\n",
      "        [ 0.0110],\n",
      "        [ 0.0506],\n",
      "        [ 0.0669],\n",
      "        [-0.0243],\n",
      "        [ 0.0368],\n",
      "        [ 0.0089],\n",
      "        [ 0.0142],\n",
      "        [ 0.0846],\n",
      "        [ 0.0523],\n",
      "        [ 0.0350],\n",
      "        [ 0.0360],\n",
      "        [ 0.0736],\n",
      "        [ 0.0163],\n",
      "        [ 0.0214],\n",
      "        [ 0.0010],\n",
      "        [ 0.0171],\n",
      "        [-0.0274],\n",
      "        [-0.0054],\n",
      "        [ 0.0592],\n",
      "        [ 0.0168],\n",
      "        [ 0.0152],\n",
      "        [ 0.2262]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0509, 0.0515, 0.0511, 0.0507, 0.0500, 0.0507, 0.0491, 0.0482, 0.0482,\n",
      "        0.0498, 0.0499, 0.0489, 0.0498, 0.0510, 0.0515, 0.0504, 0.0501, 0.0509,\n",
      "        0.0504, 0.0492, 0.0489, 0.0471, 0.0480, 0.0501, 0.0498, 0.0492, 0.0508,\n",
      "        0.0510, 0.0505, 0.0484, 0.0503, 0.0505], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0232],\n",
      "        [-0.0158],\n",
      "        [-0.0380],\n",
      "        [ 0.0405],\n",
      "        [ 0.0360],\n",
      "        [ 0.0992],\n",
      "        [-0.0131],\n",
      "        [-0.0158],\n",
      "        [ 0.0379],\n",
      "        [ 0.0694],\n",
      "        [-0.0083],\n",
      "        [ 0.0097],\n",
      "        [ 0.0038],\n",
      "        [ 0.0294],\n",
      "        [ 0.0352],\n",
      "        [ 0.0360],\n",
      "        [ 0.1369],\n",
      "        [ 0.1488],\n",
      "        [ 0.0414],\n",
      "        [ 0.0041],\n",
      "        [-0.0153],\n",
      "        [ 0.0201],\n",
      "        [ 0.0618],\n",
      "        [-0.0056],\n",
      "        [-0.0172],\n",
      "        [ 0.0233],\n",
      "        [ 0.0487],\n",
      "        [-0.0559],\n",
      "        [ 0.0646],\n",
      "        [ 0.0174],\n",
      "        [ 0.0195],\n",
      "        [ 0.0507]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0494, 0.0500, 0.0492, 0.0499, 0.0501, 0.0509, 0.0513, 0.0516, 0.0531,\n",
      "        0.0552, 0.0557, 0.0562, 0.0560, 0.0551, 0.0565, 0.0564, 0.0574, 0.0573,\n",
      "        0.0569, 0.0567, 0.0563, 0.0559, 0.0558, 0.0581, 0.0578, 0.0582, 0.0585,\n",
      "        0.0597, 0.0607, 0.0617, 0.0629, 0.0620], device='cuda:0')\n",
      "tensor([[ 0.0541],\n",
      "        [ 0.0645],\n",
      "        [ 0.0928],\n",
      "        [ 0.0214],\n",
      "        [ 0.0263],\n",
      "        [ 0.0436],\n",
      "        [ 0.0068],\n",
      "        [ 0.0205],\n",
      "        [-0.0056],\n",
      "        [ 0.0182],\n",
      "        [ 0.0383],\n",
      "        [ 0.0226],\n",
      "        [ 0.1295],\n",
      "        [ 0.0755],\n",
      "        [ 0.0346],\n",
      "        [ 0.0253],\n",
      "        [ 0.0318],\n",
      "        [ 0.0187],\n",
      "        [ 0.0156],\n",
      "        [ 0.0325],\n",
      "        [-0.0270],\n",
      "        [ 0.0229],\n",
      "        [ 0.0551],\n",
      "        [-0.0139],\n",
      "        [ 0.0527],\n",
      "        [ 0.0351],\n",
      "        [-0.0119],\n",
      "        [ 0.0676],\n",
      "        [ 0.0713],\n",
      "        [ 0.0397],\n",
      "        [ 0.0118],\n",
      "        [ 0.0525]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0617, 0.0619, 0.0619, 0.0613, 0.0608, 0.0598, 0.0600, 0.0597, 0.0590,\n",
      "        0.0575, 0.0575, 0.0587, 0.0584, 0.0578, 0.0585, 0.0593, 0.0600, 0.0624,\n",
      "        0.0650, 0.0693, 0.0680, 0.0669, 0.0676, 0.0681, 0.0683, 0.0681, 0.0657,\n",
      "        0.0647, 0.0626, 0.0626, 0.0654, 0.0653], device='cuda:0')\n",
      "tensor([[ 0.0743],\n",
      "        [-0.0715],\n",
      "        [-0.0084],\n",
      "        [-0.1013],\n",
      "        [ 0.0267],\n",
      "        [ 0.0265],\n",
      "        [ 0.0448],\n",
      "        [ 0.1252],\n",
      "        [ 0.0272],\n",
      "        [-0.0003],\n",
      "        [ 0.0056],\n",
      "        [ 0.0589],\n",
      "        [ 0.0897],\n",
      "        [ 0.0505],\n",
      "        [ 0.1055],\n",
      "        [ 0.0514],\n",
      "        [ 0.0196],\n",
      "        [ 0.0237],\n",
      "        [ 0.0173],\n",
      "        [-0.0088],\n",
      "        [ 0.0614],\n",
      "        [ 0.0041],\n",
      "        [ 0.0040],\n",
      "        [ 0.1507],\n",
      "        [-0.0081],\n",
      "        [-0.0144],\n",
      "        [ 0.0082],\n",
      "        [ 0.0619],\n",
      "        [ 0.0089],\n",
      "        [ 0.0437],\n",
      "        [ 0.0081],\n",
      "        [ 0.0453]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0630, 0.0644, 0.0659, 0.0643, 0.0637, 0.0639, 0.0653, 0.0669, 0.0665,\n",
      "        0.0653, 0.0645, 0.0650, 0.0646, 0.0653, 0.0622, 0.0615, 0.0619, 0.0600,\n",
      "        0.0591, 0.0590, 0.0607, 0.0605, 0.0601, 0.0600, 0.0606, 0.0601, 0.0598,\n",
      "        0.0607, 0.0618, 0.0608, 0.0611, 0.0622], device='cuda:0')\n",
      "tensor([[ 0.0234],\n",
      "        [ 0.0461],\n",
      "        [ 0.0223],\n",
      "        [ 0.0308],\n",
      "        [ 0.0790],\n",
      "        [ 0.1102],\n",
      "        [ 0.0692],\n",
      "        [ 0.0174],\n",
      "        [ 0.0262],\n",
      "        [-0.0344],\n",
      "        [ 0.0275],\n",
      "        [ 0.0521],\n",
      "        [ 0.0119],\n",
      "        [ 0.0003],\n",
      "        [ 0.0520],\n",
      "        [ 0.0143],\n",
      "        [ 0.0079],\n",
      "        [ 0.0364],\n",
      "        [ 0.0110],\n",
      "        [-0.0003],\n",
      "        [ 0.0623],\n",
      "        [ 0.0435],\n",
      "        [ 0.0044],\n",
      "        [ 0.1066],\n",
      "        [ 0.0258],\n",
      "        [ 0.0298],\n",
      "        [ 0.0012],\n",
      "        [ 0.0137],\n",
      "        [ 0.0354],\n",
      "        [-0.0168],\n",
      "        [ 0.1079],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0621, 0.0619, 0.0606, 0.0610, 0.0606, 0.0606, 0.0598, 0.0602, 0.0608,\n",
      "        0.0610, 0.0611, 0.0607, 0.0603, 0.0603, 0.0604, 0.0601, 0.0603, 0.0600,\n",
      "        0.0589, 0.0603, 0.0603, 0.0600, 0.0592, 0.0598, 0.0580, 0.0574, 0.0589,\n",
      "        0.0587, 0.0588, 0.0585, 0.0575, 0.0562], device='cuda:0')\n",
      "tensor([[-0.0164],\n",
      "        [-0.0104],\n",
      "        [ 0.0022],\n",
      "        [ 0.0041],\n",
      "        [ 0.0980],\n",
      "        [-0.0296],\n",
      "        [ 0.0486],\n",
      "        [-0.0180],\n",
      "        [ 0.0119],\n",
      "        [ 0.0048],\n",
      "        [ 0.0177],\n",
      "        [ 0.0158],\n",
      "        [-0.0283],\n",
      "        [-0.0164],\n",
      "        [ 0.0539],\n",
      "        [ 0.0572],\n",
      "        [ 0.0287],\n",
      "        [ 0.0063],\n",
      "        [ 0.0508],\n",
      "        [ 0.0073],\n",
      "        [ 0.0148],\n",
      "        [ 0.0680],\n",
      "        [ 0.0784],\n",
      "        [ 0.1180],\n",
      "        [ 0.0292],\n",
      "        [ 0.0076],\n",
      "        [ 0.0277],\n",
      "        [ 0.0209],\n",
      "        [ 0.0209],\n",
      "        [ 0.0948],\n",
      "        [ 0.0632],\n",
      "        [ 0.0239]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0551, 0.0561, 0.0580, 0.0580, 0.0572, 0.0558, 0.0555, 0.0548, 0.0538,\n",
      "        0.0532, 0.0537, 0.0551, 0.0539, 0.0555, 0.0552, 0.0563, 0.0572, 0.0575,\n",
      "        0.0580, 0.0569, 0.0575, 0.0577, 0.0581, 0.0580, 0.0586, 0.0597, 0.0595,\n",
      "        0.0584, 0.0587, 0.0583, 0.0577, 0.0580], device='cuda:0')\n",
      "tensor([[-0.0222],\n",
      "        [ 0.0729],\n",
      "        [ 0.0479],\n",
      "        [-0.0394],\n",
      "        [ 0.0123],\n",
      "        [ 0.0577],\n",
      "        [ 0.0172],\n",
      "        [ 0.0428],\n",
      "        [ 0.0407],\n",
      "        [ 0.0580],\n",
      "        [-0.0341],\n",
      "        [ 0.0222],\n",
      "        [ 0.0498],\n",
      "        [ 0.0233],\n",
      "        [ 0.0070],\n",
      "        [ 0.0101],\n",
      "        [-0.0002],\n",
      "        [ 0.0127],\n",
      "        [ 0.0432],\n",
      "        [ 0.0734],\n",
      "        [ 0.0728],\n",
      "        [-0.0208],\n",
      "        [ 0.0266],\n",
      "        [ 0.0283],\n",
      "        [-0.0120],\n",
      "        [-0.0277],\n",
      "        [ 0.0683],\n",
      "        [ 0.0197],\n",
      "        [ 0.0593],\n",
      "        [ 0.0433],\n",
      "        [ 0.0601],\n",
      "        [ 0.0293]], device='cuda:0', grad_fn=<AddmmBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([0.0582, 0.0565, 0.0555, 0.0553, 0.0562, 0.0577, 0.0568, 0.0558, 0.0565,\n",
      "        0.0562, 0.0561, 0.0548, 0.0551, 0.0548, 0.0544, 0.0522, 0.0524, 0.0530,\n",
      "        0.0539, 0.0529, 0.0516, 0.0536, 0.0536, 0.0546, 0.0533, 0.0516, 0.0523,\n",
      "        0.0523, 0.0517, 0.0515, 0.0515, 0.0515], device='cuda:0')\n",
      "tensor([[ 0.0114],\n",
      "        [ 0.1234],\n",
      "        [ 0.0456],\n",
      "        [ 0.0107],\n",
      "        [ 0.0123],\n",
      "        [-0.0162],\n",
      "        [ 0.0130],\n",
      "        [-0.0473],\n",
      "        [ 0.0132],\n",
      "        [-0.0093],\n",
      "        [-0.0124],\n",
      "        [ 0.0355],\n",
      "        [ 0.0069],\n",
      "        [ 0.0304],\n",
      "        [-0.0075],\n",
      "        [ 0.0313],\n",
      "        [ 0.0195],\n",
      "        [ 0.0046],\n",
      "        [-0.0078],\n",
      "        [-0.0189],\n",
      "        [ 0.0574],\n",
      "        [ 0.0197],\n",
      "        [ 0.0091],\n",
      "        [ 0.0115],\n",
      "        [ 0.0233],\n",
      "        [ 0.0014],\n",
      "        [ 0.0015],\n",
      "        [ 0.0271],\n",
      "        [ 0.0117],\n",
      "        [ 0.0682],\n",
      "        [ 0.0468],\n",
      "        [ 0.0286]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0507, 0.0508, 0.0507, 0.0504, 0.0507, 0.0508, 0.0509, 0.0511, 0.0523,\n",
      "        0.0529, 0.0540, 0.0536, 0.0516, 0.0516, 0.0505, 0.0505, 0.0508, 0.0507,\n",
      "        0.0512, 0.0506, 0.0500, 0.0506, 0.0510, 0.0518, 0.0518, 0.0515, 0.0524,\n",
      "        0.0523, 0.0515, 0.0503, 0.0506, 0.0520], device='cuda:0')\n",
      "tensor([[ 0.0155],\n",
      "        [-0.0231],\n",
      "        [-0.0390],\n",
      "        [ 0.0594],\n",
      "        [ 0.0057],\n",
      "        [-0.0010],\n",
      "        [ 0.0188],\n",
      "        [ 0.0679],\n",
      "        [ 0.0527],\n",
      "        [ 0.0381],\n",
      "        [ 0.0626],\n",
      "        [ 0.0845],\n",
      "        [ 0.0659],\n",
      "        [ 0.0263],\n",
      "        [ 0.0851],\n",
      "        [ 0.0267],\n",
      "        [-0.0098],\n",
      "        [ 0.0689],\n",
      "        [ 0.0419],\n",
      "        [ 0.0076],\n",
      "        [ 0.0355],\n",
      "        [ 0.0003],\n",
      "        [-0.0081],\n",
      "        [ 0.0210],\n",
      "        [ 0.0617],\n",
      "        [-0.0470],\n",
      "        [ 0.0048],\n",
      "        [-0.0184],\n",
      "        [ 0.0233],\n",
      "        [ 0.0215],\n",
      "        [ 0.0413],\n",
      "        [ 0.1093]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0515, 0.0524, 0.0529, 0.0529, 0.0531, 0.0535, 0.0538, 0.0542, 0.0549,\n",
      "        0.0546, 0.0542, 0.0541, 0.0533, 0.0531, 0.0544, 0.0548, 0.0545, 0.0538,\n",
      "        0.0541, 0.0536, 0.0532, 0.0535, 0.0535, 0.0545, 0.0542, 0.0552, 0.0558,\n",
      "        0.0573, 0.0580, 0.0582, 0.0576, 0.0578], device='cuda:0')\n",
      "tensor([[ 0.0405],\n",
      "        [ 0.1875],\n",
      "        [ 0.1008],\n",
      "        [ 0.0471],\n",
      "        [ 0.1008],\n",
      "        [ 0.0736],\n",
      "        [ 0.0626],\n",
      "        [-0.0147],\n",
      "        [ 0.0400],\n",
      "        [-0.0118],\n",
      "        [-0.0046],\n",
      "        [ 0.0046],\n",
      "        [ 0.0231],\n",
      "        [-0.0065],\n",
      "        [ 0.0254],\n",
      "        [ 0.0275],\n",
      "        [ 0.0563],\n",
      "        [ 0.0029],\n",
      "        [ 0.0997],\n",
      "        [ 0.0386],\n",
      "        [ 0.0220],\n",
      "        [-0.0116],\n",
      "        [-0.0077],\n",
      "        [-0.0276],\n",
      "        [-0.0333],\n",
      "        [ 0.0434],\n",
      "        [-0.0128],\n",
      "        [-0.0048],\n",
      "        [ 0.0758],\n",
      "        [ 0.0135],\n",
      "        [-0.0125],\n",
      "        [-0.0400]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0581, 0.0590, 0.0584, 0.0586, 0.0580, 0.0578, 0.0590, 0.0596, 0.0587,\n",
      "        0.0588, 0.0573, 0.0562, 0.0569, 0.0570, 0.0580, 0.0580, 0.0568, 0.0567,\n",
      "        0.0561, 0.0562, 0.0558, 0.0561, 0.0558, 0.0551, 0.0545, 0.0540, 0.0538,\n",
      "        0.0535, 0.0543, 0.0548, 0.0549, 0.0549], device='cuda:0')\n",
      "tensor([[ 0.0157],\n",
      "        [-0.0099],\n",
      "        [ 0.0167],\n",
      "        [ 0.0028],\n",
      "        [-0.0016],\n",
      "        [-0.0124],\n",
      "        [ 0.0286],\n",
      "        [ 0.0031],\n",
      "        [-0.0050],\n",
      "        [ 0.0065],\n",
      "        [ 0.1084],\n",
      "        [ 0.0816],\n",
      "        [ 0.0974],\n",
      "        [ 0.0047],\n",
      "        [ 0.0868],\n",
      "        [ 0.1497],\n",
      "        [ 0.1193],\n",
      "        [ 0.0222],\n",
      "        [ 0.0234],\n",
      "        [-0.0613],\n",
      "        [ 0.0557],\n",
      "        [-0.0630],\n",
      "        [ 0.0081],\n",
      "        [ 0.0204],\n",
      "        [ 0.0211],\n",
      "        [ 0.0398],\n",
      "        [ 0.0512],\n",
      "        [-0.0194],\n",
      "        [ 0.0100],\n",
      "        [-0.0050],\n",
      "        [-0.0369],\n",
      "        [-0.0190]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0549, 0.0545, 0.0552, 0.0576, 0.0564, 0.0586, 0.0590, 0.0605, 0.0604,\n",
      "        0.0629, 0.0637, 0.0629, 0.0601, 0.0595, 0.0580, 0.0590, 0.0567, 0.0571,\n",
      "        0.0583, 0.0581, 0.0570, 0.0559, 0.0564, 0.0556, 0.0555, 0.0547, 0.0546,\n",
      "        0.0552, 0.0574, 0.0585, 0.0579, 0.0597], device='cuda:0')\n",
      "tensor([[-0.0467],\n",
      "        [ 0.0420],\n",
      "        [ 0.0287],\n",
      "        [ 0.0256],\n",
      "        [ 0.1492],\n",
      "        [ 0.0783],\n",
      "        [ 0.0456],\n",
      "        [ 0.0121],\n",
      "        [-0.0196],\n",
      "        [-0.0054],\n",
      "        [ 0.0177],\n",
      "        [ 0.0243],\n",
      "        [ 0.0245],\n",
      "        [-0.0171],\n",
      "        [ 0.0510],\n",
      "        [-0.0117],\n",
      "        [ 0.0159],\n",
      "        [ 0.0574],\n",
      "        [ 0.0083],\n",
      "        [ 0.1006],\n",
      "        [-0.0112],\n",
      "        [ 0.0052],\n",
      "        [-0.0278],\n",
      "        [ 0.0244],\n",
      "        [ 0.0430],\n",
      "        [ 0.0465],\n",
      "        [-0.0574],\n",
      "        [ 0.0833],\n",
      "        [ 0.0720],\n",
      "        [ 0.0154],\n",
      "        [ 0.0049],\n",
      "        [ 0.0135]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0601, 0.0595, 0.0595, 0.0585, 0.0588, 0.0598, 0.0607, 0.0609, 0.0613,\n",
      "        0.0615, 0.0626, 0.0631, 0.0634, 0.0613, 0.0610, 0.0617, 0.0629, 0.0622,\n",
      "        0.0619, 0.0612, 0.0611, 0.0606, 0.0599, 0.0607, 0.0630, 0.0619, 0.0623,\n",
      "        0.0620, 0.0626, 0.0627, 0.0630, 0.0636], device='cuda:0')\n",
      "tensor([[ 0.0273],\n",
      "        [ 0.0074],\n",
      "        [ 0.0009],\n",
      "        [ 0.0429],\n",
      "        [ 0.0052],\n",
      "        [ 0.1594],\n",
      "        [ 0.0710],\n",
      "        [ 0.0502],\n",
      "        [ 0.0395],\n",
      "        [-0.0082],\n",
      "        [-0.0325],\n",
      "        [-0.0281],\n",
      "        [ 0.0957],\n",
      "        [ 0.0106],\n",
      "        [ 0.0465],\n",
      "        [ 0.0041],\n",
      "        [ 0.0173],\n",
      "        [ 0.0548],\n",
      "        [-0.0164],\n",
      "        [ 0.0374],\n",
      "        [-0.0023],\n",
      "        [-0.0140],\n",
      "        [ 0.0216],\n",
      "        [ 0.0075],\n",
      "        [ 0.0318],\n",
      "        [ 0.0068],\n",
      "        [ 0.0578],\n",
      "        [ 0.0441],\n",
      "        [ 0.0398],\n",
      "        [ 0.0660],\n",
      "        [ 0.0137],\n",
      "        [ 0.0244]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0654, 0.0651, 0.0650, 0.0629, 0.0626, 0.0625, 0.0623, 0.0619, 0.0621,\n",
      "        0.0621, 0.0630, 0.0624, 0.0614, 0.0627, 0.0626, 0.0627, 0.0641, 0.0643,\n",
      "        0.0638, 0.0636, 0.0641, 0.0650, 0.0647, 0.0649, 0.0667, 0.0666, 0.0661,\n",
      "        0.0649, 0.0656, 0.0659, 0.0656, 0.0656], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0359],\n",
      "        [ 0.0429],\n",
      "        [-0.0160],\n",
      "        [-0.0124],\n",
      "        [ 0.0404],\n",
      "        [ 0.0574],\n",
      "        [ 0.0148],\n",
      "        [ 0.0349],\n",
      "        [ 0.0677],\n",
      "        [ 0.0743],\n",
      "        [ 0.1108],\n",
      "        [ 0.0016],\n",
      "        [ 0.0116],\n",
      "        [ 0.0278],\n",
      "        [ 0.0151],\n",
      "        [ 0.0193],\n",
      "        [ 0.0996],\n",
      "        [ 0.0555],\n",
      "        [ 0.1241],\n",
      "        [-0.0457],\n",
      "        [-0.0165],\n",
      "        [-0.0303],\n",
      "        [ 0.0916],\n",
      "        [-0.0443],\n",
      "        [ 0.0860],\n",
      "        [-0.0253],\n",
      "        [ 0.0248],\n",
      "        [ 0.0232],\n",
      "        [ 0.0158],\n",
      "        [ 0.0169],\n",
      "        [ 0.0033],\n",
      "        [ 0.0146]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0659, 0.0659, 0.0669, 0.0673, 0.0676, 0.0674, 0.0668, 0.0665, 0.0663,\n",
      "        0.0665, 0.0655, 0.0645, 0.0636, 0.0624, 0.0625, 0.0634, 0.0650, 0.0657,\n",
      "        0.0648, 0.0646, 0.0650, 0.0650, 0.0647, 0.0648, 0.0647, 0.0647, 0.0656,\n",
      "        0.0653, 0.0642, 0.0637, 0.0658, 0.0673], device='cuda:0')\n",
      "tensor([[ 0.0125],\n",
      "        [ 0.0268],\n",
      "        [-0.0267],\n",
      "        [ 0.0482],\n",
      "        [ 0.0365],\n",
      "        [ 0.0230],\n",
      "        [ 0.0057],\n",
      "        [ 0.0078],\n",
      "        [ 0.0144],\n",
      "        [-0.0060],\n",
      "        [ 0.0286],\n",
      "        [ 0.0357],\n",
      "        [ 0.0315],\n",
      "        [ 0.0686],\n",
      "        [ 0.0238],\n",
      "        [ 0.0605],\n",
      "        [ 0.0831],\n",
      "        [ 0.0484],\n",
      "        [ 0.0182],\n",
      "        [ 0.1026],\n",
      "        [ 0.0641],\n",
      "        [ 0.1020],\n",
      "        [ 0.0404],\n",
      "        [ 0.0497],\n",
      "        [ 0.0940],\n",
      "        [ 0.0787],\n",
      "        [-0.1091],\n",
      "        [ 0.0245],\n",
      "        [ 0.0085],\n",
      "        [-0.0423],\n",
      "        [ 0.0247],\n",
      "        [ 0.0170]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0659, 0.0637, 0.0646, 0.0660, 0.0653, 0.0656, 0.0668, 0.0669, 0.0677,\n",
      "        0.0678, 0.0678, 0.0680, 0.0679, 0.0676, 0.0691, 0.0690, 0.0708, 0.0680,\n",
      "        0.0634, 0.0649, 0.0646, 0.0648, 0.0648, 0.0630, 0.0623, 0.0613, 0.0607,\n",
      "        0.0599, 0.0617, 0.0618, 0.0618, 0.0607], device='cuda:0')\n",
      "tensor([[-5.9057e-03],\n",
      "        [-1.5717e-02],\n",
      "        [ 4.9920e-02],\n",
      "        [ 4.6227e-02],\n",
      "        [ 7.2538e-03],\n",
      "        [ 2.3226e-02],\n",
      "        [ 6.1628e-02],\n",
      "        [ 1.8078e-02],\n",
      "        [ 8.5336e-04],\n",
      "        [ 1.0179e-01],\n",
      "        [ 1.4874e-02],\n",
      "        [ 2.4555e-02],\n",
      "        [-4.5931e-03],\n",
      "        [ 8.2180e-02],\n",
      "        [ 6.4745e-02],\n",
      "        [ 1.1939e-02],\n",
      "        [ 1.8315e-02],\n",
      "        [ 4.4435e-02],\n",
      "        [ 3.1998e-02],\n",
      "        [ 1.3380e-02],\n",
      "        [-9.0604e-03],\n",
      "        [-4.0777e-05],\n",
      "        [ 8.1104e-02],\n",
      "        [ 4.7688e-02],\n",
      "        [-8.0559e-05],\n",
      "        [ 1.2766e-01],\n",
      "        [ 1.9331e-02],\n",
      "        [ 4.6887e-02],\n",
      "        [ 4.7998e-02],\n",
      "        [ 9.5164e-03],\n",
      "        [-3.6641e-02],\n",
      "        [-1.4227e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0621, 0.0633, 0.0624, 0.0646, 0.0639, 0.0631, 0.0632, 0.0633, 0.0637,\n",
      "        0.0639, 0.0633, 0.0621, 0.0622, 0.0620, 0.0611, 0.0600, 0.0594, 0.0586,\n",
      "        0.0585, 0.0575, 0.0555, 0.0578, 0.0583, 0.0584, 0.0573, 0.0563, 0.0569,\n",
      "        0.0568, 0.0569, 0.0562, 0.0568, 0.0582], device='cuda:0')\n",
      "tensor([[ 0.0238],\n",
      "        [ 0.0002],\n",
      "        [ 0.0060],\n",
      "        [-0.0089],\n",
      "        [ 0.0272],\n",
      "        [ 0.0406],\n",
      "        [ 0.0513],\n",
      "        [ 0.0984],\n",
      "        [ 0.0381],\n",
      "        [ 0.0753],\n",
      "        [ 0.0312],\n",
      "        [ 0.0496],\n",
      "        [ 0.0583],\n",
      "        [-0.0884],\n",
      "        [-0.0231],\n",
      "        [-0.0298],\n",
      "        [ 0.1021],\n",
      "        [ 0.0220],\n",
      "        [ 0.0334],\n",
      "        [ 0.0174],\n",
      "        [ 0.0046],\n",
      "        [ 0.0209],\n",
      "        [ 0.0231],\n",
      "        [-0.0108],\n",
      "        [-0.0149],\n",
      "        [ 0.0669],\n",
      "        [ 0.0918],\n",
      "        [-0.0659],\n",
      "        [ 0.0132],\n",
      "        [-0.0190],\n",
      "        [ 0.0300],\n",
      "        [ 0.0203]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0594, 0.0594, 0.0603, 0.0607, 0.0605, 0.0591, 0.0578, 0.0564, 0.0563,\n",
      "        0.0572, 0.0577, 0.0590, 0.0580, 0.0574, 0.0571, 0.0565, 0.0569, 0.0574,\n",
      "        0.0565, 0.0546, 0.0539, 0.0537, 0.0519, 0.0493, 0.0516, 0.0511, 0.0508,\n",
      "        0.0476, 0.0476, 0.0486, 0.0492, 0.0493], device='cuda:0')\n",
      "tensor([[ 0.0590],\n",
      "        [ 0.0332],\n",
      "        [ 0.0082],\n",
      "        [ 0.0195],\n",
      "        [-0.0096],\n",
      "        [ 0.0040],\n",
      "        [ 0.0403],\n",
      "        [ 0.0402],\n",
      "        [ 0.0918],\n",
      "        [-0.0137],\n",
      "        [-0.0071],\n",
      "        [-0.0294],\n",
      "        [-0.0351],\n",
      "        [ 0.0493],\n",
      "        [ 0.0696],\n",
      "        [-0.0328],\n",
      "        [ 0.0039],\n",
      "        [ 0.0295],\n",
      "        [ 0.0655],\n",
      "        [ 0.0847],\n",
      "        [-0.0100],\n",
      "        [ 0.0842],\n",
      "        [ 0.1090],\n",
      "        [ 0.0477],\n",
      "        [ 0.0357],\n",
      "        [-0.0570],\n",
      "        [-0.0308],\n",
      "        [-0.0017],\n",
      "        [ 0.0271],\n",
      "        [-0.0334],\n",
      "        [ 0.0039],\n",
      "        [-0.0099]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0482, 0.0474, 0.0457, 0.0441, 0.0447, 0.0445, 0.0418, 0.0399, 0.0387,\n",
      "        0.0393, 0.0376, 0.0379, 0.0419, 0.0438, 0.0464, 0.0485, 0.0476, 0.0476,\n",
      "        0.0448, 0.0445, 0.0436, 0.0441, 0.0434, 0.0420, 0.0419, 0.0419, 0.0447,\n",
      "        0.0435, 0.0450, 0.0446, 0.0441, 0.0415], device='cuda:0')\n",
      "tensor([[ 0.0317],\n",
      "        [ 0.1280],\n",
      "        [ 0.0424],\n",
      "        [ 0.0906],\n",
      "        [ 0.0375],\n",
      "        [ 0.0728],\n",
      "        [ 0.0144],\n",
      "        [ 0.0648],\n",
      "        [-0.0164],\n",
      "        [-0.0100],\n",
      "        [ 0.0103],\n",
      "        [-0.0224],\n",
      "        [ 0.0663],\n",
      "        [ 0.0640],\n",
      "        [ 0.0345],\n",
      "        [ 0.0086],\n",
      "        [ 0.0355],\n",
      "        [ 0.0161],\n",
      "        [ 0.0708],\n",
      "        [ 0.0101],\n",
      "        [-0.0119],\n",
      "        [ 0.0118],\n",
      "        [ 0.0888],\n",
      "        [ 0.0788],\n",
      "        [ 0.0399],\n",
      "        [ 0.0754],\n",
      "        [-0.0183],\n",
      "        [-0.0174],\n",
      "        [-0.0012],\n",
      "        [ 0.0049],\n",
      "        [-0.0199],\n",
      "        [ 0.0165]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0410, 0.0417, 0.0415, 0.0415, 0.0398, 0.0407, 0.0399, 0.0385, 0.0380,\n",
      "        0.0404, 0.0408, 0.0398, 0.0392, 0.0401, 0.0402, 0.0407, 0.0420, 0.0417,\n",
      "        0.0416, 0.0407, 0.0414, 0.0407, 0.0405, 0.0404, 0.0404, 0.0406, 0.0403,\n",
      "        0.0396, 0.0398, 0.0397, 0.0394, 0.0387], device='cuda:0')\n",
      "tensor([[ 0.0444],\n",
      "        [-0.0055],\n",
      "        [-0.0248],\n",
      "        [-0.0176],\n",
      "        [ 0.0567],\n",
      "        [ 0.0670],\n",
      "        [-0.0622],\n",
      "        [-0.0544],\n",
      "        [-0.0722],\n",
      "        [ 0.0472],\n",
      "        [ 0.0419],\n",
      "        [ 0.0418],\n",
      "        [-0.0116],\n",
      "        [-0.0202],\n",
      "        [-0.0258],\n",
      "        [ 0.1198],\n",
      "        [ 0.0799],\n",
      "        [ 0.0351],\n",
      "        [ 0.0542],\n",
      "        [ 0.0637],\n",
      "        [-0.0117],\n",
      "        [ 0.0298],\n",
      "        [ 0.0174],\n",
      "        [ 0.0257],\n",
      "        [ 0.0081],\n",
      "        [ 0.0304],\n",
      "        [ 0.0103],\n",
      "        [ 0.0104],\n",
      "        [ 0.0045],\n",
      "        [-0.0211],\n",
      "        [ 0.0533],\n",
      "        [ 0.0083]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0375, 0.0370, 0.0352, 0.0334, 0.0350, 0.0363, 0.0373, 0.0373, 0.0385,\n",
      "        0.0396, 0.0428, 0.0431, 0.0430, 0.0434, 0.0448, 0.0436, 0.0430, 0.0431,\n",
      "        0.0444, 0.0450, 0.0457, 0.0452, 0.0441, 0.0442, 0.0435, 0.0436, 0.0447,\n",
      "        0.0460, 0.0469, 0.0458, 0.0453, 0.0471], device='cuda:0')\n",
      "tensor([[ 0.0171],\n",
      "        [ 0.0058],\n",
      "        [ 0.0157],\n",
      "        [ 0.0092],\n",
      "        [ 0.0381],\n",
      "        [ 0.0502],\n",
      "        [ 0.0206],\n",
      "        [ 0.0129],\n",
      "        [ 0.1434],\n",
      "        [ 0.0055],\n",
      "        [ 0.0165],\n",
      "        [ 0.0562],\n",
      "        [ 0.0624],\n",
      "        [ 0.0007],\n",
      "        [ 0.0386],\n",
      "        [-0.0233],\n",
      "        [-0.0146],\n",
      "        [ 0.0337],\n",
      "        [ 0.1040],\n",
      "        [-0.0333],\n",
      "        [ 0.0240],\n",
      "        [-0.0228],\n",
      "        [-0.0242],\n",
      "        [-0.0173],\n",
      "        [ 0.0592],\n",
      "        [-0.0280],\n",
      "        [ 0.0152],\n",
      "        [-0.0292],\n",
      "        [-0.0187],\n",
      "        [ 0.0255],\n",
      "        [ 0.0150],\n",
      "        [-0.0041]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0489, 0.0489, 0.0492, 0.0496, 0.0496, 0.0509, 0.0514, 0.0532, 0.0533,\n",
      "        0.0529, 0.0512, 0.0507, 0.0493, 0.0497, 0.0496, 0.0499, 0.0494, 0.0479,\n",
      "        0.0495, 0.0490, 0.0487, 0.0504, 0.0492, 0.0495, 0.0508, 0.0512, 0.0502,\n",
      "        0.0515, 0.0507, 0.0507, 0.0498, 0.0502], device='cuda:0')\n",
      "tensor([[ 0.0142],\n",
      "        [-0.0011],\n",
      "        [-0.0017],\n",
      "        [ 0.0819],\n",
      "        [-0.0006],\n",
      "        [ 0.0259],\n",
      "        [ 0.0124],\n",
      "        [ 0.0184],\n",
      "        [ 0.0335],\n",
      "        [ 0.0646],\n",
      "        [ 0.0059],\n",
      "        [ 0.0060],\n",
      "        [-0.0645],\n",
      "        [ 0.0415],\n",
      "        [ 0.0132],\n",
      "        [ 0.0076],\n",
      "        [ 0.0194],\n",
      "        [ 0.0579],\n",
      "        [ 0.1379],\n",
      "        [ 0.0340],\n",
      "        [ 0.0095],\n",
      "        [ 0.0078],\n",
      "        [ 0.0616],\n",
      "        [ 0.0156],\n",
      "        [-0.0393],\n",
      "        [ 0.0452],\n",
      "        [ 0.0155],\n",
      "        [ 0.0143],\n",
      "        [ 0.0364],\n",
      "        [ 0.0069],\n",
      "        [-0.0156],\n",
      "        [-0.0064]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0510, 0.0513, 0.0509, 0.0509, 0.0500, 0.0500, 0.0499, 0.0493, 0.0495,\n",
      "        0.0508, 0.0513, 0.0516, 0.0513, 0.0536, 0.0533, 0.0535, 0.0549, 0.0543,\n",
      "        0.0544, 0.0554, 0.0554, 0.0557, 0.0557, 0.0556, 0.0541, 0.0542, 0.0546,\n",
      "        0.0546, 0.0552, 0.0557, 0.0554, 0.0545], device='cuda:0')\n",
      "tensor([[ 1.4927e-02],\n",
      "        [-8.0829e-02],\n",
      "        [ 2.0479e-02],\n",
      "        [ 4.0495e-02],\n",
      "        [ 2.8048e-02],\n",
      "        [ 1.4493e-02],\n",
      "        [ 4.8493e-02],\n",
      "        [-2.4638e-02],\n",
      "        [ 7.7088e-02],\n",
      "        [ 9.6552e-05],\n",
      "        [ 4.0527e-02],\n",
      "        [ 6.1457e-02],\n",
      "        [-2.4141e-02],\n",
      "        [ 2.5773e-02],\n",
      "        [ 9.2140e-02],\n",
      "        [-2.6992e-02],\n",
      "        [ 4.3128e-02],\n",
      "        [ 3.1726e-02],\n",
      "        [ 2.9735e-02],\n",
      "        [ 7.9182e-02],\n",
      "        [-1.0862e-02],\n",
      "        [ 5.9300e-02],\n",
      "        [ 2.7047e-02],\n",
      "        [ 2.8978e-02],\n",
      "        [ 5.9858e-02],\n",
      "        [ 1.1323e-01],\n",
      "        [-1.2243e-02],\n",
      "        [ 2.2139e-02],\n",
      "        [-1.0264e-02],\n",
      "        [ 1.0099e-02],\n",
      "        [ 1.6754e-02],\n",
      "        [-1.1647e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0551, 0.0559, 0.0564, 0.0562, 0.0558, 0.0546, 0.0554, 0.0558, 0.0554,\n",
      "        0.0550, 0.0545, 0.0553, 0.0553, 0.0550, 0.0539, 0.0544, 0.0546, 0.0551,\n",
      "        0.0552, 0.0555, 0.0567, 0.0577, 0.0569, 0.0557, 0.0576, 0.0580, 0.0581,\n",
      "        0.0583, 0.0588, 0.0602, 0.0612, 0.0607], device='cuda:0')\n",
      "tensor([[ 0.0076],\n",
      "        [ 0.0391],\n",
      "        [ 0.0418],\n",
      "        [ 0.0192],\n",
      "        [ 0.0681],\n",
      "        [ 0.0174],\n",
      "        [ 0.0336],\n",
      "        [ 0.0174],\n",
      "        [ 0.0237],\n",
      "        [ 0.0003],\n",
      "        [ 0.1537],\n",
      "        [ 0.0911],\n",
      "        [-0.0459],\n",
      "        [ 0.0312],\n",
      "        [-0.0160],\n",
      "        [ 0.0031],\n",
      "        [ 0.0433],\n",
      "        [-0.0065],\n",
      "        [-0.0317],\n",
      "        [ 0.0548],\n",
      "        [-0.0168],\n",
      "        [-0.0011],\n",
      "        [ 0.0313],\n",
      "        [ 0.0184],\n",
      "        [-0.0161],\n",
      "        [ 0.0292],\n",
      "        [ 0.0169],\n",
      "        [ 0.0164],\n",
      "        [ 0.0792],\n",
      "        [ 0.0724],\n",
      "        [ 0.0342],\n",
      "        [ 0.0259]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0604, 0.0607, 0.0609, 0.0614, 0.0602, 0.0585, 0.0582, 0.0588, 0.0599,\n",
      "        0.0606, 0.0596, 0.0602, 0.0608, 0.0606, 0.0604, 0.0612, 0.0623, 0.0630,\n",
      "        0.0631, 0.0631, 0.0629, 0.0643, 0.0666, 0.0663, 0.0666, 0.0660, 0.0659,\n",
      "        0.0654, 0.0647, 0.0646, 0.0648, 0.0653], device='cuda:0')\n",
      "tensor([[-0.0315],\n",
      "        [-0.0353],\n",
      "        [ 0.0400],\n",
      "        [ 0.0505],\n",
      "        [ 0.0180],\n",
      "        [ 0.0023],\n",
      "        [ 0.0290],\n",
      "        [ 0.0603],\n",
      "        [ 0.0158],\n",
      "        [ 0.0070],\n",
      "        [ 0.0558],\n",
      "        [ 0.0796],\n",
      "        [ 0.0382],\n",
      "        [ 0.0166],\n",
      "        [ 0.0182],\n",
      "        [ 0.0306],\n",
      "        [ 0.0292],\n",
      "        [ 0.0046],\n",
      "        [ 0.0529],\n",
      "        [ 0.0359],\n",
      "        [ 0.0401],\n",
      "        [-0.0313],\n",
      "        [ 0.1186],\n",
      "        [-0.0022],\n",
      "        [-0.0158],\n",
      "        [ 0.0161],\n",
      "        [ 0.0788],\n",
      "        [ 0.1339],\n",
      "        [-0.0170],\n",
      "        [-0.0127],\n",
      "        [ 0.0641],\n",
      "        [-0.0423]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0649, 0.0650, 0.0652, 0.0648, 0.0653, 0.0659, 0.0660, 0.0660, 0.0650,\n",
      "        0.0650, 0.0653, 0.0655, 0.0649, 0.0639, 0.0643, 0.0648, 0.0641, 0.0639,\n",
      "        0.0646, 0.0648, 0.0653, 0.0660, 0.0662, 0.0652, 0.0642, 0.0642, 0.0641,\n",
      "        0.0638, 0.0627, 0.0621, 0.0616, 0.0616], device='cuda:0')\n",
      "tensor([[ 1.9694e-02],\n",
      "        [ 1.7751e-02],\n",
      "        [ 6.8527e-03],\n",
      "        [ 7.2274e-02],\n",
      "        [ 4.1357e-02],\n",
      "        [ 3.1645e-02],\n",
      "        [-2.1321e-02],\n",
      "        [-3.9610e-02],\n",
      "        [-1.2003e-02],\n",
      "        [ 5.9170e-02],\n",
      "        [ 1.3729e-01],\n",
      "        [ 9.6699e-02],\n",
      "        [ 9.9524e-02],\n",
      "        [ 7.9549e-03],\n",
      "        [-1.3525e-04],\n",
      "        [ 4.9752e-02],\n",
      "        [ 7.3905e-02],\n",
      "        [ 4.8237e-02],\n",
      "        [ 2.9789e-02],\n",
      "        [ 1.7186e-02],\n",
      "        [-3.2265e-02],\n",
      "        [-1.5250e-02],\n",
      "        [-3.5486e-02],\n",
      "        [ 7.9448e-03],\n",
      "        [ 6.3113e-02],\n",
      "        [ 4.5291e-02],\n",
      "        [ 5.0438e-02],\n",
      "        [ 1.0538e-01],\n",
      "        [ 3.8009e-02],\n",
      "        [ 3.6732e-02],\n",
      "        [ 5.7638e-03],\n",
      "        [ 9.1474e-03]], device='cuda:0', grad_fn=<AddmmBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([0.0611, 0.0600, 0.0596, 0.0606, 0.0615, 0.0629, 0.0620, 0.0613, 0.0603,\n",
      "        0.0604, 0.0596, 0.0580, 0.0584, 0.0578, 0.0566, 0.0573, 0.0558, 0.0545,\n",
      "        0.0559, 0.0567, 0.0574, 0.0560, 0.0567, 0.0571, 0.0565, 0.0552, 0.0549,\n",
      "        0.0551, 0.0552, 0.0546, 0.0542, 0.0544], device='cuda:0')\n",
      "tensor([[ 0.0011],\n",
      "        [-0.0366],\n",
      "        [ 0.0365],\n",
      "        [ 0.0038],\n",
      "        [ 0.0003],\n",
      "        [ 0.0239],\n",
      "        [ 0.0859],\n",
      "        [ 0.0050],\n",
      "        [ 0.0988],\n",
      "        [ 0.0770],\n",
      "        [ 0.0241],\n",
      "        [ 0.0310],\n",
      "        [ 0.0537],\n",
      "        [ 0.0247],\n",
      "        [ 0.0202],\n",
      "        [ 0.0224],\n",
      "        [ 0.0607],\n",
      "        [ 0.0943],\n",
      "        [ 0.0464],\n",
      "        [ 0.0117],\n",
      "        [ 0.0349],\n",
      "        [ 0.0423],\n",
      "        [ 0.0482],\n",
      "        [ 0.0269],\n",
      "        [ 0.0088],\n",
      "        [ 0.0333],\n",
      "        [ 0.0397],\n",
      "        [-0.0066],\n",
      "        [ 0.0089],\n",
      "        [-0.0032],\n",
      "        [ 0.0235],\n",
      "        [-0.0082]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0549, 0.0556, 0.0558, 0.0561, 0.0555, 0.0543, 0.0542, 0.0554, 0.0551,\n",
      "        0.0520, 0.0516, 0.0511, 0.0503, 0.0508, 0.0513, 0.0520, 0.0515, 0.0511,\n",
      "        0.0508, 0.0499, 0.0515, 0.0508, 0.0495, 0.0501, 0.0492, 0.0485, 0.0485,\n",
      "        0.0482, 0.0478, 0.0483, 0.0495, 0.0508], device='cuda:0')\n",
      "tensor([[-0.0531],\n",
      "        [-0.0290],\n",
      "        [-0.0250],\n",
      "        [ 0.0393],\n",
      "        [ 0.0231],\n",
      "        [-0.0086],\n",
      "        [ 0.2173],\n",
      "        [ 0.0931],\n",
      "        [ 0.0632],\n",
      "        [ 0.0281],\n",
      "        [ 0.0124],\n",
      "        [-0.0077],\n",
      "        [ 0.0466],\n",
      "        [ 0.0413],\n",
      "        [ 0.0108],\n",
      "        [ 0.0254],\n",
      "        [ 0.0200],\n",
      "        [ 0.0181],\n",
      "        [ 0.0294],\n",
      "        [ 0.0111],\n",
      "        [ 0.0493],\n",
      "        [ 0.0418],\n",
      "        [-0.0038],\n",
      "        [-0.0117],\n",
      "        [ 0.0331],\n",
      "        [ 0.0032],\n",
      "        [-0.0438],\n",
      "        [ 0.0507],\n",
      "        [ 0.0270],\n",
      "        [ 0.0352],\n",
      "        [-0.0096],\n",
      "        [ 0.0057]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0504, 0.0549, 0.0553, 0.0540, 0.0532, 0.0537, 0.0551, 0.0559, 0.0551,\n",
      "        0.0549, 0.0552, 0.0540, 0.0525, 0.0519, 0.0515, 0.0534, 0.0539, 0.0541,\n",
      "        0.0531, 0.0528, 0.0516, 0.0515, 0.0523, 0.0518, 0.0518, 0.0525, 0.0529,\n",
      "        0.0534, 0.0528, 0.0527, 0.0525, 0.0526], device='cuda:0')\n",
      "tensor([[ 0.0580],\n",
      "        [ 0.0562],\n",
      "        [ 0.0109],\n",
      "        [ 0.0101],\n",
      "        [ 0.0222],\n",
      "        [-0.0205],\n",
      "        [ 0.0170],\n",
      "        [ 0.0148],\n",
      "        [-0.0034],\n",
      "        [ 0.0163],\n",
      "        [ 0.0990],\n",
      "        [ 0.0100],\n",
      "        [ 0.0254],\n",
      "        [ 0.0353],\n",
      "        [ 0.0109],\n",
      "        [ 0.0313],\n",
      "        [-0.0009],\n",
      "        [ 0.0219],\n",
      "        [ 0.0762],\n",
      "        [-0.0287],\n",
      "        [ 0.0645],\n",
      "        [ 0.0156],\n",
      "        [ 0.0219],\n",
      "        [ 0.0383],\n",
      "        [-0.0149],\n",
      "        [-0.0297],\n",
      "        [ 0.0573],\n",
      "        [-0.0010],\n",
      "        [-0.0049],\n",
      "        [-0.0059],\n",
      "        [-0.0331],\n",
      "        [ 0.0027]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0522, 0.0525, 0.0530, 0.0531, 0.0534, 0.0537, 0.0536, 0.0527, 0.0529,\n",
      "        0.0551, 0.0538, 0.0534, 0.0536, 0.0537, 0.0537, 0.0528, 0.0525, 0.0520,\n",
      "        0.0520, 0.0513, 0.0509, 0.0512, 0.0517, 0.0498, 0.0505, 0.0523, 0.0516,\n",
      "        0.0516, 0.0514, 0.0513, 0.0509, 0.0497], device='cuda:0')\n",
      "tensor([[ 0.0440],\n",
      "        [ 0.0221],\n",
      "        [ 0.0398],\n",
      "        [ 0.0446],\n",
      "        [-0.0223],\n",
      "        [ 0.0741],\n",
      "        [-0.0316],\n",
      "        [-0.0044],\n",
      "        [ 0.0199],\n",
      "        [-0.0200],\n",
      "        [ 0.0416],\n",
      "        [-0.0436],\n",
      "        [ 0.0792],\n",
      "        [ 0.0554],\n",
      "        [ 0.0366],\n",
      "        [ 0.0464],\n",
      "        [-0.0173],\n",
      "        [ 0.0884],\n",
      "        [ 0.0614],\n",
      "        [ 0.0242],\n",
      "        [ 0.0166],\n",
      "        [ 0.0534],\n",
      "        [-0.0196],\n",
      "        [ 0.0198],\n",
      "        [ 0.0224],\n",
      "        [ 0.0178],\n",
      "        [-0.0291],\n",
      "        [ 0.0348],\n",
      "        [ 0.0718],\n",
      "        [ 0.0408],\n",
      "        [ 0.0040],\n",
      "        [ 0.0864]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0502, 0.0502, 0.0520, 0.0518, 0.0503, 0.0500, 0.0496, 0.0493, 0.0496,\n",
      "        0.0513, 0.0521, 0.0529, 0.0539, 0.0538, 0.0565, 0.0547, 0.0556, 0.0548,\n",
      "        0.0557, 0.0574, 0.0573, 0.0563, 0.0580, 0.0608, 0.0608, 0.0614, 0.0624,\n",
      "        0.0613, 0.0601, 0.0595, 0.0608, 0.0603], device='cuda:0')\n",
      "tensor([[-0.0206],\n",
      "        [ 0.0098],\n",
      "        [ 0.0527],\n",
      "        [ 0.0864],\n",
      "        [ 0.0551],\n",
      "        [ 0.1252],\n",
      "        [ 0.0183],\n",
      "        [ 0.0548],\n",
      "        [-0.0158],\n",
      "        [-0.0094],\n",
      "        [ 0.0069],\n",
      "        [-0.0067],\n",
      "        [ 0.0182],\n",
      "        [ 0.0092],\n",
      "        [ 0.0185],\n",
      "        [ 0.0014],\n",
      "        [ 0.0840],\n",
      "        [ 0.0429],\n",
      "        [ 0.0391],\n",
      "        [-0.0034],\n",
      "        [ 0.1303],\n",
      "        [ 0.1662],\n",
      "        [ 0.0629],\n",
      "        [ 0.0636],\n",
      "        [ 0.0251],\n",
      "        [-0.0251],\n",
      "        [ 0.0140],\n",
      "        [ 0.0004],\n",
      "        [ 0.0043],\n",
      "        [-0.0222],\n",
      "        [ 0.0412],\n",
      "        [ 0.0144]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0598, 0.0602, 0.0594, 0.0610, 0.0613, 0.0613, 0.0607, 0.0606, 0.0613,\n",
      "        0.0616, 0.0613, 0.0634, 0.0633, 0.0633, 0.0642, 0.0666, 0.0677, 0.0659,\n",
      "        0.0672, 0.0678, 0.0677, 0.0677, 0.0676, 0.0679, 0.0689, 0.0689, 0.0680,\n",
      "        0.0678, 0.0686, 0.0690, 0.0686, 0.0690], device='cuda:0')\n",
      "tensor([[-0.0145],\n",
      "        [-0.0035],\n",
      "        [ 0.0232],\n",
      "        [ 0.0314],\n",
      "        [ 0.0728],\n",
      "        [ 0.0205],\n",
      "        [ 0.0405],\n",
      "        [-0.0053],\n",
      "        [ 0.0704],\n",
      "        [ 0.0490],\n",
      "        [ 0.0131],\n",
      "        [ 0.0359],\n",
      "        [ 0.0131],\n",
      "        [ 0.0457],\n",
      "        [ 0.0210],\n",
      "        [ 0.0441],\n",
      "        [ 0.0336],\n",
      "        [ 0.0426],\n",
      "        [ 0.0335],\n",
      "        [ 0.1626],\n",
      "        [ 0.0779],\n",
      "        [-0.0029],\n",
      "        [ 0.0893],\n",
      "        [-0.0039],\n",
      "        [ 0.1400],\n",
      "        [ 0.0352],\n",
      "        [ 0.0026],\n",
      "        [ 0.0656],\n",
      "        [ 0.0083],\n",
      "        [-0.0028],\n",
      "        [ 0.0380],\n",
      "        [-0.0140]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0679, 0.0680, 0.0680, 0.0676, 0.0678, 0.0678, 0.0679, 0.0669, 0.0687,\n",
      "        0.0674, 0.0678, 0.0687, 0.0696, 0.0699, 0.0705, 0.0714, 0.0709, 0.0712,\n",
      "        0.0701, 0.0689, 0.0685, 0.0688, 0.0688, 0.0698, 0.0697, 0.0696, 0.0699,\n",
      "        0.0710, 0.0711, 0.0717, 0.0716, 0.0705], device='cuda:0')\n",
      "tensor([[ 0.1161],\n",
      "        [ 0.0329],\n",
      "        [-0.0335],\n",
      "        [ 0.0363],\n",
      "        [ 0.0111],\n",
      "        [ 0.0187],\n",
      "        [ 0.0477],\n",
      "        [ 0.0235],\n",
      "        [-0.0147],\n",
      "        [-0.0330],\n",
      "        [ 0.0147],\n",
      "        [ 0.0226],\n",
      "        [ 0.0301],\n",
      "        [ 0.0678],\n",
      "        [ 0.0113],\n",
      "        [ 0.0280],\n",
      "        [ 0.0591],\n",
      "        [ 0.0736],\n",
      "        [ 0.0848],\n",
      "        [ 0.0201],\n",
      "        [ 0.0271],\n",
      "        [ 0.0646],\n",
      "        [ 0.0316],\n",
      "        [ 0.1022],\n",
      "        [ 0.0441],\n",
      "        [-0.0264],\n",
      "        [ 0.0148],\n",
      "        [ 0.0509],\n",
      "        [ 0.0129],\n",
      "        [ 0.0458],\n",
      "        [-0.0123],\n",
      "        [ 0.0380]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0710, 0.0718, 0.0726, 0.0733, 0.0731, 0.0727, 0.0730, 0.0730, 0.0746,\n",
      "        0.0738, 0.0740, 0.0740, 0.0742, 0.0731, 0.0723, 0.0717, 0.0717, 0.0708,\n",
      "        0.0705, 0.0707, 0.0719, 0.0711, 0.0705, 0.0702, 0.0715, 0.0725, 0.0719,\n",
      "        0.0703, 0.0714, 0.0713, 0.0709, 0.0720], device='cuda:0')\n",
      "tensor([[-0.0193],\n",
      "        [ 0.0463],\n",
      "        [ 0.0519],\n",
      "        [ 0.0573],\n",
      "        [-0.0170],\n",
      "        [ 0.0248],\n",
      "        [ 0.0236],\n",
      "        [ 0.0699],\n",
      "        [ 0.0412],\n",
      "        [ 0.0397],\n",
      "        [ 0.1043],\n",
      "        [ 0.0446],\n",
      "        [ 0.0824],\n",
      "        [ 0.0531],\n",
      "        [ 0.0494],\n",
      "        [-0.0231],\n",
      "        [ 0.0134],\n",
      "        [ 0.0241],\n",
      "        [ 0.0075],\n",
      "        [ 0.0081],\n",
      "        [-0.0052],\n",
      "        [ 0.0580],\n",
      "        [ 0.0513],\n",
      "        [ 0.1107],\n",
      "        [-0.0084],\n",
      "        [ 0.0244],\n",
      "        [ 0.0108],\n",
      "        [-0.0165],\n",
      "        [ 0.0331],\n",
      "        [ 0.0110],\n",
      "        [ 0.0199],\n",
      "        [ 0.0671]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0714, 0.0727, 0.0739, 0.0743, 0.0754, 0.0757, 0.0759, 0.0761, 0.0761,\n",
      "        0.0741, 0.0747, 0.0750, 0.0748, 0.0739, 0.0735, 0.0741, 0.0735, 0.0731,\n",
      "        0.0723, 0.0735, 0.0751, 0.0746, 0.0749, 0.0744, 0.0745, 0.0746, 0.0742,\n",
      "        0.0740, 0.0734, 0.0734, 0.0730, 0.0732], device='cuda:0')\n",
      "tensor([[ 0.0009],\n",
      "        [ 0.0491],\n",
      "        [ 0.0617],\n",
      "        [-0.0121],\n",
      "        [ 0.0359],\n",
      "        [ 0.0379],\n",
      "        [-0.0163],\n",
      "        [ 0.0230],\n",
      "        [ 0.0577],\n",
      "        [ 0.0543],\n",
      "        [ 0.0290],\n",
      "        [-0.0038],\n",
      "        [ 0.0283],\n",
      "        [ 0.0617],\n",
      "        [ 0.0656],\n",
      "        [ 0.0165],\n",
      "        [ 0.1389],\n",
      "        [ 0.0617],\n",
      "        [-0.0176],\n",
      "        [ 0.0047],\n",
      "        [ 0.0128],\n",
      "        [ 0.0210],\n",
      "        [ 0.0227],\n",
      "        [ 0.0220],\n",
      "        [ 0.0034],\n",
      "        [ 0.0258],\n",
      "        [ 0.0482],\n",
      "        [ 0.0076],\n",
      "        [ 0.0414],\n",
      "        [ 0.0134],\n",
      "        [ 0.1795],\n",
      "        [ 0.1281]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0733, 0.0740, 0.0752, 0.0761, 0.0761, 0.0750, 0.0745, 0.0742, 0.0732,\n",
      "        0.0736, 0.0724, 0.0725, 0.0728, 0.0730, 0.0744, 0.0749, 0.0747, 0.0739,\n",
      "        0.0745, 0.0747, 0.0754, 0.0776, 0.0773, 0.0788, 0.0790, 0.0794, 0.0795,\n",
      "        0.0807, 0.0807, 0.0812, 0.0810, 0.0800], device='cuda:0')\n",
      "tensor([[ 0.1213],\n",
      "        [ 0.0266],\n",
      "        [-0.0219],\n",
      "        [ 0.1290],\n",
      "        [-0.0206],\n",
      "        [-0.0204],\n",
      "        [ 0.0800],\n",
      "        [ 0.0094],\n",
      "        [ 0.1093],\n",
      "        [ 0.0144],\n",
      "        [ 0.0052],\n",
      "        [ 0.0264],\n",
      "        [-0.0020],\n",
      "        [ 0.0375],\n",
      "        [ 0.0310],\n",
      "        [-0.0051],\n",
      "        [ 0.0045],\n",
      "        [-0.0117],\n",
      "        [ 0.0269],\n",
      "        [ 0.0355],\n",
      "        [ 0.0209],\n",
      "        [ 0.0478],\n",
      "        [-0.0221],\n",
      "        [-0.0507],\n",
      "        [ 0.0353],\n",
      "        [-0.0163],\n",
      "        [ 0.0365],\n",
      "        [-0.0033],\n",
      "        [-0.0323],\n",
      "        [-0.0038],\n",
      "        [ 0.0315],\n",
      "        [-0.0016]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0790, 0.0783, 0.0779, 0.0777, 0.0782, 0.0783, 0.0769, 0.0766, 0.0762,\n",
      "        0.0773, 0.0771, 0.0772, 0.0767, 0.0763, 0.0755, 0.0751, 0.0749, 0.0744,\n",
      "        0.0740, 0.0747, 0.0751, 0.0747, 0.0743, 0.0745, 0.0753, 0.0751, 0.0748,\n",
      "        0.0748, 0.0748, 0.0768, 0.0762, 0.0767], device='cuda:0')\n",
      "tensor([[-0.0121],\n",
      "        [ 0.0027],\n",
      "        [ 0.0318],\n",
      "        [ 0.0482],\n",
      "        [ 0.0797],\n",
      "        [ 0.0734],\n",
      "        [ 0.1398],\n",
      "        [-0.0015],\n",
      "        [-0.0477],\n",
      "        [ 0.0186],\n",
      "        [ 0.0011],\n",
      "        [ 0.1344],\n",
      "        [ 0.0788],\n",
      "        [ 0.0136],\n",
      "        [ 0.0595],\n",
      "        [ 0.0120],\n",
      "        [ 0.0994],\n",
      "        [-0.0021],\n",
      "        [ 0.0467],\n",
      "        [ 0.0503],\n",
      "        [ 0.0302],\n",
      "        [ 0.0893],\n",
      "        [ 0.0162],\n",
      "        [ 0.0300],\n",
      "        [-0.0090],\n",
      "        [ 0.0123],\n",
      "        [-0.0187],\n",
      "        [ 0.0224],\n",
      "        [ 0.0645],\n",
      "        [ 0.0539],\n",
      "        [ 0.0365],\n",
      "        [ 0.0216]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0764, 0.0768, 0.0760, 0.0740, 0.0755, 0.0753, 0.0738, 0.0730, 0.0715,\n",
      "        0.0702, 0.0668, 0.0682, 0.0702, 0.0701, 0.0721, 0.0730, 0.0727, 0.0713,\n",
      "        0.0699, 0.0702, 0.0704, 0.0718, 0.0727, 0.0731, 0.0723, 0.0707, 0.0696,\n",
      "        0.0685, 0.0686, 0.0697, 0.0724, 0.0715], device='cuda:0')\n",
      "tensor([[-0.0399],\n",
      "        [ 0.1494],\n",
      "        [-0.0293],\n",
      "        [ 0.0273],\n",
      "        [ 0.0269],\n",
      "        [-0.0226],\n",
      "        [ 0.0259],\n",
      "        [ 0.0148],\n",
      "        [ 0.0120],\n",
      "        [-0.0113],\n",
      "        [ 0.0189],\n",
      "        [ 0.0063],\n",
      "        [ 0.0253],\n",
      "        [ 0.0268],\n",
      "        [-0.0150],\n",
      "        [ 0.0899],\n",
      "        [ 0.0580],\n",
      "        [ 0.0023],\n",
      "        [ 0.0354],\n",
      "        [-0.0008],\n",
      "        [ 0.0675],\n",
      "        [-0.0180],\n",
      "        [ 0.0035],\n",
      "        [ 0.0171],\n",
      "        [ 0.0371],\n",
      "        [-0.0224],\n",
      "        [ 0.0676],\n",
      "        [ 0.0223],\n",
      "        [ 0.0567],\n",
      "        [-0.0038],\n",
      "        [ 0.0460],\n",
      "        [-0.0262]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0717, 0.0714, 0.0717, 0.0722, 0.0738, 0.0726, 0.0718, 0.0710, 0.0721,\n",
      "        0.0731, 0.0747, 0.0753, 0.0747, 0.0745, 0.0744, 0.0759, 0.0762, 0.0750,\n",
      "        0.0743, 0.0741, 0.0748, 0.0739, 0.0728, 0.0727, 0.0718, 0.0730, 0.0732,\n",
      "        0.0750, 0.0757, 0.0773, 0.0774, 0.0780], device='cuda:0')\n",
      "tensor([[ 0.0152],\n",
      "        [-0.0016],\n",
      "        [ 0.0284],\n",
      "        [ 0.0350],\n",
      "        [-0.0276],\n",
      "        [ 0.0117],\n",
      "        [ 0.0713],\n",
      "        [ 0.0313],\n",
      "        [ 0.0028],\n",
      "        [ 0.0196],\n",
      "        [-0.0295],\n",
      "        [-0.0190],\n",
      "        [ 0.0221],\n",
      "        [ 0.0269],\n",
      "        [ 0.0327],\n",
      "        [-0.0441],\n",
      "        [ 0.0439],\n",
      "        [ 0.0310],\n",
      "        [-0.0011],\n",
      "        [ 0.0308],\n",
      "        [ 0.0133],\n",
      "        [ 0.0147],\n",
      "        [ 0.0481],\n",
      "        [ 0.1289],\n",
      "        [ 0.0566],\n",
      "        [ 0.0125],\n",
      "        [ 0.0194],\n",
      "        [-0.0190],\n",
      "        [ 0.0500],\n",
      "        [ 0.0218],\n",
      "        [ 0.0256],\n",
      "        [ 0.0155]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0796, 0.0796, 0.0793, 0.0779, 0.0788, 0.0799, 0.0807, 0.0805, 0.0809,\n",
      "        0.0820, 0.0844, 0.0837, 0.0856, 0.0837, 0.0841, 0.0850, 0.0844, 0.0836,\n",
      "        0.0820, 0.0822, 0.0823, 0.0841, 0.0843, 0.0840, 0.0861, 0.0866, 0.0872,\n",
      "        0.0860, 0.0850, 0.0849, 0.0863, 0.0855], device='cuda:0')\n",
      "tensor([[ 0.0325],\n",
      "        [ 0.0352],\n",
      "        [ 0.0143],\n",
      "        [-0.0447],\n",
      "        [-0.0131],\n",
      "        [ 0.0297],\n",
      "        [-0.0304],\n",
      "        [ 0.0365],\n",
      "        [-0.0116],\n",
      "        [ 0.0630],\n",
      "        [ 0.0092],\n",
      "        [ 0.0705],\n",
      "        [ 0.0558],\n",
      "        [ 0.0116],\n",
      "        [ 0.0571],\n",
      "        [ 0.0715],\n",
      "        [-0.0122],\n",
      "        [ 0.0469],\n",
      "        [ 0.0167],\n",
      "        [ 0.0676],\n",
      "        [ 0.0314],\n",
      "        [ 0.0409],\n",
      "        [ 0.0168],\n",
      "        [ 0.0289],\n",
      "        [ 0.0754],\n",
      "        [ 0.0436],\n",
      "        [-0.0529],\n",
      "        [ 0.0236],\n",
      "        [-0.0027],\n",
      "        [ 0.0394],\n",
      "        [ 0.0894],\n",
      "        [ 0.0334]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0856, 0.0831, 0.0825, 0.0806, 0.0826, 0.0816, 0.0851, 0.0843, 0.0840,\n",
      "        0.0849, 0.0848, 0.0845, 0.0852, 0.0858, 0.0867, 0.0856, 0.0855, 0.0841,\n",
      "        0.0841, 0.0824, 0.0812, 0.0818, 0.0829, 0.0840, 0.0833, 0.0843, 0.0826,\n",
      "        0.0818, 0.0809, 0.0806, 0.0806, 0.0807], device='cuda:0')\n",
      "tensor([[ 0.0254],\n",
      "        [-0.0081],\n",
      "        [ 0.0308],\n",
      "        [ 0.0635],\n",
      "        [ 0.0413],\n",
      "        [ 0.0350],\n",
      "        [ 0.0442],\n",
      "        [ 0.0337],\n",
      "        [ 0.0572],\n",
      "        [ 0.0095],\n",
      "        [ 0.0181],\n",
      "        [-0.0042],\n",
      "        [ 0.0468],\n",
      "        [ 0.0316],\n",
      "        [ 0.0141],\n",
      "        [-0.0011],\n",
      "        [ 0.0621],\n",
      "        [ 0.0372],\n",
      "        [ 0.1092],\n",
      "        [-0.0308],\n",
      "        [ 0.0126],\n",
      "        [ 0.0665],\n",
      "        [ 0.1292],\n",
      "        [ 0.0816],\n",
      "        [ 0.0336],\n",
      "        [ 0.0528],\n",
      "        [ 0.0082],\n",
      "        [ 0.0505],\n",
      "        [ 0.1077],\n",
      "        [ 0.0172],\n",
      "        [-0.0138],\n",
      "        [-0.0025]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0822, 0.0833, 0.0823, 0.0828, 0.0822, 0.0812, 0.0811, 0.0828, 0.0820,\n",
      "        0.0812, 0.0788, 0.0770, 0.0775, 0.0764, 0.0771, 0.0788, 0.0788, 0.0809,\n",
      "        0.0803, 0.0792, 0.0804, 0.0785, 0.0777, 0.0765, 0.0743, 0.0752, 0.0752,\n",
      "        0.0745, 0.0726, 0.0721, 0.0728, 0.0728], device='cuda:0')\n",
      "tensor([[-6.7430e-02],\n",
      "        [ 4.7029e-02],\n",
      "        [-1.8080e-02],\n",
      "        [ 4.1229e-02],\n",
      "        [-2.4418e-02],\n",
      "        [ 4.4031e-02],\n",
      "        [ 4.8965e-02],\n",
      "        [ 1.0845e-01],\n",
      "        [ 5.3255e-02],\n",
      "        [ 2.7686e-02],\n",
      "        [ 7.6457e-02],\n",
      "        [ 7.8016e-02],\n",
      "        [ 1.5826e-03],\n",
      "        [-7.3787e-03],\n",
      "        [ 8.5024e-02],\n",
      "        [ 1.0111e-01],\n",
      "        [ 7.9626e-02],\n",
      "        [ 6.3717e-02],\n",
      "        [-4.1166e-03],\n",
      "        [ 2.7036e-03],\n",
      "        [-6.3457e-05],\n",
      "        [ 1.5784e-02],\n",
      "        [ 8.3214e-02],\n",
      "        [ 3.1608e-02],\n",
      "        [ 4.4241e-02],\n",
      "        [ 5.6922e-03],\n",
      "        [-6.9513e-03],\n",
      "        [ 9.9537e-03],\n",
      "        [-5.6637e-03],\n",
      "        [ 2.0538e-02],\n",
      "        [ 4.5077e-02],\n",
      "        [ 9.2688e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0753, 0.0771, 0.0762, 0.0749, 0.0736, 0.0722, 0.0722, 0.0743, 0.0737,\n",
      "        0.0758, 0.0764, 0.0761, 0.0779, 0.0780, 0.0755, 0.0747, 0.0734, 0.0746,\n",
      "        0.0756, 0.0739, 0.0742, 0.0719, 0.0731, 0.0732, 0.0751, 0.0743, 0.0708,\n",
      "        0.0688, 0.0693, 0.0694, 0.0709, 0.0734], device='cuda:0')\n",
      "tensor([[ 0.0214],\n",
      "        [ 0.0517],\n",
      "        [ 0.1562],\n",
      "        [ 0.0389],\n",
      "        [ 0.0588],\n",
      "        [ 0.1070],\n",
      "        [-0.0037],\n",
      "        [ 0.0146],\n",
      "        [-0.0095],\n",
      "        [-0.0078],\n",
      "        [-0.0149],\n",
      "        [ 0.0118],\n",
      "        [ 0.0224],\n",
      "        [ 0.0517],\n",
      "        [ 0.0390],\n",
      "        [ 0.0075],\n",
      "        [ 0.0292],\n",
      "        [ 0.0059],\n",
      "        [-0.0059],\n",
      "        [ 0.0379],\n",
      "        [-0.0203],\n",
      "        [-0.0081],\n",
      "        [ 0.0058],\n",
      "        [-0.0171],\n",
      "        [-0.0309],\n",
      "        [ 0.0151],\n",
      "        [ 0.0734],\n",
      "        [ 0.1038],\n",
      "        [ 0.0656],\n",
      "        [ 0.0770],\n",
      "        [ 0.0249],\n",
      "        [-0.0502]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0752, 0.0733, 0.0722, 0.0749, 0.0722, 0.0735, 0.0737, 0.0737, 0.0731,\n",
      "        0.0728, 0.0749, 0.0748, 0.0746, 0.0754, 0.0736, 0.0727, 0.0731, 0.0727,\n",
      "        0.0725, 0.0717, 0.0705, 0.0703, 0.0697, 0.0697, 0.0692, 0.0700, 0.0694,\n",
      "        0.0694, 0.0692, 0.0686, 0.0686, 0.0691], device='cuda:0')\n",
      "tensor([[ 0.0117],\n",
      "        [ 0.0194],\n",
      "        [ 0.0111],\n",
      "        [ 0.0308],\n",
      "        [ 0.0203],\n",
      "        [ 0.0340],\n",
      "        [ 0.1013],\n",
      "        [ 0.0866],\n",
      "        [-0.0191],\n",
      "        [ 0.0529],\n",
      "        [ 0.0787],\n",
      "        [ 0.0441],\n",
      "        [-0.0126],\n",
      "        [ 0.0257],\n",
      "        [ 0.0196],\n",
      "        [ 0.0334],\n",
      "        [ 0.0679],\n",
      "        [-0.0026],\n",
      "        [-0.0017],\n",
      "        [ 0.0481],\n",
      "        [ 0.0064],\n",
      "        [-0.0576],\n",
      "        [ 0.0082],\n",
      "        [ 0.0259],\n",
      "        [-0.0534],\n",
      "        [ 0.0359],\n",
      "        [ 0.0368],\n",
      "        [ 0.0282],\n",
      "        [ 0.0002],\n",
      "        [ 0.0025],\n",
      "        [ 0.0614],\n",
      "        [-0.0127]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0688, 0.0706, 0.0705, 0.0705, 0.0702, 0.0696, 0.0684, 0.0686, 0.0688,\n",
      "        0.0681, 0.0673, 0.0652, 0.0665, 0.0670, 0.0687, 0.0610, 0.0573, 0.0607,\n",
      "        0.0601, 0.0575, 0.0550, 0.0573, 0.0576, 0.0575, 0.0569, 0.0568, 0.0562,\n",
      "        0.0541, 0.0550, 0.0573, 0.0580, 0.0580], device='cuda:0')\n",
      "tensor([[ 0.0774],\n",
      "        [ 0.0299],\n",
      "        [-0.0032],\n",
      "        [ 0.0590],\n",
      "        [ 0.0118],\n",
      "        [ 0.1548],\n",
      "        [-0.0064],\n",
      "        [-0.0347],\n",
      "        [ 0.0554],\n",
      "        [ 0.0240],\n",
      "        [ 0.0382],\n",
      "        [ 0.0310],\n",
      "        [ 0.0140],\n",
      "        [ 0.0021],\n",
      "        [ 0.0303],\n",
      "        [ 0.0022],\n",
      "        [-0.0008],\n",
      "        [ 0.0465],\n",
      "        [ 0.0309],\n",
      "        [ 0.0793],\n",
      "        [ 0.0234],\n",
      "        [-0.0005],\n",
      "        [ 0.0098],\n",
      "        [-0.0226],\n",
      "        [-0.0103],\n",
      "        [ 0.0368],\n",
      "        [ 0.0053],\n",
      "        [ 0.0091],\n",
      "        [ 0.0249],\n",
      "        [ 0.0609],\n",
      "        [ 0.0256],\n",
      "        [ 0.0465]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0616, 0.0637, 0.0640, 0.0632, 0.0639, 0.0643, 0.0656, 0.0668, 0.0634,\n",
      "        0.0652, 0.0656, 0.0660, 0.0650, 0.0649, 0.0629, 0.0635, 0.0638, 0.0635,\n",
      "        0.0624, 0.0622, 0.0624, 0.0640, 0.0629, 0.0646, 0.0663, 0.0655, 0.0634,\n",
      "        0.0647, 0.0622, 0.0610, 0.0624, 0.0612], device='cuda:0')\n",
      "tensor([[ 1.7312e-01],\n",
      "        [ 4.1530e-02],\n",
      "        [ 1.7551e-02],\n",
      "        [ 5.8282e-02],\n",
      "        [-1.0750e-02],\n",
      "        [ 9.2560e-02],\n",
      "        [ 6.4718e-02],\n",
      "        [-8.5492e-03],\n",
      "        [-1.3292e-02],\n",
      "        [ 3.8720e-02],\n",
      "        [-8.0269e-05],\n",
      "        [ 7.9796e-03],\n",
      "        [ 5.4193e-03],\n",
      "        [-4.8627e-03],\n",
      "        [ 8.1847e-03],\n",
      "        [ 2.7406e-02],\n",
      "        [ 2.6228e-02],\n",
      "        [ 3.5255e-02],\n",
      "        [-1.5072e-02],\n",
      "        [-1.6160e-02],\n",
      "        [ 5.9969e-03],\n",
      "        [ 4.2062e-02],\n",
      "        [ 5.1512e-02],\n",
      "        [ 1.5230e-02],\n",
      "        [-7.0808e-03],\n",
      "        [-2.4098e-02],\n",
      "        [ 4.0117e-02],\n",
      "        [-1.1931e-02],\n",
      "        [ 1.4186e-02],\n",
      "        [ 6.6813e-02],\n",
      "        [ 5.6776e-02],\n",
      "        [-1.3985e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0593, 0.0585, 0.0602, 0.0593, 0.0590, 0.0570, 0.0561, 0.0555, 0.0577,\n",
      "        0.0590, 0.0584, 0.0550, 0.0547, 0.0551, 0.0533, 0.0516, 0.0544, 0.0548,\n",
      "        0.0525, 0.0517, 0.0508, 0.0541, 0.0560, 0.0543, 0.0536, 0.0524, 0.0514,\n",
      "        0.0488, 0.0478, 0.0480, 0.0480, 0.0483], device='cuda:0')\n",
      "tensor([[ 0.0293],\n",
      "        [ 0.0498],\n",
      "        [ 0.0884],\n",
      "        [-0.0101],\n",
      "        [ 0.0409],\n",
      "        [ 0.0255],\n",
      "        [ 0.0409],\n",
      "        [-0.0111],\n",
      "        [ 0.0611],\n",
      "        [ 0.0952],\n",
      "        [ 0.0339],\n",
      "        [ 0.0402],\n",
      "        [ 0.0326],\n",
      "        [ 0.0072],\n",
      "        [ 0.0335],\n",
      "        [ 0.0403],\n",
      "        [ 0.0234],\n",
      "        [ 0.0164],\n",
      "        [-0.0061],\n",
      "        [-0.0081],\n",
      "        [ 0.0271],\n",
      "        [ 0.0164],\n",
      "        [ 0.0118],\n",
      "        [ 0.0288],\n",
      "        [-0.0193],\n",
      "        [ 0.0939],\n",
      "        [-0.0211],\n",
      "        [ 0.0094],\n",
      "        [ 0.0006],\n",
      "        [-0.0002],\n",
      "        [ 0.0154],\n",
      "        [-0.0080]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0516, 0.0507, 0.0513, 0.0527, 0.0548, 0.0533, 0.0531, 0.0545, 0.0539,\n",
      "        0.0535, 0.0536, 0.0529, 0.0525, 0.0534, 0.0531, 0.0519, 0.0507, 0.0506,\n",
      "        0.0508, 0.0505, 0.0495, 0.0480, 0.0481, 0.0484, 0.0476, 0.0497, 0.0491,\n",
      "        0.0502, 0.0508, 0.0505, 0.0503, 0.0509], device='cuda:0')\n",
      "tensor([[-0.0045],\n",
      "        [ 0.0075],\n",
      "        [ 0.0586],\n",
      "        [-0.0270],\n",
      "        [ 0.0259],\n",
      "        [ 0.0155],\n",
      "        [ 0.0010],\n",
      "        [ 0.0067],\n",
      "        [ 0.0323],\n",
      "        [ 0.0348],\n",
      "        [-0.0153],\n",
      "        [ 0.0161],\n",
      "        [ 0.0415],\n",
      "        [ 0.1310],\n",
      "        [ 0.0591],\n",
      "        [ 0.0405],\n",
      "        [ 0.1046],\n",
      "        [ 0.0440],\n",
      "        [ 0.0153],\n",
      "        [ 0.0043],\n",
      "        [-0.0225],\n",
      "        [-0.0146],\n",
      "        [ 0.0583],\n",
      "        [ 0.0136],\n",
      "        [ 0.0422],\n",
      "        [ 0.0092],\n",
      "        [-0.0091],\n",
      "        [ 0.0120],\n",
      "        [-0.0496],\n",
      "        [ 0.1868],\n",
      "        [-0.0239],\n",
      "        [-0.0138]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0507, 0.0510, 0.0504, 0.0506, 0.0521, 0.0528, 0.0515, 0.0517, 0.0535,\n",
      "        0.0544, 0.0545, 0.0542, 0.0543, 0.0538, 0.0533, 0.0534, 0.0525, 0.0526,\n",
      "        0.0538, 0.0545, 0.0528, 0.0515, 0.0503, 0.0486, 0.0498, 0.0514, 0.0516,\n",
      "        0.0497, 0.0488, 0.0495, 0.0487, 0.0485], device='cuda:0')\n",
      "tensor([[ 0.0225],\n",
      "        [-0.0125],\n",
      "        [ 0.0055],\n",
      "        [-0.0354],\n",
      "        [-0.0845],\n",
      "        [ 0.0151],\n",
      "        [ 0.0373],\n",
      "        [ 0.0648],\n",
      "        [ 0.0962],\n",
      "        [ 0.0171],\n",
      "        [ 0.0325],\n",
      "        [ 0.0631],\n",
      "        [ 0.0970],\n",
      "        [-0.0526],\n",
      "        [ 0.0230],\n",
      "        [ 0.0268],\n",
      "        [ 0.0148],\n",
      "        [ 0.1477],\n",
      "        [ 0.0620],\n",
      "        [ 0.0087],\n",
      "        [ 0.0362],\n",
      "        [-0.0104],\n",
      "        [ 0.0032],\n",
      "        [ 0.0168],\n",
      "        [ 0.0166],\n",
      "        [ 0.0258],\n",
      "        [-0.0265],\n",
      "        [ 0.0166],\n",
      "        [ 0.0416],\n",
      "        [ 0.0453],\n",
      "        [ 0.0276],\n",
      "        [ 0.0062]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0488, 0.0499, 0.0499, 0.0501, 0.0491, 0.0488, 0.0478, 0.0467, 0.0462,\n",
      "        0.0473, 0.0470, 0.0478, 0.0486, 0.0484, 0.0475, 0.0469, 0.0481, 0.0474,\n",
      "        0.0488, 0.0469, 0.0461, 0.0466, 0.0464, 0.0457, 0.0452, 0.0452, 0.0449,\n",
      "        0.0445, 0.0446, 0.0453, 0.0448, 0.0429], device='cuda:0')\n",
      "tensor([[ 0.0767],\n",
      "        [ 0.0655],\n",
      "        [ 0.0156],\n",
      "        [ 0.0014],\n",
      "        [ 0.0534],\n",
      "        [ 0.0108],\n",
      "        [ 0.0019],\n",
      "        [ 0.0303],\n",
      "        [ 0.0517],\n",
      "        [ 0.0081],\n",
      "        [ 0.0952],\n",
      "        [ 0.2513],\n",
      "        [ 0.0696],\n",
      "        [ 0.1010],\n",
      "        [ 0.0708],\n",
      "        [ 0.0452],\n",
      "        [-0.0030],\n",
      "        [ 0.0037],\n",
      "        [ 0.0568],\n",
      "        [ 0.0269],\n",
      "        [-0.0007],\n",
      "        [ 0.0274],\n",
      "        [ 0.0324],\n",
      "        [ 0.0205],\n",
      "        [ 0.0147],\n",
      "        [ 0.0276],\n",
      "        [-0.0013],\n",
      "        [ 0.0005],\n",
      "        [ 0.0131],\n",
      "        [ 0.0430],\n",
      "        [ 0.0108],\n",
      "        [ 0.0913]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0440, 0.0435, 0.0454, 0.0458, 0.0458, 0.0479, 0.0484, 0.0487, 0.0476,\n",
      "        0.0471, 0.0479, 0.0465, 0.0453, 0.0445, 0.0446, 0.0438, 0.0436, 0.0444,\n",
      "        0.0461, 0.0446, 0.0433, 0.0435, 0.0435, 0.0432, 0.0427, 0.0415, 0.0395,\n",
      "        0.0403, 0.0391, 0.0394, 0.0442, 0.0454], device='cuda:0')\n",
      "tensor([[ 0.0064],\n",
      "        [ 0.0929],\n",
      "        [-0.0239],\n",
      "        [ 0.0045],\n",
      "        [ 0.0052],\n",
      "        [ 0.0330],\n",
      "        [ 0.0843],\n",
      "        [ 0.1493],\n",
      "        [ 0.0330],\n",
      "        [ 0.0485],\n",
      "        [ 0.0114],\n",
      "        [ 0.0185],\n",
      "        [ 0.0271],\n",
      "        [-0.0165],\n",
      "        [ 0.1130],\n",
      "        [ 0.0110],\n",
      "        [ 0.0227],\n",
      "        [-0.0018],\n",
      "        [-0.0066],\n",
      "        [ 0.0072],\n",
      "        [ 0.0279],\n",
      "        [ 0.1153],\n",
      "        [ 0.0242],\n",
      "        [ 0.0065],\n",
      "        [-0.0028],\n",
      "        [-0.0045],\n",
      "        [ 0.0222],\n",
      "        [-0.0195],\n",
      "        [ 0.0512],\n",
      "        [ 0.0313],\n",
      "        [ 0.0283],\n",
      "        [ 0.0139]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0438, 0.0450, 0.0448, 0.0450, 0.0456, 0.0463, 0.0460, 0.0441, 0.0416,\n",
      "        0.0407, 0.0420, 0.0402, 0.0403, 0.0400, 0.0410, 0.0424, 0.0441, 0.0423,\n",
      "        0.0423, 0.0407, 0.0404, 0.0398, 0.0398, 0.0393, 0.0388, 0.0397, 0.0374,\n",
      "        0.0376, 0.0368, 0.0379, 0.0374, 0.0372], device='cuda:0')\n",
      "tensor([[ 0.0337],\n",
      "        [ 0.0288],\n",
      "        [ 0.0296],\n",
      "        [ 0.0297],\n",
      "        [ 0.0395],\n",
      "        [ 0.0025],\n",
      "        [ 0.0748],\n",
      "        [ 0.0018],\n",
      "        [-0.0304],\n",
      "        [-0.0023],\n",
      "        [-0.0106],\n",
      "        [ 0.0115],\n",
      "        [ 0.0671],\n",
      "        [ 0.0246],\n",
      "        [ 0.1403],\n",
      "        [-0.0678],\n",
      "        [ 0.0204],\n",
      "        [ 0.0273],\n",
      "        [-0.0371],\n",
      "        [ 0.1129],\n",
      "        [ 0.0427],\n",
      "        [ 0.0562],\n",
      "        [ 0.0937],\n",
      "        [ 0.0076],\n",
      "        [-0.0088],\n",
      "        [ 0.0484],\n",
      "        [ 0.0586],\n",
      "        [ 0.0156],\n",
      "        [ 0.0255],\n",
      "        [ 0.0504],\n",
      "        [ 0.0060],\n",
      "        [ 0.0476]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0364, 0.0374, 0.0349, 0.0339, 0.0345, 0.0336, 0.0318, 0.0314, 0.0295,\n",
      "        0.0269, 0.0256, 0.0279, 0.0285, 0.0299, 0.0311, 0.0314, 0.0307, 0.0300,\n",
      "        0.0294, 0.0291, 0.0282, 0.0277, 0.0280, 0.0278, 0.0273, 0.0269, 0.0292,\n",
      "        0.0286, 0.0315, 0.0327, 0.0333, 0.0336], device='cuda:0')\n",
      "tensor([[ 0.0219],\n",
      "        [ 0.0643],\n",
      "        [ 0.0582],\n",
      "        [ 0.0615],\n",
      "        [ 0.0704],\n",
      "        [ 0.0356],\n",
      "        [ 0.0328],\n",
      "        [ 0.0056],\n",
      "        [ 0.0104],\n",
      "        [ 0.0855],\n",
      "        [ 0.0790],\n",
      "        [ 0.0242],\n",
      "        [ 0.0119],\n",
      "        [-0.0239],\n",
      "        [ 0.0750],\n",
      "        [-0.0128],\n",
      "        [ 0.0414],\n",
      "        [ 0.0335],\n",
      "        [ 0.0337],\n",
      "        [ 0.0392],\n",
      "        [ 0.0110],\n",
      "        [-0.0187],\n",
      "        [-0.0050],\n",
      "        [-0.0028],\n",
      "        [ 0.0028],\n",
      "        [-0.0008],\n",
      "        [ 0.0193],\n",
      "        [-0.0344],\n",
      "        [ 0.0755],\n",
      "        [-0.0407],\n",
      "        [ 0.1073],\n",
      "        [-0.0693]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0331, 0.0330, 0.0339, 0.0351, 0.0376, 0.0362, 0.0345, 0.0342, 0.0331,\n",
      "        0.0341, 0.0373, 0.0377, 0.0366, 0.0373, 0.0367, 0.0386, 0.0350, 0.0360,\n",
      "        0.0370, 0.0368, 0.0353, 0.0353, 0.0345, 0.0339, 0.0321, 0.0308, 0.0305,\n",
      "        0.0314, 0.0311, 0.0321, 0.0330, 0.0333], device='cuda:0')\n",
      "tensor([[-0.0413],\n",
      "        [-0.0211],\n",
      "        [ 0.0276],\n",
      "        [ 0.0949],\n",
      "        [ 0.1425],\n",
      "        [ 0.0238],\n",
      "        [ 0.0113],\n",
      "        [-0.0176],\n",
      "        [ 0.0642],\n",
      "        [ 0.0580],\n",
      "        [-0.0124],\n",
      "        [ 0.0199],\n",
      "        [ 0.0882],\n",
      "        [ 0.0550],\n",
      "        [ 0.0324],\n",
      "        [-0.0106],\n",
      "        [-0.0126],\n",
      "        [ 0.0274],\n",
      "        [-0.0052],\n",
      "        [ 0.0418],\n",
      "        [ 0.0456],\n",
      "        [ 0.0171],\n",
      "        [-0.0089],\n",
      "        [ 0.0173],\n",
      "        [ 0.0241],\n",
      "        [ 0.0673],\n",
      "        [ 0.0231],\n",
      "        [ 0.0385],\n",
      "        [ 0.0838],\n",
      "        [ 0.0641],\n",
      "        [ 0.0322],\n",
      "        [-0.0033]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0331, 0.0311, 0.0304, 0.0308, 0.0298, 0.0293, 0.0305, 0.0315, 0.0314,\n",
      "        0.0308, 0.0301, 0.0295, 0.0314, 0.0309, 0.0306, 0.0308, 0.0297, 0.0301,\n",
      "        0.0294, 0.0286, 0.0292, 0.0303, 0.0306, 0.0302, 0.0299, 0.0297, 0.0289,\n",
      "        0.0305, 0.0313, 0.0307, 0.0304, 0.0290], device='cuda:0')\n",
      "tensor([[ 0.0266],\n",
      "        [ 0.0083],\n",
      "        [-0.0135],\n",
      "        [-0.0262],\n",
      "        [ 0.0733],\n",
      "        [ 0.0545],\n",
      "        [ 0.0582],\n",
      "        [-0.0395],\n",
      "        [ 0.0537],\n",
      "        [ 0.0583],\n",
      "        [ 0.0286],\n",
      "        [-0.0403],\n",
      "        [-0.0485],\n",
      "        [ 0.1178],\n",
      "        [ 0.0556],\n",
      "        [ 0.0459],\n",
      "        [ 0.0947],\n",
      "        [ 0.0260],\n",
      "        [ 0.0600],\n",
      "        [ 0.0151],\n",
      "        [ 0.0475],\n",
      "        [ 0.0301],\n",
      "        [ 0.0329],\n",
      "        [ 0.0299],\n",
      "        [ 0.0213],\n",
      "        [ 0.1033],\n",
      "        [ 0.1070],\n",
      "        [ 0.0385],\n",
      "        [ 0.0251],\n",
      "        [ 0.0609],\n",
      "        [ 0.0286],\n",
      "        [ 0.0412]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0282, 0.0274, 0.0280, 0.0279, 0.0290, 0.0288, 0.0288, 0.0288, 0.0338,\n",
      "        0.0360, 0.0347, 0.0363, 0.0377, 0.0373, 0.0397, 0.0386, 0.0391, 0.0394,\n",
      "        0.0402, 0.0428, 0.0443, 0.0457, 0.0433, 0.0450, 0.0450, 0.0452, 0.0433,\n",
      "        0.0420, 0.0433, 0.0434, 0.0443, 0.0457], device='cuda:0')\n",
      "tensor([[ 0.0235],\n",
      "        [ 0.0088],\n",
      "        [-0.0109],\n",
      "        [ 0.0175],\n",
      "        [ 0.0229],\n",
      "        [ 0.0674],\n",
      "        [ 0.0210],\n",
      "        [ 0.0378],\n",
      "        [ 0.0690],\n",
      "        [ 0.0096],\n",
      "        [ 0.0062],\n",
      "        [ 0.0336],\n",
      "        [ 0.0090],\n",
      "        [ 0.0130],\n",
      "        [ 0.0478],\n",
      "        [-0.0051],\n",
      "        [ 0.0303],\n",
      "        [ 0.0318],\n",
      "        [-0.0155],\n",
      "        [ 0.1318],\n",
      "        [ 0.0146],\n",
      "        [-0.0135],\n",
      "        [-0.0220],\n",
      "        [ 0.0290],\n",
      "        [-0.0164],\n",
      "        [ 0.0477],\n",
      "        [ 0.1627],\n",
      "        [-0.0219],\n",
      "        [ 0.1297],\n",
      "        [-0.0355],\n",
      "        [ 0.0202],\n",
      "        [ 0.0633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0440, 0.0443, 0.0455, 0.0448, 0.0455, 0.0443, 0.0436, 0.0448, 0.0443,\n",
      "        0.0453, 0.0441, 0.0440, 0.0426, 0.0425, 0.0411, 0.0427, 0.0427, 0.0420,\n",
      "        0.0417, 0.0416, 0.0409, 0.0392, 0.0392, 0.0391, 0.0402, 0.0426, 0.0422,\n",
      "        0.0412, 0.0426, 0.0426, 0.0435, 0.0435], device='cuda:0')\n",
      "tensor([[ 0.0318],\n",
      "        [ 0.0373],\n",
      "        [ 0.0196],\n",
      "        [ 0.0192],\n",
      "        [ 0.0372],\n",
      "        [ 0.0090],\n",
      "        [ 0.0377],\n",
      "        [ 0.0017],\n",
      "        [ 0.0791],\n",
      "        [ 0.1136],\n",
      "        [ 0.0343],\n",
      "        [ 0.0369],\n",
      "        [-0.0058],\n",
      "        [ 0.0353],\n",
      "        [ 0.0005],\n",
      "        [ 0.0187],\n",
      "        [ 0.0086],\n",
      "        [ 0.0349],\n",
      "        [ 0.0201],\n",
      "        [ 0.0244],\n",
      "        [ 0.0113],\n",
      "        [-0.0074],\n",
      "        [-0.0278],\n",
      "        [ 0.1175],\n",
      "        [ 0.0843],\n",
      "        [ 0.0013],\n",
      "        [ 0.0253],\n",
      "        [ 0.0712],\n",
      "        [ 0.0411],\n",
      "        [-0.0250],\n",
      "        [ 0.0126],\n",
      "        [ 0.0536]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0425, 0.0438, 0.0433, 0.0421, 0.0418, 0.0415, 0.0405, 0.0404, 0.0427,\n",
      "        0.0425, 0.0420, 0.0438, 0.0426, 0.0434, 0.0426, 0.0440, 0.0445, 0.0467,\n",
      "        0.0467, 0.0449, 0.0447, 0.0454, 0.0445, 0.0435, 0.0439, 0.0453, 0.0445,\n",
      "        0.0437, 0.0435, 0.0442, 0.0451, 0.0452], device='cuda:0')\n",
      "tensor([[ 0.0473],\n",
      "        [ 0.0240],\n",
      "        [ 0.0461],\n",
      "        [ 0.0145],\n",
      "        [ 0.0105],\n",
      "        [ 0.0861],\n",
      "        [ 0.0320],\n",
      "        [-0.0013],\n",
      "        [ 0.0690],\n",
      "        [-0.0100],\n",
      "        [ 0.0855],\n",
      "        [ 0.0441],\n",
      "        [-0.0070],\n",
      "        [ 0.0421],\n",
      "        [ 0.0905],\n",
      "        [-0.0407],\n",
      "        [ 0.0107],\n",
      "        [ 0.0018],\n",
      "        [ 0.0302],\n",
      "        [ 0.1113],\n",
      "        [ 0.0903],\n",
      "        [ 0.0171],\n",
      "        [ 0.0391],\n",
      "        [ 0.0005],\n",
      "        [-0.0082],\n",
      "        [ 0.0191],\n",
      "        [-0.0031],\n",
      "        [ 0.0476],\n",
      "        [ 0.0381],\n",
      "        [ 0.0346],\n",
      "        [-0.0193],\n",
      "        [ 0.0029]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0447, 0.0451, 0.0438, 0.0433, 0.0432, 0.0428, 0.0423, 0.0416, 0.0422,\n",
      "        0.0408, 0.0410, 0.0422, 0.0417, 0.0436, 0.0432, 0.0429, 0.0425, 0.0424,\n",
      "        0.0424, 0.0423, 0.0418, 0.0417, 0.0410, 0.0416, 0.0426, 0.0412, 0.0414,\n",
      "        0.0421, 0.0418, 0.0411, 0.0405, 0.0403], device='cuda:0')\n",
      "tensor([[ 0.1186],\n",
      "        [ 0.1106],\n",
      "        [ 0.0080],\n",
      "        [ 0.0129],\n",
      "        [ 0.0381],\n",
      "        [-0.0044],\n",
      "        [-0.0170],\n",
      "        [-0.0283],\n",
      "        [-0.0079],\n",
      "        [ 0.1226],\n",
      "        [ 0.0787],\n",
      "        [ 0.0195],\n",
      "        [ 0.0684],\n",
      "        [ 0.0252],\n",
      "        [ 0.0284],\n",
      "        [ 0.0076],\n",
      "        [ 0.0548],\n",
      "        [ 0.0732],\n",
      "        [ 0.0375],\n",
      "        [ 0.1030],\n",
      "        [-0.0090],\n",
      "        [-0.0016],\n",
      "        [ 0.0487],\n",
      "        [ 0.0178],\n",
      "        [ 0.0015],\n",
      "        [ 0.0303],\n",
      "        [ 0.0266],\n",
      "        [ 0.0241],\n",
      "        [ 0.0102],\n",
      "        [ 0.0289],\n",
      "        [ 0.0887],\n",
      "        [ 0.0301]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0401, 0.0390, 0.0377, 0.0381, 0.0370, 0.0370, 0.0374, 0.0383, 0.0369,\n",
      "        0.0366, 0.0362, 0.0352, 0.0356, 0.0348, 0.0339, 0.0349, 0.0345, 0.0331,\n",
      "        0.0338, 0.0345, 0.0345, 0.0333, 0.0328, 0.0331, 0.0339, 0.0345, 0.0333,\n",
      "        0.0342, 0.0357, 0.0357, 0.0342, 0.0347], device='cuda:0')\n",
      "tensor([[-0.0264],\n",
      "        [ 0.0242],\n",
      "        [-0.0083],\n",
      "        [-0.0166],\n",
      "        [ 0.0342],\n",
      "        [-0.0138],\n",
      "        [-0.0337],\n",
      "        [ 0.0427],\n",
      "        [ 0.0065],\n",
      "        [-0.0339],\n",
      "        [ 0.0035],\n",
      "        [ 0.0495],\n",
      "        [-0.0279],\n",
      "        [ 0.0704],\n",
      "        [ 0.0813],\n",
      "        [ 0.0211],\n",
      "        [ 0.0540],\n",
      "        [-0.0028],\n",
      "        [ 0.0276],\n",
      "        [ 0.0736],\n",
      "        [ 0.0447],\n",
      "        [ 0.0080],\n",
      "        [ 0.0510],\n",
      "        [ 0.0859],\n",
      "        [-0.0086],\n",
      "        [ 0.0186],\n",
      "        [ 0.0087],\n",
      "        [-0.0179],\n",
      "        [ 0.0575],\n",
      "        [ 0.1130],\n",
      "        [ 0.1013],\n",
      "        [ 0.0718]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0345, 0.0339, 0.0349, 0.0336, 0.0339, 0.0342, 0.0339, 0.0338, 0.0333,\n",
      "        0.0338, 0.0357, 0.0366, 0.0358, 0.0364, 0.0371, 0.0374, 0.0386, 0.0370,\n",
      "        0.0363, 0.0349, 0.0364, 0.0384, 0.0401, 0.0401, 0.0415, 0.0413, 0.0415,\n",
      "        0.0429, 0.0423, 0.0424, 0.0425, 0.0419], device='cuda:0')\n",
      "tensor([[ 0.1106],\n",
      "        [ 0.0681],\n",
      "        [ 0.0382],\n",
      "        [ 0.0438],\n",
      "        [ 0.0297],\n",
      "        [-0.0256],\n",
      "        [ 0.0197],\n",
      "        [ 0.0484],\n",
      "        [ 0.0805],\n",
      "        [ 0.0067],\n",
      "        [ 0.0492],\n",
      "        [ 0.0037],\n",
      "        [ 0.1213],\n",
      "        [ 0.0158],\n",
      "        [ 0.0311],\n",
      "        [-0.0354],\n",
      "        [-0.0070],\n",
      "        [ 0.0179],\n",
      "        [ 0.0403],\n",
      "        [ 0.0232],\n",
      "        [ 0.0455],\n",
      "        [ 0.0191],\n",
      "        [ 0.1799],\n",
      "        [ 0.0291],\n",
      "        [ 0.0478],\n",
      "        [-0.0230],\n",
      "        [ 0.0711],\n",
      "        [-0.0166],\n",
      "        [ 0.0337],\n",
      "        [ 0.0630],\n",
      "        [ 0.0737],\n",
      "        [-0.0015]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0432, 0.0436, 0.0437, 0.0443, 0.0424, 0.0431, 0.0442, 0.0430, 0.0431,\n",
      "        0.0434, 0.0431, 0.0438, 0.0444, 0.0448, 0.0446, 0.0447, 0.0456, 0.0471,\n",
      "        0.0461, 0.0464, 0.0471, 0.0458, 0.0455, 0.0460, 0.0462, 0.0463, 0.0470,\n",
      "        0.0471, 0.0476, 0.0469, 0.0459, 0.0454], device='cuda:0')\n",
      "tensor([[ 0.0175],\n",
      "        [ 0.0113],\n",
      "        [ 0.0329],\n",
      "        [-0.0032],\n",
      "        [ 0.0310],\n",
      "        [ 0.0659],\n",
      "        [-0.0289],\n",
      "        [ 0.0173],\n",
      "        [ 0.0128],\n",
      "        [-0.0019],\n",
      "        [-0.0339],\n",
      "        [-0.0162],\n",
      "        [ 0.0239],\n",
      "        [ 0.0020],\n",
      "        [ 0.0199],\n",
      "        [ 0.0447],\n",
      "        [ 0.0016],\n",
      "        [ 0.0638],\n",
      "        [ 0.0093],\n",
      "        [ 0.0041],\n",
      "        [ 0.0173],\n",
      "        [ 0.0410],\n",
      "        [ 0.0568],\n",
      "        [ 0.0236],\n",
      "        [-0.0007],\n",
      "        [ 0.0285],\n",
      "        [ 0.0328],\n",
      "        [ 0.0221],\n",
      "        [ 0.0264],\n",
      "        [ 0.0703],\n",
      "        [ 0.0279],\n",
      "        [ 0.0377]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0457, 0.0441, 0.0442, 0.0445, 0.0449, 0.0441, 0.0444, 0.0447, 0.0456,\n",
      "        0.0456, 0.0455, 0.0450, 0.0445, 0.0457, 0.0466, 0.0466, 0.0464, 0.0466,\n",
      "        0.0469, 0.0476, 0.0486, 0.0484, 0.0482, 0.0487, 0.0490, 0.0503, 0.0499,\n",
      "        0.0519, 0.0515, 0.0522, 0.0545, 0.0554], device='cuda:0')\n",
      "tensor([[ 4.9063e-02],\n",
      "        [ 1.5689e-02],\n",
      "        [ 8.6177e-02],\n",
      "        [ 1.0475e-01],\n",
      "        [ 1.7750e-02],\n",
      "        [-8.4314e-05],\n",
      "        [ 5.0326e-02],\n",
      "        [ 9.9132e-02],\n",
      "        [-5.3404e-02],\n",
      "        [ 4.7471e-02],\n",
      "        [ 3.1070e-02],\n",
      "        [ 2.0548e-02],\n",
      "        [ 1.4334e-02],\n",
      "        [ 2.3772e-02],\n",
      "        [ 4.0536e-02],\n",
      "        [ 8.0755e-02],\n",
      "        [ 1.6405e-02],\n",
      "        [ 9.9112e-02],\n",
      "        [ 2.5931e-02],\n",
      "        [ 6.4732e-02],\n",
      "        [ 1.2932e-01],\n",
      "        [-1.7944e-02],\n",
      "        [ 5.4117e-02],\n",
      "        [ 7.7905e-02],\n",
      "        [-4.5151e-06],\n",
      "        [ 1.3909e-03],\n",
      "        [ 4.7577e-02],\n",
      "        [ 4.0916e-02],\n",
      "        [ 3.0523e-02],\n",
      "        [-3.5171e-02],\n",
      "        [ 3.6850e-02],\n",
      "        [ 8.6277e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0538, 0.0545, 0.0558, 0.0558, 0.0545, 0.0548, 0.0564, 0.0568, 0.0573,\n",
      "        0.0578, 0.0586, 0.0569, 0.0557, 0.0556, 0.0569, 0.0561, 0.0553, 0.0557,\n",
      "        0.0555, 0.0562, 0.0579, 0.0581, 0.0576, 0.0582, 0.0575, 0.0563, 0.0562,\n",
      "        0.0573, 0.0573, 0.0573, 0.0564, 0.0567], device='cuda:0')\n",
      "tensor([[ 2.7366e-03],\n",
      "        [-2.3550e-03],\n",
      "        [ 9.2904e-04],\n",
      "        [ 2.3314e-02],\n",
      "        [-6.4233e-03],\n",
      "        [ 9.1514e-03],\n",
      "        [ 4.2816e-02],\n",
      "        [ 2.7669e-02],\n",
      "        [ 6.6102e-02],\n",
      "        [ 1.9070e-02],\n",
      "        [ 1.0811e-02],\n",
      "        [ 1.1131e-02],\n",
      "        [-6.6192e-03],\n",
      "        [ 8.7854e-03],\n",
      "        [ 1.9138e-02],\n",
      "        [ 1.4605e-02],\n",
      "        [ 9.9920e-03],\n",
      "        [ 5.1175e-02],\n",
      "        [-2.9724e-03],\n",
      "        [ 3.8875e-02],\n",
      "        [ 8.9686e-05],\n",
      "        [ 4.9189e-02],\n",
      "        [-3.9521e-03],\n",
      "        [-1.1593e-02],\n",
      "        [ 1.1304e-01],\n",
      "        [ 1.1110e-01],\n",
      "        [ 1.6107e-01],\n",
      "        [-2.4631e-03],\n",
      "        [ 6.3357e-02],\n",
      "        [-1.6371e-02],\n",
      "        [ 1.0363e-01],\n",
      "        [ 4.1701e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0575, 0.0571, 0.0580, 0.0592, 0.0579, 0.0574, 0.0580, 0.0569, 0.0569,\n",
      "        0.0571, 0.0570, 0.0581, 0.0580, 0.0570, 0.0573, 0.0576, 0.0576, 0.0581,\n",
      "        0.0580, 0.0595, 0.0610, 0.0604, 0.0601, 0.0599, 0.0598, 0.0580, 0.0585,\n",
      "        0.0562, 0.0564, 0.0572, 0.0579, 0.0576], device='cuda:0')\n",
      "tensor([[ 0.0977],\n",
      "        [ 0.0070],\n",
      "        [ 0.0103],\n",
      "        [-0.0027],\n",
      "        [ 0.0388],\n",
      "        [ 0.0794],\n",
      "        [ 0.0435],\n",
      "        [ 0.0259],\n",
      "        [-0.0006],\n",
      "        [ 0.0105],\n",
      "        [ 0.0204],\n",
      "        [ 0.0480],\n",
      "        [ 0.1374],\n",
      "        [-0.0071],\n",
      "        [ 0.0238],\n",
      "        [ 0.0528],\n",
      "        [ 0.0423],\n",
      "        [ 0.1510],\n",
      "        [ 0.0214],\n",
      "        [ 0.0549],\n",
      "        [-0.0010],\n",
      "        [ 0.0428],\n",
      "        [ 0.0527],\n",
      "        [ 0.0141],\n",
      "        [-0.0018],\n",
      "        [ 0.0346],\n",
      "        [ 0.0426],\n",
      "        [-0.0041],\n",
      "        [ 0.0263],\n",
      "        [-0.0193],\n",
      "        [-0.0112],\n",
      "        [-0.0086]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0575, 0.0571, 0.0573, 0.0563, 0.0563, 0.0556, 0.0555, 0.0542, 0.0553,\n",
      "        0.0545, 0.0544, 0.0547, 0.0569, 0.0564, 0.0566, 0.0562, 0.0552, 0.0552,\n",
      "        0.0554, 0.0556, 0.0566, 0.0556, 0.0545, 0.0548, 0.0545, 0.0555, 0.0565,\n",
      "        0.0557, 0.0567, 0.0563, 0.0554, 0.0555], device='cuda:0')\n",
      "tensor([[-0.0571],\n",
      "        [-0.0201],\n",
      "        [-0.0298],\n",
      "        [ 0.0436],\n",
      "        [ 0.0163],\n",
      "        [ 0.0301],\n",
      "        [ 0.0084],\n",
      "        [ 0.0277],\n",
      "        [-0.0174],\n",
      "        [ 0.0192],\n",
      "        [ 0.0184],\n",
      "        [ 0.0617],\n",
      "        [ 0.1538],\n",
      "        [ 0.0366],\n",
      "        [ 0.0355],\n",
      "        [ 0.0719],\n",
      "        [ 0.1013],\n",
      "        [ 0.0793],\n",
      "        [-0.0057],\n",
      "        [ 0.0172],\n",
      "        [ 0.0525],\n",
      "        [-0.0104],\n",
      "        [ 0.0071],\n",
      "        [ 0.0149],\n",
      "        [ 0.0035],\n",
      "        [ 0.0071],\n",
      "        [ 0.0040],\n",
      "        [ 0.0228],\n",
      "        [ 0.0119],\n",
      "        [ 0.0075],\n",
      "        [ 0.0077],\n",
      "        [ 0.0009]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0554, 0.0555, 0.0562, 0.0568, 0.0576, 0.0572, 0.0581, 0.0601, 0.0593,\n",
      "        0.0606, 0.0601, 0.0610, 0.0620, 0.0618, 0.0615, 0.0621, 0.0624, 0.0618,\n",
      "        0.0622, 0.0619, 0.0628, 0.0624, 0.0628, 0.0633, 0.0627, 0.0624, 0.0623,\n",
      "        0.0617, 0.0610, 0.0606, 0.0607, 0.0612], device='cuda:0')\n",
      "tensor([[ 0.0810],\n",
      "        [ 0.0276],\n",
      "        [ 0.0815],\n",
      "        [ 0.0305],\n",
      "        [ 0.0365],\n",
      "        [ 0.0334],\n",
      "        [ 0.0123],\n",
      "        [ 0.0481],\n",
      "        [ 0.0103],\n",
      "        [ 0.0272],\n",
      "        [-0.0119],\n",
      "        [ 0.0092],\n",
      "        [ 0.0601],\n",
      "        [ 0.0082],\n",
      "        [-0.0035],\n",
      "        [ 0.0107],\n",
      "        [ 0.0438],\n",
      "        [ 0.1117],\n",
      "        [-0.0106],\n",
      "        [ 0.0413],\n",
      "        [ 0.0936],\n",
      "        [ 0.0136],\n",
      "        [-0.0074],\n",
      "        [ 0.0774],\n",
      "        [-0.0060],\n",
      "        [ 0.0444],\n",
      "        [ 0.0350],\n",
      "        [-0.0889],\n",
      "        [ 0.1061],\n",
      "        [-0.0440],\n",
      "        [-0.0091],\n",
      "        [-0.0290]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0613, 0.0621, 0.0611, 0.0613, 0.0613, 0.0611, 0.0610, 0.0622, 0.0624,\n",
      "        0.0618, 0.0620, 0.0618, 0.0629, 0.0626, 0.0626, 0.0629, 0.0632, 0.0634,\n",
      "        0.0632, 0.0620, 0.0613, 0.0615, 0.0603, 0.0610, 0.0601, 0.0604, 0.0611,\n",
      "        0.0615, 0.0625, 0.0623, 0.0629, 0.0634], device='cuda:0')\n",
      "tensor([[-0.0163],\n",
      "        [ 0.0188],\n",
      "        [ 0.0306],\n",
      "        [ 0.0268],\n",
      "        [ 0.0335],\n",
      "        [ 0.0281],\n",
      "        [-0.0061],\n",
      "        [ 0.0182],\n",
      "        [ 0.0028],\n",
      "        [ 0.0280],\n",
      "        [ 0.0080],\n",
      "        [ 0.0397],\n",
      "        [ 0.1065],\n",
      "        [ 0.0265],\n",
      "        [ 0.0023],\n",
      "        [ 0.0262],\n",
      "        [ 0.0013],\n",
      "        [ 0.0123],\n",
      "        [-0.0233],\n",
      "        [ 0.0058],\n",
      "        [-0.0149],\n",
      "        [ 0.0593],\n",
      "        [ 0.0053],\n",
      "        [ 0.0121],\n",
      "        [ 0.0666],\n",
      "        [ 0.0508],\n",
      "        [ 0.0108],\n",
      "        [-0.0380],\n",
      "        [ 0.0088],\n",
      "        [ 0.1191],\n",
      "        [ 0.1035],\n",
      "        [ 0.1160]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0625, 0.0628, 0.0632, 0.0627, 0.0628, 0.0629, 0.0646, 0.0646, 0.0646,\n",
      "        0.0657, 0.0650, 0.0646, 0.0645, 0.0654, 0.0645, 0.0638, 0.0638, 0.0635,\n",
      "        0.0634, 0.0631, 0.0632, 0.0638, 0.0629, 0.0628, 0.0610, 0.0612, 0.0588,\n",
      "        0.0582, 0.0586, 0.0585, 0.0585, 0.0567], device='cuda:0')\n",
      "tensor([[-0.0011],\n",
      "        [ 0.1258],\n",
      "        [ 0.1040],\n",
      "        [ 0.0435],\n",
      "        [ 0.0056],\n",
      "        [-0.0176],\n",
      "        [ 0.0070],\n",
      "        [ 0.0366],\n",
      "        [-0.0155],\n",
      "        [ 0.0511],\n",
      "        [ 0.0989],\n",
      "        [-0.0166],\n",
      "        [ 0.0630],\n",
      "        [ 0.0210],\n",
      "        [-0.0166],\n",
      "        [ 0.0381],\n",
      "        [ 0.0967],\n",
      "        [ 0.0143],\n",
      "        [-0.0028],\n",
      "        [ 0.0245],\n",
      "        [ 0.0033],\n",
      "        [ 0.0168],\n",
      "        [ 0.0540],\n",
      "        [ 0.0513],\n",
      "        [ 0.0054],\n",
      "        [ 0.1080],\n",
      "        [ 0.0108],\n",
      "        [-0.0027],\n",
      "        [ 0.0726],\n",
      "        [ 0.0037],\n",
      "        [ 0.0013],\n",
      "        [-0.0190]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0564, 0.0573, 0.0585, 0.0593, 0.0594, 0.0610, 0.0608, 0.0598, 0.0597,\n",
      "        0.0581, 0.0573, 0.0576, 0.0578, 0.0588, 0.0581, 0.0587, 0.0585, 0.0597,\n",
      "        0.0607, 0.0604, 0.0609, 0.0602, 0.0611, 0.0617, 0.0608, 0.0607, 0.0603,\n",
      "        0.0603, 0.0610, 0.0613, 0.0607, 0.0612], device='cuda:0')\n",
      "tensor([[-0.0025],\n",
      "        [-0.0345],\n",
      "        [ 0.0147],\n",
      "        [ 0.0210],\n",
      "        [ 0.0341],\n",
      "        [ 0.0082],\n",
      "        [-0.0149],\n",
      "        [ 0.0114],\n",
      "        [ 0.0144],\n",
      "        [ 0.0129],\n",
      "        [ 0.0592],\n",
      "        [-0.0474],\n",
      "        [ 0.0494],\n",
      "        [ 0.0124],\n",
      "        [ 0.0266],\n",
      "        [ 0.0075],\n",
      "        [ 0.2389],\n",
      "        [ 0.0632],\n",
      "        [ 0.0163],\n",
      "        [ 0.0902],\n",
      "        [ 0.1030],\n",
      "        [-0.0288],\n",
      "        [ 0.0038],\n",
      "        [ 0.0334],\n",
      "        [-0.0394],\n",
      "        [ 0.0705],\n",
      "        [ 0.1019],\n",
      "        [ 0.0591],\n",
      "        [-0.0264],\n",
      "        [ 0.0367],\n",
      "        [ 0.0257],\n",
      "        [ 0.0139]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0609, 0.0607, 0.0604, 0.0604, 0.0601, 0.0596, 0.0590, 0.0592, 0.0605,\n",
      "        0.0605, 0.0609, 0.0626, 0.0629, 0.0624, 0.0635, 0.0631, 0.0624, 0.0613,\n",
      "        0.0616, 0.0616, 0.0610, 0.0608, 0.0601, 0.0601, 0.0606, 0.0606, 0.0613,\n",
      "        0.0620, 0.0626, 0.0613, 0.0616, 0.0610], device='cuda:0')\n",
      "tensor([[ 0.0393],\n",
      "        [ 0.0071],\n",
      "        [ 0.0258],\n",
      "        [ 0.0097],\n",
      "        [-0.0222],\n",
      "        [ 0.1111],\n",
      "        [ 0.0182],\n",
      "        [ 0.0204],\n",
      "        [ 0.0529],\n",
      "        [ 0.0179],\n",
      "        [ 0.0647],\n",
      "        [ 0.0706],\n",
      "        [ 0.0413],\n",
      "        [ 0.0118],\n",
      "        [ 0.0373],\n",
      "        [ 0.0221],\n",
      "        [ 0.0300],\n",
      "        [ 0.0404],\n",
      "        [-0.0382],\n",
      "        [ 0.0425],\n",
      "        [ 0.0197],\n",
      "        [ 0.0031],\n",
      "        [ 0.0159],\n",
      "        [ 0.0158],\n",
      "        [ 0.0134],\n",
      "        [ 0.0237],\n",
      "        [-0.0136],\n",
      "        [ 0.0677],\n",
      "        [ 0.0588],\n",
      "        [ 0.0364],\n",
      "        [ 0.0245],\n",
      "        [ 0.0739]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0604, 0.0599, 0.0600, 0.0612, 0.0620, 0.0624, 0.0617, 0.0608, 0.0601,\n",
      "        0.0606, 0.0604, 0.0598, 0.0601, 0.0595, 0.0617, 0.0611, 0.0609, 0.0606,\n",
      "        0.0605, 0.0621, 0.0623, 0.0621, 0.0621, 0.0622, 0.0625, 0.0624, 0.0629,\n",
      "        0.0628, 0.0635, 0.0634, 0.0633, 0.0647], device='cuda:0')\n",
      "tensor([[-0.0004],\n",
      "        [ 0.0283],\n",
      "        [ 0.1025],\n",
      "        [ 0.0292],\n",
      "        [ 0.0077],\n",
      "        [-0.0219],\n",
      "        [ 0.0451],\n",
      "        [ 0.0729],\n",
      "        [ 0.0476],\n",
      "        [-0.0039],\n",
      "        [ 0.0353],\n",
      "        [ 0.0078],\n",
      "        [ 0.0042],\n",
      "        [-0.0093],\n",
      "        [ 0.0625],\n",
      "        [-0.0581],\n",
      "        [ 0.0395],\n",
      "        [-0.0406],\n",
      "        [ 0.0011],\n",
      "        [ 0.0903],\n",
      "        [ 0.0142],\n",
      "        [-0.0200],\n",
      "        [-0.0295],\n",
      "        [ 0.0272],\n",
      "        [-0.0353],\n",
      "        [ 0.0122],\n",
      "        [-0.0206],\n",
      "        [ 0.0318],\n",
      "        [ 0.0266],\n",
      "        [-0.0232],\n",
      "        [-0.0372],\n",
      "        [ 0.0576]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0643, 0.0646, 0.0649, 0.0646, 0.0644, 0.0644, 0.0643, 0.0650, 0.0641,\n",
      "        0.0634, 0.0626, 0.0632, 0.0636, 0.0624, 0.0624, 0.0628, 0.0621, 0.0618,\n",
      "        0.0621, 0.0624, 0.0624, 0.0630, 0.0615, 0.0610, 0.0612, 0.0610, 0.0608,\n",
      "        0.0604, 0.0587, 0.0569, 0.0570, 0.0573], device='cuda:0')\n",
      "tensor([[ 0.0128],\n",
      "        [ 0.0307],\n",
      "        [ 0.0791],\n",
      "        [ 0.1004],\n",
      "        [ 0.0008],\n",
      "        [ 0.0137],\n",
      "        [ 0.0191],\n",
      "        [ 0.0125],\n",
      "        [ 0.0463],\n",
      "        [ 0.0747],\n",
      "        [ 0.0735],\n",
      "        [ 0.0485],\n",
      "        [ 0.0317],\n",
      "        [ 0.0089],\n",
      "        [-0.0225],\n",
      "        [ 0.0866],\n",
      "        [ 0.0568],\n",
      "        [ 0.0167],\n",
      "        [ 0.0206],\n",
      "        [ 0.0076],\n",
      "        [ 0.0671],\n",
      "        [ 0.0023],\n",
      "        [ 0.0388],\n",
      "        [ 0.0403],\n",
      "        [ 0.0133],\n",
      "        [-0.0019],\n",
      "        [-0.0020],\n",
      "        [ 0.0015],\n",
      "        [-0.0040],\n",
      "        [ 0.0463],\n",
      "        [ 0.0227],\n",
      "        [ 0.0617]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0579, 0.0574, 0.0571, 0.0575, 0.0579, 0.0583, 0.0576, 0.0564, 0.0561,\n",
      "        0.0561, 0.0553, 0.0552, 0.0555, 0.0555, 0.0561, 0.0557, 0.0552, 0.0545,\n",
      "        0.0532, 0.0538, 0.0537, 0.0542, 0.0531, 0.0532, 0.0539, 0.0535, 0.0548,\n",
      "        0.0547, 0.0554, 0.0554, 0.0549, 0.0550], device='cuda:0')\n",
      "tensor([[-1.3173e-02],\n",
      "        [ 2.1727e-02],\n",
      "        [-2.9472e-02],\n",
      "        [ 3.0070e-02],\n",
      "        [ 5.4310e-02],\n",
      "        [-3.0017e-02],\n",
      "        [ 2.3724e-02],\n",
      "        [ 4.9920e-02],\n",
      "        [ 5.0895e-02],\n",
      "        [ 1.1389e-04],\n",
      "        [ 2.2354e-02],\n",
      "        [ 2.6744e-02],\n",
      "        [ 7.0429e-03],\n",
      "        [-1.0264e-02],\n",
      "        [ 3.6909e-02],\n",
      "        [ 4.0874e-02],\n",
      "        [-1.2008e-03],\n",
      "        [ 2.0970e-04],\n",
      "        [ 5.0092e-02],\n",
      "        [ 2.5041e-02],\n",
      "        [ 5.6702e-02],\n",
      "        [ 2.3401e-02],\n",
      "        [ 1.2607e-01],\n",
      "        [-3.1234e-02],\n",
      "        [ 3.3944e-02],\n",
      "        [ 7.4310e-03],\n",
      "        [ 3.0585e-02],\n",
      "        [ 7.5014e-02],\n",
      "        [ 1.8641e-01],\n",
      "        [ 1.3067e-01],\n",
      "        [ 4.7699e-02],\n",
      "        [ 4.4403e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0556, 0.0570, 0.0571, 0.0567, 0.0567, 0.0575, 0.0574, 0.0576, 0.0581,\n",
      "        0.0593, 0.0596, 0.0587, 0.0590, 0.0587, 0.0580, 0.0579, 0.0574, 0.0579,\n",
      "        0.0572, 0.0574, 0.0573, 0.0578, 0.0605, 0.0616, 0.0619, 0.0613, 0.0613,\n",
      "        0.0614, 0.0616, 0.0609, 0.0597, 0.0595], device='cuda:0')\n",
      "tensor([[ 2.0286e-01],\n",
      "        [ 1.9219e-02],\n",
      "        [-7.6094e-02],\n",
      "        [ 3.5252e-02],\n",
      "        [ 7.0140e-02],\n",
      "        [-8.8877e-03],\n",
      "        [ 3.9591e-03],\n",
      "        [ 4.2382e-03],\n",
      "        [ 3.8551e-02],\n",
      "        [ 5.4939e-02],\n",
      "        [ 1.1317e-02],\n",
      "        [ 6.4469e-02],\n",
      "        [ 9.5667e-02],\n",
      "        [-7.4439e-05],\n",
      "        [ 1.6165e-02],\n",
      "        [ 2.1476e-02],\n",
      "        [ 6.5183e-02],\n",
      "        [ 5.4225e-02],\n",
      "        [ 4.4066e-03],\n",
      "        [ 4.7684e-02],\n",
      "        [ 3.6400e-02],\n",
      "        [-1.5006e-02],\n",
      "        [ 4.5458e-02],\n",
      "        [-1.3037e-03],\n",
      "        [ 3.6433e-02],\n",
      "        [ 1.5080e-02],\n",
      "        [ 2.4405e-03],\n",
      "        [ 9.5125e-02],\n",
      "        [ 1.6553e-02],\n",
      "        [-1.7526e-02],\n",
      "        [ 2.2846e-02],\n",
      "        [ 4.8762e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0599, 0.0604, 0.0602, 0.0604, 0.0601, 0.0594, 0.0587, 0.0591, 0.0599,\n",
      "        0.0593, 0.0593, 0.0602, 0.0598, 0.0601, 0.0600, 0.0602, 0.0608, 0.0605,\n",
      "        0.0598, 0.0596, 0.0597, 0.0603, 0.0594, 0.0600, 0.0596, 0.0600, 0.0600,\n",
      "        0.0598, 0.0591, 0.0583, 0.0583, 0.0583], device='cuda:0')\n",
      "tensor([[ 0.0341],\n",
      "        [ 0.0537],\n",
      "        [ 0.0069],\n",
      "        [ 0.0804],\n",
      "        [-0.0017],\n",
      "        [ 0.0857],\n",
      "        [ 0.0274],\n",
      "        [ 0.0702],\n",
      "        [ 0.1171],\n",
      "        [-0.0063],\n",
      "        [-0.0188],\n",
      "        [ 0.0098],\n",
      "        [-0.0024],\n",
      "        [ 0.0554],\n",
      "        [-0.0074],\n",
      "        [ 0.0717],\n",
      "        [ 0.0210],\n",
      "        [ 0.1335],\n",
      "        [ 0.0825],\n",
      "        [ 0.0257],\n",
      "        [-0.0031],\n",
      "        [ 0.0150],\n",
      "        [ 0.0005],\n",
      "        [-0.0349],\n",
      "        [ 0.0072],\n",
      "        [ 0.0291],\n",
      "        [ 0.0471],\n",
      "        [ 0.0408],\n",
      "        [ 0.0765],\n",
      "        [ 0.0280],\n",
      "        [ 0.0240],\n",
      "        [ 0.0096]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0584, 0.0583, 0.0573, 0.0562, 0.0572, 0.0564, 0.0568, 0.0566, 0.0573,\n",
      "        0.0570, 0.0573, 0.0576, 0.0578, 0.0582, 0.0572, 0.0567, 0.0569, 0.0567,\n",
      "        0.0569, 0.0564, 0.0561, 0.0567, 0.0569, 0.0571, 0.0567, 0.0563, 0.0568,\n",
      "        0.0571, 0.0571, 0.0567, 0.0576, 0.0576], device='cuda:0')\n",
      "tensor([[-0.0201],\n",
      "        [ 0.0351],\n",
      "        [ 0.0177],\n",
      "        [ 0.0171],\n",
      "        [ 0.0205],\n",
      "        [-0.0070],\n",
      "        [ 0.0458],\n",
      "        [-0.0162],\n",
      "        [-0.0533],\n",
      "        [ 0.1622],\n",
      "        [-0.0090],\n",
      "        [-0.0246],\n",
      "        [-0.0133],\n",
      "        [-0.0054],\n",
      "        [-0.0089],\n",
      "        [ 0.0497],\n",
      "        [ 0.0695],\n",
      "        [ 0.1328],\n",
      "        [ 0.0223],\n",
      "        [ 0.0007],\n",
      "        [ 0.0154],\n",
      "        [ 0.0372],\n",
      "        [ 0.0449],\n",
      "        [ 0.1058],\n",
      "        [-0.0203],\n",
      "        [ 0.0688],\n",
      "        [-0.0029],\n",
      "        [-0.0381],\n",
      "        [ 0.0471],\n",
      "        [ 0.0907],\n",
      "        [ 0.0600],\n",
      "        [ 0.0079]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0571, 0.0567, 0.0562, 0.0544, 0.0545, 0.0554, 0.0551, 0.0548, 0.0553,\n",
      "        0.0573, 0.0575, 0.0570, 0.0578, 0.0569, 0.0569, 0.0576, 0.0576, 0.0593,\n",
      "        0.0600, 0.0601, 0.0595, 0.0583, 0.0587, 0.0584, 0.0588, 0.0584, 0.0576,\n",
      "        0.0578, 0.0582, 0.0588, 0.0584, 0.0587], device='cuda:0')\n",
      "tensor([[ 0.0119],\n",
      "        [ 0.0369],\n",
      "        [ 0.0347],\n",
      "        [ 0.0335],\n",
      "        [-0.0231],\n",
      "        [ 0.0697],\n",
      "        [ 0.0285],\n",
      "        [ 0.0479],\n",
      "        [ 0.0134],\n",
      "        [ 0.0305],\n",
      "        [-0.0006],\n",
      "        [ 0.0343],\n",
      "        [ 0.1404],\n",
      "        [ 0.1219],\n",
      "        [ 0.0452],\n",
      "        [ 0.1333],\n",
      "        [ 0.1027],\n",
      "        [ 0.0147],\n",
      "        [ 0.0052],\n",
      "        [ 0.0880],\n",
      "        [-0.0155],\n",
      "        [ 0.0210],\n",
      "        [-0.0223],\n",
      "        [ 0.1034],\n",
      "        [ 0.0047],\n",
      "        [-0.0234],\n",
      "        [-0.0042],\n",
      "        [-0.0167],\n",
      "        [ 0.0374],\n",
      "        [ 0.0019],\n",
      "        [ 0.0438],\n",
      "        [ 0.0198]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0593, 0.0589, 0.0586, 0.0584, 0.0587, 0.0593, 0.0597, 0.0605, 0.0605,\n",
      "        0.0607, 0.0612, 0.0615, 0.0601, 0.0607, 0.0595, 0.0595, 0.0601, 0.0595,\n",
      "        0.0593, 0.0594, 0.0593, 0.0597, 0.0601, 0.0602, 0.0597, 0.0593, 0.0591,\n",
      "        0.0593, 0.0592, 0.0587, 0.0590, 0.0595], device='cuda:0')\n",
      "tensor([[ 0.0089],\n",
      "        [-0.0053],\n",
      "        [ 0.0094],\n",
      "        [ 0.0090],\n",
      "        [ 0.1335],\n",
      "        [ 0.1063],\n",
      "        [ 0.0606],\n",
      "        [ 0.0629],\n",
      "        [ 0.1205],\n",
      "        [ 0.0327],\n",
      "        [ 0.0306],\n",
      "        [ 0.0044],\n",
      "        [ 0.0206],\n",
      "        [ 0.0239],\n",
      "        [ 0.0342],\n",
      "        [ 0.0213],\n",
      "        [ 0.0176],\n",
      "        [ 0.0253],\n",
      "        [ 0.0082],\n",
      "        [ 0.0251],\n",
      "        [ 0.0162],\n",
      "        [-0.0002],\n",
      "        [ 0.0316],\n",
      "        [ 0.0178],\n",
      "        [ 0.0423],\n",
      "        [ 0.0303],\n",
      "        [-0.0026],\n",
      "        [ 0.0015],\n",
      "        [-0.0026],\n",
      "        [-0.0210],\n",
      "        [ 0.0205],\n",
      "        [-0.0325]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0591, 0.0591, 0.0584, 0.0571, 0.0570, 0.0577, 0.0575, 0.0574, 0.0569,\n",
      "        0.0570, 0.0567, 0.0567, 0.0563, 0.0561, 0.0561, 0.0559, 0.0563, 0.0565,\n",
      "        0.0556, 0.0549, 0.0550, 0.0542, 0.0531, 0.0518, 0.0530, 0.0534, 0.0528,\n",
      "        0.0524, 0.0513, 0.0522, 0.0516, 0.0525], device='cuda:0')\n",
      "tensor([[ 0.0267],\n",
      "        [-0.0170],\n",
      "        [-0.0239],\n",
      "        [-0.0295],\n",
      "        [-0.0172],\n",
      "        [-0.0142],\n",
      "        [-0.0233],\n",
      "        [ 0.0162],\n",
      "        [-0.0037],\n",
      "        [ 0.0473],\n",
      "        [ 0.0433],\n",
      "        [-0.0082],\n",
      "        [ 0.0116],\n",
      "        [ 0.0389],\n",
      "        [ 0.0836],\n",
      "        [ 0.0493],\n",
      "        [ 0.0153],\n",
      "        [ 0.0007],\n",
      "        [ 0.0306],\n",
      "        [-0.0049],\n",
      "        [ 0.0041],\n",
      "        [ 0.0239],\n",
      "        [ 0.0005],\n",
      "        [-0.0243],\n",
      "        [ 0.0436],\n",
      "        [-0.0161],\n",
      "        [ 0.0529],\n",
      "        [ 0.1459],\n",
      "        [ 0.0129],\n",
      "        [ 0.0951],\n",
      "        [ 0.0344],\n",
      "        [-0.1234]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0527, 0.0518, 0.0514, 0.0514, 0.0515, 0.0511, 0.0515, 0.0511, 0.0510,\n",
      "        0.0502, 0.0505, 0.0510, 0.0520, 0.0518, 0.0518, 0.0519, 0.0515, 0.0505,\n",
      "        0.0514, 0.0526, 0.0549, 0.0549, 0.0554, 0.0556, 0.0557, 0.0569, 0.0580,\n",
      "        0.0582, 0.0579, 0.0593, 0.0595, 0.0593], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1594],\n",
      "        [ 0.1073],\n",
      "        [ 0.1694],\n",
      "        [ 0.1346],\n",
      "        [ 0.0112],\n",
      "        [ 0.0555],\n",
      "        [-0.0224],\n",
      "        [-0.0077],\n",
      "        [ 0.1468],\n",
      "        [-0.0607],\n",
      "        [ 0.0245],\n",
      "        [ 0.0441],\n",
      "        [-0.0056],\n",
      "        [ 0.0213],\n",
      "        [ 0.0299],\n",
      "        [ 0.0517],\n",
      "        [ 0.0087],\n",
      "        [ 0.0234],\n",
      "        [ 0.0089],\n",
      "        [-0.0295],\n",
      "        [ 0.0132],\n",
      "        [-0.0352],\n",
      "        [ 0.0432],\n",
      "        [ 0.0386],\n",
      "        [ 0.0876],\n",
      "        [-0.0070],\n",
      "        [-0.0212],\n",
      "        [ 0.0044],\n",
      "        [-0.0102],\n",
      "        [ 0.0719],\n",
      "        [ 0.0709],\n",
      "        [ 0.0463]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0584, 0.0577, 0.0582, 0.0574, 0.0576, 0.0574, 0.0590, 0.0583, 0.0593,\n",
      "        0.0596, 0.0593, 0.0588, 0.0581, 0.0595, 0.0584, 0.0582, 0.0579, 0.0577,\n",
      "        0.0578, 0.0570, 0.0566, 0.0577, 0.0592, 0.0593, 0.0590, 0.0598, 0.0601,\n",
      "        0.0598, 0.0617, 0.0608, 0.0604, 0.0593], device='cuda:0')\n",
      "tensor([[ 0.0485],\n",
      "        [ 0.1009],\n",
      "        [ 0.1184],\n",
      "        [ 0.0226],\n",
      "        [-0.0011],\n",
      "        [-0.0169],\n",
      "        [-0.0376],\n",
      "        [ 0.0064],\n",
      "        [ 0.0213],\n",
      "        [-0.0065],\n",
      "        [ 0.0222],\n",
      "        [-0.0468],\n",
      "        [ 0.0420],\n",
      "        [ 0.1011],\n",
      "        [ 0.0042],\n",
      "        [ 0.0515],\n",
      "        [ 0.0507],\n",
      "        [ 0.0936],\n",
      "        [ 0.0232],\n",
      "        [ 0.0080],\n",
      "        [ 0.0385],\n",
      "        [ 0.0144],\n",
      "        [-0.0033],\n",
      "        [ 0.0934],\n",
      "        [ 0.0257],\n",
      "        [ 0.0400],\n",
      "        [ 0.0433],\n",
      "        [-0.0081],\n",
      "        [ 0.0073],\n",
      "        [ 0.0070],\n",
      "        [ 0.0985],\n",
      "        [ 0.1282]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0602, 0.0592, 0.0598, 0.0594, 0.0582, 0.0570, 0.0577, 0.0580, 0.0574,\n",
      "        0.0567, 0.0565, 0.0569, 0.0570, 0.0576, 0.0575, 0.0571, 0.0570, 0.0573,\n",
      "        0.0597, 0.0593, 0.0588, 0.0604, 0.0599, 0.0605, 0.0607, 0.0613, 0.0615,\n",
      "        0.0623, 0.0630, 0.0637, 0.0631, 0.0672], device='cuda:0')\n",
      "tensor([[ 0.0529],\n",
      "        [ 0.1035],\n",
      "        [ 0.0653],\n",
      "        [ 0.0383],\n",
      "        [ 0.0917],\n",
      "        [ 0.0425],\n",
      "        [ 0.0252],\n",
      "        [ 0.0062],\n",
      "        [ 0.0835],\n",
      "        [-0.0577],\n",
      "        [-0.0037],\n",
      "        [ 0.0358],\n",
      "        [-0.0011],\n",
      "        [-0.0041],\n",
      "        [ 0.0407],\n",
      "        [ 0.0227],\n",
      "        [ 0.0260],\n",
      "        [ 0.0200],\n",
      "        [ 0.0249],\n",
      "        [-0.0135],\n",
      "        [ 0.0258],\n",
      "        [-0.0012],\n",
      "        [ 0.0506],\n",
      "        [-0.0506],\n",
      "        [ 0.0011],\n",
      "        [ 0.1183],\n",
      "        [-0.0122],\n",
      "        [ 0.0115],\n",
      "        [ 0.0396],\n",
      "        [ 0.0249],\n",
      "        [ 0.0099],\n",
      "        [ 0.0205]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0649, 0.0659, 0.0652, 0.0663, 0.0660, 0.0656, 0.0660, 0.0659, 0.0668,\n",
      "        0.0683, 0.0679, 0.0674, 0.0673, 0.0683, 0.0686, 0.0684, 0.0685, 0.0678,\n",
      "        0.0671, 0.0672, 0.0669, 0.0674, 0.0696, 0.0693, 0.0691, 0.0706, 0.0691,\n",
      "        0.0695, 0.0678, 0.0674, 0.0663, 0.0660], device='cuda:0')\n",
      "tensor([[ 0.0376],\n",
      "        [ 0.0066],\n",
      "        [ 0.0350],\n",
      "        [-0.0294],\n",
      "        [ 0.0080],\n",
      "        [ 0.1516],\n",
      "        [ 0.0445],\n",
      "        [ 0.0723],\n",
      "        [ 0.0360],\n",
      "        [ 0.0492],\n",
      "        [ 0.0083],\n",
      "        [ 0.0839],\n",
      "        [ 0.0370],\n",
      "        [-0.0483],\n",
      "        [ 0.0069],\n",
      "        [ 0.0461],\n",
      "        [ 0.1267],\n",
      "        [ 0.0252],\n",
      "        [ 0.0483],\n",
      "        [ 0.0433],\n",
      "        [ 0.0461],\n",
      "        [ 0.0374],\n",
      "        [ 0.0862],\n",
      "        [ 0.0750],\n",
      "        [ 0.0202],\n",
      "        [ 0.0805],\n",
      "        [ 0.0036],\n",
      "        [ 0.0030],\n",
      "        [ 0.0217],\n",
      "        [ 0.0539],\n",
      "        [-0.0066],\n",
      "        [-0.0013]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0653, 0.0647, 0.0646, 0.0646, 0.0635, 0.0637, 0.0619, 0.0625, 0.0625,\n",
      "        0.0635, 0.0624, 0.0640, 0.0631, 0.0630, 0.0643, 0.0638, 0.0665, 0.0655,\n",
      "        0.0652, 0.0631, 0.0631, 0.0633, 0.0622, 0.0625, 0.0628, 0.0619, 0.0615,\n",
      "        0.0612, 0.0603, 0.0613, 0.0587, 0.0622], device='cuda:0')\n",
      "tensor([[ 0.0318],\n",
      "        [ 0.0109],\n",
      "        [ 0.0685],\n",
      "        [ 0.0878],\n",
      "        [-0.0061],\n",
      "        [ 0.0126],\n",
      "        [ 0.0437],\n",
      "        [-0.0377],\n",
      "        [ 0.0051],\n",
      "        [-0.0132],\n",
      "        [-0.0003],\n",
      "        [-0.0276],\n",
      "        [ 0.0531],\n",
      "        [ 0.0311],\n",
      "        [ 0.0312],\n",
      "        [-0.0223],\n",
      "        [-0.0021],\n",
      "        [ 0.0254],\n",
      "        [ 0.0511],\n",
      "        [ 0.0666],\n",
      "        [ 0.0306],\n",
      "        [ 0.1090],\n",
      "        [ 0.0460],\n",
      "        [ 0.0172],\n",
      "        [ 0.0288],\n",
      "        [ 0.0392],\n",
      "        [-0.0017],\n",
      "        [ 0.0443],\n",
      "        [ 0.1232],\n",
      "        [ 0.0553],\n",
      "        [-0.0702],\n",
      "        [ 0.0417]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0602, 0.0600, 0.0587, 0.0581, 0.0592, 0.0586, 0.0586, 0.0574, 0.0575,\n",
      "        0.0570, 0.0578, 0.0578, 0.0586, 0.0587, 0.0598, 0.0602, 0.0608, 0.0598,\n",
      "        0.0591, 0.0603, 0.0614, 0.0615, 0.0628, 0.0628, 0.0622, 0.0617, 0.0628,\n",
      "        0.0622, 0.0617, 0.0617, 0.0620, 0.0605], device='cuda:0')\n",
      "tensor([[-0.0087],\n",
      "        [-0.0294],\n",
      "        [ 0.0068],\n",
      "        [ 0.0099],\n",
      "        [ 0.0515],\n",
      "        [ 0.0287],\n",
      "        [ 0.0249],\n",
      "        [ 0.0070],\n",
      "        [ 0.0856],\n",
      "        [ 0.1191],\n",
      "        [ 0.0885],\n",
      "        [ 0.0603],\n",
      "        [ 0.0437],\n",
      "        [ 0.0088],\n",
      "        [-0.0486],\n",
      "        [ 0.0303],\n",
      "        [-0.0298],\n",
      "        [ 0.0341],\n",
      "        [-0.0046],\n",
      "        [-0.0239],\n",
      "        [ 0.0233],\n",
      "        [ 0.0396],\n",
      "        [ 0.0333],\n",
      "        [ 0.0174],\n",
      "        [ 0.0488],\n",
      "        [ 0.0124],\n",
      "        [ 0.0445],\n",
      "        [ 0.0521],\n",
      "        [ 0.0304],\n",
      "        [ 0.0425],\n",
      "        [ 0.0372],\n",
      "        [-0.0239]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0642, 0.0647, 0.0645, 0.0678, 0.0721, 0.0700, 0.0705, 0.0688, 0.0703,\n",
      "        0.0712, 0.0708, 0.0711, 0.0706, 0.0711, 0.0709, 0.0727, 0.0731, 0.0739,\n",
      "        0.0721, 0.0723, 0.0725, 0.0712, 0.0727, 0.0726, 0.0718, 0.0728, 0.0731,\n",
      "        0.0726, 0.0728, 0.0719, 0.0725, 0.0717], device='cuda:0')\n",
      "tensor([[ 0.0519],\n",
      "        [ 0.0343],\n",
      "        [ 0.0250],\n",
      "        [ 0.0054],\n",
      "        [-0.0241],\n",
      "        [-0.0397],\n",
      "        [ 0.0636],\n",
      "        [-0.0394],\n",
      "        [-0.0509],\n",
      "        [ 0.0003],\n",
      "        [ 0.0060],\n",
      "        [ 0.0453],\n",
      "        [ 0.0364],\n",
      "        [ 0.0476],\n",
      "        [ 0.0263],\n",
      "        [ 0.0310],\n",
      "        [ 0.0035],\n",
      "        [-0.0064],\n",
      "        [ 0.0527],\n",
      "        [ 0.0023],\n",
      "        [ 0.0204],\n",
      "        [ 0.0943],\n",
      "        [ 0.0256],\n",
      "        [ 0.0194],\n",
      "        [ 0.0272],\n",
      "        [ 0.0268],\n",
      "        [ 0.0268],\n",
      "        [ 0.0618],\n",
      "        [ 0.0614],\n",
      "        [ 0.0742],\n",
      "        [ 0.0700],\n",
      "        [ 0.0170]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0710, 0.0703, 0.0688, 0.0692, 0.0698, 0.0712, 0.0717, 0.0709, 0.0717,\n",
      "        0.0712, 0.0717, 0.0711, 0.0704, 0.0700, 0.0705, 0.0690, 0.0693, 0.0696,\n",
      "        0.0695, 0.0711, 0.0704, 0.0707, 0.0719, 0.0716, 0.0722, 0.0718, 0.0715,\n",
      "        0.0713, 0.0719, 0.0724, 0.0724, 0.0740], device='cuda:0')\n",
      "tensor([[ 0.0004],\n",
      "        [-0.0212],\n",
      "        [ 0.0122],\n",
      "        [ 0.0137],\n",
      "        [ 0.0532],\n",
      "        [ 0.1564],\n",
      "        [ 0.1177],\n",
      "        [ 0.0449],\n",
      "        [ 0.1284],\n",
      "        [ 0.0672],\n",
      "        [ 0.0752],\n",
      "        [ 0.0296],\n",
      "        [ 0.0045],\n",
      "        [-0.0485],\n",
      "        [ 0.0549],\n",
      "        [ 0.0196],\n",
      "        [ 0.0294],\n",
      "        [ 0.0412],\n",
      "        [ 0.0156],\n",
      "        [ 0.1017],\n",
      "        [ 0.0954],\n",
      "        [ 0.1059],\n",
      "        [ 0.0868],\n",
      "        [ 0.0088],\n",
      "        [-0.0090],\n",
      "        [-0.0470],\n",
      "        [ 0.0097],\n",
      "        [ 0.0272],\n",
      "        [ 0.0077],\n",
      "        [ 0.0358],\n",
      "        [ 0.0057],\n",
      "        [ 0.0216]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0740, 0.0737, 0.0729, 0.0754, 0.0745, 0.0745, 0.0739, 0.0735, 0.0750,\n",
      "        0.0745, 0.0754, 0.0748, 0.0749, 0.0752, 0.0728, 0.0728, 0.0727, 0.0730,\n",
      "        0.0728, 0.0719, 0.0713, 0.0722, 0.0723, 0.0728, 0.0719, 0.0724, 0.0735,\n",
      "        0.0739, 0.0746, 0.0751, 0.0726, 0.0719], device='cuda:0')\n",
      "tensor([[ 0.1230],\n",
      "        [ 0.0951],\n",
      "        [ 0.0772],\n",
      "        [ 0.0222],\n",
      "        [ 0.0914],\n",
      "        [-0.0072],\n",
      "        [ 0.0287],\n",
      "        [ 0.0515],\n",
      "        [ 0.0036],\n",
      "        [ 0.0190],\n",
      "        [ 0.0221],\n",
      "        [ 0.0269],\n",
      "        [ 0.0300],\n",
      "        [ 0.0156],\n",
      "        [-0.0027],\n",
      "        [ 0.0206],\n",
      "        [-0.0160],\n",
      "        [ 0.0229],\n",
      "        [-0.0074],\n",
      "        [ 0.0010],\n",
      "        [ 0.0598],\n",
      "        [-0.0249],\n",
      "        [ 0.0594],\n",
      "        [-0.0311],\n",
      "        [-0.0012],\n",
      "        [-0.0098],\n",
      "        [ 0.0213],\n",
      "        [ 0.0774],\n",
      "        [ 0.0228],\n",
      "        [ 0.0677],\n",
      "        [-0.0041],\n",
      "        [ 0.1244]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0728, 0.0722, 0.0714, 0.0718, 0.0717, 0.0708, 0.0713, 0.0721, 0.0715,\n",
      "        0.0717, 0.0719, 0.0711, 0.0713, 0.0713, 0.0714, 0.0704, 0.0705, 0.0708,\n",
      "        0.0705, 0.0727, 0.0722, 0.0727, 0.0721, 0.0722, 0.0728, 0.0697, 0.0688,\n",
      "        0.0684, 0.0666, 0.0665, 0.0669, 0.0675], device='cuda:0')\n",
      "tensor([[ 0.0334],\n",
      "        [-0.0769],\n",
      "        [ 0.0818],\n",
      "        [ 0.0410],\n",
      "        [ 0.0243],\n",
      "        [ 0.0283],\n",
      "        [ 0.0762],\n",
      "        [ 0.0407],\n",
      "        [ 0.0225],\n",
      "        [ 0.0581],\n",
      "        [ 0.0272],\n",
      "        [ 0.0021],\n",
      "        [-0.0019],\n",
      "        [ 0.0263],\n",
      "        [ 0.0200],\n",
      "        [ 0.0461],\n",
      "        [ 0.0189],\n",
      "        [ 0.0312],\n",
      "        [ 0.0314],\n",
      "        [ 0.0519],\n",
      "        [ 0.0757],\n",
      "        [-0.0144],\n",
      "        [ 0.0283],\n",
      "        [-0.0079],\n",
      "        [ 0.0186],\n",
      "        [ 0.0327],\n",
      "        [ 0.0035],\n",
      "        [ 0.0216],\n",
      "        [ 0.0167],\n",
      "        [ 0.0236],\n",
      "        [ 0.0513],\n",
      "        [ 0.0305]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0683, 0.0680, 0.0666, 0.0675, 0.0680, 0.0674, 0.0662, 0.0662, 0.0659,\n",
      "        0.0677, 0.0675, 0.0660, 0.0653, 0.0635, 0.0634, 0.0640, 0.0625, 0.0628,\n",
      "        0.0628, 0.0631, 0.0624, 0.0621, 0.0628, 0.0616, 0.0616, 0.0624, 0.0631,\n",
      "        0.0634, 0.0629, 0.0621, 0.0625, 0.0643], device='cuda:0')\n",
      "tensor([[ 8.4590e-04],\n",
      "        [-1.3174e-02],\n",
      "        [ 4.5451e-02],\n",
      "        [ 4.2832e-02],\n",
      "        [ 4.6243e-02],\n",
      "        [ 3.4968e-02],\n",
      "        [ 8.8616e-03],\n",
      "        [ 6.1286e-02],\n",
      "        [ 7.7110e-02],\n",
      "        [ 6.4174e-03],\n",
      "        [ 1.1532e-01],\n",
      "        [ 8.1626e-02],\n",
      "        [-1.2560e-02],\n",
      "        [ 1.2077e-01],\n",
      "        [ 1.2405e-03],\n",
      "        [ 4.3581e-02],\n",
      "        [ 1.6480e-02],\n",
      "        [ 2.0684e-02],\n",
      "        [ 2.7199e-02],\n",
      "        [-2.1243e-02],\n",
      "        [ 2.6931e-03],\n",
      "        [-9.7921e-03],\n",
      "        [ 1.9500e-02],\n",
      "        [-4.7925e-02],\n",
      "        [ 4.2834e-03],\n",
      "        [ 6.7521e-03],\n",
      "        [ 4.2829e-03],\n",
      "        [-3.2556e-02],\n",
      "        [-2.6258e-02],\n",
      "        [-3.5491e-02],\n",
      "        [ 3.4640e-02],\n",
      "        [-6.2995e-05]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0626, 0.0621, 0.0638, 0.0637, 0.0637, 0.0660, 0.0653, 0.0649, 0.0653,\n",
      "        0.0644, 0.0640, 0.0629, 0.0629, 0.0634, 0.0634, 0.0629, 0.0628, 0.0634,\n",
      "        0.0618, 0.0613, 0.0606, 0.0607, 0.0604, 0.0593, 0.0590, 0.0595, 0.0609,\n",
      "        0.0616, 0.0609, 0.0607, 0.0649, 0.0634], device='cuda:0')\n",
      "tensor([[-0.0149],\n",
      "        [ 0.0411],\n",
      "        [ 0.0151],\n",
      "        [ 0.1957],\n",
      "        [ 0.1116],\n",
      "        [ 0.0095],\n",
      "        [ 0.0591],\n",
      "        [ 0.0461],\n",
      "        [-0.0008],\n",
      "        [-0.0125],\n",
      "        [ 0.0269],\n",
      "        [ 0.0514],\n",
      "        [ 0.0338],\n",
      "        [-0.0036],\n",
      "        [ 0.0695],\n",
      "        [ 0.0145],\n",
      "        [-0.0427],\n",
      "        [ 0.0401],\n",
      "        [-0.0118],\n",
      "        [-0.0066],\n",
      "        [ 0.0460],\n",
      "        [ 0.0187],\n",
      "        [ 0.0970],\n",
      "        [-0.0521],\n",
      "        [-0.0134],\n",
      "        [-0.0327],\n",
      "        [ 0.0766],\n",
      "        [ 0.0614],\n",
      "        [-0.0005],\n",
      "        [-0.0011],\n",
      "        [ 0.0338],\n",
      "        [ 0.0633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0609, 0.0618, 0.0612, 0.0613, 0.0607, 0.0606, 0.0613, 0.0613, 0.0618,\n",
      "        0.0621, 0.0603, 0.0587, 0.0607, 0.0593, 0.0584, 0.0579, 0.0564, 0.0554,\n",
      "        0.0550, 0.0538, 0.0545, 0.0548, 0.0545, 0.0541, 0.0542, 0.0545, 0.0563,\n",
      "        0.0544, 0.0557, 0.0554, 0.0553, 0.0548], device='cuda:0')\n",
      "tensor([[ 0.0306],\n",
      "        [ 0.0548],\n",
      "        [ 0.0301],\n",
      "        [ 0.0290],\n",
      "        [-0.0188],\n",
      "        [-0.0059],\n",
      "        [-0.0604],\n",
      "        [-0.0291],\n",
      "        [-0.0222],\n",
      "        [ 0.0582],\n",
      "        [-0.0098],\n",
      "        [-0.0231],\n",
      "        [ 0.0173],\n",
      "        [-0.0289],\n",
      "        [-0.0302],\n",
      "        [-0.0141],\n",
      "        [ 0.0292],\n",
      "        [ 0.1079],\n",
      "        [ 0.0217],\n",
      "        [ 0.0559],\n",
      "        [ 0.0856],\n",
      "        [ 0.0631],\n",
      "        [ 0.0052],\n",
      "        [-0.0131],\n",
      "        [ 0.0280],\n",
      "        [ 0.0807],\n",
      "        [ 0.0633],\n",
      "        [ 0.0277],\n",
      "        [ 0.0019],\n",
      "        [ 0.0081],\n",
      "        [ 0.0125],\n",
      "        [-0.0331]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0533, 0.0538, 0.0536, 0.0550, 0.0542, 0.0545, 0.0545, 0.0539, 0.0538,\n",
      "        0.0535, 0.0535, 0.0539, 0.0570, 0.0569, 0.0584, 0.0584, 0.0578, 0.0575,\n",
      "        0.0579, 0.0584, 0.0601, 0.0594, 0.0591, 0.0582, 0.0578, 0.0575, 0.0587,\n",
      "        0.0579, 0.0563, 0.0567, 0.0576, 0.0563], device='cuda:0')\n",
      "tensor([[-0.0047],\n",
      "        [-0.0154],\n",
      "        [ 0.0729],\n",
      "        [ 0.0310],\n",
      "        [ 0.0134],\n",
      "        [ 0.0187],\n",
      "        [ 0.0246],\n",
      "        [ 0.0374],\n",
      "        [-0.0238],\n",
      "        [ 0.0438],\n",
      "        [ 0.1409],\n",
      "        [ 0.0630],\n",
      "        [ 0.0306],\n",
      "        [ 0.0543],\n",
      "        [ 0.1028],\n",
      "        [ 0.0511],\n",
      "        [ 0.0804],\n",
      "        [ 0.0596],\n",
      "        [ 0.0803],\n",
      "        [ 0.0515],\n",
      "        [ 0.2151],\n",
      "        [ 0.0491],\n",
      "        [ 0.0038],\n",
      "        [ 0.0569],\n",
      "        [ 0.0050],\n",
      "        [ 0.0337],\n",
      "        [ 0.0338],\n",
      "        [ 0.0332],\n",
      "        [ 0.0350],\n",
      "        [ 0.0303],\n",
      "        [ 0.0049],\n",
      "        [-0.0121]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0573, 0.0573, 0.0572, 0.0566, 0.0567, 0.0545, 0.0557, 0.0556, 0.0553,\n",
      "        0.0603, 0.0579, 0.0604, 0.0598, 0.0597, 0.0635, 0.0634, 0.0625, 0.0629,\n",
      "        0.0622, 0.0622, 0.0649, 0.0641, 0.0635, 0.0646, 0.0638, 0.0638, 0.0618,\n",
      "        0.0626, 0.0624, 0.0629, 0.0615, 0.0600], device='cuda:0')\n",
      "tensor([[-0.0250],\n",
      "        [-0.0041],\n",
      "        [ 0.0325],\n",
      "        [-0.0229],\n",
      "        [ 0.0077],\n",
      "        [ 0.0190],\n",
      "        [ 0.0106],\n",
      "        [ 0.0431],\n",
      "        [ 0.0437],\n",
      "        [ 0.0139],\n",
      "        [ 0.0829],\n",
      "        [-0.0035],\n",
      "        [-0.0042],\n",
      "        [-0.0620],\n",
      "        [ 0.0156],\n",
      "        [ 0.0380],\n",
      "        [ 0.0336],\n",
      "        [ 0.1202],\n",
      "        [ 0.0337],\n",
      "        [ 0.0342],\n",
      "        [ 0.0290],\n",
      "        [ 0.0348],\n",
      "        [ 0.0353],\n",
      "        [-0.0125],\n",
      "        [ 0.0085],\n",
      "        [ 0.0140],\n",
      "        [ 0.0082],\n",
      "        [ 0.0206],\n",
      "        [ 0.0115],\n",
      "        [ 0.0382],\n",
      "        [ 0.0741],\n",
      "        [ 0.0659]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0601, 0.0595, 0.0621, 0.0626, 0.0612, 0.0606, 0.0598, 0.0601, 0.0590,\n",
      "        0.0587, 0.0576, 0.0575, 0.0539, 0.0556, 0.0557, 0.0548, 0.0554, 0.0539,\n",
      "        0.0529, 0.0528, 0.0535, 0.0542, 0.0532, 0.0517, 0.0514, 0.0505, 0.0511,\n",
      "        0.0502, 0.0495, 0.0477, 0.0446, 0.0454], device='cuda:0')\n",
      "tensor([[-0.0152],\n",
      "        [-0.0140],\n",
      "        [ 0.0341],\n",
      "        [ 0.0940],\n",
      "        [-0.0269],\n",
      "        [-0.0778],\n",
      "        [ 0.0332],\n",
      "        [-0.0074],\n",
      "        [-0.0099],\n",
      "        [ 0.0307],\n",
      "        [ 0.1264],\n",
      "        [ 0.0265],\n",
      "        [-0.0168],\n",
      "        [ 0.0181],\n",
      "        [ 0.0092],\n",
      "        [ 0.0070],\n",
      "        [-0.0054],\n",
      "        [-0.0068],\n",
      "        [ 0.0036],\n",
      "        [-0.0053],\n",
      "        [ 0.0119],\n",
      "        [ 0.0602],\n",
      "        [ 0.0020],\n",
      "        [ 0.0473],\n",
      "        [ 0.0667],\n",
      "        [ 0.0437],\n",
      "        [ 0.0521],\n",
      "        [-0.0089],\n",
      "        [ 0.0323],\n",
      "        [-0.0098],\n",
      "        [ 0.0516],\n",
      "        [-0.0497]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0433, 0.0486, 0.0467, 0.0466, 0.0455, 0.0463, 0.0455, 0.0438, 0.0439,\n",
      "        0.0452, 0.0448, 0.0439, 0.0433, 0.0421, 0.0411, 0.0412, 0.0412, 0.0412,\n",
      "        0.0443, 0.0439, 0.0442, 0.0461, 0.0451, 0.0455, 0.0455, 0.0449, 0.0445,\n",
      "        0.0461, 0.0455, 0.0458, 0.0443, 0.0423], device='cuda:0')\n",
      "tensor([[-0.0143],\n",
      "        [ 0.0389],\n",
      "        [ 0.0354],\n",
      "        [ 0.0553],\n",
      "        [ 0.0449],\n",
      "        [-0.0189],\n",
      "        [ 0.0979],\n",
      "        [ 0.0632],\n",
      "        [ 0.0476],\n",
      "        [ 0.0460],\n",
      "        [ 0.0468],\n",
      "        [ 0.0477],\n",
      "        [ 0.0473],\n",
      "        [-0.0029],\n",
      "        [ 0.0235],\n",
      "        [-0.0115],\n",
      "        [ 0.0665],\n",
      "        [ 0.0269],\n",
      "        [ 0.0430],\n",
      "        [ 0.0327],\n",
      "        [ 0.0180],\n",
      "        [ 0.0252],\n",
      "        [ 0.1030],\n",
      "        [ 0.0239],\n",
      "        [ 0.0039],\n",
      "        [-0.0443],\n",
      "        [-0.0472],\n",
      "        [ 0.0760],\n",
      "        [ 0.0931],\n",
      "        [ 0.0247],\n",
      "        [-0.0098],\n",
      "        [ 0.0447]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0424, 0.0436, 0.0433, 0.0427, 0.0433, 0.0438, 0.0430, 0.0432, 0.0442,\n",
      "        0.0454, 0.0460, 0.0473, 0.0449, 0.0461, 0.0469, 0.0473, 0.0494, 0.0480,\n",
      "        0.0482, 0.0477, 0.0486, 0.0492, 0.0492, 0.0502, 0.0520, 0.0502, 0.0511,\n",
      "        0.0491, 0.0491, 0.0502, 0.0508, 0.0513], device='cuda:0')\n",
      "tensor([[ 0.1007],\n",
      "        [ 0.0047],\n",
      "        [ 0.0217],\n",
      "        [ 0.0369],\n",
      "        [ 0.0150],\n",
      "        [ 0.0192],\n",
      "        [ 0.0165],\n",
      "        [-0.0288],\n",
      "        [ 0.0296],\n",
      "        [ 0.0187],\n",
      "        [ 0.0322],\n",
      "        [ 0.0177],\n",
      "        [ 0.0974],\n",
      "        [ 0.0320],\n",
      "        [ 0.0273],\n",
      "        [ 0.0448],\n",
      "        [ 0.0506],\n",
      "        [ 0.0936],\n",
      "        [ 0.0897],\n",
      "        [ 0.0536],\n",
      "        [ 0.0292],\n",
      "        [ 0.0256],\n",
      "        [ 0.0169],\n",
      "        [ 0.0016],\n",
      "        [-0.0073],\n",
      "        [-0.0022],\n",
      "        [-0.0328],\n",
      "        [ 0.0134],\n",
      "        [ 0.0198],\n",
      "        [ 0.0528],\n",
      "        [ 0.0447],\n",
      "        [ 0.0441]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0507, 0.0513, 0.0501, 0.0510, 0.0523, 0.0529, 0.0539, 0.0536, 0.0533,\n",
      "        0.0535, 0.0548, 0.0575, 0.0560, 0.0566, 0.0582, 0.0576, 0.0587, 0.0576,\n",
      "        0.0573, 0.0572, 0.0567, 0.0575, 0.0576, 0.0581, 0.0578, 0.0576, 0.0572,\n",
      "        0.0566, 0.0582, 0.0584, 0.0578, 0.0595], device='cuda:0')\n",
      "tensor([[-0.0098],\n",
      "        [ 0.0256],\n",
      "        [ 0.0575],\n",
      "        [ 0.0194],\n",
      "        [ 0.0226],\n",
      "        [ 0.0087],\n",
      "        [ 0.0002],\n",
      "        [ 0.0948],\n",
      "        [ 0.1708],\n",
      "        [ 0.0148],\n",
      "        [ 0.0469],\n",
      "        [ 0.0710],\n",
      "        [-0.0424],\n",
      "        [-0.0359],\n",
      "        [ 0.0153],\n",
      "        [ 0.0054],\n",
      "        [ 0.0645],\n",
      "        [ 0.1295],\n",
      "        [ 0.1287],\n",
      "        [ 0.0161],\n",
      "        [-0.0055],\n",
      "        [ 0.0019],\n",
      "        [ 0.0520],\n",
      "        [ 0.0050],\n",
      "        [ 0.0284],\n",
      "        [-0.0045],\n",
      "        [-0.0131],\n",
      "        [ 0.0357],\n",
      "        [ 0.0403],\n",
      "        [ 0.0384],\n",
      "        [ 0.0640],\n",
      "        [ 0.0182]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0595, 0.0595, 0.0621, 0.0619, 0.0591, 0.0587, 0.0597, 0.0604, 0.0603,\n",
      "        0.0600, 0.0595, 0.0585, 0.0575, 0.0581, 0.0588, 0.0604, 0.0594, 0.0593,\n",
      "        0.0566, 0.0588, 0.0584, 0.0591, 0.0585, 0.0588, 0.0582, 0.0601, 0.0593,\n",
      "        0.0598, 0.0612, 0.0597, 0.0604, 0.0588], device='cuda:0')\n",
      "tensor([[ 0.0288],\n",
      "        [ 0.0009],\n",
      "        [ 0.0539],\n",
      "        [ 0.0353],\n",
      "        [ 0.0009],\n",
      "        [ 0.0173],\n",
      "        [-0.0932],\n",
      "        [ 0.0720],\n",
      "        [ 0.0248],\n",
      "        [ 0.0289],\n",
      "        [ 0.0464],\n",
      "        [ 0.0570],\n",
      "        [ 0.0588],\n",
      "        [ 0.1028],\n",
      "        [ 0.0191],\n",
      "        [ 0.0344],\n",
      "        [ 0.0400],\n",
      "        [ 0.0308],\n",
      "        [ 0.0099],\n",
      "        [-0.0019],\n",
      "        [-0.0245],\n",
      "        [-0.0007],\n",
      "        [ 0.0267],\n",
      "        [ 0.0320],\n",
      "        [-0.0318],\n",
      "        [ 0.0176],\n",
      "        [ 0.0069],\n",
      "        [-0.0005],\n",
      "        [-0.0114],\n",
      "        [ 0.0501],\n",
      "        [ 0.0257],\n",
      "        [-0.0013]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0570, 0.0560, 0.0564, 0.0570, 0.0579, 0.0590, 0.0610, 0.0607, 0.0634,\n",
      "        0.0635, 0.0625, 0.0640, 0.0631, 0.0638, 0.0618, 0.0610, 0.0616, 0.0610,\n",
      "        0.0607, 0.0585, 0.0594, 0.0588, 0.0594, 0.0581, 0.0576, 0.0594, 0.0604,\n",
      "        0.0616, 0.0593, 0.0600, 0.0601, 0.0600], device='cuda:0')\n",
      "tensor([[ 4.8206e-02],\n",
      "        [ 7.2053e-03],\n",
      "        [ 2.7431e-02],\n",
      "        [ 3.1345e-02],\n",
      "        [ 4.6155e-03],\n",
      "        [ 5.1023e-02],\n",
      "        [ 1.0884e-01],\n",
      "        [ 6.8747e-02],\n",
      "        [ 4.7770e-02],\n",
      "        [ 2.9815e-02],\n",
      "        [ 6.4120e-03],\n",
      "        [ 7.7333e-02],\n",
      "        [ 5.7064e-02],\n",
      "        [ 3.9209e-02],\n",
      "        [-2.5545e-02],\n",
      "        [-1.7673e-02],\n",
      "        [ 9.1370e-02],\n",
      "        [ 2.9562e-03],\n",
      "        [ 3.6604e-03],\n",
      "        [-1.0513e-05],\n",
      "        [ 3.9391e-02],\n",
      "        [-3.9982e-03],\n",
      "        [-1.1902e-02],\n",
      "        [ 2.0737e-02],\n",
      "        [ 2.3193e-02],\n",
      "        [ 2.2331e-02],\n",
      "        [-4.5469e-03],\n",
      "        [ 2.4970e-02],\n",
      "        [-3.9621e-03],\n",
      "        [ 8.0715e-03],\n",
      "        [ 3.2076e-03],\n",
      "        [ 8.3306e-04]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0644, 0.0649, 0.0653, 0.0653, 0.0657, 0.0650, 0.0657, 0.0638, 0.0638,\n",
      "        0.0628, 0.0619, 0.0612, 0.0593, 0.0609, 0.0610, 0.0615, 0.0604, 0.0591,\n",
      "        0.0588, 0.0560, 0.0569, 0.0584, 0.0569, 0.0590, 0.0578, 0.0559, 0.0570,\n",
      "        0.0600, 0.0601, 0.0616, 0.0622, 0.0610], device='cuda:0')\n",
      "tensor([[-9.7899e-03],\n",
      "        [ 3.4734e-02],\n",
      "        [ 1.1231e-01],\n",
      "        [ 1.1821e-01],\n",
      "        [ 2.3823e-02],\n",
      "        [ 4.1121e-02],\n",
      "        [ 1.5348e-02],\n",
      "        [ 9.2756e-03],\n",
      "        [ 1.1745e-01],\n",
      "        [ 2.5764e-02],\n",
      "        [ 1.3173e-01],\n",
      "        [ 1.2803e-04],\n",
      "        [ 2.7035e-02],\n",
      "        [-3.1626e-02],\n",
      "        [ 2.5369e-02],\n",
      "        [ 4.1181e-02],\n",
      "        [ 1.8637e-02],\n",
      "        [ 2.4962e-02],\n",
      "        [-5.4738e-03],\n",
      "        [ 1.3117e-02],\n",
      "        [ 2.8243e-02],\n",
      "        [ 2.5467e-02],\n",
      "        [ 5.2778e-02],\n",
      "        [-1.2546e-02],\n",
      "        [ 2.5089e-02],\n",
      "        [-2.2662e-02],\n",
      "        [-1.0480e-02],\n",
      "        [-2.8496e-02],\n",
      "        [ 5.9801e-02],\n",
      "        [ 7.4991e-03],\n",
      "        [ 1.6952e-04],\n",
      "        [-1.9314e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0618, 0.0609, 0.0624, 0.0637, 0.0652, 0.0628, 0.0606, 0.0603, 0.0595,\n",
      "        0.0593, 0.0595, 0.0584, 0.0597, 0.0594, 0.0575, 0.0576, 0.0578, 0.0575,\n",
      "        0.0575, 0.0581, 0.0570, 0.0573, 0.0567, 0.0556, 0.0566, 0.0569, 0.0563,\n",
      "        0.0566, 0.0557, 0.0551, 0.0547, 0.0536], device='cuda:0')\n",
      "tensor([[-9.2160e-03],\n",
      "        [-7.6835e-03],\n",
      "        [ 2.9388e-02],\n",
      "        [ 6.2571e-02],\n",
      "        [-3.8452e-02],\n",
      "        [ 4.5217e-02],\n",
      "        [-5.6531e-03],\n",
      "        [ 3.4726e-02],\n",
      "        [-1.4864e-02],\n",
      "        [-3.3649e-02],\n",
      "        [-3.6192e-03],\n",
      "        [ 7.6536e-05],\n",
      "        [ 2.3474e-03],\n",
      "        [ 8.5895e-02],\n",
      "        [ 1.0155e-01],\n",
      "        [ 1.7943e-02],\n",
      "        [ 7.6985e-03],\n",
      "        [-2.8134e-03],\n",
      "        [-1.6547e-02],\n",
      "        [ 3.3069e-02],\n",
      "        [-1.1058e-02],\n",
      "        [-5.1854e-03],\n",
      "        [ 7.5246e-03],\n",
      "        [ 7.1699e-02],\n",
      "        [ 7.1278e-02],\n",
      "        [-6.2770e-03],\n",
      "        [ 1.0939e-01],\n",
      "        [ 9.1111e-02],\n",
      "        [ 5.2030e-02],\n",
      "        [ 4.3614e-02],\n",
      "        [ 6.8060e-02],\n",
      "        [ 4.3852e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0536, 0.0539, 0.0539, 0.0531, 0.0522, 0.0539, 0.0541, 0.0566, 0.0572,\n",
      "        0.0566, 0.0559, 0.0545, 0.0538, 0.0539, 0.0538, 0.0551, 0.0545, 0.0542,\n",
      "        0.0563, 0.0554, 0.0570, 0.0566, 0.0572, 0.0560, 0.0553, 0.0550, 0.0542,\n",
      "        0.0562, 0.0553, 0.0536, 0.0533, 0.0544], device='cuda:0')\n",
      "tensor([[ 0.0680],\n",
      "        [ 0.0912],\n",
      "        [ 0.0480],\n",
      "        [ 0.0708],\n",
      "        [ 0.0077],\n",
      "        [ 0.0275],\n",
      "        [-0.0129],\n",
      "        [-0.0021],\n",
      "        [ 0.0518],\n",
      "        [-0.0149],\n",
      "        [-0.0175],\n",
      "        [-0.0003],\n",
      "        [ 0.0434],\n",
      "        [ 0.0272],\n",
      "        [ 0.0275],\n",
      "        [ 0.0518],\n",
      "        [ 0.0399],\n",
      "        [ 0.0772],\n",
      "        [ 0.0419],\n",
      "        [ 0.0553],\n",
      "        [ 0.0103],\n",
      "        [ 0.0764],\n",
      "        [ 0.0274],\n",
      "        [ 0.0320],\n",
      "        [ 0.0202],\n",
      "        [ 0.0532],\n",
      "        [ 0.0064],\n",
      "        [ 0.0148],\n",
      "        [ 0.0934],\n",
      "        [ 0.0211],\n",
      "        [ 0.0216],\n",
      "        [-0.0252]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0551, 0.0541, 0.0529, 0.0520, 0.0516, 0.0516, 0.0536, 0.0525, 0.0517,\n",
      "        0.0505, 0.0511, 0.0516, 0.0535, 0.0522, 0.0520, 0.0520, 0.0523, 0.0529,\n",
      "        0.0520, 0.0511, 0.0500, 0.0505, 0.0497, 0.0489, 0.0491, 0.0485, 0.0491,\n",
      "        0.0469, 0.0477, 0.0477, 0.0476, 0.0473], device='cuda:0')\n",
      "tensor([[-0.0091],\n",
      "        [-0.0211],\n",
      "        [-0.0194],\n",
      "        [ 0.0031],\n",
      "        [-0.0202],\n",
      "        [-0.0311],\n",
      "        [ 0.0346],\n",
      "        [-0.0127],\n",
      "        [ 0.0032],\n",
      "        [ 0.0597],\n",
      "        [ 0.0219],\n",
      "        [ 0.0435],\n",
      "        [ 0.0908],\n",
      "        [ 0.0454],\n",
      "        [ 0.0506],\n",
      "        [ 0.0617],\n",
      "        [ 0.0382],\n",
      "        [ 0.0526],\n",
      "        [-0.0304],\n",
      "        [ 0.0071],\n",
      "        [ 0.0066],\n",
      "        [ 0.0415],\n",
      "        [ 0.0413],\n",
      "        [ 0.0094],\n",
      "        [ 0.0623],\n",
      "        [ 0.0684],\n",
      "        [ 0.0402],\n",
      "        [ 0.0131],\n",
      "        [-0.0242],\n",
      "        [ 0.0106],\n",
      "        [ 0.0360],\n",
      "        [ 0.0181]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0477, 0.0476, 0.0473, 0.0464, 0.0463, 0.0470, 0.0491, 0.0492, 0.0501,\n",
      "        0.0519, 0.0514, 0.0505, 0.0492, 0.0497, 0.0495, 0.0485, 0.0491, 0.0504,\n",
      "        0.0508, 0.0514, 0.0502, 0.0498, 0.0488, 0.0486, 0.0494, 0.0508, 0.0510,\n",
      "        0.0504, 0.0501, 0.0491, 0.0491, 0.0479], device='cuda:0')\n",
      "tensor([[ 0.0250],\n",
      "        [ 0.0183],\n",
      "        [ 0.0165],\n",
      "        [ 0.0707],\n",
      "        [-0.0551],\n",
      "        [ 0.0054],\n",
      "        [ 0.0047],\n",
      "        [-0.0084],\n",
      "        [ 0.0373],\n",
      "        [ 0.0121],\n",
      "        [-0.0255],\n",
      "        [ 0.0394],\n",
      "        [ 0.0170],\n",
      "        [ 0.0133],\n",
      "        [ 0.0281],\n",
      "        [ 0.0210],\n",
      "        [-0.0153],\n",
      "        [ 0.0175],\n",
      "        [ 0.0619],\n",
      "        [ 0.0661],\n",
      "        [ 0.0623],\n",
      "        [-0.0044],\n",
      "        [-0.0043],\n",
      "        [ 0.0193],\n",
      "        [ 0.0620],\n",
      "        [ 0.0336],\n",
      "        [ 0.0287],\n",
      "        [ 0.1318],\n",
      "        [ 0.2630],\n",
      "        [ 0.0370],\n",
      "        [ 0.0290],\n",
      "        [ 0.0571]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0479, 0.0480, 0.0480, 0.0476, 0.0476, 0.0473, 0.0467, 0.0479, 0.0476,\n",
      "        0.0476, 0.0470, 0.0461, 0.0463, 0.0458, 0.0455, 0.0457, 0.0464, 0.0461,\n",
      "        0.0461, 0.0473, 0.0470, 0.0474, 0.0495, 0.0497, 0.0479, 0.0480, 0.0491,\n",
      "        0.0501, 0.0491, 0.0495, 0.0492, 0.0477], device='cuda:0')\n",
      "tensor([[ 0.1478],\n",
      "        [ 0.0264],\n",
      "        [ 0.0738],\n",
      "        [ 0.0341],\n",
      "        [-0.0051],\n",
      "        [-0.0158],\n",
      "        [-0.0011],\n",
      "        [-0.0288],\n",
      "        [ 0.0102],\n",
      "        [ 0.0502],\n",
      "        [ 0.0082],\n",
      "        [ 0.0419],\n",
      "        [-0.0637],\n",
      "        [ 0.0070],\n",
      "        [ 0.0533],\n",
      "        [ 0.0392],\n",
      "        [ 0.0193],\n",
      "        [ 0.0252],\n",
      "        [ 0.0255],\n",
      "        [ 0.0280],\n",
      "        [-0.0017],\n",
      "        [-0.0241],\n",
      "        [ 0.0440],\n",
      "        [ 0.1341],\n",
      "        [ 0.0203],\n",
      "        [ 0.0403],\n",
      "        [ 0.0269],\n",
      "        [-0.0369],\n",
      "        [ 0.0057],\n",
      "        [ 0.0241],\n",
      "        [ 0.0395],\n",
      "        [ 0.0377]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0476, 0.0480, 0.0483, 0.0479, 0.0467, 0.0467, 0.0463, 0.0460, 0.0467,\n",
      "        0.0458, 0.0469, 0.0466, 0.0452, 0.0445, 0.0445, 0.0446, 0.0454, 0.0466,\n",
      "        0.0467, 0.0463, 0.0455, 0.0446, 0.0445, 0.0455, 0.0449, 0.0451, 0.0452,\n",
      "        0.0440, 0.0455, 0.0436, 0.0446, 0.0445], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0101],\n",
      "        [ 0.0482],\n",
      "        [-0.0057],\n",
      "        [-0.0064],\n",
      "        [ 0.0277],\n",
      "        [ 0.0442],\n",
      "        [ 0.0143],\n",
      "        [ 0.0542],\n",
      "        [ 0.0524],\n",
      "        [ 0.0648],\n",
      "        [ 0.0388],\n",
      "        [ 0.0233],\n",
      "        [ 0.0308],\n",
      "        [ 0.0609],\n",
      "        [ 0.0269],\n",
      "        [-0.0870],\n",
      "        [ 0.0205],\n",
      "        [ 0.0411],\n",
      "        [ 0.0449],\n",
      "        [ 0.0366],\n",
      "        [ 0.0424],\n",
      "        [-0.0122],\n",
      "        [ 0.0403],\n",
      "        [ 0.1039],\n",
      "        [ 0.0886],\n",
      "        [ 0.0198],\n",
      "        [ 0.0549],\n",
      "        [ 0.0924],\n",
      "        [ 0.0179],\n",
      "        [ 0.0515],\n",
      "        [-0.0093],\n",
      "        [ 0.0223]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0457, 0.0458, 0.0448, 0.0457, 0.0463, 0.0467, 0.0463, 0.0442, 0.0427,\n",
      "        0.0424, 0.0412, 0.0412, 0.0417, 0.0414, 0.0411, 0.0410, 0.0405, 0.0407,\n",
      "        0.0392, 0.0386, 0.0415, 0.0433, 0.0433, 0.0426, 0.0415, 0.0408, 0.0417,\n",
      "        0.0424, 0.0427, 0.0430, 0.0417, 0.0410], device='cuda:0')\n",
      "tensor([[ 0.0230],\n",
      "        [ 0.0317],\n",
      "        [-0.0003],\n",
      "        [ 0.0187],\n",
      "        [ 0.0480],\n",
      "        [-0.0047],\n",
      "        [ 0.0610],\n",
      "        [ 0.0453],\n",
      "        [ 0.0173],\n",
      "        [-0.0205],\n",
      "        [ 0.0073],\n",
      "        [ 0.0231],\n",
      "        [-0.0196],\n",
      "        [ 0.1394],\n",
      "        [ 0.0299],\n",
      "        [-0.0090],\n",
      "        [ 0.0453],\n",
      "        [ 0.0419],\n",
      "        [ 0.0212],\n",
      "        [ 0.0084],\n",
      "        [ 0.0263],\n",
      "        [ 0.0136],\n",
      "        [-0.0013],\n",
      "        [ 0.0070],\n",
      "        [ 0.0366],\n",
      "        [ 0.0140],\n",
      "        [ 0.0502],\n",
      "        [ 0.0313],\n",
      "        [-0.0160],\n",
      "        [-0.0356],\n",
      "        [ 0.0269],\n",
      "        [ 0.0027]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0410, 0.0402, 0.0402, 0.0405, 0.0404, 0.0424, 0.0429, 0.0451, 0.0451,\n",
      "        0.0446, 0.0433, 0.0445, 0.0452, 0.0439, 0.0436, 0.0443, 0.0452, 0.0449,\n",
      "        0.0438, 0.0440, 0.0446, 0.0466, 0.0477, 0.0473, 0.0479, 0.0470, 0.0480,\n",
      "        0.0474, 0.0469, 0.0483, 0.0479, 0.0495], device='cuda:0')\n",
      "tensor([[-0.0417],\n",
      "        [-0.0009],\n",
      "        [ 0.0009],\n",
      "        [-0.0238],\n",
      "        [ 0.0272],\n",
      "        [ 0.0151],\n",
      "        [ 0.0222],\n",
      "        [ 0.0489],\n",
      "        [-0.0176],\n",
      "        [ 0.0558],\n",
      "        [ 0.0383],\n",
      "        [ 0.0167],\n",
      "        [ 0.0235],\n",
      "        [ 0.0940],\n",
      "        [ 0.1333],\n",
      "        [-0.0076],\n",
      "        [ 0.0101],\n",
      "        [ 0.1366],\n",
      "        [ 0.0175],\n",
      "        [ 0.0109],\n",
      "        [ 0.0044],\n",
      "        [ 0.0233],\n",
      "        [ 0.0824],\n",
      "        [ 0.0168],\n",
      "        [ 0.0385],\n",
      "        [ 0.0162],\n",
      "        [ 0.0321],\n",
      "        [ 0.0876],\n",
      "        [-0.0057],\n",
      "        [-0.0427],\n",
      "        [-0.0089],\n",
      "        [-0.0286]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0480, 0.0477, 0.0477, 0.0477, 0.0477, 0.0486, 0.0485, 0.0502, 0.0513,\n",
      "        0.0538, 0.0528, 0.0533, 0.0545, 0.0535, 0.0539, 0.0536, 0.0547, 0.0567,\n",
      "        0.0559, 0.0547, 0.0551, 0.0548, 0.0554, 0.0554, 0.0533, 0.0532, 0.0538,\n",
      "        0.0531, 0.0528, 0.0542, 0.0542, 0.0548], device='cuda:0')\n",
      "tensor([[-0.0150],\n",
      "        [ 0.0260],\n",
      "        [ 0.0199],\n",
      "        [ 0.0192],\n",
      "        [ 0.0876],\n",
      "        [ 0.0892],\n",
      "        [ 0.0074],\n",
      "        [ 0.0625],\n",
      "        [ 0.0220],\n",
      "        [ 0.0318],\n",
      "        [-0.0108],\n",
      "        [ 0.0402],\n",
      "        [ 0.0210],\n",
      "        [ 0.0811],\n",
      "        [ 0.1099],\n",
      "        [ 0.0939],\n",
      "        [ 0.1259],\n",
      "        [ 0.0405],\n",
      "        [ 0.0313],\n",
      "        [ 0.0097],\n",
      "        [-0.0161],\n",
      "        [-0.0580],\n",
      "        [ 0.0309],\n",
      "        [-0.0257],\n",
      "        [ 0.0359],\n",
      "        [-0.0113],\n",
      "        [ 0.0460],\n",
      "        [ 0.0279],\n",
      "        [ 0.0188],\n",
      "        [ 0.0436],\n",
      "        [ 0.0155],\n",
      "        [ 0.0174]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0544, 0.0520, 0.0526, 0.0539, 0.0535, 0.0538, 0.0541, 0.0528, 0.0514,\n",
      "        0.0505, 0.0498, 0.0486, 0.0500, 0.0504, 0.0495, 0.0491, 0.0502, 0.0485,\n",
      "        0.0485, 0.0491, 0.0488, 0.0505, 0.0510, 0.0505, 0.0513, 0.0504, 0.0514,\n",
      "        0.0520, 0.0513, 0.0528, 0.0533, 0.0533], device='cuda:0')\n",
      "tensor([[-0.0053],\n",
      "        [-0.0026],\n",
      "        [ 0.0405],\n",
      "        [ 0.0477],\n",
      "        [ 0.0123],\n",
      "        [ 0.0413],\n",
      "        [ 0.0061],\n",
      "        [ 0.0383],\n",
      "        [ 0.0280],\n",
      "        [ 0.0004],\n",
      "        [ 0.0475],\n",
      "        [ 0.1412],\n",
      "        [-0.0277],\n",
      "        [-0.0103],\n",
      "        [ 0.0103],\n",
      "        [ 0.0074],\n",
      "        [ 0.0104],\n",
      "        [ 0.0438],\n",
      "        [ 0.0279],\n",
      "        [ 0.0416],\n",
      "        [ 0.0315],\n",
      "        [ 0.0159],\n",
      "        [ 0.0138],\n",
      "        [ 0.1064],\n",
      "        [ 0.0069],\n",
      "        [ 0.0121],\n",
      "        [ 0.0034],\n",
      "        [ 0.0227],\n",
      "        [ 0.0136],\n",
      "        [ 0.0964],\n",
      "        [ 0.1267],\n",
      "        [-0.0424]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0536, 0.0536, 0.0542, 0.0541, 0.0539, 0.0559, 0.0570, 0.0569, 0.0560,\n",
      "        0.0554, 0.0562, 0.0567, 0.0584, 0.0587, 0.0576, 0.0573, 0.0564, 0.0566,\n",
      "        0.0569, 0.0572, 0.0576, 0.0573, 0.0572, 0.0562, 0.0567, 0.0562, 0.0559,\n",
      "        0.0559, 0.0550, 0.0548, 0.0545, 0.0551], device='cuda:0')\n",
      "tensor([[-0.0318],\n",
      "        [-0.0098],\n",
      "        [ 0.0767],\n",
      "        [ 0.0453],\n",
      "        [ 0.0241],\n",
      "        [ 0.0208],\n",
      "        [ 0.0222],\n",
      "        [ 0.0488],\n",
      "        [ 0.0102],\n",
      "        [ 0.0413],\n",
      "        [ 0.0304],\n",
      "        [ 0.0148],\n",
      "        [ 0.0130],\n",
      "        [-0.0146],\n",
      "        [ 0.0164],\n",
      "        [ 0.0714],\n",
      "        [ 0.0929],\n",
      "        [ 0.0073],\n",
      "        [-0.0003],\n",
      "        [ 0.0370],\n",
      "        [-0.0204],\n",
      "        [ 0.0178],\n",
      "        [ 0.0516],\n",
      "        [ 0.0422],\n",
      "        [ 0.0398],\n",
      "        [ 0.0322],\n",
      "        [ 0.0088],\n",
      "        [ 0.0527],\n",
      "        [ 0.0437],\n",
      "        [ 0.0272],\n",
      "        [ 0.1124],\n",
      "        [ 0.1085]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0547, 0.0542, 0.0538, 0.0539, 0.0539, 0.0533, 0.0536, 0.0539, 0.0533,\n",
      "        0.0519, 0.0516, 0.0495, 0.0494, 0.0501, 0.0511, 0.0505, 0.0513, 0.0510,\n",
      "        0.0498, 0.0497, 0.0500, 0.0514, 0.0529, 0.0522, 0.0519, 0.0529, 0.0529,\n",
      "        0.0523, 0.0523, 0.0516, 0.0520, 0.0528], device='cuda:0')\n",
      "tensor([[ 0.0364],\n",
      "        [ 0.0035],\n",
      "        [ 0.0214],\n",
      "        [-0.0171],\n",
      "        [-0.0157],\n",
      "        [ 0.0422],\n",
      "        [ 0.0663],\n",
      "        [-0.0343],\n",
      "        [ 0.0873],\n",
      "        [ 0.0825],\n",
      "        [ 0.1077],\n",
      "        [ 0.0907],\n",
      "        [ 0.0100],\n",
      "        [ 0.0335],\n",
      "        [ 0.0192],\n",
      "        [ 0.0311],\n",
      "        [ 0.0055],\n",
      "        [ 0.0216],\n",
      "        [-0.0058],\n",
      "        [ 0.0054],\n",
      "        [ 0.0067],\n",
      "        [ 0.0150],\n",
      "        [ 0.0396],\n",
      "        [-0.0059],\n",
      "        [-0.0069],\n",
      "        [-0.0119],\n",
      "        [ 0.0715],\n",
      "        [ 0.0702],\n",
      "        [ 0.0174],\n",
      "        [-0.0291],\n",
      "        [-0.0131],\n",
      "        [ 0.0092]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0533, 0.0545, 0.0597, 0.0569, 0.0597, 0.0595, 0.0595, 0.0585, 0.0603,\n",
      "        0.0604, 0.0594, 0.0593, 0.0585, 0.0581, 0.0573, 0.0581, 0.0582, 0.0595,\n",
      "        0.0587, 0.0582, 0.0562, 0.0553, 0.0554, 0.0551, 0.0544, 0.0542, 0.0550,\n",
      "        0.0550, 0.0587, 0.0584, 0.0587, 0.0613], device='cuda:0')\n",
      "tensor([[ 0.0282],\n",
      "        [ 0.0236],\n",
      "        [ 0.0382],\n",
      "        [ 0.0511],\n",
      "        [ 0.0012],\n",
      "        [ 0.1052],\n",
      "        [ 0.0426],\n",
      "        [ 0.0075],\n",
      "        [ 0.0404],\n",
      "        [-0.0177],\n",
      "        [ 0.0126],\n",
      "        [ 0.0251],\n",
      "        [-0.0263],\n",
      "        [ 0.0269],\n",
      "        [ 0.0311],\n",
      "        [ 0.0221],\n",
      "        [ 0.0538],\n",
      "        [ 0.0194],\n",
      "        [-0.0102],\n",
      "        [ 0.0062],\n",
      "        [ 0.0914],\n",
      "        [ 0.0196],\n",
      "        [ 0.0150],\n",
      "        [-0.0266],\n",
      "        [-0.0093],\n",
      "        [ 0.0272],\n",
      "        [ 0.0596],\n",
      "        [ 0.0705],\n",
      "        [ 0.0411],\n",
      "        [ 0.0564],\n",
      "        [ 0.0525],\n",
      "        [ 0.1063]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0626, 0.0615, 0.0624, 0.0624, 0.0622, 0.0632, 0.0640, 0.0631, 0.0650,\n",
      "        0.0659, 0.0663, 0.0663, 0.0656, 0.0650, 0.0668, 0.0663, 0.0674, 0.0683,\n",
      "        0.0683, 0.0690, 0.0714, 0.0699, 0.0709, 0.0705, 0.0712, 0.0708, 0.0690,\n",
      "        0.0674, 0.0683, 0.0687, 0.0694, 0.0740], device='cuda:0')\n",
      "tensor([[ 0.0519],\n",
      "        [ 0.0029],\n",
      "        [-0.0070],\n",
      "        [ 0.0371],\n",
      "        [ 0.0378],\n",
      "        [ 0.0513],\n",
      "        [ 0.0168],\n",
      "        [ 0.0869],\n",
      "        [ 0.2157],\n",
      "        [ 0.1010],\n",
      "        [-0.0046],\n",
      "        [-0.0135],\n",
      "        [ 0.0054],\n",
      "        [-0.0003],\n",
      "        [ 0.0527],\n",
      "        [ 0.0125],\n",
      "        [ 0.0304],\n",
      "        [ 0.0181],\n",
      "        [ 0.0203],\n",
      "        [ 0.0149],\n",
      "        [ 0.0618],\n",
      "        [ 0.0755],\n",
      "        [-0.0100],\n",
      "        [ 0.0206],\n",
      "        [ 0.0466],\n",
      "        [ 0.0376],\n",
      "        [ 0.0333],\n",
      "        [-0.0096],\n",
      "        [ 0.0156],\n",
      "        [ 0.0326],\n",
      "        [-0.0082],\n",
      "        [-0.0114]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0756, 0.0765, 0.0793, 0.0784, 0.0793, 0.0753, 0.0746, 0.0787, 0.0777,\n",
      "        0.0805, 0.0808, 0.0784, 0.0752, 0.0776, 0.0771, 0.0748, 0.0750, 0.0770,\n",
      "        0.0774, 0.0814, 0.0799, 0.0802, 0.0792, 0.0820, 0.0804, 0.0815, 0.0815,\n",
      "        0.0779, 0.0777, 0.0799, 0.0796, 0.0793], device='cuda:0')\n",
      "tensor([[ 7.7022e-02],\n",
      "        [ 9.6603e-02],\n",
      "        [ 3.1283e-02],\n",
      "        [-1.2527e-03],\n",
      "        [-1.5550e-02],\n",
      "        [ 5.3178e-02],\n",
      "        [ 7.2391e-02],\n",
      "        [ 6.0172e-03],\n",
      "        [-2.7468e-02],\n",
      "        [ 3.1546e-02],\n",
      "        [ 3.4478e-02],\n",
      "        [ 8.7705e-02],\n",
      "        [ 4.8047e-02],\n",
      "        [ 2.4663e-02],\n",
      "        [ 9.5048e-02],\n",
      "        [ 1.8565e-01],\n",
      "        [ 3.8344e-02],\n",
      "        [ 1.5894e-04],\n",
      "        [ 5.1820e-02],\n",
      "        [ 3.9297e-03],\n",
      "        [ 1.3558e-02],\n",
      "        [-3.8827e-02],\n",
      "        [ 6.6459e-03],\n",
      "        [ 3.5541e-02],\n",
      "        [-3.8490e-02],\n",
      "        [ 4.0529e-02],\n",
      "        [-4.8738e-03],\n",
      "        [ 1.6099e-02],\n",
      "        [ 4.5083e-02],\n",
      "        [-9.0407e-03],\n",
      "        [ 3.3063e-03],\n",
      "        [ 1.2126e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0758, 0.0767, 0.0784, 0.0792, 0.0781, 0.0829, 0.0829, 0.0849, 0.0849,\n",
      "        0.0902, 0.0931, 0.0923, 0.0913, 0.0902, 0.0916, 0.0882, 0.0863, 0.0879,\n",
      "        0.0910, 0.0900, 0.0938, 0.0911, 0.0913, 0.0945, 0.0931, 0.0948, 0.0942,\n",
      "        0.0944, 0.0905, 0.0936, 0.0941, 0.0960], device='cuda:0')\n",
      "tensor([[ 0.0160],\n",
      "        [-0.0503],\n",
      "        [ 0.0353],\n",
      "        [ 0.0078],\n",
      "        [ 0.0537],\n",
      "        [ 0.0193],\n",
      "        [ 0.0719],\n",
      "        [ 0.0081],\n",
      "        [ 0.1234],\n",
      "        [ 0.0362],\n",
      "        [-0.0006],\n",
      "        [ 0.0620],\n",
      "        [ 0.0547],\n",
      "        [ 0.0469],\n",
      "        [ 0.0254],\n",
      "        [-0.0317],\n",
      "        [-0.0080],\n",
      "        [ 0.1128],\n",
      "        [ 0.0012],\n",
      "        [-0.0028],\n",
      "        [ 0.0429],\n",
      "        [ 0.0347],\n",
      "        [ 0.0140],\n",
      "        [-0.0121],\n",
      "        [ 0.0032],\n",
      "        [ 0.0314],\n",
      "        [ 0.0029],\n",
      "        [-0.0234],\n",
      "        [ 0.0062],\n",
      "        [ 0.0359],\n",
      "        [-0.0245],\n",
      "        [ 0.0741]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0948, 0.0964, 0.0964, 0.0966, 0.0972, 0.0978, 0.0979, 0.0984, 0.0970,\n",
      "        0.0963, 0.0925, 0.0916, 0.0941, 0.0931, 0.0960, 0.0957, 0.0975, 0.0953,\n",
      "        0.0941, 0.0935, 0.0957, 0.0954, 0.0931, 0.0923, 0.0945, 0.0945, 0.0976,\n",
      "        0.0975, 0.0969, 0.0969, 0.0972, 0.0954], device='cuda:0')\n",
      "tensor([[ 0.0652],\n",
      "        [ 0.0280],\n",
      "        [ 0.0274],\n",
      "        [ 0.0142],\n",
      "        [-0.0167],\n",
      "        [ 0.0340],\n",
      "        [ 0.0823],\n",
      "        [ 0.0306],\n",
      "        [-0.0251],\n",
      "        [ 0.1017],\n",
      "        [ 0.0188],\n",
      "        [ 0.0069],\n",
      "        [ 0.0081],\n",
      "        [ 0.0204],\n",
      "        [ 0.0632],\n",
      "        [-0.0133],\n",
      "        [ 0.0214],\n",
      "        [ 0.0161],\n",
      "        [ 0.0676],\n",
      "        [ 0.0604],\n",
      "        [ 0.0889],\n",
      "        [-0.0151],\n",
      "        [ 0.0389],\n",
      "        [-0.0005],\n",
      "        [ 0.0270],\n",
      "        [ 0.0563],\n",
      "        [ 0.0310],\n",
      "        [ 0.0345],\n",
      "        [-0.0092],\n",
      "        [ 0.0222],\n",
      "        [ 0.0326],\n",
      "        [-0.0264]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0973, 0.0998, 0.0993, 0.0976, 0.1009, 0.1013, 0.1010, 0.1015, 0.1024,\n",
      "        0.0998, 0.1015, 0.0991, 0.0997, 0.0994, 0.0998, 0.0975, 0.0975, 0.0987,\n",
      "        0.0997, 0.0990, 0.1013, 0.1015, 0.1013, 0.1016, 0.1022, 0.1038, 0.1009,\n",
      "        0.1016, 0.1012, 0.1019, 0.1026, 0.1034], device='cuda:0')\n",
      "tensor([[ 0.0438],\n",
      "        [-0.0181],\n",
      "        [ 0.0460],\n",
      "        [ 0.0610],\n",
      "        [-0.0080],\n",
      "        [ 0.0616],\n",
      "        [ 0.0854],\n",
      "        [ 0.0989],\n",
      "        [ 0.0695],\n",
      "        [ 0.0166],\n",
      "        [ 0.1549],\n",
      "        [ 0.0521],\n",
      "        [ 0.0542],\n",
      "        [ 0.0395],\n",
      "        [ 0.0269],\n",
      "        [ 0.0344],\n",
      "        [ 0.0231],\n",
      "        [ 0.0508],\n",
      "        [ 0.0507],\n",
      "        [-0.0524],\n",
      "        [ 0.0703],\n",
      "        [ 0.0452],\n",
      "        [ 0.0300],\n",
      "        [ 0.0763],\n",
      "        [ 0.0027],\n",
      "        [-0.0084],\n",
      "        [-0.0144],\n",
      "        [ 0.0584],\n",
      "        [-0.0038],\n",
      "        [ 0.0400],\n",
      "        [ 0.0125],\n",
      "        [ 0.0471]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1066, 0.1071, 0.1091, 0.1100, 0.1108, 0.1137, 0.1124, 0.1167, 0.1165,\n",
      "        0.1192, 0.1159, 0.1190, 0.1177, 0.1192, 0.1189, 0.1165, 0.1171, 0.1183,\n",
      "        0.1174, 0.1196, 0.1195, 0.1187, 0.1171, 0.1171, 0.1183, 0.1168, 0.1153,\n",
      "        0.1153, 0.1121, 0.1115, 0.1136, 0.1161], device='cuda:0')\n",
      "tensor([[-0.0175],\n",
      "        [ 0.0590],\n",
      "        [ 0.0921],\n",
      "        [ 0.0434],\n",
      "        [-0.0068],\n",
      "        [ 0.0308],\n",
      "        [ 0.0226],\n",
      "        [ 0.0247],\n",
      "        [-0.0235],\n",
      "        [ 0.0333],\n",
      "        [ 0.0547],\n",
      "        [ 0.0024],\n",
      "        [ 0.0167],\n",
      "        [ 0.0172],\n",
      "        [ 0.0286],\n",
      "        [ 0.0077],\n",
      "        [ 0.0176],\n",
      "        [ 0.0251],\n",
      "        [ 0.0351],\n",
      "        [ 0.0881],\n",
      "        [ 0.0935],\n",
      "        [ 0.1316],\n",
      "        [ 0.1240],\n",
      "        [ 0.0809],\n",
      "        [ 0.0303],\n",
      "        [ 0.0270],\n",
      "        [ 0.0282],\n",
      "        [ 0.0414],\n",
      "        [ 0.0312],\n",
      "        [-0.0532],\n",
      "        [ 0.0267],\n",
      "        [ 0.0247]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1173, 0.1158, 0.1142, 0.1121, 0.1128, 0.1148, 0.1153, 0.1174, 0.1143,\n",
      "        0.1146, 0.1150, 0.1156, 0.1192, 0.1201, 0.1236, 0.1245, 0.1238, 0.1248,\n",
      "        0.1261, 0.1266, 0.1263, 0.1260, 0.1235, 0.1201, 0.1224, 0.1227, 0.1236,\n",
      "        0.1215, 0.1243, 0.1221, 0.1242, 0.1263], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5256e-02],\n",
      "        [ 3.4566e-02],\n",
      "        [ 1.5665e-02],\n",
      "        [-8.7972e-03],\n",
      "        [ 1.9024e-02],\n",
      "        [ 4.0525e-02],\n",
      "        [-1.2698e-02],\n",
      "        [ 4.7291e-02],\n",
      "        [ 7.2968e-03],\n",
      "        [-5.1146e-03],\n",
      "        [ 1.0036e-02],\n",
      "        [ 9.7831e-02],\n",
      "        [ 3.6574e-02],\n",
      "        [ 3.9854e-02],\n",
      "        [ 9.8270e-02],\n",
      "        [ 3.7818e-02],\n",
      "        [ 5.5475e-02],\n",
      "        [ 2.4641e-02],\n",
      "        [ 3.7938e-02],\n",
      "        [ 9.3523e-02],\n",
      "        [-3.3154e-02],\n",
      "        [ 1.9447e-02],\n",
      "        [ 8.7800e-02],\n",
      "        [-6.0678e-05],\n",
      "        [ 4.6242e-02],\n",
      "        [ 1.2342e-02],\n",
      "        [ 9.7049e-02],\n",
      "        [-3.8530e-02],\n",
      "        [-5.2696e-02],\n",
      "        [ 4.3262e-02],\n",
      "        [ 4.7007e-02],\n",
      "        [ 5.5766e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1235, 0.1239, 0.1248, 0.1226, 0.1223, 0.1235, 0.1288, 0.1289, 0.1276,\n",
      "        0.1294, 0.1292, 0.1264, 0.1248, 0.1229, 0.1233, 0.1230, 0.1239, 0.1218,\n",
      "        0.1221, 0.1212, 0.1202, 0.1202, 0.1198, 0.1207, 0.1230, 0.1243, 0.1260,\n",
      "        0.1243, 0.1254, 0.1239, 0.1217, 0.1183], device='cuda:0')\n",
      "tensor([[-0.0287],\n",
      "        [ 0.0038],\n",
      "        [ 0.0407],\n",
      "        [ 0.0981],\n",
      "        [ 0.0036],\n",
      "        [ 0.0800],\n",
      "        [ 0.0745],\n",
      "        [ 0.0710],\n",
      "        [-0.0022],\n",
      "        [ 0.0531],\n",
      "        [-0.0384],\n",
      "        [-0.0088],\n",
      "        [ 0.0035],\n",
      "        [ 0.0590],\n",
      "        [ 0.0358],\n",
      "        [-0.0030],\n",
      "        [ 0.0316],\n",
      "        [ 0.0336],\n",
      "        [ 0.0055],\n",
      "        [ 0.0032],\n",
      "        [ 0.0045],\n",
      "        [ 0.0152],\n",
      "        [ 0.0358],\n",
      "        [ 0.0345],\n",
      "        [ 0.0146],\n",
      "        [ 0.0449],\n",
      "        [ 0.0132],\n",
      "        [ 0.1007],\n",
      "        [ 0.0516],\n",
      "        [ 0.0370],\n",
      "        [-0.0643],\n",
      "        [-0.0271]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1180, 0.1199, 0.1212, 0.1193, 0.1218, 0.1208, 0.1221, 0.1246, 0.1252,\n",
      "        0.1251, 0.1251, 0.1242, 0.1248, 0.1258, 0.1245, 0.1261, 0.1269, 0.1270,\n",
      "        0.1260, 0.1279, 0.1302, 0.1326, 0.1317, 0.1328, 0.1317, 0.1305, 0.1320,\n",
      "        0.1341, 0.1356, 0.1367, 0.1369, 0.1393], device='cuda:0')\n",
      "tensor([[ 0.0414],\n",
      "        [ 0.1316],\n",
      "        [ 0.1169],\n",
      "        [ 0.0319],\n",
      "        [ 0.0526],\n",
      "        [ 0.0229],\n",
      "        [ 0.0780],\n",
      "        [ 0.0363],\n",
      "        [ 0.1226],\n",
      "        [-0.0213],\n",
      "        [ 0.0847],\n",
      "        [ 0.0358],\n",
      "        [ 0.0826],\n",
      "        [ 0.0560],\n",
      "        [ 0.0249],\n",
      "        [ 0.0234],\n",
      "        [-0.0015],\n",
      "        [-0.0003],\n",
      "        [ 0.0101],\n",
      "        [ 0.0443],\n",
      "        [ 0.0324],\n",
      "        [-0.0273],\n",
      "        [-0.0031],\n",
      "        [ 0.0441],\n",
      "        [ 0.0526],\n",
      "        [ 0.0764],\n",
      "        [ 0.0257],\n",
      "        [ 0.0510],\n",
      "        [ 0.0560],\n",
      "        [ 0.0053],\n",
      "        [-0.0281],\n",
      "        [ 0.0079]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1378, 0.1373, 0.1385, 0.1363, 0.1363, 0.1328, 0.1348, 0.1339, 0.1307,\n",
      "        0.1322, 0.1325, 0.1319, 0.1335, 0.1319, 0.1304, 0.1304, 0.1301, 0.1270,\n",
      "        0.1251, 0.1249, 0.1251, 0.1267, 0.1286, 0.1305, 0.1313, 0.1277, 0.1280,\n",
      "        0.1264, 0.1266, 0.1286, 0.1260, 0.1235], device='cuda:0')\n",
      "tensor([[ 0.0925],\n",
      "        [ 0.0034],\n",
      "        [ 0.0245],\n",
      "        [ 0.0222],\n",
      "        [ 0.0847],\n",
      "        [ 0.0730],\n",
      "        [ 0.0388],\n",
      "        [ 0.0908],\n",
      "        [ 0.1063],\n",
      "        [ 0.0363],\n",
      "        [-0.0012],\n",
      "        [-0.0082],\n",
      "        [ 0.0727],\n",
      "        [-0.0214],\n",
      "        [-0.0038],\n",
      "        [ 0.0679],\n",
      "        [ 0.1056],\n",
      "        [ 0.0178],\n",
      "        [ 0.0265],\n",
      "        [ 0.0338],\n",
      "        [ 0.0084],\n",
      "        [-0.0312],\n",
      "        [ 0.0102],\n",
      "        [ 0.1123],\n",
      "        [ 0.0466],\n",
      "        [ 0.0720],\n",
      "        [ 0.0960],\n",
      "        [ 0.0362],\n",
      "        [ 0.0159],\n",
      "        [-0.0015],\n",
      "        [-0.0148],\n",
      "        [ 0.0377]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1236, 0.1215, 0.1243, 0.1193, 0.1211, 0.1199, 0.1208, 0.1196, 0.1215,\n",
      "        0.1212, 0.1251, 0.1271, 0.1249, 0.1235, 0.1218, 0.1235, 0.1239, 0.1245,\n",
      "        0.1267, 0.1258, 0.1267, 0.1279, 0.1274, 0.1261, 0.1248, 0.1245, 0.1270,\n",
      "        0.1274, 0.1266, 0.1263, 0.1251, 0.1251], device='cuda:0')\n",
      "tensor([[ 0.1500],\n",
      "        [ 0.0062],\n",
      "        [ 0.0275],\n",
      "        [ 0.0321],\n",
      "        [ 0.0095],\n",
      "        [-0.0157],\n",
      "        [ 0.0571],\n",
      "        [-0.0208],\n",
      "        [ 0.0059],\n",
      "        [ 0.0035],\n",
      "        [ 0.0127],\n",
      "        [ 0.0218],\n",
      "        [-0.0151],\n",
      "        [-0.0085],\n",
      "        [ 0.0283],\n",
      "        [ 0.0235],\n",
      "        [ 0.0335],\n",
      "        [ 0.0252],\n",
      "        [ 0.0007],\n",
      "        [ 0.0218],\n",
      "        [-0.0003],\n",
      "        [ 0.0130],\n",
      "        [ 0.0341],\n",
      "        [ 0.0428],\n",
      "        [-0.0316],\n",
      "        [ 0.0043],\n",
      "        [ 0.0350],\n",
      "        [ 0.0188],\n",
      "        [ 0.0185],\n",
      "        [ 0.0414],\n",
      "        [ 0.0785],\n",
      "        [-0.0123]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1239, 0.1212, 0.1230, 0.1236, 0.1230, 0.1211, 0.1189, 0.1179, 0.1186,\n",
      "        0.1170, 0.1161, 0.1164, 0.1152, 0.1155, 0.1150, 0.1158, 0.1115, 0.1091,\n",
      "        0.1112, 0.1080, 0.1094, 0.1105, 0.1094, 0.1117, 0.1102, 0.1102, 0.1103,\n",
      "        0.1099, 0.1096, 0.1097, 0.1121, 0.1140], device='cuda:0')\n",
      "tensor([[ 0.0216],\n",
      "        [-0.0295],\n",
      "        [-0.0437],\n",
      "        [ 0.0025],\n",
      "        [ 0.0819],\n",
      "        [ 0.0179],\n",
      "        [ 0.0202],\n",
      "        [ 0.0024],\n",
      "        [ 0.0274],\n",
      "        [-0.0014],\n",
      "        [ 0.0196],\n",
      "        [ 0.0814],\n",
      "        [ 0.0302],\n",
      "        [ 0.1064],\n",
      "        [ 0.0053],\n",
      "        [ 0.0386],\n",
      "        [ 0.0258],\n",
      "        [ 0.0008],\n",
      "        [ 0.1483],\n",
      "        [ 0.0541],\n",
      "        [ 0.0386],\n",
      "        [ 0.0774],\n",
      "        [ 0.0243],\n",
      "        [ 0.0543],\n",
      "        [ 0.0171],\n",
      "        [-0.0295],\n",
      "        [-0.0300],\n",
      "        [-0.0221],\n",
      "        [ 0.0267],\n",
      "        [ 0.0289],\n",
      "        [ 0.0589],\n",
      "        [-0.0075]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1106, 0.1109, 0.1124, 0.1130, 0.1118, 0.1097, 0.1078, 0.1088, 0.1083,\n",
      "        0.1109, 0.1114, 0.1118, 0.1130, 0.1150, 0.1153, 0.1162, 0.1153, 0.1139,\n",
      "        0.1133, 0.1133, 0.1152, 0.1170, 0.1150, 0.1152, 0.1130, 0.1130, 0.1118,\n",
      "        0.1091, 0.1103, 0.1102, 0.1106, 0.1093], device='cuda:0')\n",
      "tensor([[-0.0700],\n",
      "        [ 0.0069],\n",
      "        [ 0.0548],\n",
      "        [ 0.0083],\n",
      "        [-0.0169],\n",
      "        [ 0.0236],\n",
      "        [ 0.0687],\n",
      "        [ 0.0473],\n",
      "        [ 0.0566],\n",
      "        [-0.0004],\n",
      "        [ 0.0308],\n",
      "        [-0.0197],\n",
      "        [ 0.0296],\n",
      "        [ 0.0198],\n",
      "        [ 0.0096],\n",
      "        [ 0.0065],\n",
      "        [ 0.1027],\n",
      "        [ 0.0572],\n",
      "        [ 0.1453],\n",
      "        [ 0.0335],\n",
      "        [ 0.0121],\n",
      "        [ 0.0071],\n",
      "        [-0.0010],\n",
      "        [-0.0174],\n",
      "        [-0.0518],\n",
      "        [ 0.0208],\n",
      "        [ 0.0501],\n",
      "        [ 0.0035],\n",
      "        [-0.0055],\n",
      "        [-0.0159],\n",
      "        [-0.0244],\n",
      "        [-0.0290]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1136, 0.1121, 0.1139, 0.1133, 0.1119, 0.1115, 0.1105, 0.1115, 0.1128,\n",
      "        0.1145, 0.1145, 0.1150, 0.1183, 0.1180, 0.1173, 0.1139, 0.1145, 0.1156,\n",
      "        0.1140, 0.1134, 0.1121, 0.1133, 0.1142, 0.1128, 0.1112, 0.1099, 0.1090,\n",
      "        0.1081, 0.1080, 0.1068, 0.1074, 0.1066], device='cuda:0')\n",
      "tensor([[ 0.0871],\n",
      "        [ 0.0150],\n",
      "        [ 0.0801],\n",
      "        [ 0.0613],\n",
      "        [ 0.0562],\n",
      "        [ 0.0347],\n",
      "        [ 0.0293],\n",
      "        [ 0.0338],\n",
      "        [ 0.0437],\n",
      "        [ 0.0379],\n",
      "        [ 0.0771],\n",
      "        [ 0.0417],\n",
      "        [ 0.0210],\n",
      "        [-0.0597],\n",
      "        [ 0.0143],\n",
      "        [ 0.0582],\n",
      "        [ 0.0906],\n",
      "        [ 0.0198],\n",
      "        [-0.0094],\n",
      "        [ 0.0174],\n",
      "        [ 0.0390],\n",
      "        [ 0.0379],\n",
      "        [ 0.1055],\n",
      "        [ 0.1199],\n",
      "        [ 0.0341],\n",
      "        [ 0.0552],\n",
      "        [ 0.0034],\n",
      "        [ 0.0738],\n",
      "        [ 0.0777],\n",
      "        [ 0.1373],\n",
      "        [ 0.0402],\n",
      "        [ 0.0060]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1077, 0.1080, 0.1081, 0.1086, 0.1052, 0.1056, 0.1055, 0.1056, 0.1038,\n",
      "        0.1041, 0.1040, 0.0997, 0.0978, 0.1009, 0.1019, 0.1013, 0.1057, 0.1050,\n",
      "        0.1053, 0.1037, 0.1025, 0.1049, 0.1056, 0.1056, 0.1072, 0.1062, 0.1056,\n",
      "        0.1074, 0.1072, 0.1050, 0.1040, 0.1050], device='cuda:0')\n",
      "tensor([[ 0.0069],\n",
      "        [-0.0316],\n",
      "        [ 0.0043],\n",
      "        [-0.0091],\n",
      "        [-0.0098],\n",
      "        [-0.0028],\n",
      "        [ 0.0006],\n",
      "        [-0.0289],\n",
      "        [-0.0184],\n",
      "        [ 0.0362],\n",
      "        [ 0.0565],\n",
      "        [ 0.1428],\n",
      "        [ 0.0500],\n",
      "        [ 0.0065],\n",
      "        [ 0.0059],\n",
      "        [-0.0331],\n",
      "        [ 0.0274],\n",
      "        [ 0.0525],\n",
      "        [ 0.0611],\n",
      "        [ 0.0524],\n",
      "        [ 0.1703],\n",
      "        [ 0.0218],\n",
      "        [ 0.1058],\n",
      "        [ 0.0279],\n",
      "        [ 0.0154],\n",
      "        [ 0.0117],\n",
      "        [ 0.0349],\n",
      "        [ 0.0229],\n",
      "        [-0.0438],\n",
      "        [ 0.0200],\n",
      "        [-0.0350],\n",
      "        [ 0.1019]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1074, 0.1084, 0.1074, 0.1068, 0.1071, 0.1060, 0.1052, 0.1072, 0.1086,\n",
      "        0.1094, 0.1087, 0.1114, 0.1140, 0.1164, 0.1227, 0.1245, 0.1239, 0.1207,\n",
      "        0.1257, 0.1238, 0.1251, 0.1239, 0.1246, 0.1261, 0.1260, 0.1263, 0.1294,\n",
      "        0.1271, 0.1282, 0.1289, 0.1280, 0.1288], device='cuda:0')\n",
      "tensor([[ 0.1304],\n",
      "        [ 0.0527],\n",
      "        [ 0.0873],\n",
      "        [ 0.0520],\n",
      "        [-0.0363],\n",
      "        [-0.0068],\n",
      "        [ 0.0361],\n",
      "        [ 0.0215],\n",
      "        [ 0.0654],\n",
      "        [ 0.0854],\n",
      "        [ 0.0303],\n",
      "        [-0.0148],\n",
      "        [ 0.0285],\n",
      "        [ 0.0343],\n",
      "        [ 0.0263],\n",
      "        [ 0.0648],\n",
      "        [ 0.0986],\n",
      "        [ 0.1111],\n",
      "        [ 0.0989],\n",
      "        [ 0.0263],\n",
      "        [ 0.0308],\n",
      "        [ 0.0333],\n",
      "        [ 0.0533],\n",
      "        [ 0.0498],\n",
      "        [ 0.0234],\n",
      "        [-0.0168],\n",
      "        [ 0.0231],\n",
      "        [-0.0216],\n",
      "        [-0.0317],\n",
      "        [ 0.0115],\n",
      "        [ 0.1022],\n",
      "        [-0.0572]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1274, 0.1267, 0.1269, 0.1254, 0.1254, 0.1264, 0.1243, 0.1257, 0.1251,\n",
      "        0.1254, 0.1297, 0.1304, 0.1314, 0.1302, 0.1294, 0.1295, 0.1274, 0.1269,\n",
      "        0.1271, 0.1279, 0.1292, 0.1274, 0.1255, 0.1245, 0.1239, 0.1246, 0.1239,\n",
      "        0.1236, 0.1230, 0.1243, 0.1227, 0.1246], device='cuda:0')\n",
      "tensor([[-0.0217],\n",
      "        [ 0.0250],\n",
      "        [ 0.0825],\n",
      "        [ 0.0218],\n",
      "        [ 0.0033],\n",
      "        [-0.0128],\n",
      "        [ 0.0034],\n",
      "        [ 0.0169],\n",
      "        [ 0.0468],\n",
      "        [-0.0084],\n",
      "        [ 0.0239],\n",
      "        [ 0.0711],\n",
      "        [ 0.0324],\n",
      "        [-0.0484],\n",
      "        [ 0.0388],\n",
      "        [ 0.0041],\n",
      "        [ 0.0061],\n",
      "        [ 0.0567],\n",
      "        [ 0.0480],\n",
      "        [ 0.0209],\n",
      "        [ 0.0347],\n",
      "        [ 0.0593],\n",
      "        [ 0.0665],\n",
      "        [ 0.0032],\n",
      "        [ 0.0144],\n",
      "        [ 0.1032],\n",
      "        [ 0.0467],\n",
      "        [ 0.0290],\n",
      "        [-0.0268],\n",
      "        [ 0.0907],\n",
      "        [-0.0208],\n",
      "        [ 0.0386]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1254, 0.1239, 0.1246, 0.1295, 0.1285, 0.1292, 0.1302, 0.1304, 0.1283,\n",
      "        0.1273, 0.1282, 0.1304, 0.1279, 0.1295, 0.1294, 0.1304, 0.1313, 0.1292,\n",
      "        0.1292, 0.1263, 0.1271, 0.1257, 0.1261, 0.1257, 0.1242, 0.1224, 0.1239,\n",
      "        0.1236, 0.1255, 0.1255, 0.1280, 0.1261], device='cuda:0')\n",
      "tensor([[ 5.6634e-02],\n",
      "        [ 1.5331e-02],\n",
      "        [ 2.9128e-02],\n",
      "        [ 1.4031e-02],\n",
      "        [ 1.7557e-02],\n",
      "        [ 1.5954e-02],\n",
      "        [-1.3991e-02],\n",
      "        [ 5.2356e-02],\n",
      "        [ 9.3568e-02],\n",
      "        [-2.2229e-02],\n",
      "        [ 6.8841e-02],\n",
      "        [-4.8775e-02],\n",
      "        [ 5.9162e-03],\n",
      "        [ 4.6340e-03],\n",
      "        [ 2.0588e-02],\n",
      "        [-8.7104e-03],\n",
      "        [ 1.2544e-02],\n",
      "        [ 1.1489e-02],\n",
      "        [ 6.9398e-02],\n",
      "        [ 3.7259e-02],\n",
      "        [ 3.0660e-02],\n",
      "        [ 6.7815e-02],\n",
      "        [ 9.4969e-02],\n",
      "        [ 2.1436e-02],\n",
      "        [ 2.2611e-02],\n",
      "        [-2.2555e-02],\n",
      "        [ 2.2748e-03],\n",
      "        [ 3.5744e-02],\n",
      "        [ 5.4568e-02],\n",
      "        [ 5.1226e-05],\n",
      "        [ 1.4263e-02],\n",
      "        [ 4.3659e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1248, 0.1245, 0.1224, 0.1227, 0.1199, 0.1207, 0.1190, 0.1199, 0.1214,\n",
      "        0.1209, 0.1198, 0.1209, 0.1212, 0.1261, 0.1260, 0.1252, 0.1269, 0.1274,\n",
      "        0.1269, 0.1261, 0.1266, 0.1261, 0.1236, 0.1224, 0.1221, 0.1229, 0.1221,\n",
      "        0.1229, 0.1269, 0.1257, 0.1280, 0.1279], device='cuda:0')\n",
      "tensor([[ 0.0412],\n",
      "        [-0.0186],\n",
      "        [-0.0073],\n",
      "        [ 0.0586],\n",
      "        [-0.0421],\n",
      "        [ 0.0045],\n",
      "        [ 0.0390],\n",
      "        [-0.0101],\n",
      "        [ 0.0077],\n",
      "        [ 0.0795],\n",
      "        [ 0.0529],\n",
      "        [ 0.1311],\n",
      "        [ 0.0046],\n",
      "        [ 0.1401],\n",
      "        [ 0.0823],\n",
      "        [ 0.0394],\n",
      "        [ 0.0912],\n",
      "        [ 0.0320],\n",
      "        [ 0.0085],\n",
      "        [ 0.0328],\n",
      "        [ 0.0250],\n",
      "        [ 0.0021],\n",
      "        [ 0.0018],\n",
      "        [ 0.0572],\n",
      "        [ 0.1204],\n",
      "        [ 0.0076],\n",
      "        [ 0.0091],\n",
      "        [ 0.0250],\n",
      "        [ 0.0128],\n",
      "        [-0.0195],\n",
      "        [ 0.0353],\n",
      "        [-0.0345]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1270, 0.1267, 0.1273, 0.1322, 0.1338, 0.1372, 0.1379, 0.1381, 0.1397,\n",
      "        0.1425, 0.1421, 0.1418, 0.1409, 0.1432, 0.1419, 0.1406, 0.1426, 0.1428,\n",
      "        0.1384, 0.1363, 0.1387, 0.1366, 0.1359, 0.1364, 0.1387, 0.1387, 0.1376,\n",
      "        0.1388, 0.1395, 0.1379, 0.1390, 0.1412], device='cuda:0')\n",
      "tensor([[ 0.0367],\n",
      "        [ 0.0083],\n",
      "        [ 0.0317],\n",
      "        [ 0.0489],\n",
      "        [-0.0014],\n",
      "        [ 0.0947],\n",
      "        [ 0.0447],\n",
      "        [ 0.0129],\n",
      "        [ 0.0096],\n",
      "        [ 0.0089],\n",
      "        [ 0.0730],\n",
      "        [-0.0364],\n",
      "        [-0.0067],\n",
      "        [-0.0102],\n",
      "        [ 0.0190],\n",
      "        [ 0.0403],\n",
      "        [ 0.0253],\n",
      "        [ 0.0092],\n",
      "        [ 0.0586],\n",
      "        [-0.0118],\n",
      "        [ 0.0727],\n",
      "        [ 0.1022],\n",
      "        [-0.0006],\n",
      "        [-0.0021],\n",
      "        [-0.0016],\n",
      "        [ 0.0360],\n",
      "        [-0.0151],\n",
      "        [ 0.0154],\n",
      "        [ 0.0221],\n",
      "        [ 0.0294],\n",
      "        [ 0.0395],\n",
      "        [-0.0037]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1401, 0.1401, 0.1376, 0.1344, 0.1338, 0.1360, 0.1364, 0.1342, 0.1329,\n",
      "        0.1326, 0.1323, 0.1348, 0.1335, 0.1328, 0.1316, 0.1277, 0.1288, 0.1300,\n",
      "        0.1302, 0.1307, 0.1320, 0.1316, 0.1301, 0.1307, 0.1270, 0.1279, 0.1294,\n",
      "        0.1307, 0.1319, 0.1333, 0.1339, 0.1338], device='cuda:0')\n",
      "tensor([[ 0.0069],\n",
      "        [ 0.0172],\n",
      "        [ 0.0459],\n",
      "        [ 0.0551],\n",
      "        [ 0.0364],\n",
      "        [ 0.0209],\n",
      "        [ 0.0632],\n",
      "        [ 0.0992],\n",
      "        [ 0.0129],\n",
      "        [ 0.0256],\n",
      "        [ 0.0247],\n",
      "        [-0.0086],\n",
      "        [ 0.0829],\n",
      "        [-0.0286],\n",
      "        [ 0.0371],\n",
      "        [-0.0208],\n",
      "        [ 0.1466],\n",
      "        [-0.0295],\n",
      "        [ 0.0681],\n",
      "        [-0.0214],\n",
      "        [ 0.0148],\n",
      "        [ 0.0656],\n",
      "        [ 0.0580],\n",
      "        [ 0.0281],\n",
      "        [ 0.0130],\n",
      "        [ 0.0160],\n",
      "        [-0.0042],\n",
      "        [ 0.1316],\n",
      "        [ 0.0002],\n",
      "        [ 0.0458],\n",
      "        [ 0.0204],\n",
      "        [ 0.0042]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1313, 0.1314, 0.1316, 0.1331, 0.1326, 0.1329, 0.1308, 0.1298, 0.1301,\n",
      "        0.1291, 0.1288, 0.1283, 0.1280, 0.1292, 0.1308, 0.1317, 0.1344, 0.1345,\n",
      "        0.1319, 0.1325, 0.1331, 0.1351, 0.1378, 0.1378, 0.1373, 0.1359, 0.1353,\n",
      "        0.1347, 0.1339, 0.1319, 0.1326, 0.1332], device='cuda:0')\n",
      "tensor([[ 3.6764e-02],\n",
      "        [-2.0643e-02],\n",
      "        [ 1.4684e-02],\n",
      "        [ 5.1819e-02],\n",
      "        [ 2.7444e-02],\n",
      "        [ 4.3568e-02],\n",
      "        [ 5.4516e-02],\n",
      "        [ 2.7083e-02],\n",
      "        [-1.7052e-02],\n",
      "        [ 1.0286e-04],\n",
      "        [ 2.2108e-02],\n",
      "        [ 6.2093e-02],\n",
      "        [-3.6734e-02],\n",
      "        [ 1.0866e-02],\n",
      "        [ 1.0156e-02],\n",
      "        [ 5.2879e-02],\n",
      "        [ 1.9127e-02],\n",
      "        [-1.8745e-02],\n",
      "        [-3.5272e-02],\n",
      "        [ 3.7681e-03],\n",
      "        [ 1.1730e-01],\n",
      "        [ 4.0682e-02],\n",
      "        [ 5.8330e-02],\n",
      "        [-5.6935e-02],\n",
      "        [ 1.2349e-01],\n",
      "        [ 7.6568e-02],\n",
      "        [ 2.8161e-03],\n",
      "        [-1.8546e-02],\n",
      "        [ 1.2096e-02],\n",
      "        [ 4.5346e-02],\n",
      "        [ 1.3706e-02],\n",
      "        [-1.1772e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1339, 0.1325, 0.1339, 0.1311, 0.1314, 0.1295, 0.1233, 0.1208, 0.1238,\n",
      "        0.1226, 0.1223, 0.1217, 0.1209, 0.1217, 0.1235, 0.1248, 0.1261, 0.1271,\n",
      "        0.1269, 0.1282, 0.1276, 0.1269, 0.1277, 0.1266, 0.1239, 0.1260, 0.1269,\n",
      "        0.1274, 0.1289, 0.1325, 0.1335, 0.1328], device='cuda:0')\n",
      "tensor([[ 0.0107],\n",
      "        [ 0.0291],\n",
      "        [ 0.0122],\n",
      "        [ 0.1181],\n",
      "        [ 0.0369],\n",
      "        [ 0.0687],\n",
      "        [ 0.0334],\n",
      "        [ 0.0613],\n",
      "        [ 0.0820],\n",
      "        [ 0.0401],\n",
      "        [ 0.0052],\n",
      "        [-0.0082],\n",
      "        [ 0.0425],\n",
      "        [ 0.0792],\n",
      "        [ 0.0781],\n",
      "        [ 0.0025],\n",
      "        [-0.0056],\n",
      "        [ 0.0613],\n",
      "        [ 0.0140],\n",
      "        [-0.0176],\n",
      "        [ 0.0649],\n",
      "        [ 0.1175],\n",
      "        [-0.0167],\n",
      "        [ 0.0796],\n",
      "        [ 0.0404],\n",
      "        [-0.0435],\n",
      "        [-0.0360],\n",
      "        [-0.0198],\n",
      "        [ 0.0030],\n",
      "        [ 0.0177],\n",
      "        [-0.0159],\n",
      "        [ 0.0367]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1333, 0.1341, 0.1335, 0.1332, 0.1345, 0.1366, 0.1338, 0.1348, 0.1359,\n",
      "        0.1372, 0.1362, 0.1357, 0.1335, 0.1333, 0.1323, 0.1311, 0.1308, 0.1302,\n",
      "        0.1304, 0.1300, 0.1292, 0.1294, 0.1313, 0.1323, 0.1302, 0.1305, 0.1322,\n",
      "        0.1322, 0.1319, 0.1313, 0.1302, 0.1308], device='cuda:0')\n",
      "tensor([[-0.0013],\n",
      "        [-0.0245],\n",
      "        [-0.0314],\n",
      "        [ 0.0007],\n",
      "        [ 0.0330],\n",
      "        [ 0.0500],\n",
      "        [ 0.0097],\n",
      "        [ 0.1225],\n",
      "        [ 0.0607],\n",
      "        [ 0.0034],\n",
      "        [-0.0190],\n",
      "        [ 0.0451],\n",
      "        [ 0.0345],\n",
      "        [ 0.0315],\n",
      "        [ 0.0247],\n",
      "        [ 0.1250],\n",
      "        [ 0.0410],\n",
      "        [ 0.0266],\n",
      "        [ 0.0049],\n",
      "        [-0.0203],\n",
      "        [ 0.0603],\n",
      "        [ 0.0034],\n",
      "        [ 0.0974],\n",
      "        [-0.0151],\n",
      "        [ 0.0508],\n",
      "        [ 0.0172],\n",
      "        [ 0.0086],\n",
      "        [ 0.0392],\n",
      "        [ 0.0327],\n",
      "        [ 0.0142],\n",
      "        [-0.0192],\n",
      "        [ 0.0853]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1310, 0.1323, 0.1332, 0.1335, 0.1317, 0.1310, 0.1308, 0.1313, 0.1323,\n",
      "        0.1304, 0.1313, 0.1319, 0.1304, 0.1320, 0.1304, 0.1271, 0.1269, 0.1270,\n",
      "        0.1302, 0.1276, 0.1276, 0.1266, 0.1274, 0.1276, 0.1274, 0.1276, 0.1291,\n",
      "        0.1319, 0.1319, 0.1335, 0.1325, 0.1314], device='cuda:0')\n",
      "tensor([[ 0.0634],\n",
      "        [-0.0294],\n",
      "        [ 0.0702],\n",
      "        [ 0.0543],\n",
      "        [ 0.0342],\n",
      "        [-0.0148],\n",
      "        [ 0.0214],\n",
      "        [ 0.0415],\n",
      "        [-0.0312],\n",
      "        [-0.0022],\n",
      "        [ 0.0321],\n",
      "        [ 0.0144],\n",
      "        [ 0.0357],\n",
      "        [-0.0041],\n",
      "        [ 0.0128],\n",
      "        [ 0.0598],\n",
      "        [ 0.0477],\n",
      "        [ 0.0669],\n",
      "        [-0.0093],\n",
      "        [ 0.0295],\n",
      "        [ 0.0455],\n",
      "        [ 0.0723],\n",
      "        [ 0.0162],\n",
      "        [ 0.0619],\n",
      "        [ 0.1408],\n",
      "        [ 0.0172],\n",
      "        [ 0.0567],\n",
      "        [ 0.0095],\n",
      "        [ 0.1592],\n",
      "        [-0.0249],\n",
      "        [-0.0079],\n",
      "        [ 0.0229]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1313, 0.1332, 0.1348, 0.1326, 0.1319, 0.1335, 0.1348, 0.1356, 0.1341,\n",
      "        0.1353, 0.1369, 0.1382, 0.1376, 0.1367, 0.1372, 0.1397, 0.1406, 0.1401,\n",
      "        0.1421, 0.1422, 0.1443, 0.1440, 0.1449, 0.1463, 0.1455, 0.1449, 0.1449,\n",
      "        0.1463, 0.1457, 0.1435, 0.1444, 0.1483], device='cuda:0')\n",
      "tensor([[-0.0015],\n",
      "        [-0.0096],\n",
      "        [ 0.0532],\n",
      "        [ 0.0421],\n",
      "        [ 0.0052],\n",
      "        [-0.0124],\n",
      "        [ 0.0062],\n",
      "        [ 0.0168],\n",
      "        [ 0.0009],\n",
      "        [ 0.0994],\n",
      "        [ 0.0484],\n",
      "        [ 0.0750],\n",
      "        [ 0.0884],\n",
      "        [ 0.0128],\n",
      "        [ 0.0979],\n",
      "        [ 0.0669],\n",
      "        [ 0.0009],\n",
      "        [-0.0182],\n",
      "        [ 0.0259],\n",
      "        [ 0.0048],\n",
      "        [ 0.0043],\n",
      "        [ 0.0473],\n",
      "        [ 0.0080],\n",
      "        [ 0.0729],\n",
      "        [ 0.0332],\n",
      "        [ 0.0094],\n",
      "        [ 0.0236],\n",
      "        [-0.0266],\n",
      "        [-0.0227],\n",
      "        [ 0.0840],\n",
      "        [ 0.0780],\n",
      "        [ 0.0979]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1469, 0.1481, 0.1515, 0.1539, 0.1567, 0.1562, 0.1581, 0.1605, 0.1608,\n",
      "        0.1612, 0.1623, 0.1629, 0.1626, 0.1611, 0.1617, 0.1642, 0.1676, 0.1643,\n",
      "        0.1602, 0.1630, 0.1630, 0.1645, 0.1565, 0.1583, 0.1561, 0.1567, 0.1570,\n",
      "        0.1609, 0.1649, 0.1589, 0.1571, 0.1573], device='cuda:0')\n",
      "tensor([[ 0.0017],\n",
      "        [ 0.0610],\n",
      "        [ 0.0383],\n",
      "        [-0.0033],\n",
      "        [ 0.0162],\n",
      "        [-0.0982],\n",
      "        [-0.0367],\n",
      "        [-0.0205],\n",
      "        [ 0.0587],\n",
      "        [-0.0265],\n",
      "        [ 0.0409],\n",
      "        [-0.0337],\n",
      "        [-0.0129],\n",
      "        [ 0.0416],\n",
      "        [ 0.0683],\n",
      "        [ 0.0343],\n",
      "        [ 0.0166],\n",
      "        [-0.0334],\n",
      "        [-0.0115],\n",
      "        [-0.0230],\n",
      "        [ 0.0460],\n",
      "        [ 0.0118],\n",
      "        [-0.0111],\n",
      "        [ 0.0886],\n",
      "        [ 0.0265],\n",
      "        [ 0.0084],\n",
      "        [ 0.0796],\n",
      "        [ 0.0192],\n",
      "        [ 0.0717],\n",
      "        [ 0.0320],\n",
      "        [ 0.0127],\n",
      "        [ 0.1326]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1511, 0.1555, 0.1578, 0.1574, 0.1599, 0.1590, 0.1573, 0.1596, 0.1633,\n",
      "        0.1626, 0.1636, 0.1638, 0.1646, 0.1664, 0.1658, 0.1638, 0.1645, 0.1652,\n",
      "        0.1683, 0.1667, 0.1686, 0.1694, 0.1683, 0.1667, 0.1676, 0.1648, 0.1589,\n",
      "        0.1593, 0.1576, 0.1559, 0.1540, 0.1531], device='cuda:0')\n",
      "tensor([[ 1.2282e-01],\n",
      "        [ 8.5462e-05],\n",
      "        [-3.2670e-02],\n",
      "        [ 1.2952e-01],\n",
      "        [-3.4687e-02],\n",
      "        [-1.4876e-02],\n",
      "        [-3.1575e-02],\n",
      "        [ 6.5356e-03],\n",
      "        [ 2.1863e-02],\n",
      "        [ 7.9067e-02],\n",
      "        [ 3.2292e-02],\n",
      "        [-2.6057e-02],\n",
      "        [ 3.3919e-02],\n",
      "        [ 2.7265e-03],\n",
      "        [ 4.4610e-02],\n",
      "        [-1.4661e-02],\n",
      "        [ 2.4457e-03],\n",
      "        [ 4.0110e-02],\n",
      "        [ 2.5067e-02],\n",
      "        [-1.1636e-03],\n",
      "        [ 2.5675e-02],\n",
      "        [ 5.8498e-02],\n",
      "        [ 3.8802e-02],\n",
      "        [-3.3173e-02],\n",
      "        [ 2.2742e-02],\n",
      "        [ 1.0137e-01],\n",
      "        [ 8.7343e-03],\n",
      "        [ 2.3856e-02],\n",
      "        [ 3.0511e-02],\n",
      "        [ 3.6577e-02],\n",
      "        [ 3.9584e-02],\n",
      "        [ 1.2150e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1561, 0.1602, 0.1567, 0.1584, 0.1583, 0.1589, 0.1607, 0.1598, 0.1580,\n",
      "        0.1567, 0.1565, 0.1555, 0.1550, 0.1568, 0.1596, 0.1568, 0.1590, 0.1574,\n",
      "        0.1558, 0.1573, 0.1602, 0.1570, 0.1581, 0.1576, 0.1607, 0.1609, 0.1635,\n",
      "        0.1633, 0.1609, 0.1636, 0.1614, 0.1640], device='cuda:0')\n",
      "tensor([[ 0.0387],\n",
      "        [ 0.0303],\n",
      "        [ 0.0381],\n",
      "        [ 0.0073],\n",
      "        [ 0.0266],\n",
      "        [ 0.1019],\n",
      "        [ 0.0307],\n",
      "        [ 0.0629],\n",
      "        [ 0.1077],\n",
      "        [-0.0246],\n",
      "        [ 0.0079],\n",
      "        [ 0.0041],\n",
      "        [ 0.0677],\n",
      "        [ 0.0237],\n",
      "        [ 0.0623],\n",
      "        [-0.0784],\n",
      "        [-0.0031],\n",
      "        [ 0.0175],\n",
      "        [-0.0430],\n",
      "        [ 0.0190],\n",
      "        [ 0.1099],\n",
      "        [ 0.0360],\n",
      "        [ 0.0068],\n",
      "        [-0.0013],\n",
      "        [ 0.0446],\n",
      "        [-0.0061],\n",
      "        [ 0.0150],\n",
      "        [-0.0289],\n",
      "        [ 0.1049],\n",
      "        [ 0.0806],\n",
      "        [ 0.0993],\n",
      "        [ 0.0766]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1669, 0.1691, 0.1713, 0.1689, 0.1652, 0.1660, 0.1627, 0.1645, 0.1629,\n",
      "        0.1593, 0.1567, 0.1576, 0.1578, 0.1565, 0.1556, 0.1524, 0.1518, 0.1509,\n",
      "        0.1534, 0.1514, 0.1500, 0.1506, 0.1543, 0.1595, 0.1612, 0.1607, 0.1605,\n",
      "        0.1611, 0.1578, 0.1587, 0.1577, 0.1540], device='cuda:0')\n",
      "tensor([[ 0.1560],\n",
      "        [-0.0200],\n",
      "        [-0.0112],\n",
      "        [ 0.0114],\n",
      "        [ 0.0242],\n",
      "        [ 0.0221],\n",
      "        [ 0.0302],\n",
      "        [-0.0484],\n",
      "        [ 0.0050],\n",
      "        [ 0.0078],\n",
      "        [-0.0309],\n",
      "        [ 0.0532],\n",
      "        [ 0.0044],\n",
      "        [ 0.0450],\n",
      "        [-0.0199],\n",
      "        [ 0.0369],\n",
      "        [ 0.0280],\n",
      "        [ 0.0360],\n",
      "        [ 0.0229],\n",
      "        [ 0.0232],\n",
      "        [ 0.0644],\n",
      "        [ 0.0972],\n",
      "        [ 0.0769],\n",
      "        [-0.0047],\n",
      "        [ 0.0093],\n",
      "        [ 0.0324],\n",
      "        [ 0.0611],\n",
      "        [-0.0086],\n",
      "        [ 0.0450],\n",
      "        [ 0.0528],\n",
      "        [ 0.0727],\n",
      "        [-0.0455]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1559, 0.1568, 0.1555, 0.1574, 0.1561, 0.1542, 0.1536, 0.1519, 0.1549,\n",
      "        0.1521, 0.1537, 0.1549, 0.1540, 0.1543, 0.1537, 0.1562, 0.1573, 0.1567,\n",
      "        0.1522, 0.1515, 0.1511, 0.1528, 0.1497, 0.1452, 0.1410, 0.1379, 0.1366,\n",
      "        0.1363, 0.1364, 0.1385, 0.1379, 0.1379], device='cuda:0')\n",
      "tensor([[-0.0252],\n",
      "        [-0.0176],\n",
      "        [ 0.0127],\n",
      "        [-0.0511],\n",
      "        [ 0.0260],\n",
      "        [-0.0012],\n",
      "        [-0.0118],\n",
      "        [ 0.0577],\n",
      "        [-0.0080],\n",
      "        [-0.0277],\n",
      "        [-0.0393],\n",
      "        [-0.0123],\n",
      "        [ 0.0287],\n",
      "        [ 0.0351],\n",
      "        [ 0.0133],\n",
      "        [-0.0210],\n",
      "        [ 0.0604],\n",
      "        [ 0.0273],\n",
      "        [ 0.0234],\n",
      "        [ 0.0130],\n",
      "        [ 0.0011],\n",
      "        [ 0.0440],\n",
      "        [ 0.1431],\n",
      "        [ 0.1666],\n",
      "        [-0.0113],\n",
      "        [ 0.0556],\n",
      "        [ 0.0258],\n",
      "        [-0.0369],\n",
      "        [ 0.0300],\n",
      "        [-0.0075],\n",
      "        [-0.0456],\n",
      "        [ 0.0242]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1391, 0.1370, 0.1357, 0.1369, 0.1372, 0.1359, 0.1362, 0.1353, 0.1356,\n",
      "        0.1354, 0.1342, 0.1354, 0.1372, 0.1390, 0.1393, 0.1379, 0.1406, 0.1422,\n",
      "        0.1452, 0.1437, 0.1437, 0.1449, 0.1474, 0.1474, 0.1460, 0.1446, 0.1413,\n",
      "        0.1415, 0.1453, 0.1465, 0.1505, 0.1506], device='cuda:0')\n",
      "tensor([[ 0.0196],\n",
      "        [ 0.0306],\n",
      "        [ 0.0576],\n",
      "        [ 0.0380],\n",
      "        [ 0.1862],\n",
      "        [ 0.1270],\n",
      "        [ 0.0341],\n",
      "        [-0.0257],\n",
      "        [ 0.0870],\n",
      "        [ 0.0321],\n",
      "        [ 0.0581],\n",
      "        [ 0.0142],\n",
      "        [-0.0031],\n",
      "        [-0.0266],\n",
      "        [-0.0014],\n",
      "        [ 0.0140],\n",
      "        [ 0.0382],\n",
      "        [-0.0030],\n",
      "        [ 0.0986],\n",
      "        [ 0.0112],\n",
      "        [-0.0375],\n",
      "        [-0.0036],\n",
      "        [-0.0074],\n",
      "        [-0.0297],\n",
      "        [ 0.0311],\n",
      "        [ 0.0075],\n",
      "        [ 0.0679],\n",
      "        [ 0.0157],\n",
      "        [ 0.0993],\n",
      "        [ 0.0676],\n",
      "        [ 0.0444],\n",
      "        [-0.0451]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1509, 0.1452, 0.1429, 0.1425, 0.1440, 0.1432, 0.1441, 0.1424, 0.1444,\n",
      "        0.1452, 0.1431, 0.1410, 0.1407, 0.1393, 0.1395, 0.1378, 0.1378, 0.1353,\n",
      "        0.1384, 0.1320, 0.1313, 0.1248, 0.1267, 0.1248, 0.1235, 0.1260, 0.1238,\n",
      "        0.1246, 0.1227, 0.1240, 0.1229, 0.1242], device='cuda:0')\n",
      "tensor([[ 0.0618],\n",
      "        [ 0.0575],\n",
      "        [ 0.0592],\n",
      "        [-0.0355],\n",
      "        [ 0.0127],\n",
      "        [-0.0140],\n",
      "        [-0.0094],\n",
      "        [ 0.0219],\n",
      "        [-0.0284],\n",
      "        [ 0.0176],\n",
      "        [-0.0055],\n",
      "        [ 0.0232],\n",
      "        [-0.0512],\n",
      "        [ 0.1106],\n",
      "        [ 0.1075],\n",
      "        [ 0.0392],\n",
      "        [-0.0191],\n",
      "        [-0.0439],\n",
      "        [ 0.0124],\n",
      "        [-0.0114],\n",
      "        [-0.0157],\n",
      "        [ 0.0064],\n",
      "        [ 0.0866],\n",
      "        [-0.0054],\n",
      "        [ 0.0545],\n",
      "        [-0.0070],\n",
      "        [ 0.0005],\n",
      "        [ 0.1074],\n",
      "        [ 0.0158],\n",
      "        [ 0.0164],\n",
      "        [ 0.1043],\n",
      "        [ 0.0330]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1240, 0.1249, 0.1233, 0.1235, 0.1248, 0.1267, 0.1300, 0.1294, 0.1261,\n",
      "        0.1240, 0.1242, 0.1261, 0.1269, 0.1257, 0.1223, 0.1240, 0.1248, 0.1230,\n",
      "        0.1260, 0.1266, 0.1263, 0.1279, 0.1308, 0.1295, 0.1308, 0.1311, 0.1341,\n",
      "        0.1326, 0.1316, 0.1302, 0.1316, 0.1305], device='cuda:0')\n",
      "tensor([[ 0.0564],\n",
      "        [ 0.0248],\n",
      "        [-0.0009],\n",
      "        [ 0.0698],\n",
      "        [ 0.0407],\n",
      "        [ 0.0142],\n",
      "        [ 0.0911],\n",
      "        [ 0.0105],\n",
      "        [-0.0009],\n",
      "        [ 0.0195],\n",
      "        [-0.0167],\n",
      "        [ 0.0109],\n",
      "        [ 0.0061],\n",
      "        [ 0.0596],\n",
      "        [ 0.1474],\n",
      "        [ 0.0030],\n",
      "        [-0.0523],\n",
      "        [-0.0693],\n",
      "        [ 0.0340],\n",
      "        [ 0.0065],\n",
      "        [ 0.0337],\n",
      "        [-0.0051],\n",
      "        [ 0.0352],\n",
      "        [ 0.0125],\n",
      "        [ 0.0308],\n",
      "        [ 0.0353],\n",
      "        [-0.0221],\n",
      "        [ 0.0095],\n",
      "        [ 0.0343],\n",
      "        [ 0.0410],\n",
      "        [ 0.0436],\n",
      "        [ 0.1747]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1319, 0.1319, 0.1301, 0.1314, 0.1320, 0.1304, 0.1288, 0.1285, 0.1261,\n",
      "        0.1230, 0.1248, 0.1248, 0.1232, 0.1235, 0.1224, 0.1248, 0.1267, 0.1260,\n",
      "        0.1266, 0.1258, 0.1251, 0.1229, 0.1183, 0.1208, 0.1224, 0.1224, 0.1286,\n",
      "        0.1257, 0.1257, 0.1311, 0.1298, 0.1310], device='cuda:0')\n",
      "tensor([[ 0.0407],\n",
      "        [ 0.0493],\n",
      "        [ 0.0195],\n",
      "        [ 0.0856],\n",
      "        [ 0.0222],\n",
      "        [ 0.0091],\n",
      "        [-0.0246],\n",
      "        [ 0.0203],\n",
      "        [-0.0173],\n",
      "        [ 0.0421],\n",
      "        [ 0.0870],\n",
      "        [ 0.0817],\n",
      "        [ 0.1139],\n",
      "        [ 0.0240],\n",
      "        [ 0.0284],\n",
      "        [ 0.1039],\n",
      "        [ 0.0857],\n",
      "        [ 0.0239],\n",
      "        [-0.0216],\n",
      "        [ 0.0361],\n",
      "        [ 0.0120],\n",
      "        [-0.0079],\n",
      "        [ 0.0170],\n",
      "        [ 0.1404],\n",
      "        [ 0.0258],\n",
      "        [ 0.0059],\n",
      "        [ 0.0191],\n",
      "        [ 0.1206],\n",
      "        [ 0.0450],\n",
      "        [-0.0235],\n",
      "        [ 0.0451],\n",
      "        [-0.0233]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1335, 0.1342, 0.1326, 0.1328, 0.1369, 0.1378, 0.1403, 0.1424, 0.1410,\n",
      "        0.1387, 0.1382, 0.1390, 0.1373, 0.1395, 0.1441, 0.1437, 0.1450, 0.1456,\n",
      "        0.1500, 0.1496, 0.1481, 0.1453, 0.1455, 0.1443, 0.1438, 0.1459, 0.1465,\n",
      "        0.1453, 0.1447, 0.1494, 0.1481, 0.1511], device='cuda:0')\n",
      "tensor([[-0.0276],\n",
      "        [-0.0266],\n",
      "        [ 0.0450],\n",
      "        [ 0.0132],\n",
      "        [ 0.0496],\n",
      "        [ 0.0189],\n",
      "        [ 0.0320],\n",
      "        [ 0.0319],\n",
      "        [ 0.0439],\n",
      "        [-0.0342],\n",
      "        [ 0.0186],\n",
      "        [ 0.0629],\n",
      "        [ 0.0566],\n",
      "        [-0.0016],\n",
      "        [ 0.0498],\n",
      "        [ 0.0361],\n",
      "        [ 0.0081],\n",
      "        [-0.0288],\n",
      "        [-0.0291],\n",
      "        [ 0.0313],\n",
      "        [ 0.0008],\n",
      "        [ 0.0001],\n",
      "        [ 0.0234],\n",
      "        [ 0.0969],\n",
      "        [ 0.0599],\n",
      "        [-0.0797],\n",
      "        [ 0.0203],\n",
      "        [ 0.0718],\n",
      "        [ 0.0191],\n",
      "        [ 0.0918],\n",
      "        [ 0.0343],\n",
      "        [ 0.0075]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1518, 0.1515, 0.1545, 0.1534, 0.1543, 0.1562, 0.1576, 0.1612, 0.1645,\n",
      "        0.1626, 0.1587, 0.1607, 0.1580, 0.1592, 0.1555, 0.1573, 0.1571, 0.1537,\n",
      "        0.1546, 0.1508, 0.1519, 0.1550, 0.1556, 0.1589, 0.1578, 0.1578, 0.1661,\n",
      "        0.1629, 0.1629, 0.1599, 0.1629, 0.1640], device='cuda:0')\n",
      "tensor([[ 0.0900],\n",
      "        [ 0.0418],\n",
      "        [ 0.0068],\n",
      "        [ 0.0330],\n",
      "        [ 0.0342],\n",
      "        [ 0.1127],\n",
      "        [ 0.1132],\n",
      "        [ 0.0547],\n",
      "        [ 0.0575],\n",
      "        [ 0.0553],\n",
      "        [ 0.1476],\n",
      "        [ 0.0850],\n",
      "        [ 0.0309],\n",
      "        [ 0.0431],\n",
      "        [-0.0222],\n",
      "        [-0.0119],\n",
      "        [ 0.0226],\n",
      "        [ 0.0546],\n",
      "        [ 0.0921],\n",
      "        [ 0.0068],\n",
      "        [ 0.0242],\n",
      "        [-0.0137],\n",
      "        [-0.0206],\n",
      "        [ 0.0294],\n",
      "        [ 0.0454],\n",
      "        [-0.0119],\n",
      "        [ 0.0136],\n",
      "        [-0.0095],\n",
      "        [-0.0287],\n",
      "        [-0.0126],\n",
      "        [-0.0205],\n",
      "        [-0.0452]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1680, 0.1698, 0.1704, 0.1732, 0.1778, 0.1776, 0.1754, 0.1741, 0.1732,\n",
      "        0.1760, 0.1770, 0.1757, 0.1704, 0.1708, 0.1658, 0.1657, 0.1664, 0.1657,\n",
      "        0.1704, 0.1708, 0.1728, 0.1697, 0.1692, 0.1664, 0.1700, 0.1713, 0.1697,\n",
      "        0.1711, 0.1695, 0.1670, 0.1669, 0.1657], device='cuda:0')\n",
      "tensor([[-0.0337],\n",
      "        [-0.0020],\n",
      "        [ 0.0249],\n",
      "        [ 0.0967],\n",
      "        [ 0.1241],\n",
      "        [ 0.0045],\n",
      "        [ 0.0105],\n",
      "        [ 0.0416],\n",
      "        [ 0.0211],\n",
      "        [ 0.0225],\n",
      "        [ 0.0141],\n",
      "        [ 0.0071],\n",
      "        [ 0.1300],\n",
      "        [ 0.0905],\n",
      "        [ 0.0203],\n",
      "        [ 0.0476],\n",
      "        [ 0.0226],\n",
      "        [ 0.0080],\n",
      "        [ 0.0047],\n",
      "        [ 0.0308],\n",
      "        [-0.0133],\n",
      "        [ 0.0334],\n",
      "        [-0.0102],\n",
      "        [ 0.0295],\n",
      "        [ 0.0860],\n",
      "        [ 0.0840],\n",
      "        [ 0.0860],\n",
      "        [-0.0128],\n",
      "        [ 0.0509],\n",
      "        [ 0.0187],\n",
      "        [ 0.1326],\n",
      "        [ 0.0806]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1692, 0.1720, 0.1713, 0.1707, 0.1713, 0.1735, 0.1754, 0.1769, 0.1790,\n",
      "        0.1773, 0.1760, 0.1726, 0.1744, 0.1747, 0.1757, 0.1742, 0.1776, 0.1770,\n",
      "        0.1779, 0.1813, 0.1785, 0.1791, 0.1793, 0.1779, 0.1751, 0.1729, 0.1713,\n",
      "        0.1698, 0.1711, 0.1722, 0.1711, 0.1714], device='cuda:0')\n",
      "tensor([[-0.0053],\n",
      "        [-0.0247],\n",
      "        [-0.0232],\n",
      "        [-0.0102],\n",
      "        [-0.0101],\n",
      "        [-0.0052],\n",
      "        [ 0.0206],\n",
      "        [ 0.0351],\n",
      "        [-0.0070],\n",
      "        [-0.0259],\n",
      "        [ 0.0235],\n",
      "        [ 0.0484],\n",
      "        [ 0.0514],\n",
      "        [ 0.0953],\n",
      "        [ 0.1182],\n",
      "        [ 0.0654],\n",
      "        [ 0.1094],\n",
      "        [ 0.0752],\n",
      "        [ 0.0664],\n",
      "        [ 0.0280],\n",
      "        [ 0.0867],\n",
      "        [ 0.0378],\n",
      "        [ 0.0146],\n",
      "        [ 0.0371],\n",
      "        [ 0.0494],\n",
      "        [ 0.0046],\n",
      "        [ 0.0875],\n",
      "        [-0.0193],\n",
      "        [-0.0233],\n",
      "        [ 0.0995],\n",
      "        [ 0.0310],\n",
      "        [ 0.0115]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1725, 0.1708, 0.1688, 0.1689, 0.1700, 0.1732, 0.1748, 0.1776, 0.1803,\n",
      "        0.1819, 0.1855, 0.1853, 0.1868, 0.1849, 0.1846, 0.1871, 0.1871, 0.1869,\n",
      "        0.1838, 0.1790, 0.1770, 0.1773, 0.1795, 0.1731, 0.1726, 0.1716, 0.1705,\n",
      "        0.1670, 0.1664, 0.1670, 0.1710, 0.1720], device='cuda:0')\n",
      "tensor([[ 0.0035],\n",
      "        [ 0.0065],\n",
      "        [ 0.0143],\n",
      "        [ 0.0322],\n",
      "        [-0.0065],\n",
      "        [ 0.0193],\n",
      "        [ 0.0239],\n",
      "        [ 0.0451],\n",
      "        [ 0.0014],\n",
      "        [ 0.0260],\n",
      "        [ 0.0453],\n",
      "        [ 0.0289],\n",
      "        [ 0.0254],\n",
      "        [-0.0186],\n",
      "        [ 0.0630],\n",
      "        [ 0.0450],\n",
      "        [ 0.0261],\n",
      "        [ 0.0089],\n",
      "        [-0.0004],\n",
      "        [ 0.0021],\n",
      "        [ 0.0249],\n",
      "        [ 0.0447],\n",
      "        [ 0.0375],\n",
      "        [ 0.0417],\n",
      "        [ 0.0050],\n",
      "        [ 0.0723],\n",
      "        [ 0.0149],\n",
      "        [-0.0097],\n",
      "        [ 0.0654],\n",
      "        [ 0.1830],\n",
      "        [-0.0160],\n",
      "        [ 0.0135]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1667, 0.1657, 0.1671, 0.1642, 0.1584, 0.1646, 0.1629, 0.1648, 0.1649,\n",
      "        0.1611, 0.1584, 0.1587, 0.1633, 0.1640, 0.1655, 0.1590, 0.1611, 0.1596,\n",
      "        0.1548, 0.1573, 0.1564, 0.1522, 0.1462, 0.1401, 0.1026, 0.1165, 0.1257,\n",
      "        0.1224, 0.1233, 0.1130, 0.1201, 0.1201], device='cuda:0')\n",
      "tensor([[ 0.1192],\n",
      "        [ 0.0659],\n",
      "        [-0.0833],\n",
      "        [ 0.0255],\n",
      "        [ 0.0051],\n",
      "        [ 0.0455],\n",
      "        [ 0.0195],\n",
      "        [ 0.0549],\n",
      "        [ 0.1313],\n",
      "        [ 0.0550],\n",
      "        [-0.0051],\n",
      "        [ 0.0012],\n",
      "        [-0.0103],\n",
      "        [ 0.0305],\n",
      "        [ 0.0281],\n",
      "        [ 0.0033],\n",
      "        [ 0.0113],\n",
      "        [ 0.0799],\n",
      "        [ 0.0133],\n",
      "        [ 0.0287],\n",
      "        [-0.0360],\n",
      "        [-0.0026],\n",
      "        [-0.0458],\n",
      "        [ 0.0092],\n",
      "        [-0.0293],\n",
      "        [ 0.0183],\n",
      "        [ 0.0940],\n",
      "        [-0.0092],\n",
      "        [-0.0025],\n",
      "        [ 0.0892],\n",
      "        [ 0.0654],\n",
      "        [ 0.0325]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1227, 0.1254, 0.1277, 0.1246, 0.1232, 0.1269, 0.1218, 0.1202, 0.1198,\n",
      "        0.1215, 0.1251, 0.1243, 0.1224, 0.1198, 0.1205, 0.1173, 0.1198, 0.1195,\n",
      "        0.1207, 0.1196, 0.1164, 0.1115, 0.1121, 0.1112, 0.1065, 0.1080, 0.1100,\n",
      "        0.1124, 0.1153, 0.1118, 0.1108, 0.1167], device='cuda:0')\n",
      "tensor([[ 0.0210],\n",
      "        [ 0.0157],\n",
      "        [ 0.0749],\n",
      "        [-0.0162],\n",
      "        [ 0.0580],\n",
      "        [ 0.0095],\n",
      "        [ 0.0635],\n",
      "        [ 0.0339],\n",
      "        [ 0.1343],\n",
      "        [ 0.0096],\n",
      "        [ 0.0200],\n",
      "        [-0.0099],\n",
      "        [ 0.0350],\n",
      "        [ 0.0202],\n",
      "        [-0.0166],\n",
      "        [-0.0132],\n",
      "        [ 0.0408],\n",
      "        [ 0.0039],\n",
      "        [ 0.0090],\n",
      "        [ 0.0355],\n",
      "        [-0.0013],\n",
      "        [-0.0106],\n",
      "        [ 0.0368],\n",
      "        [ 0.0374],\n",
      "        [ 0.0054],\n",
      "        [ 0.1428],\n",
      "        [ 0.0182],\n",
      "        [ 0.0372],\n",
      "        [ 0.0492],\n",
      "        [ 0.0343],\n",
      "        [ 0.0733],\n",
      "        [-0.0361]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1177, 0.1211, 0.1171, 0.1192, 0.1204, 0.1204, 0.1218, 0.1223, 0.1174,\n",
      "        0.1177, 0.1189, 0.1171, 0.1233, 0.1246, 0.1258, 0.1264, 0.1164, 0.1198,\n",
      "        0.1168, 0.1179, 0.1176, 0.1212, 0.1198, 0.1127, 0.1111, 0.1118, 0.1112,\n",
      "        0.1145, 0.1128, 0.1139, 0.1150, 0.1134], device='cuda:0')\n",
      "tensor([[-0.0226],\n",
      "        [ 0.0456],\n",
      "        [ 0.0323],\n",
      "        [-0.0162],\n",
      "        [-0.0345],\n",
      "        [ 0.0537],\n",
      "        [ 0.1105],\n",
      "        [ 0.0006],\n",
      "        [-0.0056],\n",
      "        [-0.0771],\n",
      "        [ 0.0786],\n",
      "        [-0.0160],\n",
      "        [ 0.0098],\n",
      "        [ 0.0583],\n",
      "        [-0.0064],\n",
      "        [ 0.0438],\n",
      "        [ 0.0177],\n",
      "        [ 0.0222],\n",
      "        [ 0.0187],\n",
      "        [ 0.0322],\n",
      "        [ 0.0377],\n",
      "        [ 0.0889],\n",
      "        [ 0.0549],\n",
      "        [ 0.0077],\n",
      "        [ 0.0740],\n",
      "        [ 0.0845],\n",
      "        [ 0.0241],\n",
      "        [ 0.0004],\n",
      "        [ 0.0285],\n",
      "        [-0.0585],\n",
      "        [-0.0186],\n",
      "        [ 0.0014]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1106, 0.1105, 0.1094, 0.1090, 0.1083, 0.1080, 0.1096, 0.1125, 0.1121,\n",
      "        0.1130, 0.1150, 0.1139, 0.1136, 0.1146, 0.1168, 0.1170, 0.1179, 0.1159,\n",
      "        0.1174, 0.1195, 0.1189, 0.1192, 0.1183, 0.1187, 0.1192, 0.1196, 0.1184,\n",
      "        0.1150, 0.1171, 0.1171, 0.1153, 0.1168], device='cuda:0')\n",
      "tensor([[ 0.0106],\n",
      "        [ 0.0076],\n",
      "        [ 0.0291],\n",
      "        [-0.0156],\n",
      "        [-0.0051],\n",
      "        [ 0.0166],\n",
      "        [-0.0151],\n",
      "        [-0.0292],\n",
      "        [ 0.0370],\n",
      "        [-0.0151],\n",
      "        [ 0.0944],\n",
      "        [ 0.0261],\n",
      "        [ 0.1048],\n",
      "        [ 0.0055],\n",
      "        [ 0.0259],\n",
      "        [ 0.0420],\n",
      "        [-0.0228],\n",
      "        [-0.0182],\n",
      "        [ 0.0695],\n",
      "        [-0.0157],\n",
      "        [ 0.0695],\n",
      "        [ 0.0276],\n",
      "        [ 0.1266],\n",
      "        [ 0.1789],\n",
      "        [-0.0223],\n",
      "        [ 0.0645],\n",
      "        [ 0.0322],\n",
      "        [-0.0095],\n",
      "        [ 0.0160],\n",
      "        [ 0.0197],\n",
      "        [ 0.0301],\n",
      "        [ 0.0252]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1164, 0.1156, 0.1150, 0.1143, 0.1125, 0.1106, 0.1071, 0.1084, 0.1057,\n",
      "        0.1049, 0.1078, 0.1077, 0.1077, 0.1102, 0.1097, 0.1125, 0.1146, 0.1149,\n",
      "        0.1179, 0.1122, 0.1155, 0.1153, 0.1143, 0.1140, 0.1134, 0.1150, 0.1152,\n",
      "        0.1156, 0.1153, 0.1143, 0.1146, 0.1155], device='cuda:0')\n",
      "tensor([[ 0.0235],\n",
      "        [ 0.0513],\n",
      "        [-0.0196],\n",
      "        [-0.0114],\n",
      "        [ 0.0003],\n",
      "        [ 0.0271],\n",
      "        [-0.0132],\n",
      "        [ 0.0643],\n",
      "        [ 0.1183],\n",
      "        [ 0.0520],\n",
      "        [ 0.0327],\n",
      "        [ 0.1579],\n",
      "        [-0.0609],\n",
      "        [ 0.0288],\n",
      "        [-0.0241],\n",
      "        [ 0.0141],\n",
      "        [ 0.0484],\n",
      "        [ 0.0251],\n",
      "        [ 0.0110],\n",
      "        [ 0.1051],\n",
      "        [-0.0156],\n",
      "        [-0.0257],\n",
      "        [ 0.0158],\n",
      "        [ 0.1059],\n",
      "        [ 0.0756],\n",
      "        [ 0.0004],\n",
      "        [ 0.0933],\n",
      "        [ 0.0078],\n",
      "        [ 0.0584],\n",
      "        [ 0.1159],\n",
      "        [ 0.1513],\n",
      "        [ 0.1183]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1161, 0.1145, 0.1121, 0.1112, 0.1112, 0.1117, 0.1091, 0.1091, 0.1111,\n",
      "        0.1125, 0.1108, 0.1093, 0.1112, 0.1100, 0.1091, 0.1097, 0.1088, 0.1086,\n",
      "        0.1083, 0.1136, 0.1143, 0.1137, 0.1145, 0.1158, 0.1150, 0.1184, 0.1170,\n",
      "        0.1177, 0.1189, 0.1209, 0.1211, 0.1190], device='cuda:0')\n",
      "tensor([[ 0.0020],\n",
      "        [ 0.0173],\n",
      "        [ 0.1111],\n",
      "        [ 0.0111],\n",
      "        [ 0.0203],\n",
      "        [ 0.0538],\n",
      "        [ 0.0280],\n",
      "        [ 0.0330],\n",
      "        [ 0.1313],\n",
      "        [ 0.1631],\n",
      "        [ 0.0937],\n",
      "        [ 0.0107],\n",
      "        [ 0.0325],\n",
      "        [ 0.0904],\n",
      "        [ 0.0451],\n",
      "        [ 0.0125],\n",
      "        [ 0.0477],\n",
      "        [-0.0174],\n",
      "        [ 0.0171],\n",
      "        [-0.0212],\n",
      "        [ 0.0244],\n",
      "        [ 0.0555],\n",
      "        [ 0.0758],\n",
      "        [-0.0215],\n",
      "        [ 0.0358],\n",
      "        [ 0.0847],\n",
      "        [ 0.0428],\n",
      "        [ 0.0808],\n",
      "        [-0.0093],\n",
      "        [-0.0022],\n",
      "        [-0.0434],\n",
      "        [-0.0373]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1195, 0.1190, 0.1227, 0.1260, 0.1292, 0.1285, 0.1283, 0.1307, 0.1307,\n",
      "        0.1311, 0.1302, 0.1333, 0.1305, 0.1314, 0.1300, 0.1304, 0.1286, 0.1286,\n",
      "        0.1280, 0.1301, 0.1285, 0.1271, 0.1271, 0.1245, 0.1226, 0.1252, 0.1255,\n",
      "        0.1238, 0.1269, 0.1292, 0.1298, 0.1292], device='cuda:0')\n",
      "tensor([[ 0.0150],\n",
      "        [-0.0247],\n",
      "        [ 0.0934],\n",
      "        [ 0.0541],\n",
      "        [-0.0127],\n",
      "        [ 0.0762],\n",
      "        [ 0.0310],\n",
      "        [ 0.0326],\n",
      "        [ 0.0582],\n",
      "        [ 0.0383],\n",
      "        [ 0.0571],\n",
      "        [ 0.0286],\n",
      "        [-0.0315],\n",
      "        [ 0.0927],\n",
      "        [ 0.0331],\n",
      "        [ 0.0473],\n",
      "        [-0.0566],\n",
      "        [ 0.0376],\n",
      "        [-0.0096],\n",
      "        [ 0.0367],\n",
      "        [ 0.0285],\n",
      "        [ 0.0417],\n",
      "        [ 0.0345],\n",
      "        [ 0.0488],\n",
      "        [ 0.0107],\n",
      "        [-0.0060],\n",
      "        [ 0.0266],\n",
      "        [ 0.0074],\n",
      "        [ 0.0176],\n",
      "        [-0.0189],\n",
      "        [ 0.0034],\n",
      "        [ 0.0826]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1292, 0.1274, 0.1270, 0.1261, 0.1243, 0.1211, 0.1212, 0.1201, 0.1167,\n",
      "        0.1174, 0.1161, 0.1161, 0.1139, 0.1115, 0.1117, 0.1139, 0.1125, 0.1133,\n",
      "        0.1146, 0.1140, 0.1124, 0.1109, 0.1153, 0.1140, 0.1127, 0.1131, 0.1158,\n",
      "        0.1149, 0.1165, 0.1161, 0.1150, 0.1156], device='cuda:0')\n",
      "tensor([[-0.0063],\n",
      "        [ 0.0032],\n",
      "        [ 0.0175],\n",
      "        [-0.0038],\n",
      "        [ 0.0725],\n",
      "        [-0.0149],\n",
      "        [ 0.0131],\n",
      "        [-0.0333],\n",
      "        [-0.0077],\n",
      "        [-0.0447],\n",
      "        [-0.0338],\n",
      "        [ 0.0557],\n",
      "        [ 0.0369],\n",
      "        [ 0.0062],\n",
      "        [ 0.0588],\n",
      "        [ 0.0421],\n",
      "        [-0.0307],\n",
      "        [-0.0057],\n",
      "        [-0.0373],\n",
      "        [ 0.0634],\n",
      "        [ 0.0205],\n",
      "        [ 0.0357],\n",
      "        [ 0.0404],\n",
      "        [ 0.0098],\n",
      "        [ 0.0108],\n",
      "        [ 0.0497],\n",
      "        [ 0.1385],\n",
      "        [ 0.1751],\n",
      "        [ 0.1421],\n",
      "        [ 0.1603],\n",
      "        [ 0.0188],\n",
      "        [ 0.0013]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1139, 0.1139, 0.1145, 0.1130, 0.1140, 0.1133, 0.1145, 0.1152, 0.1170,\n",
      "        0.1170, 0.1164, 0.1159, 0.1152, 0.1153, 0.1177, 0.1179, 0.1209, 0.1195,\n",
      "        0.1208, 0.1221, 0.1238, 0.1276, 0.1252, 0.1282, 0.1276, 0.1261, 0.1258,\n",
      "        0.1243, 0.1227, 0.1233, 0.1255, 0.1271], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0527],\n",
      "        [ 0.0502],\n",
      "        [-0.0120],\n",
      "        [ 0.0689],\n",
      "        [ 0.0361],\n",
      "        [ 0.0561],\n",
      "        [ 0.0360],\n",
      "        [ 0.0274],\n",
      "        [ 0.0175],\n",
      "        [-0.0679],\n",
      "        [ 0.0240],\n",
      "        [ 0.0152],\n",
      "        [-0.0174],\n",
      "        [ 0.0772],\n",
      "        [ 0.0828],\n",
      "        [ 0.1086],\n",
      "        [-0.0042],\n",
      "        [-0.0160],\n",
      "        [ 0.0385],\n",
      "        [-0.0141],\n",
      "        [ 0.0043],\n",
      "        [ 0.0252],\n",
      "        [ 0.0481],\n",
      "        [ 0.0829],\n",
      "        [ 0.0072],\n",
      "        [ 0.0108],\n",
      "        [ 0.0089],\n",
      "        [ 0.1322],\n",
      "        [ 0.1370],\n",
      "        [ 0.0988],\n",
      "        [-0.0051],\n",
      "        [ 0.0241]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1258, 0.1251, 0.1227, 0.1214, 0.1221, 0.1223, 0.1221, 0.1184, 0.1190,\n",
      "        0.1195, 0.1171, 0.1171, 0.1174, 0.1173, 0.1189, 0.1201, 0.1177, 0.1211,\n",
      "        0.1217, 0.1207, 0.1204, 0.1215, 0.1235, 0.1249, 0.1236, 0.1217, 0.1229,\n",
      "        0.1230, 0.1233, 0.1230, 0.1236, 0.1239], device='cuda:0')\n",
      "tensor([[ 0.0388],\n",
      "        [ 0.0306],\n",
      "        [ 0.0279],\n",
      "        [ 0.0362],\n",
      "        [ 0.0406],\n",
      "        [ 0.0967],\n",
      "        [ 0.0763],\n",
      "        [ 0.0102],\n",
      "        [ 0.0019],\n",
      "        [-0.0154],\n",
      "        [-0.0297],\n",
      "        [ 0.0642],\n",
      "        [-0.0051],\n",
      "        [-0.0355],\n",
      "        [ 0.0874],\n",
      "        [-0.0083],\n",
      "        [-0.0164],\n",
      "        [ 0.0152],\n",
      "        [-0.0054],\n",
      "        [ 0.0398],\n",
      "        [ 0.0057],\n",
      "        [ 0.0643],\n",
      "        [ 0.0071],\n",
      "        [-0.0036],\n",
      "        [ 0.0524],\n",
      "        [ 0.1015],\n",
      "        [ 0.0461],\n",
      "        [ 0.0479],\n",
      "        [-0.0989],\n",
      "        [ 0.0146],\n",
      "        [ 0.0923],\n",
      "        [ 0.0302]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1257, 0.1263, 0.1260, 0.1254, 0.1264, 0.1261, 0.1254, 0.1263, 0.1246,\n",
      "        0.1236, 0.1254, 0.1251, 0.1246, 0.1248, 0.1238, 0.1251, 0.1261, 0.1264,\n",
      "        0.1274, 0.1270, 0.1283, 0.1274, 0.1267, 0.1252, 0.1274, 0.1263, 0.1295,\n",
      "        0.1305, 0.1328, 0.1350, 0.1338, 0.1323], device='cuda:0')\n",
      "tensor([[ 0.0946],\n",
      "        [ 0.1435],\n",
      "        [ 0.1170],\n",
      "        [ 0.0539],\n",
      "        [ 0.0822],\n",
      "        [ 0.0249],\n",
      "        [-0.0034],\n",
      "        [-0.0077],\n",
      "        [ 0.0304],\n",
      "        [ 0.0293],\n",
      "        [ 0.0362],\n",
      "        [ 0.0269],\n",
      "        [ 0.0412],\n",
      "        [-0.0026],\n",
      "        [ 0.0063],\n",
      "        [-0.0189],\n",
      "        [ 0.0198],\n",
      "        [-0.0023],\n",
      "        [ 0.0292],\n",
      "        [ 0.0626],\n",
      "        [ 0.0703],\n",
      "        [-0.0157],\n",
      "        [ 0.0016],\n",
      "        [ 0.0399],\n",
      "        [ 0.0366],\n",
      "        [ 0.0082],\n",
      "        [ 0.0541],\n",
      "        [ 0.0341],\n",
      "        [-0.0251],\n",
      "        [ 0.0350],\n",
      "        [ 0.0309],\n",
      "        [-0.0138]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1316, 0.1302, 0.1314, 0.1307, 0.1300, 0.1283, 0.1295, 0.1280, 0.1307,\n",
      "        0.1294, 0.1286, 0.1289, 0.1264, 0.1264, 0.1238, 0.1243, 0.1242, 0.1223,\n",
      "        0.1230, 0.1235, 0.1242, 0.1223, 0.1220, 0.1208, 0.1204, 0.1211, 0.1199,\n",
      "        0.1189, 0.1202, 0.1136, 0.1100, 0.1108], device='cuda:0')\n",
      "tensor([[ 0.0971],\n",
      "        [ 0.0457],\n",
      "        [ 0.0835],\n",
      "        [ 0.0071],\n",
      "        [ 0.0509],\n",
      "        [ 0.0483],\n",
      "        [-0.0169],\n",
      "        [ 0.0737],\n",
      "        [ 0.0346],\n",
      "        [-0.0112],\n",
      "        [-0.0113],\n",
      "        [ 0.0546],\n",
      "        [-0.0239],\n",
      "        [ 0.0666],\n",
      "        [-0.0201],\n",
      "        [-0.0478],\n",
      "        [ 0.0127],\n",
      "        [ 0.0017],\n",
      "        [ 0.0337],\n",
      "        [ 0.0285],\n",
      "        [-0.0012],\n",
      "        [ 0.0550],\n",
      "        [ 0.0159],\n",
      "        [ 0.0386],\n",
      "        [ 0.0081],\n",
      "        [ 0.1138],\n",
      "        [ 0.1152],\n",
      "        [ 0.0922],\n",
      "        [ 0.0306],\n",
      "        [ 0.0311],\n",
      "        [ 0.1000],\n",
      "        [ 0.0152]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1097, 0.1102, 0.1108, 0.1106, 0.1102, 0.1091, 0.1096, 0.1088, 0.1072,\n",
      "        0.1080, 0.1083, 0.1103, 0.1106, 0.1119, 0.1119, 0.1097, 0.1117, 0.1122,\n",
      "        0.1142, 0.1134, 0.1134, 0.1148, 0.1148, 0.1159, 0.1159, 0.1161, 0.1155,\n",
      "        0.1146, 0.1134, 0.1124, 0.1114, 0.1099], device='cuda:0')\n",
      "tensor([[-0.0243],\n",
      "        [-0.0315],\n",
      "        [ 0.0311],\n",
      "        [ 0.0117],\n",
      "        [ 0.0025],\n",
      "        [-0.0557],\n",
      "        [ 0.0126],\n",
      "        [ 0.1008],\n",
      "        [ 0.0081],\n",
      "        [ 0.0399],\n",
      "        [ 0.1481],\n",
      "        [ 0.0834],\n",
      "        [ 0.0472],\n",
      "        [ 0.0504],\n",
      "        [ 0.0960],\n",
      "        [ 0.0165],\n",
      "        [ 0.0060],\n",
      "        [ 0.0221],\n",
      "        [-0.0252],\n",
      "        [-0.0019],\n",
      "        [-0.0283],\n",
      "        [ 0.0327],\n",
      "        [ 0.0065],\n",
      "        [ 0.0332],\n",
      "        [-0.0071],\n",
      "        [ 0.0219],\n",
      "        [ 0.0040],\n",
      "        [ 0.0282],\n",
      "        [ 0.0039],\n",
      "        [ 0.0081],\n",
      "        [-0.0142],\n",
      "        [ 0.0507]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1100, 0.1103, 0.1102, 0.1096, 0.1115, 0.1139, 0.1122, 0.1124, 0.1130,\n",
      "        0.1119, 0.1105, 0.1100, 0.1103, 0.1102, 0.1100, 0.1086, 0.1102, 0.1106,\n",
      "        0.1108, 0.1094, 0.1102, 0.1100, 0.1097, 0.1087, 0.1093, 0.1118, 0.1111,\n",
      "        0.1099, 0.1100, 0.1111, 0.1100, 0.1103], device='cuda:0')\n",
      "tensor([[ 0.0199],\n",
      "        [ 0.0346],\n",
      "        [-0.0300],\n",
      "        [ 0.0861],\n",
      "        [-0.0168],\n",
      "        [ 0.0197],\n",
      "        [ 0.0317],\n",
      "        [ 0.0756],\n",
      "        [ 0.2420],\n",
      "        [ 0.0005],\n",
      "        [ 0.0290],\n",
      "        [ 0.0866],\n",
      "        [ 0.0522],\n",
      "        [-0.0574],\n",
      "        [ 0.0951],\n",
      "        [-0.0028],\n",
      "        [ 0.0309],\n",
      "        [ 0.0790],\n",
      "        [ 0.0029],\n",
      "        [ 0.0313],\n",
      "        [ 0.0414],\n",
      "        [ 0.0477],\n",
      "        [ 0.0212],\n",
      "        [ 0.0443],\n",
      "        [ 0.0388],\n",
      "        [-0.0110],\n",
      "        [ 0.0164],\n",
      "        [ 0.0739],\n",
      "        [ 0.0343],\n",
      "        [ 0.0532],\n",
      "        [-0.0016],\n",
      "        [-0.0073]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1096, 0.1117, 0.1130, 0.1158, 0.1152, 0.1124, 0.1128, 0.1133, 0.1130,\n",
      "        0.1125, 0.1131, 0.1161, 0.1152, 0.1162, 0.1164, 0.1162, 0.1177, 0.1162,\n",
      "        0.1158, 0.1139, 0.1155, 0.1148, 0.1139, 0.1136, 0.1142, 0.1146, 0.1165,\n",
      "        0.1161, 0.1153, 0.1150, 0.1171, 0.1193], device='cuda:0')\n",
      "tensor([[ 0.0194],\n",
      "        [ 0.0062],\n",
      "        [ 0.0501],\n",
      "        [ 0.0708],\n",
      "        [-0.0189],\n",
      "        [ 0.1568],\n",
      "        [ 0.0362],\n",
      "        [ 0.0697],\n",
      "        [ 0.0319],\n",
      "        [-0.0091],\n",
      "        [-0.0088],\n",
      "        [ 0.0062],\n",
      "        [ 0.0007],\n",
      "        [ 0.0058],\n",
      "        [ 0.1205],\n",
      "        [ 0.1671],\n",
      "        [ 0.0171],\n",
      "        [ 0.0622],\n",
      "        [ 0.0048],\n",
      "        [ 0.0422],\n",
      "        [ 0.0225],\n",
      "        [ 0.0022],\n",
      "        [ 0.0078],\n",
      "        [ 0.0035],\n",
      "        [ 0.0150],\n",
      "        [-0.0176],\n",
      "        [ 0.0724],\n",
      "        [ 0.0476],\n",
      "        [-0.0227],\n",
      "        [ 0.0518],\n",
      "        [ 0.0288],\n",
      "        [-0.0226]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1204, 0.1190, 0.1195, 0.1171, 0.1179, 0.1180, 0.1171, 0.1162, 0.1167,\n",
      "        0.1142, 0.1149, 0.1153, 0.1177, 0.1179, 0.1201, 0.1181, 0.1187, 0.1190,\n",
      "        0.1193, 0.1198, 0.1186, 0.1180, 0.1177, 0.1180, 0.1187, 0.1170, 0.1174,\n",
      "        0.1171, 0.1179, 0.1177, 0.1177, 0.1179], device='cuda:0')\n",
      "tensor([[ 0.0797],\n",
      "        [-0.0228],\n",
      "        [-0.0346],\n",
      "        [ 0.0659],\n",
      "        [ 0.0338],\n",
      "        [ 0.0032],\n",
      "        [ 0.0075],\n",
      "        [ 0.0109],\n",
      "        [ 0.1086],\n",
      "        [ 0.0399],\n",
      "        [ 0.1417],\n",
      "        [ 0.0344],\n",
      "        [ 0.0726],\n",
      "        [ 0.0352],\n",
      "        [ 0.0358],\n",
      "        [-0.0157],\n",
      "        [ 0.0105],\n",
      "        [ 0.0626],\n",
      "        [-0.0040],\n",
      "        [-0.0101],\n",
      "        [-0.0448],\n",
      "        [ 0.0794],\n",
      "        [ 0.0530],\n",
      "        [ 0.0600],\n",
      "        [ 0.0339],\n",
      "        [ 0.0329],\n",
      "        [-0.0078],\n",
      "        [ 0.0460],\n",
      "        [-0.0168],\n",
      "        [ 0.0331],\n",
      "        [-0.0088],\n",
      "        [-0.0232]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1183, 0.1180, 0.1195, 0.1124, 0.1094, 0.1097, 0.1090, 0.1059, 0.1086,\n",
      "        0.1077, 0.1077, 0.1097, 0.1086, 0.1080, 0.1078, 0.1012, 0.1024, 0.1015,\n",
      "        0.1009, 0.1037, 0.1038, 0.1029, 0.1024, 0.1010, 0.0997, 0.0987, 0.0982,\n",
      "        0.0991, 0.0988, 0.0963, 0.0970, 0.0948], device='cuda:0')\n",
      "tensor([[ 0.0165],\n",
      "        [ 0.0164],\n",
      "        [ 0.0341],\n",
      "        [-0.0578],\n",
      "        [ 0.0132],\n",
      "        [-0.0257],\n",
      "        [ 0.0629],\n",
      "        [-0.0095],\n",
      "        [-0.0010],\n",
      "        [ 0.0018],\n",
      "        [ 0.0288],\n",
      "        [-0.0167],\n",
      "        [ 0.0647],\n",
      "        [ 0.1330],\n",
      "        [ 0.0411],\n",
      "        [ 0.0354],\n",
      "        [ 0.0402],\n",
      "        [ 0.0688],\n",
      "        [ 0.0461],\n",
      "        [ 0.0053],\n",
      "        [-0.0208],\n",
      "        [ 0.0661],\n",
      "        [ 0.1233],\n",
      "        [ 0.0147],\n",
      "        [-0.0071],\n",
      "        [ 0.0197],\n",
      "        [ 0.0415],\n",
      "        [ 0.0197],\n",
      "        [ 0.0152],\n",
      "        [-0.0307],\n",
      "        [-0.0254],\n",
      "        [ 0.0394]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0957, 0.0950, 0.0957, 0.0966, 0.0967, 0.0964, 0.0963, 0.0954, 0.0978,\n",
      "        0.0973, 0.0982, 0.0990, 0.0993, 0.0981, 0.0975, 0.0962, 0.0960, 0.0954,\n",
      "        0.0979, 0.0984, 0.0972, 0.0964, 0.0951, 0.0942, 0.0953, 0.0939, 0.0931,\n",
      "        0.0929, 0.0913, 0.0926, 0.0925, 0.0931], device='cuda:0')\n",
      "tensor([[ 0.0391],\n",
      "        [-0.0158],\n",
      "        [ 0.0589],\n",
      "        [ 0.0127],\n",
      "        [ 0.0147],\n",
      "        [ 0.0440],\n",
      "        [-0.0518],\n",
      "        [ 0.0498],\n",
      "        [ 0.0362],\n",
      "        [ 0.0679],\n",
      "        [ 0.0477],\n",
      "        [ 0.1435],\n",
      "        [ 0.0775],\n",
      "        [ 0.0642],\n",
      "        [ 0.1003],\n",
      "        [ 0.0491],\n",
      "        [ 0.0132],\n",
      "        [-0.0025],\n",
      "        [ 0.0130],\n",
      "        [ 0.0488],\n",
      "        [ 0.0524],\n",
      "        [ 0.0464],\n",
      "        [ 0.0127],\n",
      "        [ 0.0210],\n",
      "        [-0.0144],\n",
      "        [-0.0015],\n",
      "        [ 0.0237],\n",
      "        [ 0.0939],\n",
      "        [ 0.0106],\n",
      "        [ 0.0296],\n",
      "        [ 0.0351],\n",
      "        [ 0.0322]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0933, 0.0923, 0.0926, 0.0919, 0.0919, 0.0964, 0.0975, 0.0988, 0.0985,\n",
      "        0.0993, 0.0981, 0.0976, 0.0987, 0.0963, 0.0966, 0.0990, 0.0975, 0.0982,\n",
      "        0.0972, 0.0948, 0.0950, 0.0959, 0.0939, 0.0951, 0.0956, 0.0956, 0.0972,\n",
      "        0.0962, 0.0969, 0.0984, 0.1000, 0.1025], device='cuda:0')\n",
      "tensor([[-0.0227],\n",
      "        [ 0.0201],\n",
      "        [ 0.0375],\n",
      "        [ 0.0471],\n",
      "        [ 0.1487],\n",
      "        [ 0.0308],\n",
      "        [ 0.0019],\n",
      "        [ 0.0680],\n",
      "        [ 0.0132],\n",
      "        [ 0.0255],\n",
      "        [ 0.0112],\n",
      "        [ 0.0686],\n",
      "        [-0.0144],\n",
      "        [ 0.0357],\n",
      "        [ 0.0463],\n",
      "        [ 0.0778],\n",
      "        [ 0.0193],\n",
      "        [ 0.0305],\n",
      "        [-0.0196],\n",
      "        [ 0.0261],\n",
      "        [ 0.0243],\n",
      "        [-0.0357],\n",
      "        [ 0.0213],\n",
      "        [ 0.0124],\n",
      "        [ 0.0135],\n",
      "        [ 0.0296],\n",
      "        [ 0.0342],\n",
      "        [-0.0079],\n",
      "        [ 0.0627],\n",
      "        [ 0.0101],\n",
      "        [ 0.0711],\n",
      "        [ 0.0381]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1021, 0.1018, 0.1001, 0.1026, 0.1032, 0.1032, 0.1029, 0.1022, 0.1046,\n",
      "        0.1026, 0.1019, 0.1035, 0.1032, 0.1034, 0.1035, 0.1046, 0.1047, 0.1056,\n",
      "        0.1053, 0.1071, 0.1065, 0.1080, 0.1062, 0.1062, 0.1071, 0.1090, 0.1094,\n",
      "        0.1083, 0.1074, 0.1065, 0.1047, 0.1037], device='cuda:0')\n",
      "tensor([[ 0.0165],\n",
      "        [-0.0023],\n",
      "        [ 0.0480],\n",
      "        [ 0.0385],\n",
      "        [-0.0953],\n",
      "        [ 0.0617],\n",
      "        [ 0.0218],\n",
      "        [ 0.0043],\n",
      "        [-0.0188],\n",
      "        [ 0.0461],\n",
      "        [-0.0006],\n",
      "        [ 0.0456],\n",
      "        [ 0.0406],\n",
      "        [-0.0100],\n",
      "        [-0.0025],\n",
      "        [-0.0215],\n",
      "        [ 0.0330],\n",
      "        [-0.0103],\n",
      "        [ 0.1608],\n",
      "        [ 0.2009],\n",
      "        [ 0.0736],\n",
      "        [ 0.0644],\n",
      "        [ 0.0898],\n",
      "        [-0.0385],\n",
      "        [-0.0595],\n",
      "        [-0.0094],\n",
      "        [ 0.0163],\n",
      "        [ 0.1022],\n",
      "        [ 0.0408],\n",
      "        [-0.0119],\n",
      "        [ 0.0148],\n",
      "        [ 0.0325]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1041, 0.1057, 0.1059, 0.1060, 0.1057, 0.1066, 0.1065, 0.1060, 0.1057,\n",
      "        0.1053, 0.1057, 0.1063, 0.1072, 0.1117, 0.1119, 0.1105, 0.1096, 0.1099,\n",
      "        0.1099, 0.1093, 0.1099, 0.1091, 0.1075, 0.1094, 0.1083, 0.1096, 0.1097,\n",
      "        0.1112, 0.1112, 0.1115, 0.1121, 0.1134], device='cuda:0')\n",
      "tensor([[ 0.0112],\n",
      "        [ 0.0289],\n",
      "        [-0.0321],\n",
      "        [-0.0220],\n",
      "        [ 0.0111],\n",
      "        [ 0.0794],\n",
      "        [ 0.0392],\n",
      "        [ 0.0799],\n",
      "        [ 0.0079],\n",
      "        [ 0.0557],\n",
      "        [ 0.0156],\n",
      "        [ 0.0135],\n",
      "        [ 0.0220],\n",
      "        [ 0.0428],\n",
      "        [ 0.0469],\n",
      "        [ 0.0067],\n",
      "        [-0.0088],\n",
      "        [ 0.0703],\n",
      "        [-0.0026],\n",
      "        [ 0.0291],\n",
      "        [ 0.0268],\n",
      "        [ 0.0817],\n",
      "        [-0.0096],\n",
      "        [-0.0049],\n",
      "        [ 0.1000],\n",
      "        [-0.0223],\n",
      "        [ 0.0445],\n",
      "        [ 0.0384],\n",
      "        [ 0.0166],\n",
      "        [-0.0335],\n",
      "        [ 0.1409],\n",
      "        [ 0.0085]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1153, 0.1156, 0.1173, 0.1170, 0.1179, 0.1170, 0.1189, 0.1198, 0.1209,\n",
      "        0.1209, 0.1180, 0.1221, 0.1235, 0.1224, 0.1218, 0.1229, 0.1233, 0.1232,\n",
      "        0.1232, 0.1209, 0.1223, 0.1227, 0.1240, 0.1235, 0.1229, 0.1208, 0.1209,\n",
      "        0.1201, 0.1214, 0.1180, 0.1184, 0.1186], device='cuda:0')\n",
      "tensor([[ 0.0591],\n",
      "        [ 0.0166],\n",
      "        [ 0.0661],\n",
      "        [ 0.0175],\n",
      "        [ 0.0479],\n",
      "        [-0.0053],\n",
      "        [ 0.0350],\n",
      "        [ 0.0502],\n",
      "        [ 0.0179],\n",
      "        [ 0.0057],\n",
      "        [ 0.0077],\n",
      "        [-0.0143],\n",
      "        [ 0.0318],\n",
      "        [ 0.0140],\n",
      "        [ 0.0292],\n",
      "        [ 0.0170],\n",
      "        [ 0.1129],\n",
      "        [ 0.1312],\n",
      "        [ 0.1757],\n",
      "        [ 0.0978],\n",
      "        [ 0.0901],\n",
      "        [ 0.0049],\n",
      "        [ 0.0756],\n",
      "        [ 0.0495],\n",
      "        [ 0.0865],\n",
      "        [ 0.0067],\n",
      "        [ 0.0337],\n",
      "        [ 0.0438],\n",
      "        [ 0.0166],\n",
      "        [ 0.0470],\n",
      "        [ 0.0325],\n",
      "        [ 0.0206]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1201, 0.1196, 0.1195, 0.1207, 0.1196, 0.1193, 0.1201, 0.1212, 0.1198,\n",
      "        0.1214, 0.1224, 0.1236, 0.1252, 0.1233, 0.1223, 0.1224, 0.1196, 0.1176,\n",
      "        0.1162, 0.1162, 0.1143, 0.1122, 0.1131, 0.1124, 0.1125, 0.1103, 0.1084,\n",
      "        0.1034, 0.1024, 0.1025, 0.1026, 0.1012], device='cuda:0')\n",
      "tensor([[-0.0149],\n",
      "        [ 0.1128],\n",
      "        [ 0.1121],\n",
      "        [-0.0099],\n",
      "        [ 0.0947],\n",
      "        [ 0.0516],\n",
      "        [ 0.0462],\n",
      "        [ 0.0303],\n",
      "        [ 0.0329],\n",
      "        [ 0.0528],\n",
      "        [ 0.0427],\n",
      "        [ 0.0354],\n",
      "        [ 0.0145],\n",
      "        [ 0.0334],\n",
      "        [ 0.0061],\n",
      "        [ 0.0688],\n",
      "        [ 0.0094],\n",
      "        [ 0.1057],\n",
      "        [ 0.0732],\n",
      "        [ 0.0282],\n",
      "        [-0.0136],\n",
      "        [ 0.0465],\n",
      "        [-0.0129],\n",
      "        [ 0.1137],\n",
      "        [ 0.0991],\n",
      "        [ 0.0348],\n",
      "        [ 0.0358],\n",
      "        [ 0.0331],\n",
      "        [ 0.0400],\n",
      "        [ 0.0127],\n",
      "        [ 0.0220],\n",
      "        [-0.0472]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1032, 0.1040, 0.1047, 0.1032, 0.1004, 0.1015, 0.0994, 0.0976, 0.0951,\n",
      "        0.0993, 0.1040, 0.1031, 0.1034, 0.1009, 0.1010, 0.1018, 0.1018, 0.1016,\n",
      "        0.1053, 0.1057, 0.1077, 0.1081, 0.1047, 0.1040, 0.1049, 0.1074, 0.1087,\n",
      "        0.1081, 0.1068, 0.1047, 0.1063, 0.1052], device='cuda:0')\n",
      "tensor([[ 0.0591],\n",
      "        [ 0.0265],\n",
      "        [ 0.0249],\n",
      "        [-0.0187],\n",
      "        [ 0.0710],\n",
      "        [ 0.0338],\n",
      "        [ 0.0137],\n",
      "        [ 0.0404],\n",
      "        [ 0.0480],\n",
      "        [ 0.0052],\n",
      "        [ 0.0107],\n",
      "        [ 0.0394],\n",
      "        [ 0.0506],\n",
      "        [ 0.0194],\n",
      "        [ 0.0197],\n",
      "        [-0.0229],\n",
      "        [ 0.0791],\n",
      "        [-0.0991],\n",
      "        [-0.0296],\n",
      "        [ 0.0539],\n",
      "        [ 0.0251],\n",
      "        [ 0.1359],\n",
      "        [ 0.0536],\n",
      "        [-0.0360],\n",
      "        [ 0.1219],\n",
      "        [ 0.0412],\n",
      "        [ 0.0345],\n",
      "        [-0.0005],\n",
      "        [ 0.0418],\n",
      "        [ 0.0316],\n",
      "        [ 0.0263],\n",
      "        [ 0.0586]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1040, 0.1063, 0.1094, 0.1086, 0.1075, 0.1081, 0.1086, 0.1100, 0.1052,\n",
      "        0.1029, 0.1000, 0.0991, 0.0979, 0.0981, 0.0997, 0.1052, 0.1078, 0.1080,\n",
      "        0.1068, 0.1090, 0.1084, 0.1069, 0.1059, 0.1063, 0.1053, 0.1074, 0.1087,\n",
      "        0.1081, 0.1081, 0.1065, 0.1077, 0.1109], device='cuda:0')\n",
      "tensor([[ 0.0339],\n",
      "        [ 0.0014],\n",
      "        [ 0.0369],\n",
      "        [ 0.0171],\n",
      "        [ 0.0792],\n",
      "        [ 0.1392],\n",
      "        [ 0.1277],\n",
      "        [ 0.0325],\n",
      "        [ 0.0736],\n",
      "        [ 0.1005],\n",
      "        [ 0.0081],\n",
      "        [ 0.0439],\n",
      "        [ 0.0404],\n",
      "        [-0.0217],\n",
      "        [ 0.0066],\n",
      "        [ 0.0573],\n",
      "        [-0.0041],\n",
      "        [ 0.0187],\n",
      "        [ 0.0236],\n",
      "        [-0.0158],\n",
      "        [ 0.0228],\n",
      "        [-0.0050],\n",
      "        [ 0.0110],\n",
      "        [ 0.0601],\n",
      "        [ 0.0411],\n",
      "        [ 0.0846],\n",
      "        [ 0.0358],\n",
      "        [ 0.0414],\n",
      "        [ 0.0799],\n",
      "        [ 0.0970],\n",
      "        [ 0.0127],\n",
      "        [ 0.0666]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1142, 0.1130, 0.1148, 0.1137, 0.1149, 0.1162, 0.1146, 0.1155, 0.1137,\n",
      "        0.1152, 0.1148, 0.1134, 0.1130, 0.1149, 0.1146, 0.1162, 0.1161, 0.1124,\n",
      "        0.1136, 0.1146, 0.1140, 0.1158, 0.1140, 0.1121, 0.1124, 0.1148, 0.1139,\n",
      "        0.1150, 0.1152, 0.1152, 0.1148, 0.1149], device='cuda:0')\n",
      "tensor([[ 0.0150],\n",
      "        [-0.0019],\n",
      "        [ 0.0133],\n",
      "        [-0.0315],\n",
      "        [ 0.0219],\n",
      "        [-0.0032],\n",
      "        [-0.0157],\n",
      "        [ 0.0165],\n",
      "        [ 0.0620],\n",
      "        [ 0.0280],\n",
      "        [ 0.0203],\n",
      "        [ 0.0378],\n",
      "        [-0.0167],\n",
      "        [ 0.0716],\n",
      "        [-0.0276],\n",
      "        [-0.0341],\n",
      "        [-0.0133],\n",
      "        [ 0.0279],\n",
      "        [ 0.1664],\n",
      "        [ 0.1090],\n",
      "        [ 0.0681],\n",
      "        [ 0.0485],\n",
      "        [ 0.0437],\n",
      "        [ 0.0618],\n",
      "        [ 0.0979],\n",
      "        [ 0.0604],\n",
      "        [ 0.0235],\n",
      "        [ 0.0634],\n",
      "        [ 0.0424],\n",
      "        [-0.0314],\n",
      "        [ 0.0301],\n",
      "        [-0.0153]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1146, 0.1142, 0.1131, 0.1136, 0.1131, 0.1109, 0.1094, 0.1069, 0.1087,\n",
      "        0.1084, 0.1068, 0.1077, 0.1096, 0.1174, 0.1196, 0.1220, 0.1201, 0.1215,\n",
      "        0.1236, 0.1255, 0.1274, 0.1277, 0.1307, 0.1304, 0.1305, 0.1311, 0.1325,\n",
      "        0.1341, 0.1325, 0.1336, 0.1370, 0.1375], device='cuda:0')\n",
      "tensor([[ 0.0229],\n",
      "        [ 0.0283],\n",
      "        [ 0.0566],\n",
      "        [ 0.0618],\n",
      "        [ 0.0248],\n",
      "        [ 0.0529],\n",
      "        [ 0.0944],\n",
      "        [ 0.1001],\n",
      "        [ 0.0749],\n",
      "        [ 0.0746],\n",
      "        [-0.0270],\n",
      "        [ 0.0215],\n",
      "        [ 0.0467],\n",
      "        [ 0.0579],\n",
      "        [ 0.0005],\n",
      "        [ 0.0662],\n",
      "        [ 0.0198],\n",
      "        [-0.0182],\n",
      "        [ 0.0764],\n",
      "        [ 0.0149],\n",
      "        [-0.0088],\n",
      "        [-0.0047],\n",
      "        [ 0.0347],\n",
      "        [ 0.0089],\n",
      "        [ 0.0283],\n",
      "        [ 0.0217],\n",
      "        [ 0.0183],\n",
      "        [-0.0044],\n",
      "        [ 0.0536],\n",
      "        [-0.0073],\n",
      "        [ 0.1008],\n",
      "        [-0.0846]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1397, 0.1401, 0.1429, 0.1455, 0.1435, 0.1407, 0.1381, 0.1385, 0.1339,\n",
      "        0.1353, 0.1328, 0.1354, 0.1350, 0.1384, 0.1376, 0.1372, 0.1357, 0.1332,\n",
      "        0.1307, 0.1332, 0.1320, 0.1302, 0.1317, 0.1167, 0.1155, 0.1128, 0.1125,\n",
      "        0.1148, 0.1152, 0.1140, 0.1152, 0.1133], device='cuda:0')\n",
      "tensor([[-0.1909],\n",
      "        [ 0.0548],\n",
      "        [-0.0386],\n",
      "        [-0.0091],\n",
      "        [ 0.0077],\n",
      "        [ 0.0526],\n",
      "        [-0.0039],\n",
      "        [ 0.0285],\n",
      "        [-0.0313],\n",
      "        [ 0.0211],\n",
      "        [ 0.0031],\n",
      "        [ 0.0346],\n",
      "        [ 0.0087],\n",
      "        [ 0.0993],\n",
      "        [-0.0065],\n",
      "        [ 0.0415],\n",
      "        [ 0.0722],\n",
      "        [ 0.0065],\n",
      "        [ 0.1377],\n",
      "        [ 0.0712],\n",
      "        [ 0.0072],\n",
      "        [-0.0067],\n",
      "        [-0.0061],\n",
      "        [-0.0032],\n",
      "        [ 0.0180],\n",
      "        [ 0.0533],\n",
      "        [ 0.0584],\n",
      "        [-0.0329],\n",
      "        [ 0.0700],\n",
      "        [-0.0449],\n",
      "        [-0.0132],\n",
      "        [ 0.0356]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1145, 0.1143, 0.1148, 0.1137, 0.1142, 0.1121, 0.1121, 0.1114, 0.1088,\n",
      "        0.1069, 0.1097, 0.1105, 0.1103, 0.1100, 0.1088, 0.1087, 0.1086, 0.1083,\n",
      "        0.1075, 0.1046, 0.1024, 0.1035, 0.1057, 0.1031, 0.1028, 0.1010, 0.1032,\n",
      "        0.1057, 0.1028, 0.1057, 0.1059, 0.1021], device='cuda:0')\n",
      "tensor([[ 0.0198],\n",
      "        [ 0.0260],\n",
      "        [-0.0348],\n",
      "        [ 0.0957],\n",
      "        [ 0.0560],\n",
      "        [ 0.0267],\n",
      "        [ 0.0526],\n",
      "        [-0.0145],\n",
      "        [ 0.0810],\n",
      "        [ 0.0364],\n",
      "        [ 0.0244],\n",
      "        [ 0.0198],\n",
      "        [ 0.0717],\n",
      "        [ 0.0314],\n",
      "        [ 0.0102],\n",
      "        [ 0.1319],\n",
      "        [ 0.0691],\n",
      "        [ 0.0195],\n",
      "        [ 0.0063],\n",
      "        [-0.0063],\n",
      "        [ 0.0146],\n",
      "        [-0.0231],\n",
      "        [-0.0116],\n",
      "        [ 0.0356],\n",
      "        [ 0.0043],\n",
      "        [ 0.0300],\n",
      "        [-0.0494],\n",
      "        [ 0.0134],\n",
      "        [-0.0061],\n",
      "        [ 0.1913],\n",
      "        [ 0.0472],\n",
      "        [-0.0045]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1037, 0.1032, 0.1026, 0.1006, 0.1043, 0.1043, 0.1047, 0.1049, 0.1037,\n",
      "        0.1040, 0.1060, 0.1063, 0.1047, 0.1026, 0.1024, 0.1012, 0.1016, 0.1015,\n",
      "        0.1006, 0.0995, 0.0993, 0.0982, 0.0998, 0.1000, 0.0978, 0.0984, 0.0969,\n",
      "        0.0981, 0.0972, 0.0960, 0.0954, 0.0969], device='cuda:0')\n",
      "tensor([[ 0.0639],\n",
      "        [ 0.0963],\n",
      "        [ 0.0860],\n",
      "        [ 0.0101],\n",
      "        [ 0.0005],\n",
      "        [ 0.0277],\n",
      "        [ 0.0360],\n",
      "        [ 0.0055],\n",
      "        [ 0.1057],\n",
      "        [ 0.0007],\n",
      "        [ 0.0146],\n",
      "        [-0.0195],\n",
      "        [ 0.0391],\n",
      "        [ 0.0059],\n",
      "        [-0.0204],\n",
      "        [-0.0120],\n",
      "        [ 0.0845],\n",
      "        [ 0.1337],\n",
      "        [-0.0193],\n",
      "        [ 0.0766],\n",
      "        [ 0.1236],\n",
      "        [ 0.0110],\n",
      "        [-0.0172],\n",
      "        [-0.0313],\n",
      "        [ 0.0258],\n",
      "        [-0.0117],\n",
      "        [ 0.0110],\n",
      "        [ 0.0325],\n",
      "        [-0.0407],\n",
      "        [-0.0148],\n",
      "        [ 0.0976],\n",
      "        [ 0.0376]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0978, 0.0966, 0.0972, 0.0994, 0.0982, 0.0973, 0.0967, 0.0981, 0.0979,\n",
      "        0.0948, 0.0944, 0.0967, 0.0994, 0.1012, 0.0995, 0.0997, 0.0994, 0.0994,\n",
      "        0.1004, 0.1007, 0.1003, 0.1003, 0.0993, 0.1000, 0.0993, 0.0976, 0.0979,\n",
      "        0.0975, 0.0972, 0.0976, 0.0970, 0.0969], device='cuda:0')\n",
      "tensor([[-0.0074],\n",
      "        [ 0.1291],\n",
      "        [ 0.0560],\n",
      "        [ 0.0660],\n",
      "        [ 0.0362],\n",
      "        [ 0.0928],\n",
      "        [ 0.0137],\n",
      "        [ 0.0817],\n",
      "        [ 0.0432],\n",
      "        [ 0.0692],\n",
      "        [-0.0124],\n",
      "        [-0.0516],\n",
      "        [-0.0336],\n",
      "        [-0.0421],\n",
      "        [ 0.0174],\n",
      "        [ 0.0378],\n",
      "        [ 0.0232],\n",
      "        [-0.0249],\n",
      "        [ 0.0418],\n",
      "        [ 0.0239],\n",
      "        [ 0.0423],\n",
      "        [ 0.0448],\n",
      "        [ 0.0509],\n",
      "        [ 0.2034],\n",
      "        [ 0.1232],\n",
      "        [ 0.0202],\n",
      "        [ 0.0974],\n",
      "        [ 0.1340],\n",
      "        [ 0.0387],\n",
      "        [ 0.0299],\n",
      "        [ 0.0223],\n",
      "        [ 0.0101]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0947, 0.0929, 0.0938, 0.0936, 0.0922, 0.0928, 0.0931, 0.0932, 0.0923,\n",
      "        0.0935, 0.0951, 0.0964, 0.0972, 0.0967, 0.0981, 0.1000, 0.0984, 0.1004,\n",
      "        0.1035, 0.1022, 0.1031, 0.1046, 0.1052, 0.1046, 0.1038, 0.1043, 0.1057,\n",
      "        0.1047, 0.1046, 0.1015, 0.1031, 0.1019], device='cuda:0')\n",
      "tensor([[ 0.0133],\n",
      "        [ 0.0580],\n",
      "        [ 0.0480],\n",
      "        [-0.0150],\n",
      "        [-0.0396],\n",
      "        [ 0.0576],\n",
      "        [ 0.0093],\n",
      "        [ 0.0750],\n",
      "        [ 0.0241],\n",
      "        [ 0.0252],\n",
      "        [ 0.0465],\n",
      "        [ 0.0082],\n",
      "        [ 0.0394],\n",
      "        [-0.0558],\n",
      "        [ 0.0977],\n",
      "        [ 0.1457],\n",
      "        [ 0.0253],\n",
      "        [ 0.0443],\n",
      "        [ 0.0268],\n",
      "        [-0.0073],\n",
      "        [ 0.0164],\n",
      "        [ 0.0262],\n",
      "        [ 0.0483],\n",
      "        [ 0.0077],\n",
      "        [ 0.0164],\n",
      "        [ 0.0329],\n",
      "        [-0.0010],\n",
      "        [ 0.0224],\n",
      "        [ 0.0209],\n",
      "        [ 0.0397],\n",
      "        [ 0.0022],\n",
      "        [-0.0258]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1001, 0.0976, 0.0967, 0.0975, 0.0964, 0.0956, 0.0985, 0.0987, 0.1003,\n",
      "        0.1038, 0.1007, 0.0987, 0.0993, 0.0991, 0.0970, 0.0970, 0.0967, 0.0964,\n",
      "        0.0967, 0.0975, 0.0991, 0.0967, 0.0969, 0.0953, 0.0948, 0.0948, 0.0987,\n",
      "        0.0991, 0.0990, 0.0981, 0.0975, 0.0988], device='cuda:0')\n",
      "tensor([[ 0.0213],\n",
      "        [ 0.0502],\n",
      "        [ 0.0301],\n",
      "        [ 0.0364],\n",
      "        [-0.0041],\n",
      "        [-0.0158],\n",
      "        [ 0.0111],\n",
      "        [ 0.0102],\n",
      "        [ 0.0381],\n",
      "        [ 0.0363],\n",
      "        [ 0.0135],\n",
      "        [ 0.0471],\n",
      "        [ 0.1545],\n",
      "        [ 0.0160],\n",
      "        [ 0.0378],\n",
      "        [ 0.0164],\n",
      "        [ 0.0706],\n",
      "        [ 0.0560],\n",
      "        [-0.0215],\n",
      "        [ 0.0018],\n",
      "        [ 0.0504],\n",
      "        [ 0.0627],\n",
      "        [ 0.0659],\n",
      "        [ 0.0237],\n",
      "        [ 0.0130],\n",
      "        [-0.0027],\n",
      "        [ 0.0136],\n",
      "        [ 0.0387],\n",
      "        [ 0.0309],\n",
      "        [ 0.0542],\n",
      "        [ 0.1724],\n",
      "        [ 0.0772]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0944, 0.0956, 0.0947, 0.0935, 0.0933, 0.0926, 0.0931, 0.0963, 0.0920,\n",
      "        0.0900, 0.0897, 0.0885, 0.0870, 0.0873, 0.0858, 0.0812, 0.0826, 0.0843,\n",
      "        0.0854, 0.0846, 0.0833, 0.0817, 0.0826, 0.0810, 0.0820, 0.0849, 0.0849,\n",
      "        0.0849, 0.0863, 0.0874, 0.0858, 0.0873], device='cuda:0')\n",
      "tensor([[ 0.0226],\n",
      "        [-0.0362],\n",
      "        [ 0.0959],\n",
      "        [ 0.0079],\n",
      "        [ 0.0420],\n",
      "        [ 0.0428],\n",
      "        [ 0.0752],\n",
      "        [ 0.0421],\n",
      "        [ 0.0236],\n",
      "        [ 0.0304],\n",
      "        [ 0.0152],\n",
      "        [ 0.0424],\n",
      "        [ 0.0363],\n",
      "        [-0.0304],\n",
      "        [ 0.0497],\n",
      "        [ 0.1263],\n",
      "        [ 0.0530],\n",
      "        [ 0.0130],\n",
      "        [-0.0156],\n",
      "        [-0.0378],\n",
      "        [ 0.0682],\n",
      "        [-0.0106],\n",
      "        [ 0.0292],\n",
      "        [ 0.0151],\n",
      "        [ 0.0841],\n",
      "        [-0.0069],\n",
      "        [ 0.0939],\n",
      "        [ 0.0354],\n",
      "        [-0.0061],\n",
      "        [ 0.0834],\n",
      "        [ 0.0664],\n",
      "        [ 0.0939]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0874, 0.0897, 0.0925, 0.0898, 0.0885, 0.0880, 0.0873, 0.0898, 0.0933,\n",
      "        0.0935, 0.0945, 0.0932, 0.0904, 0.0936, 0.0911, 0.0907, 0.0914, 0.0908,\n",
      "        0.0892, 0.0891, 0.0870, 0.0886, 0.0897, 0.0885, 0.0869, 0.0861, 0.0867,\n",
      "        0.0873, 0.0895, 0.0879, 0.0867, 0.0866], device='cuda:0')\n",
      "tensor([[-0.0084],\n",
      "        [ 0.1422],\n",
      "        [ 0.0239],\n",
      "        [ 0.0316],\n",
      "        [ 0.0158],\n",
      "        [-0.0031],\n",
      "        [ 0.0450],\n",
      "        [ 0.0197],\n",
      "        [-0.0089],\n",
      "        [ 0.0103],\n",
      "        [ 0.0627],\n",
      "        [ 0.0149],\n",
      "        [ 0.0769],\n",
      "        [ 0.0274],\n",
      "        [ 0.0371],\n",
      "        [ 0.0116],\n",
      "        [-0.0153],\n",
      "        [ 0.0263],\n",
      "        [ 0.0179],\n",
      "        [ 0.0138],\n",
      "        [ 0.0226],\n",
      "        [ 0.0667],\n",
      "        [ 0.1386],\n",
      "        [ 0.0114],\n",
      "        [ 0.0669],\n",
      "        [-0.0354],\n",
      "        [-0.0270],\n",
      "        [ 0.0301],\n",
      "        [ 0.0596],\n",
      "        [ 0.0687],\n",
      "        [-0.0173],\n",
      "        [ 0.0869]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0866, 0.0867, 0.0869, 0.0863, 0.0849, 0.0849, 0.0843, 0.0833, 0.0840,\n",
      "        0.0849, 0.0839, 0.0830, 0.0827, 0.0839, 0.0845, 0.0843, 0.0860, 0.0866,\n",
      "        0.0855, 0.0842, 0.0840, 0.0821, 0.0824, 0.0818, 0.0814, 0.0812, 0.0801,\n",
      "        0.0790, 0.0792, 0.0793, 0.0786, 0.0779], device='cuda:0')\n",
      "tensor([[-0.0310],\n",
      "        [-0.0268],\n",
      "        [-0.0297],\n",
      "        [-0.0474],\n",
      "        [ 0.0415],\n",
      "        [-0.0604],\n",
      "        [ 0.0613],\n",
      "        [ 0.0427],\n",
      "        [ 0.0140],\n",
      "        [ 0.0345],\n",
      "        [ 0.0031],\n",
      "        [ 0.0272],\n",
      "        [ 0.1249],\n",
      "        [ 0.0521],\n",
      "        [ 0.0664],\n",
      "        [ 0.0372],\n",
      "        [ 0.0279],\n",
      "        [ 0.0230],\n",
      "        [-0.0117],\n",
      "        [-0.0304],\n",
      "        [ 0.0701],\n",
      "        [-0.0340],\n",
      "        [ 0.0098],\n",
      "        [ 0.0282],\n",
      "        [ 0.0059],\n",
      "        [ 0.0130],\n",
      "        [ 0.0451],\n",
      "        [ 0.0596],\n",
      "        [ 0.0511],\n",
      "        [ 0.0119],\n",
      "        [ 0.0167],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0773, 0.0789, 0.0780, 0.0810, 0.0812, 0.0823, 0.0840, 0.0849, 0.0852,\n",
      "        0.0854, 0.0864, 0.0870, 0.0871, 0.0861, 0.0848, 0.0848, 0.0852, 0.0848,\n",
      "        0.0879, 0.0877, 0.0900, 0.0916, 0.0910, 0.0914, 0.0907, 0.0916, 0.0911,\n",
      "        0.0898, 0.0891, 0.0889, 0.0879, 0.0900], device='cuda:0')\n",
      "tensor([[-0.0014],\n",
      "        [ 0.0640],\n",
      "        [ 0.0865],\n",
      "        [ 0.0460],\n",
      "        [ 0.0150],\n",
      "        [ 0.0255],\n",
      "        [ 0.0671],\n",
      "        [-0.0211],\n",
      "        [-0.0350],\n",
      "        [ 0.1101],\n",
      "        [ 0.0010],\n",
      "        [ 0.0354],\n",
      "        [-0.0148],\n",
      "        [ 0.0397],\n",
      "        [ 0.0425],\n",
      "        [-0.0166],\n",
      "        [ 0.0501],\n",
      "        [ 0.0254],\n",
      "        [ 0.0141],\n",
      "        [-0.0169],\n",
      "        [ 0.0291],\n",
      "        [ 0.1132],\n",
      "        [ 0.0249],\n",
      "        [ 0.0227],\n",
      "        [ 0.0111],\n",
      "        [ 0.0380],\n",
      "        [ 0.0291],\n",
      "        [ 0.0362],\n",
      "        [ 0.0862],\n",
      "        [ 0.1836],\n",
      "        [ 0.0301],\n",
      "        [ 0.0365]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0889, 0.0888, 0.0891, 0.0876, 0.0880, 0.0883, 0.0879, 0.0877, 0.0877,\n",
      "        0.0867, 0.0858, 0.0874, 0.0882, 0.0877, 0.0871, 0.0894, 0.0905, 0.0919,\n",
      "        0.0907, 0.0901, 0.0923, 0.0929, 0.0932, 0.0939, 0.0960, 0.0954, 0.0956,\n",
      "        0.0972, 0.0963, 0.0967, 0.0951, 0.0966], device='cuda:0')\n",
      "tensor([[ 0.1291],\n",
      "        [ 0.0951],\n",
      "        [ 0.0236],\n",
      "        [ 0.0168],\n",
      "        [ 0.0239],\n",
      "        [ 0.0082],\n",
      "        [ 0.0493],\n",
      "        [-0.0102],\n",
      "        [ 0.0532],\n",
      "        [ 0.0253],\n",
      "        [ 0.0518],\n",
      "        [ 0.0548],\n",
      "        [ 0.0898],\n",
      "        [-0.0227],\n",
      "        [ 0.0296],\n",
      "        [ 0.0668],\n",
      "        [ 0.1132],\n",
      "        [-0.0408],\n",
      "        [-0.0200],\n",
      "        [-0.0322],\n",
      "        [-0.0072],\n",
      "        [ 0.0281],\n",
      "        [ 0.0375],\n",
      "        [ 0.0133],\n",
      "        [ 0.0230],\n",
      "        [ 0.0098],\n",
      "        [ 0.0261],\n",
      "        [ 0.0194],\n",
      "        [ 0.0726],\n",
      "        [ 0.0002],\n",
      "        [ 0.0402],\n",
      "        [ 0.0154]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0950, 0.0963, 0.0959, 0.0960, 0.0963, 0.0963, 0.0979, 0.0991, 0.0929,\n",
      "        0.0904, 0.0914, 0.0900, 0.0902, 0.0902, 0.0898, 0.0914, 0.0922, 0.0933,\n",
      "        0.0926, 0.0928, 0.0920, 0.0889, 0.0849, 0.0836, 0.0852, 0.0846, 0.0851,\n",
      "        0.0848, 0.0851, 0.0854, 0.0846, 0.0830], device='cuda:0')\n",
      "tensor([[-0.0151],\n",
      "        [ 0.0074],\n",
      "        [ 0.0379],\n",
      "        [ 0.0420],\n",
      "        [-0.0037],\n",
      "        [ 0.0441],\n",
      "        [ 0.0650],\n",
      "        [ 0.1282],\n",
      "        [ 0.0241],\n",
      "        [-0.0192],\n",
      "        [ 0.0481],\n",
      "        [ 0.0319],\n",
      "        [-0.0109],\n",
      "        [ 0.0172],\n",
      "        [ 0.0143],\n",
      "        [-0.0046],\n",
      "        [ 0.0297],\n",
      "        [-0.0252],\n",
      "        [ 0.0097],\n",
      "        [ 0.0345],\n",
      "        [ 0.0246],\n",
      "        [ 0.1197],\n",
      "        [ 0.0053],\n",
      "        [ 0.1179],\n",
      "        [ 0.0298],\n",
      "        [ 0.0027],\n",
      "        [ 0.0535],\n",
      "        [ 0.0544],\n",
      "        [ 0.0017],\n",
      "        [ 0.0285],\n",
      "        [ 0.0247],\n",
      "        [-0.0059]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0821, 0.0823, 0.0812, 0.0836, 0.0827, 0.0839, 0.0838, 0.0830, 0.0842,\n",
      "        0.0840, 0.0830, 0.0823, 0.0824, 0.0833, 0.0840, 0.0846, 0.0851, 0.0817,\n",
      "        0.0789, 0.0796, 0.0793, 0.0804, 0.0790, 0.0795, 0.0781, 0.0779, 0.0784,\n",
      "        0.0764, 0.0761, 0.0753, 0.0734, 0.0739], device='cuda:0')\n",
      "tensor([[-0.0351],\n",
      "        [ 0.0085],\n",
      "        [ 0.0129],\n",
      "        [ 0.0235],\n",
      "        [ 0.0321],\n",
      "        [-0.0201],\n",
      "        [-0.0212],\n",
      "        [ 0.0137],\n",
      "        [-0.0129],\n",
      "        [-0.0439],\n",
      "        [-0.0065],\n",
      "        [ 0.0314],\n",
      "        [ 0.1775],\n",
      "        [ 0.0830],\n",
      "        [ 0.0006],\n",
      "        [ 0.0294],\n",
      "        [ 0.0515],\n",
      "        [ 0.0826],\n",
      "        [ 0.0243],\n",
      "        [-0.0010],\n",
      "        [ 0.0188],\n",
      "        [ 0.0356],\n",
      "        [-0.0046],\n",
      "        [-0.0102],\n",
      "        [ 0.0678],\n",
      "        [ 0.0341],\n",
      "        [ 0.0762],\n",
      "        [ 0.0522],\n",
      "        [ 0.0483],\n",
      "        [ 0.0188],\n",
      "        [ 0.0086],\n",
      "        [ 0.0037]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0749, 0.0733, 0.0745, 0.0734, 0.0734, 0.0737, 0.0728, 0.0668, 0.0643,\n",
      "        0.0616, 0.0615, 0.0616, 0.0616, 0.0624, 0.0604, 0.0584, 0.0600, 0.0587,\n",
      "        0.0597, 0.0621, 0.0624, 0.0613, 0.0585, 0.0590, 0.0604, 0.0585, 0.0575,\n",
      "        0.0564, 0.0573, 0.0573, 0.0566, 0.0553], device='cuda:0')\n",
      "tensor([[ 0.0351],\n",
      "        [-0.0016],\n",
      "        [-0.0526],\n",
      "        [-0.0009],\n",
      "        [ 0.0530],\n",
      "        [-0.0274],\n",
      "        [ 0.0411],\n",
      "        [ 0.0163],\n",
      "        [ 0.0135],\n",
      "        [ 0.0053],\n",
      "        [ 0.0484],\n",
      "        [ 0.0274],\n",
      "        [ 0.0884],\n",
      "        [ 0.0749],\n",
      "        [ 0.0083],\n",
      "        [ 0.0403],\n",
      "        [ 0.0223],\n",
      "        [ 0.0145],\n",
      "        [ 0.0991],\n",
      "        [-0.0761],\n",
      "        [-0.0499],\n",
      "        [-0.0549],\n",
      "        [ 0.0320],\n",
      "        [ 0.1970],\n",
      "        [ 0.0673],\n",
      "        [ 0.0132],\n",
      "        [ 0.0963],\n",
      "        [ 0.0563],\n",
      "        [ 0.0527],\n",
      "        [-0.0406],\n",
      "        [-0.0093],\n",
      "        [ 0.0468]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0531, 0.0542, 0.0554, 0.0573, 0.0579, 0.0587, 0.0613, 0.0607, 0.0609,\n",
      "        0.0601, 0.0598, 0.0585, 0.0579, 0.0547, 0.0536, 0.0544, 0.0550, 0.0470,\n",
      "        0.0420, 0.0433, 0.0414, 0.0384, 0.0418, 0.0412, 0.0430, 0.0418, 0.0395,\n",
      "        0.0399, 0.0402, 0.0399, 0.0384, 0.0374], device='cuda:0')\n",
      "tensor([[ 0.0835],\n",
      "        [-0.0198],\n",
      "        [ 0.0066],\n",
      "        [-0.0019],\n",
      "        [ 0.1295],\n",
      "        [ 0.0548],\n",
      "        [ 0.0035],\n",
      "        [ 0.0257],\n",
      "        [ 0.0724],\n",
      "        [ 0.0261],\n",
      "        [ 0.0723],\n",
      "        [ 0.0306],\n",
      "        [-0.0007],\n",
      "        [ 0.0976],\n",
      "        [ 0.0312],\n",
      "        [ 0.0504],\n",
      "        [-0.0019],\n",
      "        [ 0.0063],\n",
      "        [ 0.0931],\n",
      "        [ 0.0352],\n",
      "        [ 0.0476],\n",
      "        [ 0.0020],\n",
      "        [-0.0112],\n",
      "        [ 0.0502],\n",
      "        [ 0.0439],\n",
      "        [-0.0466],\n",
      "        [-0.0275],\n",
      "        [-0.0446],\n",
      "        [ 0.0032],\n",
      "        [ 0.0784],\n",
      "        [-0.0417],\n",
      "        [ 0.0791]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0362, 0.0356, 0.0371, 0.0383, 0.0371, 0.0383, 0.0377, 0.0392, 0.0379,\n",
      "        0.0361, 0.0355, 0.0381, 0.0384, 0.0386, 0.0393, 0.0401, 0.0415, 0.0429,\n",
      "        0.0423, 0.0411, 0.0414, 0.0421, 0.0432, 0.0438, 0.0424, 0.0411, 0.0407,\n",
      "        0.0398, 0.0404, 0.0404, 0.0404, 0.0412], device='cuda:0')\n",
      "tensor([[ 0.0223],\n",
      "        [ 0.0306],\n",
      "        [ 0.0001],\n",
      "        [ 0.0314],\n",
      "        [-0.0215],\n",
      "        [-0.0248],\n",
      "        [ 0.0279],\n",
      "        [ 0.0886],\n",
      "        [ 0.1005],\n",
      "        [ 0.0863],\n",
      "        [ 0.0460],\n",
      "        [ 0.0621],\n",
      "        [ 0.0389],\n",
      "        [ 0.0668],\n",
      "        [ 0.0925],\n",
      "        [ 0.0133],\n",
      "        [ 0.0801],\n",
      "        [ 0.0097],\n",
      "        [ 0.0111],\n",
      "        [ 0.0475],\n",
      "        [ 0.0276],\n",
      "        [ 0.0677],\n",
      "        [-0.0155],\n",
      "        [-0.0002],\n",
      "        [ 0.0726],\n",
      "        [-0.0045],\n",
      "        [-0.0120],\n",
      "        [ 0.0333],\n",
      "        [-0.0132],\n",
      "        [ 0.0480],\n",
      "        [ 0.0025],\n",
      "        [-0.0159]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0411, 0.0420, 0.0442, 0.0449, 0.0454, 0.0448, 0.0460, 0.0455, 0.0460,\n",
      "        0.0470, 0.0476, 0.0467, 0.0455, 0.0464, 0.0457, 0.0458, 0.0451, 0.0452,\n",
      "        0.0442, 0.0440, 0.0448, 0.0411, 0.0404, 0.0414, 0.0418, 0.0398, 0.0408,\n",
      "        0.0420, 0.0429, 0.0429, 0.0421, 0.0424], device='cuda:0')\n",
      "tensor([[ 0.0577],\n",
      "        [ 0.1433],\n",
      "        [ 0.0065],\n",
      "        [-0.0104],\n",
      "        [ 0.0156],\n",
      "        [ 0.0237],\n",
      "        [-0.0017],\n",
      "        [ 0.0266],\n",
      "        [ 0.0199],\n",
      "        [ 0.1064],\n",
      "        [ 0.0309],\n",
      "        [ 0.0140],\n",
      "        [ 0.0500],\n",
      "        [ 0.0233],\n",
      "        [ 0.0518],\n",
      "        [ 0.0364],\n",
      "        [-0.0046],\n",
      "        [-0.0034],\n",
      "        [ 0.2374],\n",
      "        [ 0.0066],\n",
      "        [ 0.0150],\n",
      "        [ 0.0465],\n",
      "        [ 0.0169],\n",
      "        [-0.0166],\n",
      "        [-0.0225],\n",
      "        [ 0.0240],\n",
      "        [ 0.0171],\n",
      "        [-0.0069],\n",
      "        [-0.0012],\n",
      "        [ 0.0570],\n",
      "        [-0.0218],\n",
      "        [ 0.0748]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0401, 0.0410, 0.0390, 0.0386, 0.0383, 0.0386, 0.0389, 0.0405, 0.0387,\n",
      "        0.0380, 0.0371, 0.0379, 0.0379, 0.0396, 0.0384, 0.0381, 0.0389, 0.0389,\n",
      "        0.0390, 0.0377, 0.0381, 0.0384, 0.0384, 0.0374, 0.0368, 0.0373, 0.0370,\n",
      "        0.0386, 0.0393, 0.0389, 0.0379, 0.0395], device='cuda:0')\n",
      "tensor([[ 0.0388],\n",
      "        [ 0.0455],\n",
      "        [ 0.0153],\n",
      "        [ 0.0200],\n",
      "        [ 0.0064],\n",
      "        [ 0.1195],\n",
      "        [ 0.2276],\n",
      "        [ 0.1691],\n",
      "        [ 0.0947],\n",
      "        [ 0.0665],\n",
      "        [ 0.0827],\n",
      "        [ 0.0320],\n",
      "        [-0.0031],\n",
      "        [-0.0083],\n",
      "        [ 0.0270],\n",
      "        [-0.0034],\n",
      "        [ 0.0104],\n",
      "        [ 0.0140],\n",
      "        [ 0.0027],\n",
      "        [ 0.0556],\n",
      "        [-0.0101],\n",
      "        [ 0.1141],\n",
      "        [ 0.0713],\n",
      "        [ 0.0574],\n",
      "        [-0.0190],\n",
      "        [ 0.0940],\n",
      "        [-0.0319],\n",
      "        [ 0.0216],\n",
      "        [ 0.0193],\n",
      "        [ 0.0153],\n",
      "        [ 0.0065],\n",
      "        [-0.0124]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0402, 0.0430, 0.0436, 0.0430, 0.0421, 0.0443, 0.0443, 0.0445, 0.0424,\n",
      "        0.0424, 0.0432, 0.0427, 0.0427, 0.0421, 0.0396, 0.0402, 0.0393, 0.0390,\n",
      "        0.0389, 0.0389, 0.0381, 0.0383, 0.0395, 0.0402, 0.0390, 0.0390, 0.0389,\n",
      "        0.0377, 0.0361, 0.0358, 0.0358, 0.0358], device='cuda:0')\n",
      "tensor([[ 0.0320],\n",
      "        [ 0.0306],\n",
      "        [ 0.0512],\n",
      "        [-0.0229],\n",
      "        [ 0.0014],\n",
      "        [ 0.0251],\n",
      "        [ 0.0243],\n",
      "        [ 0.0152],\n",
      "        [ 0.0165],\n",
      "        [ 0.0427],\n",
      "        [ 0.0581],\n",
      "        [ 0.1732],\n",
      "        [ 0.0155],\n",
      "        [-0.0019],\n",
      "        [-0.0168],\n",
      "        [ 0.0729],\n",
      "        [ 0.2107],\n",
      "        [ 0.1877],\n",
      "        [ 0.0138],\n",
      "        [ 0.0267],\n",
      "        [ 0.0214],\n",
      "        [ 0.0514],\n",
      "        [ 0.0347],\n",
      "        [ 0.0074],\n",
      "        [ 0.0145],\n",
      "        [-0.0010],\n",
      "        [ 0.0095],\n",
      "        [ 0.0347],\n",
      "        [ 0.0263],\n",
      "        [ 0.0026],\n",
      "        [ 0.0478],\n",
      "        [ 0.0648]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0376, 0.0370, 0.0367, 0.0368, 0.0346, 0.0322, 0.0314, 0.0322, 0.0319,\n",
      "        0.0306, 0.0308, 0.0346, 0.0327, 0.0325, 0.0333, 0.0325, 0.0319, 0.0331,\n",
      "        0.0324, 0.0319, 0.0317, 0.0318, 0.0306, 0.0300, 0.0299, 0.0291, 0.0315,\n",
      "        0.0312, 0.0315, 0.0317, 0.0331, 0.0325], device='cuda:0')\n",
      "tensor([[ 0.0122],\n",
      "        [ 0.0162],\n",
      "        [ 0.0510],\n",
      "        [ 0.0069],\n",
      "        [ 0.0303],\n",
      "        [ 0.0360],\n",
      "        [ 0.0706],\n",
      "        [ 0.0108],\n",
      "        [-0.0177],\n",
      "        [ 0.0875],\n",
      "        [ 0.0279],\n",
      "        [ 0.0942],\n",
      "        [ 0.0333],\n",
      "        [ 0.0368],\n",
      "        [ 0.0006],\n",
      "        [ 0.0326],\n",
      "        [ 0.1144],\n",
      "        [-0.0260],\n",
      "        [ 0.1379],\n",
      "        [-0.0135],\n",
      "        [-0.0500],\n",
      "        [ 0.0707],\n",
      "        [ 0.0538],\n",
      "        [ 0.0550],\n",
      "        [ 0.0337],\n",
      "        [ 0.0010],\n",
      "        [ 0.0418],\n",
      "        [ 0.0081],\n",
      "        [ 0.0281],\n",
      "        [ 0.0724],\n",
      "        [ 0.0437],\n",
      "        [ 0.1353]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0327, 0.0327, 0.0328, 0.0334, 0.0348, 0.0349, 0.0350, 0.0348, 0.0345,\n",
      "        0.0331, 0.0331, 0.0324, 0.0325, 0.0321, 0.0322, 0.0321, 0.0319, 0.0306,\n",
      "        0.0305, 0.0302, 0.0302, 0.0300, 0.0300, 0.0300, 0.0299, 0.0303, 0.0325,\n",
      "        0.0330, 0.0324, 0.0327, 0.0327, 0.0330], device='cuda:0')\n",
      "tensor([[ 0.0218],\n",
      "        [ 0.0552],\n",
      "        [-0.0513],\n",
      "        [-0.0523],\n",
      "        [-0.0226],\n",
      "        [ 0.0248],\n",
      "        [ 0.0234],\n",
      "        [-0.0193],\n",
      "        [-0.0558],\n",
      "        [ 0.0213],\n",
      "        [ 0.0152],\n",
      "        [ 0.1022],\n",
      "        [-0.0362],\n",
      "        [ 0.0113],\n",
      "        [ 0.0044],\n",
      "        [ 0.0409],\n",
      "        [ 0.0815],\n",
      "        [ 0.0980],\n",
      "        [ 0.0220],\n",
      "        [-0.0126],\n",
      "        [ 0.0986],\n",
      "        [ 0.2215],\n",
      "        [ 0.2117],\n",
      "        [ 0.0170],\n",
      "        [ 0.0675],\n",
      "        [ 0.0034],\n",
      "        [-0.0463],\n",
      "        [ 0.0243],\n",
      "        [ 0.0198],\n",
      "        [ 0.0366],\n",
      "        [-0.0083],\n",
      "        [ 0.0776]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0328, 0.0324, 0.0317, 0.0311, 0.0333, 0.0327, 0.0319, 0.0322, 0.0339,\n",
      "        0.0333, 0.0337, 0.0353, 0.0350, 0.0348, 0.0350, 0.0371, 0.0408, 0.0407,\n",
      "        0.0395, 0.0396, 0.0401, 0.0387, 0.0396, 0.0421, 0.0417, 0.0410, 0.0430,\n",
      "        0.0420, 0.0430, 0.0420, 0.0421, 0.0435], device='cuda:0')\n",
      "tensor([[ 0.0403],\n",
      "        [ 0.0300],\n",
      "        [ 0.0654],\n",
      "        [ 0.0417],\n",
      "        [ 0.0050],\n",
      "        [ 0.1193],\n",
      "        [-0.0154],\n",
      "        [ 0.0284],\n",
      "        [ 0.0200],\n",
      "        [ 0.0499],\n",
      "        [ 0.0701],\n",
      "        [ 0.0601],\n",
      "        [ 0.0522],\n",
      "        [-0.0249],\n",
      "        [ 0.0032],\n",
      "        [-0.0161],\n",
      "        [ 0.0900],\n",
      "        [-0.0168],\n",
      "        [ 0.0152],\n",
      "        [ 0.0211],\n",
      "        [ 0.0928],\n",
      "        [ 0.1146],\n",
      "        [ 0.0378],\n",
      "        [ 0.0308],\n",
      "        [ 0.0188],\n",
      "        [-0.0323],\n",
      "        [ 0.0005],\n",
      "        [-0.0302],\n",
      "        [-0.0357],\n",
      "        [-0.0219],\n",
      "        [ 0.1188],\n",
      "        [-0.0174]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0458, 0.0466, 0.0449, 0.0443, 0.0435, 0.0442, 0.0439, 0.0442, 0.0442,\n",
      "        0.0443, 0.0440, 0.0460, 0.0485, 0.0470, 0.0479, 0.0486, 0.0513, 0.0497,\n",
      "        0.0500, 0.0507, 0.0500, 0.0505, 0.0497, 0.0494, 0.0480, 0.0474, 0.0488,\n",
      "        0.0504, 0.0510, 0.0498, 0.0502, 0.0507], device='cuda:0')\n",
      "tensor([[ 0.0037],\n",
      "        [ 0.0630],\n",
      "        [ 0.0732],\n",
      "        [ 0.0026],\n",
      "        [ 0.0482],\n",
      "        [ 0.0101],\n",
      "        [ 0.0206],\n",
      "        [-0.0082],\n",
      "        [-0.0229],\n",
      "        [ 0.0206],\n",
      "        [-0.0167],\n",
      "        [ 0.0820],\n",
      "        [ 0.0927],\n",
      "        [ 0.0061],\n",
      "        [ 0.1662],\n",
      "        [-0.0384],\n",
      "        [ 0.0621],\n",
      "        [ 0.0223],\n",
      "        [-0.0107],\n",
      "        [ 0.0247],\n",
      "        [ 0.0141],\n",
      "        [ 0.0020],\n",
      "        [ 0.0452],\n",
      "        [ 0.0229],\n",
      "        [ 0.0176],\n",
      "        [ 0.0504],\n",
      "        [ 0.0171],\n",
      "        [ 0.0688],\n",
      "        [ 0.0356],\n",
      "        [-0.0018],\n",
      "        [ 0.0453],\n",
      "        [-0.0196]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0500, 0.0494, 0.0501, 0.0500, 0.0486, 0.0482, 0.0469, 0.0460, 0.0460,\n",
      "        0.0500, 0.0495, 0.0473, 0.0482, 0.0489, 0.0474, 0.0474, 0.0473, 0.0466,\n",
      "        0.0421, 0.0448, 0.0440, 0.0435, 0.0432, 0.0436, 0.0445, 0.0451, 0.0452,\n",
      "        0.0430, 0.0429, 0.0440, 0.0439, 0.0432], device='cuda:0')\n",
      "tensor([[ 0.0219],\n",
      "        [ 0.0074],\n",
      "        [-0.0275],\n",
      "        [ 0.0288],\n",
      "        [-0.0229],\n",
      "        [ 0.0540],\n",
      "        [-0.0271],\n",
      "        [ 0.0367],\n",
      "        [ 0.0248],\n",
      "        [-0.0187],\n",
      "        [ 0.0009],\n",
      "        [-0.0068],\n",
      "        [ 0.0029],\n",
      "        [ 0.0390],\n",
      "        [ 0.1059],\n",
      "        [-0.0011],\n",
      "        [ 0.1077],\n",
      "        [ 0.0475],\n",
      "        [ 0.0335],\n",
      "        [ 0.0811],\n",
      "        [ 0.0179],\n",
      "        [ 0.0568],\n",
      "        [ 0.0262],\n",
      "        [-0.0175],\n",
      "        [ 0.0440],\n",
      "        [ 0.1134],\n",
      "        [ 0.0168],\n",
      "        [ 0.1493],\n",
      "        [ 0.0329],\n",
      "        [ 0.0687],\n",
      "        [ 0.0155],\n",
      "        [ 0.0103]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0432, 0.0432, 0.0440, 0.0433, 0.0429, 0.0429, 0.0424, 0.0454, 0.0461,\n",
      "        0.0469, 0.0467, 0.0486, 0.0485, 0.0495, 0.0491, 0.0482, 0.0500, 0.0495,\n",
      "        0.0483, 0.0473, 0.0445, 0.0440, 0.0429, 0.0439, 0.0452, 0.0433, 0.0438,\n",
      "        0.0435, 0.0435, 0.0427, 0.0433, 0.0432], device='cuda:0')\n",
      "tensor([[-0.0182],\n",
      "        [ 0.0411],\n",
      "        [ 0.0455],\n",
      "        [ 0.0361],\n",
      "        [-0.0070],\n",
      "        [ 0.0559],\n",
      "        [ 0.0278],\n",
      "        [ 0.0327],\n",
      "        [ 0.0342],\n",
      "        [-0.0330],\n",
      "        [-0.0252],\n",
      "        [ 0.2085],\n",
      "        [ 0.0404],\n",
      "        [ 0.0334],\n",
      "        [ 0.0158],\n",
      "        [-0.0090],\n",
      "        [ 0.0275],\n",
      "        [ 0.0447],\n",
      "        [-0.0292],\n",
      "        [-0.0239],\n",
      "        [-0.0253],\n",
      "        [ 0.0778],\n",
      "        [ 0.0341],\n",
      "        [ 0.0203],\n",
      "        [ 0.0183],\n",
      "        [-0.0444],\n",
      "        [-0.0417],\n",
      "        [-0.0388],\n",
      "        [ 0.0986],\n",
      "        [ 0.1914],\n",
      "        [ 0.0705],\n",
      "        [ 0.0169]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0426, 0.0443, 0.0433, 0.0438, 0.0438, 0.0424, 0.0497, 0.0501, 0.0507,\n",
      "        0.0498, 0.0482, 0.0486, 0.0492, 0.0497, 0.0489, 0.0482, 0.0474, 0.0480,\n",
      "        0.0492, 0.0483, 0.0483, 0.0486, 0.0498, 0.0531, 0.0525, 0.0532, 0.0541,\n",
      "        0.0536, 0.0553, 0.0559, 0.0563, 0.0559], device='cuda:0')\n",
      "tensor([[ 0.0992],\n",
      "        [ 0.0261],\n",
      "        [ 0.1608],\n",
      "        [ 0.0546],\n",
      "        [-0.0234],\n",
      "        [ 0.0512],\n",
      "        [ 0.0173],\n",
      "        [-0.0140],\n",
      "        [ 0.0110],\n",
      "        [ 0.0587],\n",
      "        [ 0.0277],\n",
      "        [ 0.0178],\n",
      "        [ 0.0088],\n",
      "        [ 0.0319],\n",
      "        [ 0.0589],\n",
      "        [ 0.1112],\n",
      "        [ 0.0311],\n",
      "        [ 0.0130],\n",
      "        [ 0.0479],\n",
      "        [ 0.0465],\n",
      "        [ 0.0030],\n",
      "        [-0.0185],\n",
      "        [ 0.0425],\n",
      "        [ 0.0098],\n",
      "        [ 0.0186],\n",
      "        [-0.0084],\n",
      "        [ 0.0044],\n",
      "        [ 0.0511],\n",
      "        [ 0.0238],\n",
      "        [ 0.0375],\n",
      "        [-0.0496],\n",
      "        [-0.0012]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0551, 0.0557, 0.0539, 0.0528, 0.0547, 0.0547, 0.0535, 0.0539, 0.0547,\n",
      "        0.0560, 0.0575, 0.0560, 0.0550, 0.0544, 0.0535, 0.0528, 0.0539, 0.0526,\n",
      "        0.0514, 0.0533, 0.0529, 0.0520, 0.0501, 0.0480, 0.0471, 0.0480, 0.0477,\n",
      "        0.0476, 0.0464, 0.0467, 0.0477, 0.0495], device='cuda:0')\n",
      "tensor([[ 0.0906],\n",
      "        [ 0.0446],\n",
      "        [-0.0561],\n",
      "        [ 0.0514],\n",
      "        [ 0.0021],\n",
      "        [ 0.0411],\n",
      "        [ 0.0250],\n",
      "        [-0.0220],\n",
      "        [ 0.0584],\n",
      "        [ 0.1332],\n",
      "        [ 0.1537],\n",
      "        [ 0.0177],\n",
      "        [ 0.0449],\n",
      "        [-0.0255],\n",
      "        [ 0.0116],\n",
      "        [-0.0022],\n",
      "        [ 0.0083],\n",
      "        [ 0.0072],\n",
      "        [-0.0302],\n",
      "        [-0.0035],\n",
      "        [-0.0216],\n",
      "        [-0.0273],\n",
      "        [ 0.0004],\n",
      "        [-0.0035],\n",
      "        [ 0.0282],\n",
      "        [-0.0153],\n",
      "        [-0.0329],\n",
      "        [-0.0200],\n",
      "        [ 0.0095],\n",
      "        [ 0.0608],\n",
      "        [ 0.1033],\n",
      "        [ 0.0824]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0479, 0.0479, 0.0464, 0.0467, 0.0544, 0.0532, 0.0542, 0.0544, 0.0545,\n",
      "        0.0542, 0.0538, 0.0550, 0.0542, 0.0551, 0.0553, 0.0544, 0.0554, 0.0569,\n",
      "        0.0564, 0.0570, 0.0560, 0.0567, 0.0570, 0.0573, 0.0590, 0.0612, 0.0607,\n",
      "        0.0606, 0.0603, 0.0626, 0.0634, 0.0626], device='cuda:0')\n",
      "tensor([[ 0.0238],\n",
      "        [ 0.0442],\n",
      "        [ 0.1414],\n",
      "        [-0.0369],\n",
      "        [ 0.0022],\n",
      "        [ 0.0050],\n",
      "        [ 0.0540],\n",
      "        [ 0.0328],\n",
      "        [ 0.0545],\n",
      "        [-0.0136],\n",
      "        [ 0.0126],\n",
      "        [ 0.0461],\n",
      "        [ 0.0387],\n",
      "        [-0.0484],\n",
      "        [ 0.0449],\n",
      "        [ 0.0026],\n",
      "        [ 0.0231],\n",
      "        [ 0.2013],\n",
      "        [ 0.0388],\n",
      "        [ 0.0364],\n",
      "        [ 0.0417],\n",
      "        [ 0.0365],\n",
      "        [ 0.0228],\n",
      "        [ 0.0815],\n",
      "        [-0.0267],\n",
      "        [-0.0235],\n",
      "        [ 0.0057],\n",
      "        [-0.0149],\n",
      "        [-0.0340],\n",
      "        [ 0.0719],\n",
      "        [ 0.0450],\n",
      "        [ 0.0945]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0626, 0.0616, 0.0609, 0.0601, 0.0604, 0.0604, 0.0609, 0.0601, 0.0609,\n",
      "        0.0625, 0.0631, 0.0631, 0.0646, 0.0638, 0.0637, 0.0628, 0.0629, 0.0624,\n",
      "        0.0622, 0.0622, 0.0616, 0.0628, 0.0629, 0.0621, 0.0615, 0.0624, 0.0619,\n",
      "        0.0647, 0.0652, 0.0653, 0.0671, 0.0660], device='cuda:0')\n",
      "tensor([[-0.0172],\n",
      "        [ 0.0314],\n",
      "        [ 0.1212],\n",
      "        [ 0.0626],\n",
      "        [ 0.0119],\n",
      "        [ 0.0429],\n",
      "        [ 0.0295],\n",
      "        [-0.0046],\n",
      "        [ 0.0868],\n",
      "        [ 0.1875],\n",
      "        [ 0.0639],\n",
      "        [-0.0140],\n",
      "        [ 0.0050],\n",
      "        [ 0.0058],\n",
      "        [ 0.0092],\n",
      "        [ 0.0118],\n",
      "        [-0.0142],\n",
      "        [ 0.0114],\n",
      "        [-0.0030],\n",
      "        [-0.0023],\n",
      "        [-0.0394],\n",
      "        [-0.0193],\n",
      "        [ 0.0764],\n",
      "        [ 0.0457],\n",
      "        [ 0.0064],\n",
      "        [ 0.0565],\n",
      "        [-0.0490],\n",
      "        [ 0.0476],\n",
      "        [-0.0573],\n",
      "        [-0.0138],\n",
      "        [ 0.0200],\n",
      "        [ 0.0387]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0671, 0.0672, 0.0687, 0.0697, 0.0693, 0.0688, 0.0669, 0.0680, 0.0686,\n",
      "        0.0683, 0.0706, 0.0687, 0.0680, 0.0684, 0.0675, 0.0647, 0.0656, 0.0669,\n",
      "        0.0681, 0.0657, 0.0662, 0.0668, 0.0671, 0.0666, 0.0671, 0.0672, 0.0668,\n",
      "        0.0631, 0.0634, 0.0643, 0.0641, 0.0641], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0353],\n",
      "        [-0.0055],\n",
      "        [ 0.0432],\n",
      "        [-0.0632],\n",
      "        [-0.0518],\n",
      "        [ 0.0269],\n",
      "        [-0.0539],\n",
      "        [-0.0017],\n",
      "        [ 0.0249],\n",
      "        [ 0.0235],\n",
      "        [ 0.0205],\n",
      "        [-0.0180],\n",
      "        [ 0.0518],\n",
      "        [ 0.0638],\n",
      "        [ 0.0619],\n",
      "        [ 0.0168],\n",
      "        [ 0.0450],\n",
      "        [ 0.0457],\n",
      "        [ 0.0318],\n",
      "        [ 0.0382],\n",
      "        [ 0.1490],\n",
      "        [ 0.1813],\n",
      "        [-0.0087],\n",
      "        [ 0.0735],\n",
      "        [ 0.0392],\n",
      "        [ 0.0269],\n",
      "        [-0.0343],\n",
      "        [-0.0432],\n",
      "        [ 0.0356],\n",
      "        [ 0.0680],\n",
      "        [ 0.0099],\n",
      "        [ 0.0777]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0643, 0.0628, 0.0650, 0.0650, 0.0653, 0.0649, 0.0635, 0.0652, 0.0641,\n",
      "        0.0631, 0.0637, 0.0640, 0.0635, 0.0653, 0.0643, 0.0677, 0.0675, 0.0675,\n",
      "        0.0684, 0.0669, 0.0686, 0.0675, 0.0678, 0.0686, 0.0681, 0.0694, 0.0699,\n",
      "        0.0712, 0.0705, 0.0705, 0.0709, 0.0722], device='cuda:0')\n",
      "tensor([[ 0.0417],\n",
      "        [ 0.0398],\n",
      "        [ 0.0210],\n",
      "        [ 0.0769],\n",
      "        [ 0.0773],\n",
      "        [ 0.0344],\n",
      "        [ 0.0767],\n",
      "        [ 0.0130],\n",
      "        [ 0.0674],\n",
      "        [ 0.0948],\n",
      "        [ 0.0383],\n",
      "        [-0.1402],\n",
      "        [-0.0267],\n",
      "        [ 0.0869],\n",
      "        [ 0.0799],\n",
      "        [-0.0395],\n",
      "        [ 0.0287],\n",
      "        [-0.0462],\n",
      "        [ 0.0693],\n",
      "        [-0.0360],\n",
      "        [-0.0147],\n",
      "        [-0.0263],\n",
      "        [ 0.0063],\n",
      "        [-0.0196],\n",
      "        [-0.0180],\n",
      "        [ 0.0286],\n",
      "        [ 0.0271],\n",
      "        [-0.0039],\n",
      "        [ 0.0605],\n",
      "        [-0.0122],\n",
      "        [-0.0252],\n",
      "        [ 0.0263]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0722, 0.0719, 0.0711, 0.0697, 0.0684, 0.0681, 0.0662, 0.0662, 0.0663,\n",
      "        0.0655, 0.0659, 0.0677, 0.0686, 0.0688, 0.0686, 0.0684, 0.0684, 0.0693,\n",
      "        0.0693, 0.0691, 0.0700, 0.0700, 0.0699, 0.0693, 0.0684, 0.0684, 0.0684,\n",
      "        0.0691, 0.0681, 0.0696, 0.0697, 0.0719], device='cuda:0')\n",
      "tensor([[ 0.1021],\n",
      "        [ 0.0958],\n",
      "        [-0.0205],\n",
      "        [ 0.0437],\n",
      "        [ 0.0002],\n",
      "        [ 0.1629],\n",
      "        [ 0.0532],\n",
      "        [ 0.0657],\n",
      "        [ 0.0629],\n",
      "        [ 0.0346],\n",
      "        [ 0.0331],\n",
      "        [ 0.0052],\n",
      "        [ 0.0122],\n",
      "        [-0.0285],\n",
      "        [ 0.0392],\n",
      "        [ 0.0595],\n",
      "        [ 0.0094],\n",
      "        [ 0.0256],\n",
      "        [ 0.0029],\n",
      "        [ 0.0165],\n",
      "        [ 0.0312],\n",
      "        [ 0.0203],\n",
      "        [-0.0473],\n",
      "        [ 0.0531],\n",
      "        [ 0.0390],\n",
      "        [ 0.1237],\n",
      "        [ 0.1240],\n",
      "        [ 0.0238],\n",
      "        [ 0.0022],\n",
      "        [-0.0412],\n",
      "        [ 0.0308],\n",
      "        [-0.0113]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0750, 0.0755, 0.0749, 0.0749, 0.0759, 0.0765, 0.0776, 0.0770, 0.0773,\n",
      "        0.0793, 0.0783, 0.0793, 0.0779, 0.0771, 0.0792, 0.0795, 0.0811, 0.0805,\n",
      "        0.0787, 0.0780, 0.0777, 0.0786, 0.0787, 0.0799, 0.0798, 0.0799, 0.0823,\n",
      "        0.0832, 0.0836, 0.0827, 0.0845, 0.0849], device='cuda:0')\n",
      "tensor([[-0.0023],\n",
      "        [-0.0201],\n",
      "        [-0.0416],\n",
      "        [-0.0018],\n",
      "        [ 0.0077],\n",
      "        [ 0.0144],\n",
      "        [ 0.0200],\n",
      "        [ 0.1218],\n",
      "        [ 0.0305],\n",
      "        [ 0.0944],\n",
      "        [ 0.1050],\n",
      "        [ 0.1272],\n",
      "        [ 0.0662],\n",
      "        [ 0.1177],\n",
      "        [ 0.0280],\n",
      "        [-0.0188],\n",
      "        [ 0.0216],\n",
      "        [ 0.0600],\n",
      "        [ 0.0217],\n",
      "        [-0.0065],\n",
      "        [-0.0174],\n",
      "        [-0.0172],\n",
      "        [ 0.0266],\n",
      "        [ 0.0602],\n",
      "        [-0.0116],\n",
      "        [-0.0116],\n",
      "        [ 0.0007],\n",
      "        [ 0.0703],\n",
      "        [-0.0362],\n",
      "        [ 0.0147],\n",
      "        [ 0.0535],\n",
      "        [ 0.0083]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0836, 0.0858, 0.0889, 0.0911, 0.0913, 0.0932, 0.0951, 0.0925, 0.0895,\n",
      "        0.0904, 0.0920, 0.0914, 0.0907, 0.0914, 0.0913, 0.0916, 0.0920, 0.0922,\n",
      "        0.0929, 0.0925, 0.0928, 0.0907, 0.0910, 0.0932, 0.0956, 0.0942, 0.0950,\n",
      "        0.0929, 0.0901, 0.0905, 0.0920, 0.0916], device='cuda:0')\n",
      "tensor([[-0.0053],\n",
      "        [ 0.0925],\n",
      "        [ 0.1467],\n",
      "        [-0.0222],\n",
      "        [ 0.0830],\n",
      "        [ 0.0735],\n",
      "        [-0.0008],\n",
      "        [ 0.0841],\n",
      "        [ 0.0612],\n",
      "        [ 0.0508],\n",
      "        [-0.0240],\n",
      "        [ 0.0391],\n",
      "        [ 0.0415],\n",
      "        [-0.0243],\n",
      "        [ 0.0216],\n",
      "        [-0.0115],\n",
      "        [ 0.1379],\n",
      "        [ 0.0504],\n",
      "        [ 0.1066],\n",
      "        [ 0.0451],\n",
      "        [ 0.0641],\n",
      "        [-0.0180],\n",
      "        [ 0.0109],\n",
      "        [-0.0168],\n",
      "        [ 0.0692],\n",
      "        [ 0.0115],\n",
      "        [-0.0034],\n",
      "        [ 0.0196],\n",
      "        [ 0.0333],\n",
      "        [-0.0163],\n",
      "        [ 0.0091],\n",
      "        [ 0.0252]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0885, 0.0886, 0.0869, 0.0863, 0.0860, 0.0873, 0.0891, 0.0905, 0.0905,\n",
      "        0.0901, 0.0914, 0.0962, 0.0954, 0.0959, 0.0972, 0.0967, 0.0933, 0.0942,\n",
      "        0.0953, 0.0941, 0.0960, 0.0950, 0.0975, 0.0982, 0.0995, 0.0985, 0.1007,\n",
      "        0.1032, 0.1034, 0.1074, 0.1071, 0.1003], device='cuda:0')\n",
      "tensor([[ 0.0651],\n",
      "        [ 0.0064],\n",
      "        [ 0.0849],\n",
      "        [ 0.2342],\n",
      "        [ 0.0444],\n",
      "        [-0.0041],\n",
      "        [ 0.0557],\n",
      "        [ 0.0423],\n",
      "        [ 0.1138],\n",
      "        [ 0.0153],\n",
      "        [ 0.0441],\n",
      "        [ 0.0153],\n",
      "        [-0.0104],\n",
      "        [ 0.0474],\n",
      "        [ 0.0500],\n",
      "        [ 0.0420],\n",
      "        [ 0.0119],\n",
      "        [-0.0278],\n",
      "        [ 0.0208],\n",
      "        [-0.0164],\n",
      "        [-0.0435],\n",
      "        [-0.0082],\n",
      "        [-0.0424],\n",
      "        [-0.0316],\n",
      "        [-0.0029],\n",
      "        [ 0.0095],\n",
      "        [ 0.0221],\n",
      "        [ 0.0104],\n",
      "        [ 0.0034],\n",
      "        [ 0.0572],\n",
      "        [-0.0279],\n",
      "        [-0.0083]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1037, 0.1031, 0.1077, 0.1087, 0.1094, 0.1115, 0.1114, 0.1093, 0.1102,\n",
      "        0.1077, 0.1094, 0.1090, 0.1093, 0.1102, 0.1105, 0.1096, 0.1097, 0.1115,\n",
      "        0.1130, 0.1134, 0.1149, 0.1122, 0.1068, 0.1078, 0.1066, 0.1046, 0.1034,\n",
      "        0.1007, 0.1016, 0.1007, 0.1028, 0.1021], device='cuda:0')\n",
      "tensor([[-0.0205],\n",
      "        [ 0.0785],\n",
      "        [ 0.0634],\n",
      "        [-0.0530],\n",
      "        [-0.0752],\n",
      "        [ 0.1095],\n",
      "        [ 0.0074],\n",
      "        [ 0.0018],\n",
      "        [ 0.0308],\n",
      "        [-0.0266],\n",
      "        [ 0.0758],\n",
      "        [ 0.5741],\n",
      "        [ 0.0789],\n",
      "        [ 0.0571],\n",
      "        [ 0.0311],\n",
      "        [ 0.0391],\n",
      "        [-0.0119],\n",
      "        [-0.0110],\n",
      "        [-0.0259],\n",
      "        [ 0.0118],\n",
      "        [ 0.0563],\n",
      "        [ 0.0807],\n",
      "        [ 0.0126],\n",
      "        [-0.0160],\n",
      "        [-0.0465],\n",
      "        [ 0.0091],\n",
      "        [-0.0531],\n",
      "        [-0.0092],\n",
      "        [-0.0327],\n",
      "        [-0.0383],\n",
      "        [ 0.1141],\n",
      "        [ 0.0167]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1001, 0.0997, 0.0981, 0.0975, 0.0945, 0.0959, 0.0925, 0.0910, 0.0897,\n",
      "        0.0919, 0.0950, 0.0938, 0.0922, 0.0916, 0.0902, 0.0904, 0.0922, 0.0916,\n",
      "        0.0923, 0.0911, 0.0928, 0.0914, 0.0923, 0.0919, 0.0894, 0.0879, 0.0900,\n",
      "        0.0905, 0.0900, 0.0917, 0.0951, 0.0945], device='cuda:0')\n",
      "tensor([[ 0.0605],\n",
      "        [-0.0175],\n",
      "        [ 0.0157],\n",
      "        [ 0.3387],\n",
      "        [ 0.0279],\n",
      "        [-0.0240],\n",
      "        [ 0.0370],\n",
      "        [ 0.0390],\n",
      "        [ 0.0352],\n",
      "        [ 0.0130],\n",
      "        [ 0.0042],\n",
      "        [-0.0207],\n",
      "        [ 0.0014],\n",
      "        [ 0.0362],\n",
      "        [-0.0136],\n",
      "        [ 0.0414],\n",
      "        [ 0.0146],\n",
      "        [ 0.0148],\n",
      "        [ 0.0376],\n",
      "        [ 0.0372],\n",
      "        [ 0.0122],\n",
      "        [ 0.0106],\n",
      "        [ 0.0362],\n",
      "        [ 0.0582],\n",
      "        [ 0.0781],\n",
      "        [ 0.0414],\n",
      "        [ 0.0494],\n",
      "        [ 0.0156],\n",
      "        [ 0.0232],\n",
      "        [ 0.0285],\n",
      "        [ 0.0240],\n",
      "        [-0.0393]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0967, 0.0933, 0.0976, 0.0964, 0.0942, 0.0939, 0.0947, 0.0967, 0.0956,\n",
      "        0.0951, 0.0984, 0.1006, 0.0994, 0.0973, 0.0962, 0.0969, 0.0957, 0.0957,\n",
      "        0.0933, 0.0935, 0.0936, 0.0931, 0.0905, 0.0923, 0.0932, 0.0939, 0.0939,\n",
      "        0.0953, 0.0954, 0.0948, 0.0926, 0.0942], device='cuda:0')\n",
      "tensor([[ 0.0681],\n",
      "        [ 0.0438],\n",
      "        [ 0.0046],\n",
      "        [ 0.0444],\n",
      "        [ 0.0138],\n",
      "        [-0.0258],\n",
      "        [ 0.0612],\n",
      "        [-0.0249],\n",
      "        [ 0.0144],\n",
      "        [ 0.0301],\n",
      "        [-0.0068],\n",
      "        [ 0.0190],\n",
      "        [ 0.0469],\n",
      "        [-0.0170],\n",
      "        [ 0.0027],\n",
      "        [ 0.0365],\n",
      "        [ 0.0651],\n",
      "        [ 0.0522],\n",
      "        [ 0.0127],\n",
      "        [ 0.0120],\n",
      "        [ 0.0098],\n",
      "        [-0.0370],\n",
      "        [ 0.0717],\n",
      "        [-0.0151],\n",
      "        [-0.0283],\n",
      "        [ 0.2696],\n",
      "        [ 0.0344],\n",
      "        [-0.0203],\n",
      "        [-0.0082],\n",
      "        [ 0.1102],\n",
      "        [ 0.0862],\n",
      "        [-0.0165]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0938, 0.0938, 0.0926, 0.0951, 0.0944, 0.0933, 0.0923, 0.0914, 0.0873,\n",
      "        0.0858, 0.0892, 0.0863, 0.0880, 0.0885, 0.0891, 0.0894, 0.0871, 0.0886,\n",
      "        0.0880, 0.0861, 0.0833, 0.0854, 0.0860, 0.0832, 0.0838, 0.0838, 0.0827,\n",
      "        0.0789, 0.0835, 0.0842, 0.0944, 0.1012], device='cuda:0')\n",
      "tensor([[-0.0232],\n",
      "        [ 0.0870],\n",
      "        [ 0.0795],\n",
      "        [ 0.1088],\n",
      "        [ 0.4032],\n",
      "        [ 0.0636],\n",
      "        [ 0.0089],\n",
      "        [ 0.1815],\n",
      "        [ 0.1057],\n",
      "        [ 0.0326],\n",
      "        [-0.0527],\n",
      "        [ 0.0459],\n",
      "        [ 0.0229],\n",
      "        [-0.0124],\n",
      "        [-0.0409],\n",
      "        [ 0.0209],\n",
      "        [-0.0022],\n",
      "        [ 0.0014],\n",
      "        [-0.0094],\n",
      "        [-0.0270],\n",
      "        [-0.0211],\n",
      "        [-0.0368],\n",
      "        [ 0.0561],\n",
      "        [ 0.0595],\n",
      "        [-0.0095],\n",
      "        [ 0.0127],\n",
      "        [-0.0165],\n",
      "        [ 0.0079],\n",
      "        [ 0.0047],\n",
      "        [ 0.0081],\n",
      "        [ 0.0131],\n",
      "        [ 0.0153]], device='cuda:0', grad_fn=<AddmmBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([0.1015, 0.1024, 0.1071, 0.1037, 0.1044, 0.1065, 0.1090, 0.1088, 0.1094,\n",
      "        0.1102, 0.1133, 0.1162, 0.1137, 0.1148, 0.1148, 0.1168, 0.1149, 0.1156,\n",
      "        0.1196, 0.1201, 0.1214, 0.1227, 0.1273, 0.1291, 0.1282, 0.1328, 0.1311,\n",
      "        0.1255, 0.1202, 0.1179, 0.1212, 0.1189], device='cuda:0')\n",
      "tensor([[ 0.0697],\n",
      "        [ 0.0428],\n",
      "        [-0.0544],\n",
      "        [ 0.0360],\n",
      "        [-0.0109],\n",
      "        [-0.0132],\n",
      "        [ 0.0497],\n",
      "        [ 0.0208],\n",
      "        [ 0.0438],\n",
      "        [ 0.0309],\n",
      "        [ 0.0100],\n",
      "        [ 0.0540],\n",
      "        [ 0.0745],\n",
      "        [ 0.0075],\n",
      "        [ 0.0665],\n",
      "        [ 0.0322],\n",
      "        [-0.0277],\n",
      "        [ 0.0936],\n",
      "        [ 0.0798],\n",
      "        [-0.0307],\n",
      "        [ 0.0636],\n",
      "        [ 0.0298],\n",
      "        [ 0.0362],\n",
      "        [ 0.1551],\n",
      "        [ 0.0492],\n",
      "        [ 0.0336],\n",
      "        [ 0.0162],\n",
      "        [ 0.0256],\n",
      "        [ 0.0085],\n",
      "        [ 0.0312],\n",
      "        [ 0.1880],\n",
      "        [-0.0173]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1190, 0.1156, 0.1192, 0.1156, 0.1176, 0.1187, 0.1223, 0.1279, 0.1245,\n",
      "        0.1189, 0.1164, 0.1156, 0.1091, 0.1115, 0.1121, 0.1103, 0.1121, 0.1111,\n",
      "        0.1196, 0.1221, 0.1198, 0.1217, 0.1199, 0.1177, 0.1195, 0.1124, 0.1155,\n",
      "        0.1171, 0.1050, 0.1053, 0.1052, 0.1074], device='cuda:0')\n",
      "tensor([[-0.0277],\n",
      "        [ 0.4989],\n",
      "        [ 0.1788],\n",
      "        [ 0.0619],\n",
      "        [ 0.0422],\n",
      "        [-0.0657],\n",
      "        [-0.0173],\n",
      "        [ 0.0878],\n",
      "        [ 0.0109],\n",
      "        [-0.0200],\n",
      "        [ 0.0166],\n",
      "        [-0.0319],\n",
      "        [ 0.0451],\n",
      "        [-0.0208],\n",
      "        [ 0.0409],\n",
      "        [ 0.0133],\n",
      "        [ 0.0722],\n",
      "        [ 0.0391],\n",
      "        [-0.0387],\n",
      "        [ 0.0193],\n",
      "        [ 0.0439],\n",
      "        [ 0.0546],\n",
      "        [ 0.0068],\n",
      "        [ 0.1230],\n",
      "        [ 0.0716],\n",
      "        [ 0.0090],\n",
      "        [ 0.0404],\n",
      "        [ 0.0339],\n",
      "        [-0.0120],\n",
      "        [-0.0223],\n",
      "        [ 0.0386],\n",
      "        [-0.0017]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1071, 0.1068, 0.1086, 0.1080, 0.1090, 0.1080, 0.1081, 0.1081, 0.1084,\n",
      "        0.1071, 0.1057, 0.1057, 0.1071, 0.1063, 0.1078, 0.1090, 0.1094, 0.1090,\n",
      "        0.1117, 0.1131, 0.1118, 0.1111, 0.1097, 0.1091, 0.1086, 0.1069, 0.1074,\n",
      "        0.1068, 0.1052, 0.1057, 0.1046, 0.1003], device='cuda:0')\n",
      "tensor([[-0.0119],\n",
      "        [ 0.0654],\n",
      "        [ 0.0381],\n",
      "        [ 0.0162],\n",
      "        [ 0.1154],\n",
      "        [ 0.2537],\n",
      "        [ 0.0026],\n",
      "        [ 0.0099],\n",
      "        [ 0.0369],\n",
      "        [ 0.0208],\n",
      "        [ 0.0304],\n",
      "        [-0.0170],\n",
      "        [-0.0631],\n",
      "        [-0.0380],\n",
      "        [ 0.0932],\n",
      "        [ 0.0415],\n",
      "        [-0.0388],\n",
      "        [-0.0152],\n",
      "        [-0.0027],\n",
      "        [ 0.0405],\n",
      "        [-0.0008],\n",
      "        [ 0.1219],\n",
      "        [-0.0098],\n",
      "        [ 0.0005],\n",
      "        [ 0.0166],\n",
      "        [-0.0278],\n",
      "        [-0.0175],\n",
      "        [ 0.0482],\n",
      "        [ 0.1543],\n",
      "        [ 0.0190],\n",
      "        [-0.0314],\n",
      "        [ 0.1637]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1009, 0.1019, 0.1025, 0.1024, 0.1026, 0.1007, 0.1018, 0.1003, 0.1013,\n",
      "        0.0997, 0.0972, 0.0984, 0.0985, 0.0972, 0.0975, 0.0976, 0.1006, 0.0988,\n",
      "        0.0970, 0.0963, 0.0969, 0.0976, 0.0975, 0.0941, 0.0933, 0.0880, 0.0938,\n",
      "        0.0919, 0.0920, 0.0914, 0.0900, 0.0873], device='cuda:0')\n",
      "tensor([[ 0.0884],\n",
      "        [ 0.0497],\n",
      "        [ 0.0663],\n",
      "        [ 0.0874],\n",
      "        [ 0.0881],\n",
      "        [-0.0135],\n",
      "        [ 0.0901],\n",
      "        [ 0.0953],\n",
      "        [ 0.0484],\n",
      "        [ 0.0717],\n",
      "        [-0.0473],\n",
      "        [ 0.0180],\n",
      "        [ 0.0501],\n",
      "        [ 0.0100],\n",
      "        [ 0.0671],\n",
      "        [ 0.0169],\n",
      "        [-0.0045],\n",
      "        [ 0.0305],\n",
      "        [ 0.0068],\n",
      "        [ 0.1170],\n",
      "        [ 0.0653],\n",
      "        [ 0.0782],\n",
      "        [ 0.0205],\n",
      "        [ 0.1066],\n",
      "        [ 0.0083],\n",
      "        [-0.0036],\n",
      "        [ 0.0025],\n",
      "        [ 0.0249],\n",
      "        [ 0.0340],\n",
      "        [ 0.0551],\n",
      "        [ 0.0446],\n",
      "        [-0.0010]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0891, 0.1031, 0.1034, 0.1044, 0.1075, 0.1077, 0.1074, 0.1093, 0.1097,\n",
      "        0.1102, 0.1137, 0.1148, 0.1134, 0.1131, 0.1099, 0.1121, 0.1117, 0.1106,\n",
      "        0.1106, 0.1112, 0.1133, 0.1137, 0.1142, 0.1136, 0.1127, 0.1165, 0.1167,\n",
      "        0.1158, 0.1168, 0.1161, 0.1143, 0.1171], device='cuda:0')\n",
      "tensor([[ 0.0379],\n",
      "        [ 0.0317],\n",
      "        [-0.0376],\n",
      "        [ 0.0112],\n",
      "        [ 0.0179],\n",
      "        [ 0.0178],\n",
      "        [ 0.1123],\n",
      "        [ 0.0280],\n",
      "        [-0.0351],\n",
      "        [ 0.0834],\n",
      "        [ 0.0496],\n",
      "        [ 0.0600],\n",
      "        [ 0.0433],\n",
      "        [ 0.0478],\n",
      "        [ 0.0250],\n",
      "        [ 0.0097],\n",
      "        [ 0.0520],\n",
      "        [ 0.0225],\n",
      "        [ 0.0921],\n",
      "        [-0.0302],\n",
      "        [ 0.0457],\n",
      "        [ 0.0827],\n",
      "        [ 0.0526],\n",
      "        [-0.0082],\n",
      "        [-0.0182],\n",
      "        [ 0.0253],\n",
      "        [ 0.0064],\n",
      "        [-0.0152],\n",
      "        [ 0.0177],\n",
      "        [ 0.0383],\n",
      "        [-0.0232],\n",
      "        [ 0.0355]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1196, 0.1202, 0.1201, 0.1192, 0.1249, 0.1257, 0.1267, 0.1277, 0.1266,\n",
      "        0.1260, 0.1274, 0.1273, 0.1301, 0.1276, 0.1280, 0.1277, 0.1269, 0.1294,\n",
      "        0.1283, 0.1302, 0.1317, 0.1323, 0.1298, 0.1316, 0.1341, 0.1342, 0.1336,\n",
      "        0.1314, 0.1291, 0.1335, 0.1344, 0.1307], device='cuda:0')\n",
      "tensor([[ 0.0091],\n",
      "        [ 0.0428],\n",
      "        [ 0.0206],\n",
      "        [-0.0245],\n",
      "        [ 0.0739],\n",
      "        [ 0.0468],\n",
      "        [-0.0511],\n",
      "        [ 0.0258],\n",
      "        [-0.0355],\n",
      "        [-0.0480],\n",
      "        [ 0.0683],\n",
      "        [-0.0153],\n",
      "        [ 0.0229],\n",
      "        [-0.0298],\n",
      "        [-0.0272],\n",
      "        [-0.0063],\n",
      "        [ 0.0042],\n",
      "        [-0.0293],\n",
      "        [-0.0442],\n",
      "        [ 0.0213],\n",
      "        [-0.0135],\n",
      "        [-0.0247],\n",
      "        [ 0.1242],\n",
      "        [ 0.0768],\n",
      "        [ 0.1099],\n",
      "        [ 0.1462],\n",
      "        [-0.0060],\n",
      "        [ 0.0324],\n",
      "        [ 0.0185],\n",
      "        [ 0.0650],\n",
      "        [-0.0111],\n",
      "        [-0.0537]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1333, 0.1311, 0.1301, 0.1311, 0.1291, 0.1300, 0.1331, 0.1313, 0.1328,\n",
      "        0.1345, 0.1382, 0.1387, 0.1394, 0.1395, 0.1381, 0.1398, 0.1424, 0.1519,\n",
      "        0.1540, 0.1627, 0.1609, 0.1627, 0.1679, 0.1669, 0.1673, 0.1674, 0.1689,\n",
      "        0.1732, 0.1728, 0.1720, 0.1679, 0.1645], device='cuda:0')\n",
      "tensor([[ 0.0351],\n",
      "        [ 0.1876],\n",
      "        [ 0.0835],\n",
      "        [ 0.0194],\n",
      "        [ 0.0073],\n",
      "        [ 0.0343],\n",
      "        [ 0.0559],\n",
      "        [ 0.0591],\n",
      "        [ 0.0413],\n",
      "        [ 0.0780],\n",
      "        [ 0.0063],\n",
      "        [ 0.0162],\n",
      "        [ 0.0108],\n",
      "        [-0.0065],\n",
      "        [ 0.0066],\n",
      "        [-0.0008],\n",
      "        [ 0.0709],\n",
      "        [-0.0500],\n",
      "        [-0.0438],\n",
      "        [ 0.0385],\n",
      "        [ 0.0391],\n",
      "        [ 0.0794],\n",
      "        [-0.0205],\n",
      "        [ 0.0642],\n",
      "        [-0.0062],\n",
      "        [ 0.0452],\n",
      "        [ 0.0616],\n",
      "        [ 0.0685],\n",
      "        [ 0.0490],\n",
      "        [-0.0086],\n",
      "        [ 0.0281],\n",
      "        [ 0.0558]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1697, 0.1670, 0.1651, 0.1598, 0.1612, 0.1562, 0.1601, 0.1680, 0.1674,\n",
      "        0.1633, 0.1629, 0.1646, 0.1646, 0.1639, 0.1621, 0.1596, 0.1617, 0.1686,\n",
      "        0.1711, 0.1736, 0.1695, 0.1719, 0.1732, 0.1742, 0.1779, 0.1751, 0.1762,\n",
      "        0.1759, 0.1779, 0.1791, 0.1673, 0.1599], device='cuda:0')\n",
      "tensor([[ 0.0336],\n",
      "        [ 0.0398],\n",
      "        [-0.0303],\n",
      "        [ 0.3953],\n",
      "        [-0.0211],\n",
      "        [ 0.0269],\n",
      "        [ 0.0654],\n",
      "        [ 0.0429],\n",
      "        [-0.0102],\n",
      "        [ 0.0684],\n",
      "        [ 0.0143],\n",
      "        [ 0.0291],\n",
      "        [ 0.0411],\n",
      "        [ 0.0564],\n",
      "        [ 0.0267],\n",
      "        [ 0.0046],\n",
      "        [ 0.0207],\n",
      "        [ 0.0564],\n",
      "        [-0.0048],\n",
      "        [-0.0162],\n",
      "        [ 0.0307],\n",
      "        [ 0.0005],\n",
      "        [-0.0394],\n",
      "        [-0.0440],\n",
      "        [ 0.0258],\n",
      "        [-0.0279],\n",
      "        [ 0.0374],\n",
      "        [ 0.0344],\n",
      "        [-0.0078],\n",
      "        [-0.0005],\n",
      "        [ 0.0046],\n",
      "        [ 0.0063]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1584, 0.1528, 0.1587, 0.1654, 0.1664, 0.1660, 0.1636, 0.1621, 0.1564,\n",
      "        0.1531, 0.1564, 0.1493, 0.1522, 0.1519, 0.1536, 0.1519, 0.1522, 0.1503,\n",
      "        0.1475, 0.1432, 0.1506, 0.1537, 0.1542, 0.1496, 0.1505, 0.1521, 0.1518,\n",
      "        0.1525, 0.1539, 0.1517, 0.1533, 0.1531], device='cuda:0')\n",
      "tensor([[-3.1477e-02],\n",
      "        [-1.7040e-02],\n",
      "        [-1.2618e-02],\n",
      "        [-8.9369e-03],\n",
      "        [ 1.4443e-05],\n",
      "        [-2.4152e-02],\n",
      "        [-1.8325e-02],\n",
      "        [-5.5786e-02],\n",
      "        [ 1.0018e-01],\n",
      "        [ 6.3589e-02],\n",
      "        [ 1.2724e-01],\n",
      "        [ 6.7072e-02],\n",
      "        [-4.0950e-02],\n",
      "        [-1.3776e-02],\n",
      "        [ 4.4949e-02],\n",
      "        [ 6.0126e-02],\n",
      "        [ 3.7763e-02],\n",
      "        [ 2.8616e-02],\n",
      "        [-1.8855e-02],\n",
      "        [ 1.7985e-03],\n",
      "        [ 1.3519e-02],\n",
      "        [ 5.2006e-02],\n",
      "        [ 4.8866e-02],\n",
      "        [ 1.9692e-02],\n",
      "        [-8.8596e-03],\n",
      "        [-3.6204e-02],\n",
      "        [ 2.1141e-02],\n",
      "        [ 4.0422e-02],\n",
      "        [ 2.5111e-02],\n",
      "        [ 3.3471e-02],\n",
      "        [ 2.4863e-02],\n",
      "        [ 3.3012e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1518, 0.1494, 0.1503, 0.1455, 0.1453, 0.1435, 0.1424, 0.1372, 0.1422,\n",
      "        0.1412, 0.1463, 0.1425, 0.1428, 0.1422, 0.1387, 0.1356, 0.1333, 0.1372,\n",
      "        0.1421, 0.1379, 0.1378, 0.1382, 0.1419, 0.1435, 0.1431, 0.1434, 0.1457,\n",
      "        0.1429, 0.1460, 0.1488, 0.1621, 0.1587], device='cuda:0')\n",
      "tensor([[-0.0332],\n",
      "        [ 0.0642],\n",
      "        [ 0.0110],\n",
      "        [ 0.3201],\n",
      "        [ 0.0050],\n",
      "        [ 0.0292],\n",
      "        [ 0.1381],\n",
      "        [ 0.0697],\n",
      "        [ 0.0354],\n",
      "        [ 0.0680],\n",
      "        [ 0.1000],\n",
      "        [-0.0036],\n",
      "        [ 0.0032],\n",
      "        [ 0.0540],\n",
      "        [ 0.0373],\n",
      "        [ 0.0414],\n",
      "        [ 0.1077],\n",
      "        [ 0.0084],\n",
      "        [ 0.0196],\n",
      "        [ 0.0325],\n",
      "        [-0.0361],\n",
      "        [ 0.0166],\n",
      "        [ 0.0182],\n",
      "        [ 0.0035],\n",
      "        [ 0.0669],\n",
      "        [-0.0037],\n",
      "        [ 0.0138],\n",
      "        [ 0.0717],\n",
      "        [-0.0083],\n",
      "        [-0.0234],\n",
      "        [ 0.0265],\n",
      "        [ 0.0132]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1583, 0.1677, 0.1702, 0.1713, 0.1722, 0.1769, 0.1762, 0.1722, 0.1784,\n",
      "        0.1785, 0.1856, 0.1857, 0.1860, 0.1860, 0.1815, 0.1800, 0.1859, 0.1875,\n",
      "        0.1844, 0.1855, 0.1924, 0.1936, 0.1880, 0.1850, 0.1865, 0.1800, 0.1776,\n",
      "        0.1764, 0.1829, 0.1859, 0.1844, 0.1865], device='cuda:0')\n",
      "tensor([[-0.0343],\n",
      "        [-0.0257],\n",
      "        [ 0.0049],\n",
      "        [ 0.0434],\n",
      "        [ 0.0087],\n",
      "        [-0.0210],\n",
      "        [-0.0066],\n",
      "        [ 0.0337],\n",
      "        [ 0.0029],\n",
      "        [ 0.0426],\n",
      "        [ 0.0019],\n",
      "        [ 0.0218],\n",
      "        [ 0.0557],\n",
      "        [ 0.0216],\n",
      "        [ 0.0487],\n",
      "        [ 0.0190],\n",
      "        [ 0.0501],\n",
      "        [ 0.0176],\n",
      "        [ 0.0237],\n",
      "        [-0.0209],\n",
      "        [ 0.0346],\n",
      "        [ 0.0146],\n",
      "        [ 0.0037],\n",
      "        [ 0.0361],\n",
      "        [ 0.0223],\n",
      "        [-0.0288],\n",
      "        [ 0.0332],\n",
      "        [ 0.0283],\n",
      "        [ 0.0539],\n",
      "        [ 0.1088],\n",
      "        [ 0.0645],\n",
      "        [ 0.0769]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1888, 0.1909, 0.1915, 0.1930, 0.1909, 0.1924, 0.1930, 0.1880, 0.1976,\n",
      "        0.1977, 0.1948, 0.1962, 0.1939, 0.1976, 0.2014, 0.2046, 0.2039, 0.2069,\n",
      "        0.2079, 0.2069, 0.2069, 0.2057, 0.2074, 0.2113, 0.2160, 0.2275, 0.2257,\n",
      "        0.2240, 0.2290, 0.2353, 0.2334, 0.2287], device='cuda:0')\n",
      "tensor([[ 0.1821],\n",
      "        [-0.0031],\n",
      "        [ 0.1108],\n",
      "        [ 0.0678],\n",
      "        [ 0.0737],\n",
      "        [ 0.0463],\n",
      "        [-0.0034],\n",
      "        [ 0.0290],\n",
      "        [ 0.0436],\n",
      "        [-0.0253],\n",
      "        [ 0.0303],\n",
      "        [ 0.0240],\n",
      "        [ 0.0202],\n",
      "        [ 0.0213],\n",
      "        [-0.0266],\n",
      "        [ 0.0298],\n",
      "        [ 0.0343],\n",
      "        [ 0.0104],\n",
      "        [ 0.0284],\n",
      "        [-0.0022],\n",
      "        [-0.0184],\n",
      "        [ 0.0456],\n",
      "        [-0.0170],\n",
      "        [-0.0148],\n",
      "        [-0.0115],\n",
      "        [ 0.0266],\n",
      "        [ 0.0802],\n",
      "        [ 0.0893],\n",
      "        [ 0.0121],\n",
      "        [ 0.0073],\n",
      "        [-0.0045],\n",
      "        [-0.0214]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2237, 0.2311, 0.2305, 0.2281, 0.2317, 0.2322, 0.2355, 0.2343, 0.2293,\n",
      "        0.2240, 0.2250, 0.2272, 0.2255, 0.2167, 0.2263, 0.2356, 0.2358, 0.2305,\n",
      "        0.2319, 0.2287, 0.2247, 0.2260, 0.2195, 0.2201, 0.2265, 0.2253, 0.2257,\n",
      "        0.2255, 0.2237, 0.2169, 0.2098, 0.2122], device='cuda:0')\n",
      "tensor([[-0.0107],\n",
      "        [ 0.0150],\n",
      "        [-0.0230],\n",
      "        [-0.0221],\n",
      "        [ 0.0873],\n",
      "        [ 0.0988],\n",
      "        [ 0.0068],\n",
      "        [-0.0158],\n",
      "        [ 0.0160],\n",
      "        [ 0.0343],\n",
      "        [ 0.0044],\n",
      "        [ 0.1287],\n",
      "        [ 0.1224],\n",
      "        [ 0.0582],\n",
      "        [ 0.0177],\n",
      "        [ 0.0095],\n",
      "        [ 0.0313],\n",
      "        [ 0.0482],\n",
      "        [ 0.0427],\n",
      "        [ 0.0737],\n",
      "        [ 0.0697],\n",
      "        [ 0.0741],\n",
      "        [ 0.0751],\n",
      "        [ 0.0284],\n",
      "        [-0.0030],\n",
      "        [-0.0281],\n",
      "        [ 0.0292],\n",
      "        [-0.0054],\n",
      "        [-0.0154],\n",
      "        [-0.0010],\n",
      "        [ 0.1210],\n",
      "        [ 0.0251]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2116, 0.2080, 0.2160, 0.2160, 0.2139, 0.2151, 0.2260, 0.2246, 0.2206,\n",
      "        0.2207, 0.2231, 0.2287, 0.2311, 0.2252, 0.2277, 0.2271, 0.2283, 0.2330,\n",
      "        0.2293, 0.2278, 0.2286, 0.2275, 0.2247, 0.2209, 0.2166, 0.2061, 0.2110,\n",
      "        0.2291, 0.2290, 0.2178, 0.2122, 0.1933], device='cuda:0')\n",
      "tensor([[-0.0204],\n",
      "        [ 0.0316],\n",
      "        [ 0.0155],\n",
      "        [ 0.0052],\n",
      "        [-0.0502],\n",
      "        [ 0.0682],\n",
      "        [ 0.0359],\n",
      "        [ 0.0347],\n",
      "        [-0.0280],\n",
      "        [ 0.0887],\n",
      "        [ 0.0208],\n",
      "        [ 0.0054],\n",
      "        [-0.0101],\n",
      "        [ 0.0206],\n",
      "        [ 0.0959],\n",
      "        [-0.0471],\n",
      "        [ 0.0531],\n",
      "        [ 0.0502],\n",
      "        [ 0.0416],\n",
      "        [ 0.0264],\n",
      "        [-0.0279],\n",
      "        [ 0.0400],\n",
      "        [ 0.0266],\n",
      "        [ 0.0153],\n",
      "        [ 0.0015],\n",
      "        [ 0.0056],\n",
      "        [ 0.0406],\n",
      "        [ 0.0361],\n",
      "        [ 0.1510],\n",
      "        [ 0.0491],\n",
      "        [ 0.0708],\n",
      "        [-0.0742]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2154, 0.2128, 0.2070, 0.2133, 0.2207, 0.2215, 0.2234, 0.2194, 0.2157,\n",
      "        0.2114, 0.2145, 0.2089, 0.2148, 0.2204, 0.2252, 0.2219, 0.2241, 0.2281,\n",
      "        0.2300, 0.2243, 0.2343, 0.2399, 0.2393, 0.2466, 0.2423, 0.2414, 0.2387,\n",
      "        0.2458, 0.2473, 0.2414, 0.2322, 0.2207], device='cuda:0')\n",
      "tensor([[ 0.0038],\n",
      "        [ 0.0300],\n",
      "        [ 0.0241],\n",
      "        [ 0.0044],\n",
      "        [-0.0158],\n",
      "        [-0.0150],\n",
      "        [ 0.1134],\n",
      "        [ 0.0652],\n",
      "        [-0.0332],\n",
      "        [-0.0017],\n",
      "        [ 0.0296],\n",
      "        [ 0.0016],\n",
      "        [ 0.0718],\n",
      "        [ 0.0402],\n",
      "        [-0.0609],\n",
      "        [ 0.0195],\n",
      "        [-0.0517],\n",
      "        [ 0.0395],\n",
      "        [ 0.0242],\n",
      "        [ 0.0323],\n",
      "        [ 0.0030],\n",
      "        [ 0.0318],\n",
      "        [ 0.0273],\n",
      "        [ 0.0423],\n",
      "        [ 0.0217],\n",
      "        [-0.0204],\n",
      "        [ 0.0156],\n",
      "        [ 0.0444],\n",
      "        [ 0.0148],\n",
      "        [ 0.1257],\n",
      "        [ 0.2180],\n",
      "        [ 0.0142]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2178, 0.2190, 0.2257, 0.2216, 0.2169, 0.2219, 0.2229, 0.2136, 0.2148,\n",
      "        0.2209, 0.2234, 0.2243, 0.2278, 0.2302, 0.2321, 0.2293, 0.2269, 0.2268,\n",
      "        0.2170, 0.2172, 0.2219, 0.2231, 0.2250, 0.2287, 0.2367, 0.2172, 0.2154,\n",
      "        0.2150, 0.2125, 0.2086, 0.2098, 0.2126], device='cuda:0')\n",
      "tensor([[ 4.4465e-02],\n",
      "        [-3.3040e-02],\n",
      "        [ 1.7377e-01],\n",
      "        [ 1.3402e-02],\n",
      "        [-2.3218e-02],\n",
      "        [ 5.2281e-02],\n",
      "        [-9.1990e-03],\n",
      "        [ 3.1495e-02],\n",
      "        [ 3.3153e-02],\n",
      "        [ 4.8042e-02],\n",
      "        [ 2.5168e-02],\n",
      "        [ 1.2646e-02],\n",
      "        [ 6.5745e-02],\n",
      "        [ 9.1949e-02],\n",
      "        [ 6.4654e-03],\n",
      "        [ 1.4623e-02],\n",
      "        [ 2.8301e-02],\n",
      "        [ 3.8099e-02],\n",
      "        [ 1.6284e-02],\n",
      "        [ 2.2172e-02],\n",
      "        [ 3.9647e-02],\n",
      "        [ 3.7840e-02],\n",
      "        [ 1.0328e-01],\n",
      "        [ 6.8522e-02],\n",
      "        [ 2.7678e-02],\n",
      "        [ 5.4066e-02],\n",
      "        [ 1.7517e-02],\n",
      "        [-4.7753e-02],\n",
      "        [ 1.7510e-01],\n",
      "        [-9.5554e-05],\n",
      "        [ 1.2294e-01],\n",
      "        [-9.4493e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2139, 0.2182, 0.2154, 0.2129, 0.2159, 0.2122, 0.2122, 0.2190, 0.2232,\n",
      "        0.2237, 0.2225, 0.2216, 0.2234, 0.2234, 0.2231, 0.2237, 0.2228, 0.2293,\n",
      "        0.2299, 0.2274, 0.2215, 0.2219, 0.2145, 0.2144, 0.2125, 0.2077, 0.2110,\n",
      "        0.2148, 0.2175, 0.2160, 0.2198, 0.2190], device='cuda:0')\n",
      "tensor([[ 0.0937],\n",
      "        [-0.0007],\n",
      "        [ 0.0400],\n",
      "        [ 0.0184],\n",
      "        [ 0.0312],\n",
      "        [ 0.0146],\n",
      "        [ 0.0164],\n",
      "        [ 0.0266],\n",
      "        [ 0.0599],\n",
      "        [ 0.0190],\n",
      "        [ 0.0556],\n",
      "        [ 0.0189],\n",
      "        [-0.0054],\n",
      "        [ 0.0326],\n",
      "        [ 0.0651],\n",
      "        [ 0.0109],\n",
      "        [ 0.0394],\n",
      "        [ 0.0370],\n",
      "        [ 0.0454],\n",
      "        [ 0.0135],\n",
      "        [ 0.0282],\n",
      "        [ 0.0366],\n",
      "        [ 0.0551],\n",
      "        [-0.0153],\n",
      "        [ 0.0469],\n",
      "        [ 0.0054],\n",
      "        [ 0.0213],\n",
      "        [ 0.0449],\n",
      "        [ 0.2038],\n",
      "        [ 0.1081],\n",
      "        [ 0.0471],\n",
      "        [ 0.1124]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2206, 0.2237, 0.2218, 0.2201, 0.2252, 0.2311, 0.2288, 0.2272, 0.2246,\n",
      "        0.2260, 0.2274, 0.2306, 0.2280, 0.2311, 0.2280, 0.2275, 0.2319, 0.2268,\n",
      "        0.2317, 0.2399, 0.2353, 0.2352, 0.2433, 0.2594, 0.2517, 0.2582, 0.2579,\n",
      "        0.2531, 0.2539, 0.2536, 0.2544, 0.2567], device='cuda:0')\n",
      "tensor([[-0.0174],\n",
      "        [-0.0187],\n",
      "        [ 0.0079],\n",
      "        [ 0.0228],\n",
      "        [-0.0135],\n",
      "        [-0.0012],\n",
      "        [-0.0138],\n",
      "        [ 0.0265],\n",
      "        [ 0.0087],\n",
      "        [ 0.0382],\n",
      "        [ 0.0256],\n",
      "        [ 0.0233],\n",
      "        [ 0.0359],\n",
      "        [ 0.2636],\n",
      "        [ 0.1239],\n",
      "        [ 0.0418],\n",
      "        [ 0.0219],\n",
      "        [ 0.0493],\n",
      "        [ 0.0496],\n",
      "        [ 0.0260],\n",
      "        [-0.0189],\n",
      "        [ 0.0208],\n",
      "        [ 0.0018],\n",
      "        [ 0.0454],\n",
      "        [-0.0457],\n",
      "        [-0.0004],\n",
      "        [ 0.0926],\n",
      "        [-0.0426],\n",
      "        [-0.0285],\n",
      "        [ 0.0222],\n",
      "        [-0.0242],\n",
      "        [-0.0398]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2562, 0.2590, 0.2576, 0.2573, 0.2641, 0.2625, 0.2632, 0.2686, 0.2778,\n",
      "        0.2758, 0.2750, 0.2759, 0.2724, 0.2727, 0.2687, 0.2665, 0.2647, 0.2643,\n",
      "        0.2582, 0.2575, 0.2536, 0.2497, 0.2548, 0.2615, 0.2613, 0.2624, 0.2576,\n",
      "        0.2547, 0.2553, 0.2458, 0.2405, 0.2429], device='cuda:0')\n",
      "tensor([[ 0.0175],\n",
      "        [ 0.0577],\n",
      "        [ 0.0740],\n",
      "        [ 0.0689],\n",
      "        [-0.0281],\n",
      "        [ 0.0892],\n",
      "        [ 0.0428],\n",
      "        [ 0.0585],\n",
      "        [-0.0243],\n",
      "        [-0.0319],\n",
      "        [ 0.0406],\n",
      "        [-0.0333],\n",
      "        [ 0.0374],\n",
      "        [ 0.0443],\n",
      "        [ 0.0372],\n",
      "        [ 0.0339],\n",
      "        [-0.0125],\n",
      "        [-0.0047],\n",
      "        [ 0.0079],\n",
      "        [-0.0020],\n",
      "        [ 0.0073],\n",
      "        [ 0.0363],\n",
      "        [ 0.0600],\n",
      "        [-0.0027],\n",
      "        [ 0.0221],\n",
      "        [-0.0591],\n",
      "        [ 0.0689],\n",
      "        [ 0.1736],\n",
      "        [ 0.1291],\n",
      "        [ 0.0233],\n",
      "        [ 0.0412],\n",
      "        [ 0.0505]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2377, 0.2314, 0.2361, 0.2446, 0.2452, 0.2463, 0.2476, 0.2502, 0.2519,\n",
      "        0.2564, 0.2528, 0.2492, 0.2497, 0.2523, 0.2572, 0.2606, 0.2626, 0.2632,\n",
      "        0.2570, 0.2603, 0.2646, 0.2688, 0.2833, 0.2817, 0.2733, 0.2742, 0.2771,\n",
      "        0.2770, 0.2827, 0.2957, 0.2936, 0.2942], device='cuda:0')\n",
      "tensor([[-0.0225],\n",
      "        [ 0.0788],\n",
      "        [ 0.0797],\n",
      "        [-0.0061],\n",
      "        [ 0.0718],\n",
      "        [ 0.0833],\n",
      "        [ 0.1153],\n",
      "        [-0.0262],\n",
      "        [ 0.0140],\n",
      "        [-0.0369],\n",
      "        [ 0.0133],\n",
      "        [-0.0046],\n",
      "        [ 0.0376],\n",
      "        [ 0.0462],\n",
      "        [ 0.0979],\n",
      "        [-0.0160],\n",
      "        [ 0.0183],\n",
      "        [ 0.0143],\n",
      "        [ 0.0601],\n",
      "        [-0.0161],\n",
      "        [-0.0226],\n",
      "        [ 0.0037],\n",
      "        [-0.0082],\n",
      "        [ 0.0004],\n",
      "        [-0.0037],\n",
      "        [ 0.1212],\n",
      "        [-0.0405],\n",
      "        [ 0.0388],\n",
      "        [ 0.0108],\n",
      "        [-0.0042],\n",
      "        [ 0.0260],\n",
      "        [ 0.0138]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2802, 0.2848, 0.2871, 0.2857, 0.2874, 0.2842, 0.2830, 0.2787, 0.2768,\n",
      "        0.2762, 0.2851, 0.2876, 0.2832, 0.2827, 0.2843, 0.2840, 0.2898, 0.2765,\n",
      "        0.2702, 0.2467, 0.2593, 0.2653, 0.2683, 0.2626, 0.2781, 0.2724, 0.2700,\n",
      "        0.2796, 0.2857, 0.2877, 0.2889, 0.2801], device='cuda:0')\n",
      "tensor([[ 0.0069],\n",
      "        [ 0.0225],\n",
      "        [-0.0471],\n",
      "        [ 0.0254],\n",
      "        [ 0.0013],\n",
      "        [-0.0085],\n",
      "        [-0.0185],\n",
      "        [ 0.0089],\n",
      "        [ 0.0158],\n",
      "        [ 0.0264],\n",
      "        [ 0.0069],\n",
      "        [ 0.0197],\n",
      "        [-0.0130],\n",
      "        [ 0.0760],\n",
      "        [ 0.0497],\n",
      "        [ 0.1246],\n",
      "        [ 0.2197],\n",
      "        [ 0.1119],\n",
      "        [ 0.0951],\n",
      "        [ 0.0458],\n",
      "        [-0.0108],\n",
      "        [-0.0071],\n",
      "        [ 0.0156],\n",
      "        [ 0.0225],\n",
      "        [ 0.1132],\n",
      "        [ 0.0201],\n",
      "        [ 0.0155],\n",
      "        [ 0.1333],\n",
      "        [ 0.1855],\n",
      "        [ 0.0929],\n",
      "        [ 0.0290],\n",
      "        [-0.0279]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2752, 0.2835, 0.2824, 0.2926, 0.2891, 0.2960, 0.2963, 0.2911, 0.2842,\n",
      "        0.2768, 0.2755, 0.2647, 0.2624, 0.2659, 0.2724, 0.2814, 0.2898, 0.2835,\n",
      "        0.2889, 0.3031, 0.3018, 0.3099, 0.3063, 0.3177, 0.3156, 0.3150, 0.3186,\n",
      "        0.3217, 0.3260, 0.3320, 0.3314, 0.3311], device='cuda:0')\n",
      "tensor([[ 0.1933],\n",
      "        [ 0.0202],\n",
      "        [-0.0003],\n",
      "        [ 0.0558],\n",
      "        [ 0.0470],\n",
      "        [-0.0477],\n",
      "        [ 0.0060],\n",
      "        [ 0.0130],\n",
      "        [ 0.0398],\n",
      "        [-0.0065],\n",
      "        [ 0.0234],\n",
      "        [ 0.0284],\n",
      "        [-0.0310],\n",
      "        [-0.0027],\n",
      "        [ 0.0189],\n",
      "        [ 0.0224],\n",
      "        [-0.0226],\n",
      "        [ 0.0477],\n",
      "        [ 0.0359],\n",
      "        [-0.0260],\n",
      "        [ 0.0246],\n",
      "        [-0.0218],\n",
      "        [ 0.0408],\n",
      "        [ 0.0562],\n",
      "        [ 0.0393],\n",
      "        [ 0.1177],\n",
      "        [ 0.0387],\n",
      "        [-0.0508],\n",
      "        [ 0.1150],\n",
      "        [ 0.1256],\n",
      "        [-0.0215],\n",
      "        [ 0.0916]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3288, 0.3300, 0.3326, 0.3348, 0.3382, 0.3491, 0.3518, 0.3536, 0.3525,\n",
      "        0.3571, 0.3539, 0.3562, 0.3552, 0.3589, 0.3741, 0.3710, 0.3745, 0.3822,\n",
      "        0.3707, 0.3819, 0.3762, 0.3669, 0.3686, 0.3756, 0.3779, 0.3809, 0.3704,\n",
      "        0.3775, 0.3654, 0.3704, 0.3689, 0.3729], device='cuda:0')\n",
      "tensor([[ 0.0199],\n",
      "        [-0.0210],\n",
      "        [ 0.0357],\n",
      "        [-0.0437],\n",
      "        [ 0.0038],\n",
      "        [-0.0129],\n",
      "        [-0.0088],\n",
      "        [ 0.0671],\n",
      "        [ 0.0990],\n",
      "        [ 0.1362],\n",
      "        [ 0.1302],\n",
      "        [ 0.0190],\n",
      "        [ 0.0752],\n",
      "        [ 0.0349],\n",
      "        [ 0.0584],\n",
      "        [-0.0583],\n",
      "        [-0.0330],\n",
      "        [ 0.0251],\n",
      "        [ 0.0124],\n",
      "        [-0.0096],\n",
      "        [ 0.0553],\n",
      "        [ 0.0589],\n",
      "        [-0.0147],\n",
      "        [-0.0044],\n",
      "        [ 0.0005],\n",
      "        [ 0.0015],\n",
      "        [ 0.1572],\n",
      "        [ 0.0651],\n",
      "        [ 0.0521],\n",
      "        [-0.0229],\n",
      "        [-0.0363],\n",
      "        [ 0.0028]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3859, 0.3973, 0.4111, 0.4176, 0.4246, 0.4277, 0.4226, 0.4218, 0.4162,\n",
      "        0.4129, 0.4285, 0.4265, 0.4299, 0.4237, 0.4277, 0.4178, 0.4188, 0.4073,\n",
      "        0.4175, 0.4347, 0.4401, 0.4460, 0.4052, 0.4105, 0.4191, 0.4018, 0.4027,\n",
      "        0.4135, 0.4052, 0.3981, 0.3946, 0.3812], device='cuda:0')\n",
      "tensor([[ 0.0006],\n",
      "        [-0.0124],\n",
      "        [ 0.0312],\n",
      "        [ 0.0134],\n",
      "        [-0.0513],\n",
      "        [ 0.0526],\n",
      "        [ 0.0007],\n",
      "        [ 0.0719],\n",
      "        [-0.0343],\n",
      "        [ 0.0504],\n",
      "        [ 0.0465],\n",
      "        [ 0.0282],\n",
      "        [-0.0136],\n",
      "        [ 0.0389],\n",
      "        [-0.0089],\n",
      "        [ 0.0167],\n",
      "        [ 0.0256],\n",
      "        [ 0.0065],\n",
      "        [ 0.0764],\n",
      "        [ 0.0307],\n",
      "        [ 0.0064],\n",
      "        [-0.0006],\n",
      "        [ 0.0141],\n",
      "        [ 0.0495],\n",
      "        [ 0.0522],\n",
      "        [-0.0003],\n",
      "        [ 0.0974],\n",
      "        [ 0.1039],\n",
      "        [ 0.0692],\n",
      "        [ 0.0027],\n",
      "        [ 0.0767],\n",
      "        [ 0.0241]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3728, 0.3751, 0.3651, 0.3795, 0.4023, 0.3887, 0.3881, 0.3834, 0.3922,\n",
      "        0.3860, 0.4009, 0.3986, 0.3911, 0.3908, 0.3816, 0.3784, 0.3769, 0.3745,\n",
      "        0.3846, 0.4020, 0.4032, 0.4110, 0.4094, 0.4126, 0.4011, 0.4105, 0.4082,\n",
      "        0.4012, 0.4002, 0.3788, 0.3751, 0.3713], device='cuda:0')\n",
      "tensor([[-0.0369],\n",
      "        [ 0.0656],\n",
      "        [ 0.0418],\n",
      "        [ 0.0316],\n",
      "        [ 0.0602],\n",
      "        [ 0.0180],\n",
      "        [-0.0270],\n",
      "        [-0.0155],\n",
      "        [-0.0160],\n",
      "        [ 0.0089],\n",
      "        [-0.0169],\n",
      "        [ 0.0030],\n",
      "        [-0.0012],\n",
      "        [-0.0029],\n",
      "        [ 0.0300],\n",
      "        [ 0.0300],\n",
      "        [ 0.0191],\n",
      "        [ 0.0442],\n",
      "        [ 0.0201],\n",
      "        [-0.0164],\n",
      "        [ 0.0399],\n",
      "        [ 0.0224],\n",
      "        [-0.0092],\n",
      "        [ 0.0008],\n",
      "        [ 0.0948],\n",
      "        [ 0.0785],\n",
      "        [ 0.0788],\n",
      "        [ 0.0957],\n",
      "        [ 0.1895],\n",
      "        [ 0.0209],\n",
      "        [ 0.0515],\n",
      "        [ 0.1114]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3810, 0.3853, 0.3878, 0.4008, 0.4024, 0.3993, 0.3987, 0.4151, 0.4129,\n",
      "        0.4212, 0.4224, 0.4207, 0.4139, 0.4058, 0.4043, 0.4005, 0.3831, 0.3745,\n",
      "        0.3816, 0.3866, 0.4401, 0.4525, 0.4764, 0.4814, 0.4649, 0.4644, 0.4747,\n",
      "        0.4820, 0.4814, 0.4817, 0.4749, 0.4938], device='cuda:0')\n",
      "tensor([[ 0.0636],\n",
      "        [ 0.0246],\n",
      "        [-0.0016],\n",
      "        [ 0.0446],\n",
      "        [ 0.0359],\n",
      "        [ 0.0513],\n",
      "        [ 0.0422],\n",
      "        [ 0.1174],\n",
      "        [ 0.0871],\n",
      "        [ 0.1696],\n",
      "        [ 0.0498],\n",
      "        [ 0.0718],\n",
      "        [ 0.0508],\n",
      "        [ 0.0140],\n",
      "        [ 0.0156],\n",
      "        [ 0.0665],\n",
      "        [ 0.0262],\n",
      "        [ 0.0159],\n",
      "        [-0.0542],\n",
      "        [-0.0055],\n",
      "        [ 0.0481],\n",
      "        [ 0.0419],\n",
      "        [ 0.0440],\n",
      "        [ 0.0332],\n",
      "        [ 0.0031],\n",
      "        [ 0.0191],\n",
      "        [ 0.0289],\n",
      "        [-0.0467],\n",
      "        [ 0.0472],\n",
      "        [-0.0208],\n",
      "        [ 0.0578],\n",
      "        [-0.0055]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4970, 0.5026, 0.5133, 0.5617, 0.5457, 0.5416, 0.5440, 0.5378, 0.5307,\n",
      "        0.5248, 0.5091, 0.5031, 0.5387, 0.5286, 0.5286, 0.5097, 0.5180, 0.5142,\n",
      "        0.5286, 0.5499, 0.5316, 0.5333, 0.5251, 0.5207, 0.5263, 0.5280, 0.5508,\n",
      "        0.5484, 0.5511, 0.5700, 0.5635, 0.5614], device='cuda:0')\n",
      "tensor([[-0.0240],\n",
      "        [ 0.0745],\n",
      "        [ 0.0621],\n",
      "        [ 0.0961],\n",
      "        [ 0.0176],\n",
      "        [ 0.0309],\n",
      "        [-0.0118],\n",
      "        [-0.0279],\n",
      "        [-0.0352],\n",
      "        [ 0.0481],\n",
      "        [ 0.0406],\n",
      "        [ 0.1036],\n",
      "        [ 0.0570],\n",
      "        [ 0.0020],\n",
      "        [ 0.0269],\n",
      "        [ 0.0225],\n",
      "        [ 0.0578],\n",
      "        [ 0.0480],\n",
      "        [ 0.0298],\n",
      "        [ 0.0644],\n",
      "        [ 0.0036],\n",
      "        [-0.0023],\n",
      "        [-0.0903],\n",
      "        [-0.0379],\n",
      "        [ 0.1580],\n",
      "        [ 0.1884],\n",
      "        [ 0.1766],\n",
      "        [ 0.0132],\n",
      "        [ 0.0359],\n",
      "        [-0.0018],\n",
      "        [ 0.0673],\n",
      "        [-0.0305]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5596, 0.5623, 0.5596, 0.5694, 0.5912, 0.5995, 0.6054, 0.5995, 0.6080,\n",
      "        0.6136, 0.6296, 0.6316, 0.6319, 0.6290, 0.6246, 0.6243, 0.6166, 0.5865,\n",
      "        0.5900, 0.5658, 0.5702, 0.5617, 0.5770, 0.5871, 0.5729, 0.5744, 0.5581,\n",
      "        0.5446, 0.5404, 0.5626, 0.5640, 0.5578], device='cuda:0')\n",
      "tensor([[ 0.0292],\n",
      "        [-0.0283],\n",
      "        [ 0.0602],\n",
      "        [ 0.0003],\n",
      "        [-0.0372],\n",
      "        [ 0.0340],\n",
      "        [-0.0297],\n",
      "        [ 0.0256],\n",
      "        [ 0.0082],\n",
      "        [ 0.0032],\n",
      "        [ 0.2200],\n",
      "        [-0.0063],\n",
      "        [ 0.0373],\n",
      "        [-0.0075],\n",
      "        [ 0.0331],\n",
      "        [ 0.0413],\n",
      "        [ 0.0228],\n",
      "        [-0.0038],\n",
      "        [ 0.0406],\n",
      "        [-0.0022],\n",
      "        [ 0.0442],\n",
      "        [ 0.0335],\n",
      "        [ 0.0576],\n",
      "        [ 0.0456],\n",
      "        [ 0.0669],\n",
      "        [-0.0137],\n",
      "        [ 0.0806],\n",
      "        [ 0.1847],\n",
      "        [ 0.0130],\n",
      "        [ 0.0275],\n",
      "        [-0.0516],\n",
      "        [-0.0261]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5443, 0.5632, 0.5528, 0.5635, 0.5823, 0.5877, 0.5658, 0.5614, 0.5558,\n",
      "        0.5685, 0.5570, 0.5587, 0.5614, 0.5664, 0.5626, 0.5691, 0.5818, 0.5753,\n",
      "        0.5894, 0.6042, 0.5983, 0.6172, 0.6184, 0.6060, 0.6104, 0.6039, 0.5947,\n",
      "        0.5729, 0.5953, 0.5812, 0.5720, 0.5570], device='cuda:0')\n",
      "tensor([[ 0.0995],\n",
      "        [ 0.0897],\n",
      "        [ 0.0274],\n",
      "        [-0.0333],\n",
      "        [ 0.0053],\n",
      "        [-0.0681],\n",
      "        [-0.0371],\n",
      "        [ 0.0363],\n",
      "        [-0.0154],\n",
      "        [ 0.0304],\n",
      "        [-0.0262],\n",
      "        [-0.0175],\n",
      "        [ 0.0727],\n",
      "        [-0.0296],\n",
      "        [ 0.0275],\n",
      "        [ 0.0245],\n",
      "        [-0.0215],\n",
      "        [-0.0108],\n",
      "        [ 0.0107],\n",
      "        [-0.0251],\n",
      "        [-0.0081],\n",
      "        [ 0.0686],\n",
      "        [ 0.0288],\n",
      "        [ 0.0695],\n",
      "        [-0.0959],\n",
      "        [ 0.0010],\n",
      "        [ 0.0335],\n",
      "        [-0.0140],\n",
      "        [-0.0243],\n",
      "        [ 0.0404],\n",
      "        [ 0.0829],\n",
      "        [ 0.0595]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5711, 0.5617, 0.5640, 0.5478, 0.5522, 0.5369, 0.5469, 0.5570, 0.5437,\n",
      "        0.5304, 0.5168, 0.5204, 0.5003, 0.4770, 0.4861, 0.4902, 0.4861, 0.4867,\n",
      "        0.4861, 0.4105, 0.4244, 0.4241, 0.4318, 0.4200, 0.4291, 0.4448, 0.4377,\n",
      "        0.4285, 0.4265, 0.4132, 0.4070, 0.4244], device='cuda:0')\n",
      "tensor([[-0.0335],\n",
      "        [ 0.0545],\n",
      "        [-0.0002],\n",
      "        [ 0.0488],\n",
      "        [ 0.0160],\n",
      "        [-0.0105],\n",
      "        [-0.0256],\n",
      "        [ 0.0254],\n",
      "        [ 0.0487],\n",
      "        [ 0.0318],\n",
      "        [ 0.0485],\n",
      "        [ 0.0070],\n",
      "        [ 0.0169],\n",
      "        [ 0.0199],\n",
      "        [ 0.1072],\n",
      "        [ 0.1621],\n",
      "        [ 0.0141],\n",
      "        [ 0.0370],\n",
      "        [-0.0073],\n",
      "        [ 0.0338],\n",
      "        [ 0.0007],\n",
      "        [ 0.0270],\n",
      "        [ 0.1081],\n",
      "        [ 0.0755],\n",
      "        [ 0.1400],\n",
      "        [ 0.1401],\n",
      "        [ 0.0613],\n",
      "        [ 0.0450],\n",
      "        [ 0.1149],\n",
      "        [ 0.0145],\n",
      "        [ 0.0029],\n",
      "        [ 0.0902]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4229, 0.4389, 0.4294, 0.4336, 0.4250, 0.4277, 0.4235, 0.4436, 0.4716,\n",
      "        0.4902, 0.4817, 0.4743, 0.4767, 0.4728, 0.4675, 0.4692, 0.4779, 0.5091,\n",
      "        0.5286, 0.5316, 0.5394, 0.5162, 0.4956, 0.4989, 0.4967, 0.4861, 0.4964,\n",
      "        0.5003, 0.4965, 0.5009, 0.4908, 0.4938], device='cuda:0')\n",
      "tensor([[ 0.0257],\n",
      "        [-0.0035],\n",
      "        [ 0.0127],\n",
      "        [-0.0009],\n",
      "        [-0.0133],\n",
      "        [-0.0100],\n",
      "        [-0.0300],\n",
      "        [ 0.0261],\n",
      "        [-0.0367],\n",
      "        [ 0.0322],\n",
      "        [ 0.1265],\n",
      "        [ 0.0325],\n",
      "        [ 0.1351],\n",
      "        [ 0.0722],\n",
      "        [ 0.0364],\n",
      "        [ 0.0687],\n",
      "        [ 0.1088],\n",
      "        [ 0.0750],\n",
      "        [ 0.0998],\n",
      "        [ 0.0899],\n",
      "        [-0.0219],\n",
      "        [ 0.0489],\n",
      "        [ 0.0285],\n",
      "        [ 0.0266],\n",
      "        [-0.0153],\n",
      "        [-0.0187],\n",
      "        [-0.0074],\n",
      "        [ 0.0389],\n",
      "        [ 0.0885],\n",
      "        [ 0.0962],\n",
      "        [-0.0087],\n",
      "        [ 0.0297]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4991, 0.4994, 0.4956, 0.4944, 0.4902, 0.5286, 0.5100, 0.5286, 0.5192,\n",
      "        0.5168, 0.5381, 0.5428, 0.5452, 0.5392, 0.5457, 0.5274, 0.5452, 0.5428,\n",
      "        0.5546, 0.5546, 0.5434, 0.5322, 0.5168, 0.5077, 0.5109, 0.5003, 0.5168,\n",
      "        0.5339, 0.5269, 0.5198, 0.5419, 0.5351], device='cuda:0')\n",
      "tensor([[ 0.0145],\n",
      "        [-0.0152],\n",
      "        [ 0.0287],\n",
      "        [ 0.0681],\n",
      "        [ 0.0021],\n",
      "        [-0.0100],\n",
      "        [ 0.0237],\n",
      "        [ 0.0614],\n",
      "        [ 0.0389],\n",
      "        [ 0.0210],\n",
      "        [ 0.0282],\n",
      "        [ 0.0270],\n",
      "        [ 0.0753],\n",
      "        [ 0.0104],\n",
      "        [ 0.0695],\n",
      "        [ 0.1271],\n",
      "        [-0.0063],\n",
      "        [ 0.1304],\n",
      "        [ 0.0355],\n",
      "        [ 0.0248],\n",
      "        [-0.0027],\n",
      "        [ 0.0134],\n",
      "        [ 0.0399],\n",
      "        [ 0.0048],\n",
      "        [-0.0240],\n",
      "        [ 0.0096],\n",
      "        [ 0.0767],\n",
      "        [-0.0186],\n",
      "        [ 0.0500],\n",
      "        [ 0.0307],\n",
      "        [ 0.1112],\n",
      "        [ 0.0692]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5434, 0.5257, 0.5289, 0.5339, 0.5274, 0.5322, 0.5121, 0.5050, 0.4944,\n",
      "        0.5026, 0.4908, 0.4743, 0.4660, 0.4542, 0.4678, 0.4908, 0.4675, 0.4672,\n",
      "        0.4826, 0.4908, 0.4778, 0.4894, 0.4938, 0.4861, 0.4956, 0.5003, 0.5133,\n",
      "        0.5168, 0.5204, 0.5251, 0.5505, 0.5800], device='cuda:0')\n",
      "tensor([[ 0.0566],\n",
      "        [ 0.0563],\n",
      "        [ 0.0402],\n",
      "        [ 0.0948],\n",
      "        [ 0.0831],\n",
      "        [ 0.0775],\n",
      "        [ 0.0263],\n",
      "        [ 0.0539],\n",
      "        [ 0.0184],\n",
      "        [-0.0158],\n",
      "        [ 0.0199],\n",
      "        [ 0.0220],\n",
      "        [ 0.0121],\n",
      "        [ 0.0107],\n",
      "        [-0.0037],\n",
      "        [ 0.0042],\n",
      "        [-0.0108],\n",
      "        [-0.0288],\n",
      "        [ 0.0106],\n",
      "        [-0.0211],\n",
      "        [ 0.0276],\n",
      "        [-0.0091],\n",
      "        [-0.0060],\n",
      "        [ 0.0481],\n",
      "        [-0.0193],\n",
      "        [ 0.0424],\n",
      "        [-0.0106],\n",
      "        [ 0.0185],\n",
      "        [ 0.0098],\n",
      "        [-0.0008],\n",
      "        [ 0.0303],\n",
      "        [-0.0168]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5593, 0.5428, 0.5605, 0.5398, 0.5570, 0.5531, 0.5711, 0.5605, 0.5623,\n",
      "        0.5576, 0.5446, 0.5180, 0.5032, 0.4767, 0.5091, 0.5074, 0.4767, 0.4719,\n",
      "        0.4838, 0.5121, 0.5026, 0.5032, 0.5074, 0.5097, 0.5068, 0.4914, 0.4891,\n",
      "        0.4902, 0.4991, 0.4956, 0.4672, 0.4740], device='cuda:0')\n",
      "tensor([[ 3.0504e-02],\n",
      "        [-4.3264e-03],\n",
      "        [ 1.6670e-02],\n",
      "        [ 4.5401e-02],\n",
      "        [ 5.3685e-02],\n",
      "        [ 6.7736e-03],\n",
      "        [-5.4238e-02],\n",
      "        [-3.2949e-02],\n",
      "        [ 1.8307e-02],\n",
      "        [ 3.3635e-02],\n",
      "        [-9.8721e-03],\n",
      "        [ 6.6266e-02],\n",
      "        [-1.3285e-02],\n",
      "        [ 5.6979e-02],\n",
      "        [-3.6310e-03],\n",
      "        [ 3.7349e-02],\n",
      "        [-1.7989e-02],\n",
      "        [ 1.3526e-04],\n",
      "        [ 4.1400e-02],\n",
      "        [ 2.0265e-02],\n",
      "        [-6.0018e-03],\n",
      "        [ 4.2156e-02],\n",
      "        [ 1.9511e-01],\n",
      "        [ 2.5453e-01],\n",
      "        [ 7.5469e-02],\n",
      "        [ 2.6593e-02],\n",
      "        [ 1.1560e-01],\n",
      "        [ 1.7689e-02],\n",
      "        [ 2.1397e-02],\n",
      "        [-1.9030e-02],\n",
      "        [-2.0592e-02],\n",
      "        [ 2.2976e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4740, 0.4728, 0.4956, 0.4902, 0.4817, 0.4835, 0.4967, 0.4879, 0.4985,\n",
      "        0.4838, 0.4858, 0.5047, 0.4876, 0.4814, 0.4947, 0.5136, 0.5115, 0.5522,\n",
      "        0.5463, 0.5460, 0.5421, 0.5443, 0.5286, 0.5325, 0.5156, 0.5493, 0.5304,\n",
      "        0.5215, 0.5088, 0.5091, 0.5211, 0.4991], device='cuda:0')\n",
      "tensor([[ 0.0365],\n",
      "        [ 0.0310],\n",
      "        [ 0.0188],\n",
      "        [ 0.0199],\n",
      "        [ 0.0537],\n",
      "        [-0.0351],\n",
      "        [ 0.0447],\n",
      "        [ 0.0236],\n",
      "        [ 0.0252],\n",
      "        [ 0.1851],\n",
      "        [ 0.0066],\n",
      "        [ 0.0123],\n",
      "        [-0.0028],\n",
      "        [-0.0089],\n",
      "        [-0.0006],\n",
      "        [ 0.0473],\n",
      "        [-0.0129],\n",
      "        [ 0.0230],\n",
      "        [-0.0284],\n",
      "        [ 0.0284],\n",
      "        [ 0.3681],\n",
      "        [ 0.0271],\n",
      "        [ 0.0362],\n",
      "        [ 0.1007],\n",
      "        [ 0.0200],\n",
      "        [ 0.0433],\n",
      "        [ 0.0064],\n",
      "        [ 0.0325],\n",
      "        [-0.0018],\n",
      "        [ 0.0498],\n",
      "        [ 0.0084],\n",
      "        [ 0.0756]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5181, 0.5192, 0.4982, 0.4979, 0.4767, 0.4590, 0.4770, 0.4687, 0.4625,\n",
      "        0.4749, 0.4719, 0.4716, 0.4790, 0.4687, 0.4944, 0.5345, 0.5227, 0.5121,\n",
      "        0.5097, 0.4997, 0.5018, 0.5088, 0.5109, 0.5026, 0.5204, 0.5286, 0.5280,\n",
      "        0.5301, 0.5422, 0.5416, 0.5463, 0.5505], device='cuda:0')\n",
      "tensor([[ 0.0330],\n",
      "        [ 0.0365],\n",
      "        [ 0.0291],\n",
      "        [ 0.0418],\n",
      "        [ 0.0827],\n",
      "        [ 0.0971],\n",
      "        [ 0.0535],\n",
      "        [ 0.0831],\n",
      "        [ 0.0108],\n",
      "        [ 0.0048],\n",
      "        [ 0.0601],\n",
      "        [ 0.0428],\n",
      "        [ 0.0107],\n",
      "        [-0.0248],\n",
      "        [ 0.0644],\n",
      "        [ 0.0769],\n",
      "        [ 0.1481],\n",
      "        [ 0.0332],\n",
      "        [ 0.0773],\n",
      "        [ 0.0068],\n",
      "        [ 0.0246],\n",
      "        [ 0.0224],\n",
      "        [ 0.0507],\n",
      "        [ 0.0213],\n",
      "        [-0.0659],\n",
      "        [ 0.0328],\n",
      "        [ 0.1044],\n",
      "        [ 0.0176],\n",
      "        [ 0.1000],\n",
      "        [ 0.0228],\n",
      "        [ 0.0690],\n",
      "        [-0.0553]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5629, 0.5570, 0.5587, 0.5593, 0.5496, 0.5543, 0.5540, 0.5629, 0.5702,\n",
      "        0.5900, 0.6018, 0.6083, 0.5962, 0.6043, 0.6119, 0.6004, 0.6015, 0.6107,\n",
      "        0.5924, 0.5688, 0.5711, 0.5838, 0.5800, 0.5711, 0.5629, 0.5708, 0.5700,\n",
      "        0.5546, 0.5658, 0.5617, 0.5434, 0.5381], device='cuda:0')\n",
      "tensor([[-0.0206],\n",
      "        [-0.0151],\n",
      "        [ 0.0368],\n",
      "        [ 0.0317],\n",
      "        [ 0.0964],\n",
      "        [-0.0231],\n",
      "        [-0.0358],\n",
      "        [ 0.0365],\n",
      "        [ 0.0615],\n",
      "        [ 0.0325],\n",
      "        [ 0.0259],\n",
      "        [ 0.0106],\n",
      "        [ 0.0045],\n",
      "        [ 0.0092],\n",
      "        [-0.0492],\n",
      "        [-0.0169],\n",
      "        [-0.0257],\n",
      "        [ 0.0179],\n",
      "        [ 0.0315],\n",
      "        [-0.0074],\n",
      "        [ 0.0222],\n",
      "        [ 0.0014],\n",
      "        [ 0.0495],\n",
      "        [ 0.1032],\n",
      "        [-0.0342],\n",
      "        [-0.0272],\n",
      "        [ 0.0116],\n",
      "        [ 0.0116],\n",
      "        [ 0.0785],\n",
      "        [ 0.0862],\n",
      "        [ 0.1047],\n",
      "        [ 0.2218]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5251, 0.5127, 0.5372, 0.5029, 0.5209, 0.5153, 0.5286, 0.5378, 0.5233,\n",
      "        0.5097, 0.4678, 0.4959, 0.5056, 0.5145, 0.4315, 0.4362, 0.4283, 0.4194,\n",
      "        0.4126, 0.3943, 0.4188, 0.4232, 0.4215, 0.4460, 0.4463, 0.4622, 0.4536,\n",
      "        0.4545, 0.4640, 0.4531, 0.4504, 0.4200], device='cuda:0')\n",
      "tensor([[ 0.0387],\n",
      "        [ 0.0331],\n",
      "        [ 0.1147],\n",
      "        [ 0.1146],\n",
      "        [ 0.0481],\n",
      "        [ 0.0198],\n",
      "        [-0.0135],\n",
      "        [ 0.0490],\n",
      "        [ 0.0210],\n",
      "        [ 0.1217],\n",
      "        [ 0.0999],\n",
      "        [-0.0286],\n",
      "        [-0.0133],\n",
      "        [ 0.0072],\n",
      "        [ 0.0409],\n",
      "        [ 0.0410],\n",
      "        [ 0.0325],\n",
      "        [ 0.0342],\n",
      "        [ 0.0234],\n",
      "        [ 0.0017],\n",
      "        [-0.0040],\n",
      "        [ 0.0008],\n",
      "        [-0.0065],\n",
      "        [-0.0140],\n",
      "        [ 0.0708],\n",
      "        [ 0.0853],\n",
      "        [-0.0071],\n",
      "        [-0.0422],\n",
      "        [ 0.1028],\n",
      "        [ 0.0772],\n",
      "        [ 0.0004],\n",
      "        [-0.0140]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4409, 0.4507, 0.4501, 0.4448, 0.4622, 0.4684, 0.4460, 0.4460, 0.4528,\n",
      "        0.4457, 0.4430, 0.4522, 0.4224, 0.4324, 0.4454, 0.4690, 0.4377, 0.4206,\n",
      "        0.4389, 0.4294, 0.4241, 0.4117, 0.4173, 0.3955, 0.4082, 0.4064, 0.3869,\n",
      "        0.3660, 0.4011, 0.3813, 0.3807, 0.3834], device='cuda:0')\n",
      "tensor([[ 0.1363],\n",
      "        [-0.0185],\n",
      "        [ 0.0546],\n",
      "        [-0.0110],\n",
      "        [ 0.0406],\n",
      "        [-0.0695],\n",
      "        [ 0.0235],\n",
      "        [ 0.0502],\n",
      "        [ 0.0398],\n",
      "        [ 0.0954],\n",
      "        [ 0.0237],\n",
      "        [ 0.0381],\n",
      "        [ 0.0021],\n",
      "        [ 0.0193],\n",
      "        [ 0.0145],\n",
      "        [-0.0005],\n",
      "        [ 0.0479],\n",
      "        [ 0.0107],\n",
      "        [ 0.1083],\n",
      "        [ 0.1072],\n",
      "        [ 0.1691],\n",
      "        [ 0.1056],\n",
      "        [ 0.0351],\n",
      "        [-0.0498],\n",
      "        [-0.0188],\n",
      "        [ 0.0120],\n",
      "        [-0.0063],\n",
      "        [ 0.0300],\n",
      "        [-0.0110],\n",
      "        [ 0.0089],\n",
      "        [ 0.0158],\n",
      "        [ 0.0102]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3822, 0.3813, 0.4277, 0.4209, 0.4247, 0.4226, 0.4179, 0.4221, 0.4232,\n",
      "        0.4238, 0.4188, 0.4374, 0.4923, 0.5062, 0.4935, 0.4959, 0.5023, 0.5038,\n",
      "        0.5201, 0.5238, 0.5315, 0.5097, 0.5194, 0.5016, 0.5108, 0.5201, 0.5329,\n",
      "        0.5196, 0.5097, 0.5234, 0.5180, 0.5244], device='cuda:0')\n",
      "tensor([[-0.0484],\n",
      "        [ 0.0303],\n",
      "        [ 0.0497],\n",
      "        [ 0.0255],\n",
      "        [ 0.0809],\n",
      "        [ 0.0055],\n",
      "        [-0.0096],\n",
      "        [ 0.0228],\n",
      "        [-0.0305],\n",
      "        [ 0.0016],\n",
      "        [ 0.0860],\n",
      "        [ 0.0761],\n",
      "        [ 0.0318],\n",
      "        [ 0.0032],\n",
      "        [ 0.0405],\n",
      "        [ 0.0411],\n",
      "        [-0.0496],\n",
      "        [ 0.0556],\n",
      "        [ 0.0607],\n",
      "        [ 0.0176],\n",
      "        [ 0.1066],\n",
      "        [ 0.0422],\n",
      "        [ 0.0418],\n",
      "        [ 0.0111],\n",
      "        [ 0.0249],\n",
      "        [ 0.1268],\n",
      "        [-0.0108],\n",
      "        [ 0.0037],\n",
      "        [ 0.0370],\n",
      "        [ 0.0004],\n",
      "        [ 0.1797],\n",
      "        [ 0.0488]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5323, 0.5239, 0.5074, 0.4885, 0.4951, 0.4719, 0.4781, 0.4653, 0.4526,\n",
      "        0.4816, 0.4639, 0.4762, 0.4814, 0.4887, 0.4836, 0.4497, 0.4317, 0.4454,\n",
      "        0.4292, 0.4321, 0.4063, 0.4181, 0.3978, 0.4015, 0.4016, 0.4224, 0.4313,\n",
      "        0.4507, 0.4266, 0.4296, 0.4350, 0.4278], device='cuda:0')\n",
      "tensor([[ 0.0185],\n",
      "        [-0.0370],\n",
      "        [ 0.0515],\n",
      "        [ 0.0318],\n",
      "        [ 0.0440],\n",
      "        [ 0.0251],\n",
      "        [ 0.0466],\n",
      "        [ 0.0033],\n",
      "        [ 0.0202],\n",
      "        [-0.0122],\n",
      "        [-0.0128],\n",
      "        [ 0.0579],\n",
      "        [ 0.0798],\n",
      "        [-0.0045],\n",
      "        [-0.0012],\n",
      "        [ 0.0275],\n",
      "        [ 0.2285],\n",
      "        [ 0.0585],\n",
      "        [ 0.1108],\n",
      "        [ 0.0442],\n",
      "        [ 0.0274],\n",
      "        [-0.0865],\n",
      "        [ 0.0078],\n",
      "        [ 0.0498],\n",
      "        [ 0.0063],\n",
      "        [ 0.0658],\n",
      "        [ 0.0031],\n",
      "        [ 0.0343],\n",
      "        [ 0.0345],\n",
      "        [-0.0343],\n",
      "        [-0.0514],\n",
      "        [ 0.0220]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4077, 0.4153, 0.4446, 0.4434, 0.4342, 0.4486, 0.4409, 0.4351, 0.4377,\n",
      "        0.4516, 0.4838, 0.5214, 0.5231, 0.5097, 0.5129, 0.5232, 0.5179, 0.5296,\n",
      "        0.5246, 0.5405, 0.5258, 0.5178, 0.5280, 0.5282, 0.5367, 0.5333, 0.5248,\n",
      "        0.5088, 0.5124, 0.5172, 0.5277, 0.5242], device='cuda:0')\n",
      "tensor([[ 0.0222],\n",
      "        [-0.0111],\n",
      "        [-0.0043],\n",
      "        [-0.0031],\n",
      "        [-0.0122],\n",
      "        [ 0.0438],\n",
      "        [ 0.0701],\n",
      "        [ 0.0261],\n",
      "        [ 0.0573],\n",
      "        [ 0.0023],\n",
      "        [ 0.0456],\n",
      "        [-0.0212],\n",
      "        [ 0.0993],\n",
      "        [ 0.0832],\n",
      "        [-0.0084],\n",
      "        [-0.0351],\n",
      "        [ 0.0175],\n",
      "        [ 0.0018],\n",
      "        [ 0.0373],\n",
      "        [ 0.0496],\n",
      "        [ 0.0078],\n",
      "        [ 0.0505],\n",
      "        [ 0.0255],\n",
      "        [ 0.0249],\n",
      "        [ 0.0516],\n",
      "        [ 0.0209],\n",
      "        [ 0.0320],\n",
      "        [ 0.0446],\n",
      "        [ 0.0216],\n",
      "        [ 0.0274],\n",
      "        [ 0.0518],\n",
      "        [ 0.0257]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5354, 0.5430, 0.5381, 0.5352, 0.5456, 0.5371, 0.5252, 0.5128, 0.5088,\n",
      "        0.5139, 0.5175, 0.5332, 0.5357, 0.5345, 0.5291, 0.5350, 0.5345, 0.5312,\n",
      "        0.5274, 0.5173, 0.5205, 0.5231, 0.5149, 0.5126, 0.5138, 0.5128, 0.5146,\n",
      "        0.5169, 0.5244, 0.5168, 0.5208, 0.5144], device='cuda:0')\n",
      "tensor([[ 0.0018],\n",
      "        [-0.0025],\n",
      "        [ 0.0630],\n",
      "        [ 0.0391],\n",
      "        [ 0.0125],\n",
      "        [ 0.0360],\n",
      "        [ 0.1268],\n",
      "        [ 0.0236],\n",
      "        [-0.0223],\n",
      "        [ 0.0165],\n",
      "        [ 0.0240],\n",
      "        [ 0.0010],\n",
      "        [ 0.0073],\n",
      "        [ 0.1279],\n",
      "        [ 0.0492],\n",
      "        [ 0.0141],\n",
      "        [ 0.0352],\n",
      "        [ 0.0194],\n",
      "        [ 0.0408],\n",
      "        [ 0.0790],\n",
      "        [ 0.0405],\n",
      "        [ 0.0006],\n",
      "        [ 0.0565],\n",
      "        [ 0.0336],\n",
      "        [ 0.0995],\n",
      "        [ 0.0320],\n",
      "        [ 0.0226],\n",
      "        [ 0.0572],\n",
      "        [ 0.0580],\n",
      "        [ 0.0568],\n",
      "        [ 0.0395],\n",
      "        [ 0.0633]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5102, 0.4838, 0.4753, 0.4623, 0.4712, 0.4873, 0.4933, 0.4900, 0.4933,\n",
      "        0.4733, 0.4719, 0.4800, 0.4807, 0.4744, 0.4761, 0.4814, 0.4753, 0.4807,\n",
      "        0.4777, 0.4864, 0.4946, 0.4917, 0.4838, 0.4826, 0.4728, 0.4723, 0.4764,\n",
      "        0.4807, 0.4823, 0.4767, 0.4802, 0.4747], device='cuda:0')\n",
      "tensor([[-0.0080],\n",
      "        [ 0.0494],\n",
      "        [-0.0140],\n",
      "        [ 0.0097],\n",
      "        [ 0.0565],\n",
      "        [ 0.0525],\n",
      "        [ 0.1008],\n",
      "        [ 0.0134],\n",
      "        [-0.0012],\n",
      "        [ 0.0778],\n",
      "        [ 0.0650],\n",
      "        [-0.0285],\n",
      "        [-0.0315],\n",
      "        [ 0.0592],\n",
      "        [ 0.0654],\n",
      "        [-0.0021],\n",
      "        [ 0.0214],\n",
      "        [ 0.0423],\n",
      "        [-0.0285],\n",
      "        [ 0.0030],\n",
      "        [ 0.0626],\n",
      "        [ 0.0494],\n",
      "        [-0.0397],\n",
      "        [ 0.0607],\n",
      "        [ 0.0434],\n",
      "        [ 0.0090],\n",
      "        [ 0.0048],\n",
      "        [ 0.0312],\n",
      "        [ 0.0030],\n",
      "        [ 0.0287],\n",
      "        [-0.0077],\n",
      "        [ 0.0564]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4724, 0.4620, 0.4718, 0.4672, 0.4861, 0.4855, 0.4764, 0.4726, 0.4548,\n",
      "        0.4528, 0.4601, 0.4547, 0.4436, 0.4369, 0.4364, 0.4216, 0.4360, 0.4342,\n",
      "        0.4219, 0.4082, 0.4285, 0.4268, 0.4120, 0.4058, 0.4139, 0.4186, 0.4236,\n",
      "        0.4386, 0.4403, 0.4437, 0.4460, 0.4395], device='cuda:0')\n",
      "tensor([[ 0.0219],\n",
      "        [ 0.0488],\n",
      "        [-0.0363],\n",
      "        [ 0.0516],\n",
      "        [ 0.0034],\n",
      "        [ 0.0035],\n",
      "        [ 0.0096],\n",
      "        [ 0.0871],\n",
      "        [ 0.0155],\n",
      "        [ 0.1065],\n",
      "        [ 0.1286],\n",
      "        [ 0.0262],\n",
      "        [ 0.0328],\n",
      "        [ 0.0266],\n",
      "        [ 0.0336],\n",
      "        [ 0.0580],\n",
      "        [ 0.1341],\n",
      "        [ 0.1678],\n",
      "        [ 0.0267],\n",
      "        [ 0.0021],\n",
      "        [ 0.0675],\n",
      "        [ 0.0898],\n",
      "        [ 0.1126],\n",
      "        [-0.0247],\n",
      "        [ 0.0142],\n",
      "        [ 0.0305],\n",
      "        [-0.0117],\n",
      "        [-0.0679],\n",
      "        [-0.0444],\n",
      "        [ 0.0259],\n",
      "        [ 0.1141],\n",
      "        [ 0.1001]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4401, 0.4502, 0.4570, 0.4625, 0.4618, 0.4667, 0.4590, 0.4656, 0.4778,\n",
      "        0.4805, 0.4935, 0.5034, 0.5058, 0.4938, 0.4939, 0.4912, 0.4998, 0.4979,\n",
      "        0.5001, 0.5173, 0.5185, 0.5183, 0.5196, 0.5232, 0.5319, 0.5208, 0.5227,\n",
      "        0.5215, 0.5239, 0.5260, 0.5208, 0.5256], device='cuda:0')\n",
      "tensor([[ 1.5056e-02],\n",
      "        [ 3.7882e-02],\n",
      "        [-4.1390e-02],\n",
      "        [ 3.4389e-02],\n",
      "        [-3.0043e-02],\n",
      "        [ 1.7323e-04],\n",
      "        [ 5.4898e-02],\n",
      "        [ 1.4986e-01],\n",
      "        [ 8.6946e-02],\n",
      "        [-1.3655e-03],\n",
      "        [ 5.7482e-02],\n",
      "        [-2.0717e-02],\n",
      "        [ 2.5777e-01],\n",
      "        [ 1.4262e-01],\n",
      "        [ 3.6265e-02],\n",
      "        [ 7.7328e-03],\n",
      "        [ 2.1843e-02],\n",
      "        [ 7.3959e-02],\n",
      "        [ 7.5229e-02],\n",
      "        [ 1.4006e-02],\n",
      "        [-2.6876e-04],\n",
      "        [ 1.3286e-02],\n",
      "        [ 2.9693e-02],\n",
      "        [-9.3034e-03],\n",
      "        [ 3.8870e-02],\n",
      "        [ 3.5912e-02],\n",
      "        [ 4.0712e-02],\n",
      "        [ 1.0291e-02],\n",
      "        [-2.8945e-02],\n",
      "        [-2.7982e-02],\n",
      "        [ 1.2732e-02],\n",
      "        [ 3.2949e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5302, 0.5201, 0.5104, 0.5212, 0.5267, 0.5198, 0.5316, 0.5541, 0.5482,\n",
      "        0.5494, 0.5459, 0.5546, 0.5626, 0.5487, 0.5527, 0.5538, 0.5579, 0.5659,\n",
      "        0.5603, 0.5570, 0.5544, 0.5589, 0.5640, 0.5612, 0.5520, 0.5546, 0.5648,\n",
      "        0.5740, 0.5666, 0.5697, 0.5687, 0.5576], device='cuda:0')\n",
      "tensor([[-0.0306],\n",
      "        [ 0.0313],\n",
      "        [ 0.0400],\n",
      "        [ 0.0221],\n",
      "        [ 0.0429],\n",
      "        [ 0.0113],\n",
      "        [ 0.0369],\n",
      "        [ 0.0209],\n",
      "        [ 0.0449],\n",
      "        [ 0.0507],\n",
      "        [ 0.0167],\n",
      "        [ 0.0466],\n",
      "        [ 0.0382],\n",
      "        [ 0.0879],\n",
      "        [ 0.0814],\n",
      "        [ 0.0388],\n",
      "        [ 0.0897],\n",
      "        [ 0.0371],\n",
      "        [-0.0216],\n",
      "        [-0.0009],\n",
      "        [ 0.0331],\n",
      "        [-0.0461],\n",
      "        [ 0.0341],\n",
      "        [ 0.0399],\n",
      "        [-0.0032],\n",
      "        [ 0.0224],\n",
      "        [ 0.0265],\n",
      "        [ 0.0420],\n",
      "        [ 0.0675],\n",
      "        [ 0.0099],\n",
      "        [ 0.1104],\n",
      "        [ 0.0883]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5490, 0.5383, 0.5421, 0.5352, 0.5470, 0.5204, 0.5026, 0.4904, 0.4942,\n",
      "        0.4969, 0.4915, 0.4672, 0.4793, 0.4903, 0.4908, 0.4852, 0.4828, 0.4844,\n",
      "        0.4715, 0.4766, 0.4879, 0.4841, 0.4912, 0.4903, 0.4667, 0.4592, 0.4498,\n",
      "        0.4360, 0.4457, 0.4450, 0.4396, 0.4428], device='cuda:0')\n",
      "tensor([[-2.2608e-02],\n",
      "        [ 7.8529e-02],\n",
      "        [ 6.0529e-02],\n",
      "        [ 8.2343e-02],\n",
      "        [ 1.0352e-02],\n",
      "        [ 1.7940e-02],\n",
      "        [ 2.3293e-02],\n",
      "        [ 2.4911e-02],\n",
      "        [ 8.3767e-02],\n",
      "        [ 1.9211e-01],\n",
      "        [ 6.8119e-02],\n",
      "        [ 9.7827e-02],\n",
      "        [-6.2105e-03],\n",
      "        [ 1.1562e-01],\n",
      "        [ 6.1014e-02],\n",
      "        [ 2.5994e-02],\n",
      "        [ 1.4152e-01],\n",
      "        [ 4.5776e-02],\n",
      "        [-2.2037e-02],\n",
      "        [-1.2641e-02],\n",
      "        [ 1.5360e-04],\n",
      "        [ 3.3418e-02],\n",
      "        [ 2.2637e-02],\n",
      "        [ 8.1349e-02],\n",
      "        [-3.9726e-03],\n",
      "        [ 1.4549e-02],\n",
      "        [ 8.2170e-03],\n",
      "        [ 4.4750e-02],\n",
      "        [-5.1161e-02],\n",
      "        [ 7.2399e-03],\n",
      "        [ 9.1415e-02],\n",
      "        [ 3.1686e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4442, 0.4673, 0.4809, 0.4798, 0.4828, 0.4706, 0.4771, 0.4778, 0.4932,\n",
      "        0.4870, 0.4842, 0.4851, 0.4830, 0.4884, 0.4790, 0.4851, 0.4795, 0.4699,\n",
      "        0.4667, 0.4691, 0.4719, 0.4666, 0.4575, 0.4529, 0.4570, 0.4401, 0.3936,\n",
      "        0.3951, 0.4011, 0.3784, 0.3850, 0.3839], device='cuda:0')\n",
      "tensor([[ 0.1541],\n",
      "        [-0.0070],\n",
      "        [ 0.0985],\n",
      "        [-0.0051],\n",
      "        [ 0.0378],\n",
      "        [ 0.0352],\n",
      "        [-0.0292],\n",
      "        [ 0.0954],\n",
      "        [ 0.0544],\n",
      "        [ 0.0165],\n",
      "        [ 0.0083],\n",
      "        [ 0.0050],\n",
      "        [ 0.0177],\n",
      "        [ 0.0307],\n",
      "        [ 0.0120],\n",
      "        [ 0.0180],\n",
      "        [ 0.0947],\n",
      "        [ 0.0300],\n",
      "        [ 0.0006],\n",
      "        [ 0.0331],\n",
      "        [ 0.0221],\n",
      "        [-0.0004],\n",
      "        [ 0.0336],\n",
      "        [-0.0180],\n",
      "        [ 0.0536],\n",
      "        [ 0.0481],\n",
      "        [ 0.0649],\n",
      "        [ 0.0528],\n",
      "        [ 0.1182],\n",
      "        [ 0.0274],\n",
      "        [ 0.0175],\n",
      "        [ 0.1149]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3879, 0.3813, 0.4009, 0.4011, 0.3960, 0.3932, 0.3893, 0.3903, 0.3808,\n",
      "        0.3770, 0.3763, 0.3789, 0.3768, 0.3670, 0.3397, 0.3421, 0.3702, 0.3583,\n",
      "        0.3571, 0.3689, 0.3845, 0.3798, 0.3843, 0.3855, 0.3796, 0.3749, 0.3775,\n",
      "        0.3791, 0.3732, 0.3684, 0.3661, 0.3692], device='cuda:0')\n",
      "tensor([[ 8.1706e-02],\n",
      "        [ 1.5698e-02],\n",
      "        [-2.3737e-03],\n",
      "        [ 2.2392e-02],\n",
      "        [ 8.6021e-02],\n",
      "        [-3.1934e-02],\n",
      "        [ 6.3306e-02],\n",
      "        [ 4.3323e-02],\n",
      "        [-1.4247e-02],\n",
      "        [-2.3724e-02],\n",
      "        [ 1.5850e-04],\n",
      "        [ 1.1010e-02],\n",
      "        [ 6.5102e-02],\n",
      "        [ 1.6527e-01],\n",
      "        [ 3.6363e-03],\n",
      "        [-7.0156e-03],\n",
      "        [ 6.9959e-02],\n",
      "        [ 3.2713e-03],\n",
      "        [ 1.2344e-02],\n",
      "        [ 2.4573e-02],\n",
      "        [ 1.4861e-02],\n",
      "        [ 3.2091e-02],\n",
      "        [-1.8627e-02],\n",
      "        [ 3.0978e-03],\n",
      "        [ 4.4106e-02],\n",
      "        [ 1.2590e-01],\n",
      "        [ 3.8168e-02],\n",
      "        [-1.7011e-02],\n",
      "        [ 6.5654e-02],\n",
      "        [ 5.8452e-02],\n",
      "        [ 4.8069e-02],\n",
      "        [ 2.0608e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3607, 0.3497, 0.3553, 0.3612, 0.3570, 0.3506, 0.3435, 0.3373, 0.3333,\n",
      "        0.3378, 0.3405, 0.3451, 0.3394, 0.3272, 0.3188, 0.3055, 0.3099, 0.3047,\n",
      "        0.3116, 0.3203, 0.3208, 0.3000, 0.3046, 0.3138, 0.3279, 0.3175, 0.3098,\n",
      "        0.3055, 0.3086, 0.3076, 0.3161, 0.3067], device='cuda:0')\n",
      "tensor([[ 0.0314],\n",
      "        [ 0.0201],\n",
      "        [-0.0060],\n",
      "        [ 0.0555],\n",
      "        [ 0.0077],\n",
      "        [ 0.0670],\n",
      "        [ 0.0865],\n",
      "        [ 0.0410],\n",
      "        [-0.0016],\n",
      "        [ 0.0705],\n",
      "        [-0.0041],\n",
      "        [ 0.0208],\n",
      "        [ 0.0370],\n",
      "        [ 0.0306],\n",
      "        [ 0.0405],\n",
      "        [ 0.0466],\n",
      "        [ 0.0371],\n",
      "        [ 0.0321],\n",
      "        [ 0.0835],\n",
      "        [-0.0027],\n",
      "        [ 0.0627],\n",
      "        [ 0.0096],\n",
      "        [ 0.0080],\n",
      "        [ 0.0423],\n",
      "        [ 0.0161],\n",
      "        [ 0.0664],\n",
      "        [ 0.0336],\n",
      "        [ 0.1840],\n",
      "        [ 0.1969],\n",
      "        [ 0.1179],\n",
      "        [ 0.0596],\n",
      "        [ 0.0862]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3146, 0.3210, 0.3208, 0.3043, 0.2974, 0.3092, 0.3083, 0.2944, 0.3169,\n",
      "        0.3198, 0.3132, 0.3031, 0.3013, 0.2924, 0.3014, 0.3074, 0.3190, 0.3200,\n",
      "        0.3197, 0.3203, 0.3346, 0.3421, 0.3555, 0.3703, 0.3646, 0.3633, 0.3680,\n",
      "        0.3605, 0.3558, 0.3490, 0.3400, 0.3426], device='cuda:0')\n",
      "tensor([[-0.0207],\n",
      "        [ 0.1184],\n",
      "        [ 0.1263],\n",
      "        [-0.0735],\n",
      "        [-0.0086],\n",
      "        [-0.0215],\n",
      "        [ 0.0552],\n",
      "        [-0.0088],\n",
      "        [ 0.0235],\n",
      "        [-0.0225],\n",
      "        [-0.0176],\n",
      "        [-0.0081],\n",
      "        [ 0.0056],\n",
      "        [ 0.0364],\n",
      "        [-0.0225],\n",
      "        [ 0.0110],\n",
      "        [ 0.0057],\n",
      "        [ 0.0025],\n",
      "        [ 0.0521],\n",
      "        [ 0.0401],\n",
      "        [-0.0683],\n",
      "        [ 0.0412],\n",
      "        [ 0.0423],\n",
      "        [-0.0077],\n",
      "        [-0.0137],\n",
      "        [ 0.0333],\n",
      "        [ 0.0488],\n",
      "        [ 0.0752],\n",
      "        [ 0.0035],\n",
      "        [ 0.0520],\n",
      "        [ 0.0490],\n",
      "        [-0.0078]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3368, 0.3225, 0.3290, 0.3217, 0.3265, 0.3326, 0.3378, 0.3312, 0.3202,\n",
      "        0.3232, 0.3223, 0.3196, 0.3092, 0.2868, 0.2826, 0.2800, 0.2629, 0.2783,\n",
      "        0.2737, 0.2658, 0.2561, 0.2696, 0.2624, 0.2641, 0.2481, 0.2493, 0.2502,\n",
      "        0.2408, 0.2527, 0.2826, 0.2803, 0.3042], device='cuda:0')\n",
      "tensor([[-0.0607],\n",
      "        [ 0.0726],\n",
      "        [-0.0058],\n",
      "        [ 0.0281],\n",
      "        [ 0.1300],\n",
      "        [ 0.0318],\n",
      "        [-0.0248],\n",
      "        [ 0.0309],\n",
      "        [ 0.0947],\n",
      "        [ 0.0863],\n",
      "        [ 0.1069],\n",
      "        [ 0.0209],\n",
      "        [ 0.0011],\n",
      "        [ 0.0677],\n",
      "        [ 0.0422],\n",
      "        [ 0.0190],\n",
      "        [ 0.0138],\n",
      "        [ 0.0064],\n",
      "        [ 0.0318],\n",
      "        [ 0.0498],\n",
      "        [-0.0116],\n",
      "        [ 0.0346],\n",
      "        [ 0.0833],\n",
      "        [ 0.0181],\n",
      "        [ 0.0403],\n",
      "        [ 0.1020],\n",
      "        [-0.0095],\n",
      "        [ 0.0757],\n",
      "        [-0.0530],\n",
      "        [ 0.0179],\n",
      "        [ 0.0086],\n",
      "        [-0.0143]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2873, 0.3217, 0.3314, 0.3376, 0.3326, 0.3331, 0.3213, 0.3329, 0.3423,\n",
      "        0.3432, 0.3523, 0.3536, 0.3605, 0.3704, 0.3665, 0.3659, 0.3536, 0.3472,\n",
      "        0.3458, 0.3546, 0.3555, 0.3620, 0.3586, 0.3547, 0.3509, 0.3662, 0.3817,\n",
      "        0.3795, 0.3879, 0.3825, 0.3950, 0.3913], device='cuda:0')\n",
      "tensor([[ 0.0630],\n",
      "        [ 0.0552],\n",
      "        [ 0.0860],\n",
      "        [ 0.0656],\n",
      "        [ 0.0501],\n",
      "        [ 0.1179],\n",
      "        [ 0.0288],\n",
      "        [ 0.0411],\n",
      "        [ 0.0242],\n",
      "        [ 0.1267],\n",
      "        [-0.0088],\n",
      "        [ 0.0772],\n",
      "        [-0.0238],\n",
      "        [-0.0011],\n",
      "        [-0.0178],\n",
      "        [ 0.0373],\n",
      "        [ 0.0274],\n",
      "        [ 0.0131],\n",
      "        [ 0.0566],\n",
      "        [ 0.0292],\n",
      "        [ 0.0529],\n",
      "        [ 0.0426],\n",
      "        [ 0.0220],\n",
      "        [ 0.0795],\n",
      "        [ 0.0767],\n",
      "        [ 0.0427],\n",
      "        [ 0.0244],\n",
      "        [ 0.0106],\n",
      "        [ 0.1093],\n",
      "        [ 0.2218],\n",
      "        [ 0.1474],\n",
      "        [ 0.0042]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3931, 0.3832, 0.3760, 0.3730, 0.3695, 0.3567, 0.3624, 0.3654, 0.3594,\n",
      "        0.3586, 0.3662, 0.3601, 0.3545, 0.3523, 0.3576, 0.3598, 0.3575, 0.3515,\n",
      "        0.3461, 0.3409, 0.3468, 0.3613, 0.3664, 0.3755, 0.3869, 0.3784, 0.3916,\n",
      "        0.3949, 0.3941, 0.3991, 0.3944, 0.3872], device='cuda:0')\n",
      "tensor([[ 0.0693],\n",
      "        [ 0.1579],\n",
      "        [ 0.0751],\n",
      "        [ 0.0642],\n",
      "        [ 0.0599],\n",
      "        [ 0.0218],\n",
      "        [ 0.0058],\n",
      "        [ 0.1718],\n",
      "        [-0.0141],\n",
      "        [-0.0290],\n",
      "        [ 0.0230],\n",
      "        [ 0.0010],\n",
      "        [ 0.0594],\n",
      "        [ 0.0199],\n",
      "        [-0.0062],\n",
      "        [ 0.0410],\n",
      "        [ 0.0707],\n",
      "        [ 0.0502],\n",
      "        [ 0.0082],\n",
      "        [-0.0067],\n",
      "        [ 0.0351],\n",
      "        [-0.0123],\n",
      "        [ 0.0047],\n",
      "        [ 0.1112],\n",
      "        [ 0.0288],\n",
      "        [ 0.0659],\n",
      "        [ 0.0816],\n",
      "        [ 0.0394],\n",
      "        [ 0.0605],\n",
      "        [ 0.0332],\n",
      "        [ 0.0683],\n",
      "        [ 0.0126]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3647, 0.3611, 0.3572, 0.3635, 0.3538, 0.3511, 0.3591, 0.3601, 0.3506,\n",
      "        0.3501, 0.3500, 0.3448, 0.3456, 0.3468, 0.3449, 0.3487, 0.3463, 0.3421,\n",
      "        0.3390, 0.3465, 0.3554, 0.3563, 0.3546, 0.3584, 0.3518, 0.3542, 0.3463,\n",
      "        0.3457, 0.3489, 0.3460, 0.3430, 0.3479], device='cuda:0')\n",
      "tensor([[ 0.0440],\n",
      "        [ 0.0196],\n",
      "        [ 0.0036],\n",
      "        [ 0.0316],\n",
      "        [-0.0205],\n",
      "        [ 0.0077],\n",
      "        [ 0.0070],\n",
      "        [ 0.0487],\n",
      "        [-0.0050],\n",
      "        [ 0.1287],\n",
      "        [ 0.0044],\n",
      "        [ 0.0449],\n",
      "        [ 0.1579],\n",
      "        [ 0.1326],\n",
      "        [ 0.0638],\n",
      "        [ 0.0409],\n",
      "        [-0.0128],\n",
      "        [ 0.0541],\n",
      "        [ 0.0749],\n",
      "        [-0.0218],\n",
      "        [ 0.0123],\n",
      "        [-0.0095],\n",
      "        [ 0.0731],\n",
      "        [ 0.0764],\n",
      "        [ 0.0025],\n",
      "        [ 0.0109],\n",
      "        [ 0.0291],\n",
      "        [ 0.0126],\n",
      "        [-0.0052],\n",
      "        [-0.0176],\n",
      "        [ 0.0275],\n",
      "        [ 0.0113]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3447, 0.3487, 0.3383, 0.3366, 0.3358, 0.3513, 0.3539, 0.3702, 0.3703,\n",
      "        0.3680, 0.3690, 0.3817, 0.3692, 0.3749, 0.3659, 0.3654, 0.3626, 0.3512,\n",
      "        0.3526, 0.3655, 0.3676, 0.3623, 0.3608, 0.3589, 0.3525, 0.3539, 0.3527,\n",
      "        0.3589, 0.3718, 0.3722, 0.3787, 0.3745], device='cuda:0')\n",
      "tensor([[-0.0246],\n",
      "        [ 0.0781],\n",
      "        [ 0.0739],\n",
      "        [ 0.0648],\n",
      "        [ 0.0175],\n",
      "        [ 0.1554],\n",
      "        [ 0.0555],\n",
      "        [-0.0245],\n",
      "        [ 0.0529],\n",
      "        [ 0.0462],\n",
      "        [ 0.0078],\n",
      "        [ 0.1107],\n",
      "        [-0.0118],\n",
      "        [-0.0011],\n",
      "        [-0.0304],\n",
      "        [ 0.0128],\n",
      "        [ 0.0419],\n",
      "        [-0.0090],\n",
      "        [ 0.0140]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3852, 0.3857, 0.3831, 0.3769, 0.3828, 0.3853, 0.3817, 0.3864, 0.3943,\n",
      "        0.3894, 0.3941, 0.3901, 0.3872, 0.3942, 0.4011, 0.4057, 0.3997, 0.4053,\n",
      "        0.4010], device='cuda:0')\n",
      "tensor([[ 0.0364],\n",
      "        [ 0.0639],\n",
      "        [-0.0315],\n",
      "        [ 0.0324],\n",
      "        [ 0.0373],\n",
      "        [ 0.0167],\n",
      "        [ 0.0384],\n",
      "        [ 0.1038],\n",
      "        [ 0.0812],\n",
      "        [ 0.0485],\n",
      "        [-0.0572],\n",
      "        [ 0.0078],\n",
      "        [ 0.0377],\n",
      "        [ 0.0308],\n",
      "        [ 0.0200],\n",
      "        [ 0.0837],\n",
      "        [ 0.0159],\n",
      "        [ 0.0666],\n",
      "        [ 0.0567],\n",
      "        [ 0.0698],\n",
      "        [ 0.0820],\n",
      "        [ 0.0490],\n",
      "        [ 0.0124],\n",
      "        [ 0.0662],\n",
      "        [ 0.0252],\n",
      "        [-0.0195],\n",
      "        [-0.0131],\n",
      "        [ 0.1395],\n",
      "        [ 0.0465],\n",
      "        [ 0.0356],\n",
      "        [ 0.0396],\n",
      "        [ 0.0006]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0147, 0.0146, 0.0143, 0.0138, 0.0130, 0.0129, 0.0135, 0.0135, 0.0135,\n",
      "        0.0137, 0.0132, 0.0129, 0.0134, 0.0133, 0.0135, 0.0134, 0.0134, 0.0134,\n",
      "        0.0134, 0.0130, 0.0122, 0.0113, 0.0093, 0.0098, 0.0105, 0.0111, 0.0113,\n",
      "        0.0107, 0.0097, 0.0091, 0.0093, 0.0088], device='cuda:0')\n",
      "tensor([[ 0.0726],\n",
      "        [ 0.0207],\n",
      "        [ 0.0121],\n",
      "        [ 0.0439],\n",
      "        [ 0.0779],\n",
      "        [ 0.0398],\n",
      "        [-0.0106],\n",
      "        [ 0.0186],\n",
      "        [ 0.0480],\n",
      "        [ 0.0944],\n",
      "        [ 0.0250],\n",
      "        [ 0.0088],\n",
      "        [ 0.0461],\n",
      "        [ 0.0500],\n",
      "        [ 0.0974],\n",
      "        [-0.0461],\n",
      "        [-0.0303],\n",
      "        [ 0.0764],\n",
      "        [ 0.0239],\n",
      "        [ 0.0576],\n",
      "        [ 0.0698],\n",
      "        [ 0.0289],\n",
      "        [ 0.0188],\n",
      "        [ 0.0253],\n",
      "        [ 0.0929],\n",
      "        [ 0.0244],\n",
      "        [ 0.0347],\n",
      "        [ 0.0197],\n",
      "        [ 0.0319],\n",
      "        [ 0.0285],\n",
      "        [ 0.1052],\n",
      "        [ 0.0540]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0094, 0.0092, 0.0095, 0.0090, 0.0092, 0.0091, 0.0081, 0.0069, 0.0058,\n",
      "        0.0058, 0.0035, 0.0048, 0.0054, 0.0050, 0.0034, 0.0037, 0.0037, 0.0040,\n",
      "        0.0041, 0.0033, 0.0018, 0.0010, 0.0000, 0.0017, 0.0015, 0.0019, 0.0014,\n",
      "        0.0006, 0.0009, 0.0017, 0.0009, 0.0017], device='cuda:0')\n",
      "tensor([[ 0.0145],\n",
      "        [ 0.0283],\n",
      "        [ 0.0634],\n",
      "        [ 0.0079],\n",
      "        [-0.0201],\n",
      "        [ 0.1039],\n",
      "        [ 0.0347],\n",
      "        [ 0.0600],\n",
      "        [ 0.0478],\n",
      "        [ 0.0183],\n",
      "        [-0.0047],\n",
      "        [ 0.0223],\n",
      "        [ 0.0120],\n",
      "        [ 0.0840],\n",
      "        [ 0.0474],\n",
      "        [ 0.0097],\n",
      "        [ 0.0320],\n",
      "        [ 0.0219],\n",
      "        [ 0.0522],\n",
      "        [ 0.0170],\n",
      "        [-0.0386],\n",
      "        [ 0.0477],\n",
      "        [ 0.0610],\n",
      "        [-0.0004],\n",
      "        [ 0.0437],\n",
      "        [-0.0397],\n",
      "        [ 0.0261],\n",
      "        [ 0.0903],\n",
      "        [ 0.0251],\n",
      "        [ 0.0577],\n",
      "        [ 0.0121],\n",
      "        [-0.0043]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0024, 0.0021, 0.0028, 0.0029, 0.0028, 0.0025, 0.0028, 0.0033, 0.0043,\n",
      "        0.0046, 0.0044, 0.0048, 0.0040, 0.0037, 0.0039, 0.0042, 0.0042, 0.0036,\n",
      "        0.0039, 0.0040, 0.0044, 0.0051, 0.0051, 0.0044, 0.0050, 0.0050, 0.0047,\n",
      "        0.0042, 0.0048, 0.0044, 0.0044, 0.0046], device='cuda:0')\n",
      "tensor([[ 0.0220],\n",
      "        [ 0.0374],\n",
      "        [ 0.0252],\n",
      "        [ 0.0471],\n",
      "        [ 0.0303],\n",
      "        [ 0.0559],\n",
      "        [ 0.0444],\n",
      "        [ 0.0312],\n",
      "        [ 0.0568],\n",
      "        [ 0.0974],\n",
      "        [ 0.0171],\n",
      "        [ 0.1876],\n",
      "        [ 0.1772],\n",
      "        [ 0.0986],\n",
      "        [ 0.0714],\n",
      "        [ 0.0309],\n",
      "        [ 0.0926],\n",
      "        [-0.0044],\n",
      "        [ 0.0609],\n",
      "        [ 0.0581],\n",
      "        [ 0.0951],\n",
      "        [ 0.0213],\n",
      "        [ 0.0468],\n",
      "        [ 0.0138],\n",
      "        [ 0.0597],\n",
      "        [ 0.0274],\n",
      "        [ 0.0405],\n",
      "        [-0.0062],\n",
      "        [ 0.0277],\n",
      "        [ 0.0096],\n",
      "        [-0.0068],\n",
      "        [ 0.0663]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0050, 0.0051, 0.0051, 0.0053, 0.0055, 0.0055, 0.0065, 0.0066, 0.0065,\n",
      "        0.0064, 0.0055, 0.0054, 0.0051, 0.0057, 0.0051, 0.0048, 0.0052, 0.0048,\n",
      "        0.0049, 0.0048, 0.0049, 0.0049, 0.0052, 0.0056, 0.0054, 0.0051, 0.0048,\n",
      "        0.0045, 0.0035, 0.0040, 0.0031, 0.0028], device='cuda:0')\n",
      "tensor([[ 0.0547],\n",
      "        [ 0.0536],\n",
      "        [ 0.0273],\n",
      "        [ 0.0557],\n",
      "        [ 0.0061],\n",
      "        [-0.0309],\n",
      "        [-0.0154],\n",
      "        [ 0.0315],\n",
      "        [ 0.0237],\n",
      "        [ 0.0277],\n",
      "        [ 0.0094],\n",
      "        [ 0.0291],\n",
      "        [ 0.0327],\n",
      "        [ 0.0831],\n",
      "        [ 0.0225],\n",
      "        [ 0.0272],\n",
      "        [ 0.0783],\n",
      "        [ 0.0152],\n",
      "        [ 0.0296],\n",
      "        [ 0.0316],\n",
      "        [ 0.0194],\n",
      "        [ 0.0752],\n",
      "        [ 0.0748],\n",
      "        [ 0.0198],\n",
      "        [ 0.0412],\n",
      "        [ 0.0263],\n",
      "        [ 0.0708],\n",
      "        [ 0.0881],\n",
      "        [ 0.0431],\n",
      "        [ 0.0796],\n",
      "        [ 0.1187],\n",
      "        [ 0.0549]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0030, 0.0022, 0.0028, 0.0027, 0.0033, 0.0034, 0.0034, 0.0038, 0.0033,\n",
      "        0.0031, 0.0031, 0.0038, 0.0032, 0.0035, 0.0031, 0.0027, 0.0023, 0.0015,\n",
      "        0.0021, 0.0020, 0.0016, 0.0024, 0.0029, 0.0025, 0.0029, 0.0032, 0.0035,\n",
      "        0.0035, 0.0031, 0.0035, 0.0043, 0.0038], device='cuda:0')\n",
      "tensor([[ 0.0289],\n",
      "        [ 0.0530],\n",
      "        [-0.0050],\n",
      "        [ 0.0639],\n",
      "        [ 0.0411],\n",
      "        [ 0.0712],\n",
      "        [ 0.1104],\n",
      "        [ 0.0458],\n",
      "        [ 0.0233],\n",
      "        [ 0.0180],\n",
      "        [ 0.0097],\n",
      "        [-0.0126],\n",
      "        [ 0.0640],\n",
      "        [ 0.1216],\n",
      "        [ 0.0313],\n",
      "        [ 0.0270],\n",
      "        [ 0.0199],\n",
      "        [ 0.0138],\n",
      "        [ 0.0263],\n",
      "        [ 0.0133],\n",
      "        [-0.0109],\n",
      "        [ 0.0423],\n",
      "        [ 0.0269],\n",
      "        [ 0.1193],\n",
      "        [ 0.0372],\n",
      "        [ 0.1692],\n",
      "        [ 0.1123],\n",
      "        [-0.0093],\n",
      "        [-0.0540],\n",
      "        [ 0.0365],\n",
      "        [ 0.0311],\n",
      "        [ 0.0393]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0043, 0.0042, 0.0046, 0.0042, 0.0044, 0.0045, 0.0052, 0.0052, 0.0056,\n",
      "        0.0058, 0.0060, 0.0058, 0.0054, 0.0059, 0.0058, 0.0058, 0.0058, 0.0052,\n",
      "        0.0051, 0.0055, 0.0052, 0.0053, 0.0050, 0.0048, 0.0054, 0.0054, 0.0050,\n",
      "        0.0055, 0.0055, 0.0054, 0.0054, 0.0053], device='cuda:0')\n",
      "tensor([[-0.0048],\n",
      "        [ 0.0006],\n",
      "        [ 0.0081],\n",
      "        [ 0.0590],\n",
      "        [ 0.0546],\n",
      "        [ 0.0521],\n",
      "        [ 0.0316],\n",
      "        [ 0.0020],\n",
      "        [-0.0136],\n",
      "        [ 0.1031],\n",
      "        [ 0.1506],\n",
      "        [ 0.0379],\n",
      "        [ 0.0392],\n",
      "        [ 0.0968],\n",
      "        [ 0.0885],\n",
      "        [ 0.0500],\n",
      "        [ 0.0591],\n",
      "        [ 0.0481],\n",
      "        [ 0.0528],\n",
      "        [ 0.0395],\n",
      "        [ 0.0167],\n",
      "        [-0.0071],\n",
      "        [ 0.0503],\n",
      "        [ 0.1242],\n",
      "        [ 0.0344],\n",
      "        [ 0.0190],\n",
      "        [ 0.0210],\n",
      "        [-0.0131],\n",
      "        [ 0.0062],\n",
      "        [ 0.0462],\n",
      "        [ 0.0659],\n",
      "        [ 0.1001]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0050, 0.0057, 0.0057, 0.0055, 0.0061, 0.0062, 0.0063, 0.0064, 0.0068,\n",
      "        0.0069, 0.0065, 0.0068, 0.0067, 0.0068, 0.0068, 0.0068, 0.0069, 0.0071,\n",
      "        0.0075, 0.0073, 0.0071, 0.0074, 0.0074, 0.0072, 0.0072, 0.0071, 0.0071,\n",
      "        0.0072, 0.0070, 0.0071, 0.0070, 0.0070], device='cuda:0')\n",
      "tensor([[ 0.0034],\n",
      "        [-0.0066],\n",
      "        [ 0.0333],\n",
      "        [ 0.0390],\n",
      "        [ 0.0119],\n",
      "        [ 0.0251],\n",
      "        [ 0.0462],\n",
      "        [ 0.0150],\n",
      "        [ 0.0715],\n",
      "        [ 0.0581],\n",
      "        [ 0.0072],\n",
      "        [ 0.0272],\n",
      "        [ 0.0453],\n",
      "        [-0.0346],\n",
      "        [-0.0210],\n",
      "        [-0.0094],\n",
      "        [ 0.0524],\n",
      "        [ 0.0311],\n",
      "        [-0.0232],\n",
      "        [ 0.0435],\n",
      "        [ 0.0314],\n",
      "        [ 0.0120],\n",
      "        [ 0.0274],\n",
      "        [ 0.0424],\n",
      "        [ 0.1221],\n",
      "        [ 0.0522],\n",
      "        [ 0.0278],\n",
      "        [ 0.0246],\n",
      "        [ 0.0613],\n",
      "        [ 0.0315],\n",
      "        [ 0.0555],\n",
      "        [ 0.1046]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0071, 0.0070, 0.0068, 0.0066, 0.0066, 0.0062, 0.0063, 0.0063, 0.0059,\n",
      "        0.0057, 0.0061, 0.0060, 0.0062, 0.0065, 0.0065, 0.0064, 0.0064, 0.0065,\n",
      "        0.0065, 0.0068, 0.0065, 0.0065, 0.0068, 0.0066, 0.0068, 0.0068, 0.0069,\n",
      "        0.0072, 0.0072, 0.0072, 0.0072, 0.0070], device='cuda:0')\n",
      "tensor([[ 0.0325],\n",
      "        [ 0.0052],\n",
      "        [-0.0175],\n",
      "        [-0.0247],\n",
      "        [ 0.0908],\n",
      "        [ 0.0706],\n",
      "        [ 0.0279],\n",
      "        [ 0.1284],\n",
      "        [ 0.1270],\n",
      "        [ 0.0850],\n",
      "        [ 0.0449],\n",
      "        [ 0.0464],\n",
      "        [ 0.0178],\n",
      "        [ 0.1721],\n",
      "        [ 0.0935],\n",
      "        [-0.0144],\n",
      "        [ 0.0073],\n",
      "        [-0.0070],\n",
      "        [ 0.0347],\n",
      "        [ 0.0735],\n",
      "        [ 0.0124],\n",
      "        [ 0.0432],\n",
      "        [ 0.0510],\n",
      "        [ 0.0410],\n",
      "        [ 0.0263],\n",
      "        [ 0.0031],\n",
      "        [-0.0127],\n",
      "        [ 0.1680],\n",
      "        [ 0.1113],\n",
      "        [-0.0067],\n",
      "        [ 0.0393],\n",
      "        [ 0.0290]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([19])) that is different to the input size (torch.Size([19, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0073, 0.0077, 0.0086, 0.0090, 0.0087, 0.0086, 0.0088, 0.0088, 0.0086,\n",
      "        0.0085, 0.0085, 0.0091, 0.0095, 0.0098, 0.0099, 0.0100, 0.0103, 0.0102,\n",
      "        0.0099, 0.0100, 0.0102, 0.0100, 0.0096, 0.0097, 0.0103, 0.0104, 0.0106,\n",
      "        0.0104, 0.0104, 0.0105, 0.0103, 0.0101], device='cuda:0')\n",
      "tensor([[ 0.0181],\n",
      "        [ 0.0409],\n",
      "        [ 0.0352],\n",
      "        [-0.0323],\n",
      "        [-0.0019],\n",
      "        [ 0.0006],\n",
      "        [ 0.0410],\n",
      "        [-0.0157],\n",
      "        [-0.0088],\n",
      "        [ 0.0128],\n",
      "        [ 0.0238],\n",
      "        [ 0.0084],\n",
      "        [ 0.0756],\n",
      "        [ 0.1479],\n",
      "        [ 0.0774],\n",
      "        [-0.0109],\n",
      "        [ 0.0194],\n",
      "        [ 0.0313],\n",
      "        [-0.0109],\n",
      "        [-0.0026],\n",
      "        [ 0.0633],\n",
      "        [ 0.0214],\n",
      "        [ 0.0293],\n",
      "        [ 0.0220],\n",
      "        [ 0.0468],\n",
      "        [ 0.0284],\n",
      "        [ 0.0366],\n",
      "        [-0.0357],\n",
      "        [ 0.0770],\n",
      "        [ 0.0830],\n",
      "        [ 0.1108],\n",
      "        [ 0.1481]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0099, 0.0101, 0.0101, 0.0100, 0.0099, 0.0096, 0.0097, 0.0103, 0.0108,\n",
      "        0.0105, 0.0106, 0.0103, 0.0103, 0.0102, 0.0098, 0.0100, 0.0102, 0.0099,\n",
      "        0.0099, 0.0097, 0.0096, 0.0095, 0.0094, 0.0094, 0.0090, 0.0089, 0.0084,\n",
      "        0.0081, 0.0082, 0.0076, 0.0083, 0.0085], device='cuda:0')\n",
      "tensor([[ 3.6802e-02],\n",
      "        [-2.2407e-02],\n",
      "        [-3.6790e-02],\n",
      "        [ 3.8611e-02],\n",
      "        [ 8.4995e-03],\n",
      "        [ 2.2020e-03],\n",
      "        [-8.2004e-03],\n",
      "        [ 2.2305e-02],\n",
      "        [-5.5183e-05],\n",
      "        [ 3.9999e-02],\n",
      "        [ 3.5134e-02],\n",
      "        [ 3.8113e-02],\n",
      "        [ 5.8053e-03],\n",
      "        [ 7.6132e-03],\n",
      "        [ 4.9169e-02],\n",
      "        [ 2.3445e-02],\n",
      "        [-1.4046e-02],\n",
      "        [ 2.4497e-02],\n",
      "        [ 7.4584e-04],\n",
      "        [ 2.7240e-02],\n",
      "        [ 7.8797e-03],\n",
      "        [ 2.6735e-02],\n",
      "        [ 5.6257e-02],\n",
      "        [ 6.5067e-02],\n",
      "        [ 6.4023e-02],\n",
      "        [ 2.6152e-02],\n",
      "        [ 4.1346e-02],\n",
      "        [-3.1983e-02],\n",
      "        [ 3.5037e-02],\n",
      "        [ 4.5860e-02],\n",
      "        [ 2.9773e-02],\n",
      "        [ 9.5975e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0088, 0.0082, 0.0085, 0.0082, 0.0081, 0.0079, 0.0080, 0.0081, 0.0080,\n",
      "        0.0078, 0.0078, 0.0077, 0.0076, 0.0077, 0.0077, 0.0079, 0.0080, 0.0086,\n",
      "        0.0081, 0.0081, 0.0079, 0.0083, 0.0085, 0.0083, 0.0084, 0.0087, 0.0088,\n",
      "        0.0093, 0.0095, 0.0093, 0.0092, 0.0092], device='cuda:0')\n",
      "tensor([[ 0.0744],\n",
      "        [ 0.0547],\n",
      "        [ 0.0762],\n",
      "        [ 0.0284],\n",
      "        [ 0.0502],\n",
      "        [-0.0147],\n",
      "        [-0.0145],\n",
      "        [-0.0160],\n",
      "        [ 0.0720],\n",
      "        [ 0.0575],\n",
      "        [-0.0434],\n",
      "        [ 0.0889],\n",
      "        [-0.0405],\n",
      "        [ 0.0542],\n",
      "        [ 0.0381],\n",
      "        [ 0.0404],\n",
      "        [ 0.0220],\n",
      "        [ 0.0777],\n",
      "        [ 0.0740],\n",
      "        [ 0.0058],\n",
      "        [ 0.0032],\n",
      "        [ 0.0217],\n",
      "        [ 0.0252],\n",
      "        [ 0.0411],\n",
      "        [ 0.0184],\n",
      "        [ 0.1369],\n",
      "        [ 0.0056],\n",
      "        [ 0.0283],\n",
      "        [ 0.0237],\n",
      "        [ 0.0967],\n",
      "        [ 0.0193],\n",
      "        [ 0.0502]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0088, 0.0090, 0.0092, 0.0090, 0.0091, 0.0086, 0.0087, 0.0086, 0.0087,\n",
      "        0.0089, 0.0089, 0.0091, 0.0096, 0.0095, 0.0096, 0.0095, 0.0095, 0.0094,\n",
      "        0.0094, 0.0094, 0.0091, 0.0093, 0.0095, 0.0094, 0.0099, 0.0096, 0.0091,\n",
      "        0.0090, 0.0092, 0.0091, 0.0090, 0.0095], device='cuda:0')\n",
      "tensor([[-0.0066],\n",
      "        [-0.0202],\n",
      "        [ 0.1793],\n",
      "        [ 0.0747],\n",
      "        [ 0.0080],\n",
      "        [ 0.0283],\n",
      "        [-0.0162],\n",
      "        [ 0.0220],\n",
      "        [ 0.0435],\n",
      "        [ 0.0297],\n",
      "        [ 0.0475],\n",
      "        [ 0.0367],\n",
      "        [ 0.0416],\n",
      "        [ 0.1038],\n",
      "        [ 0.1226],\n",
      "        [ 0.1233],\n",
      "        [ 0.0806],\n",
      "        [ 0.0059],\n",
      "        [ 0.0951],\n",
      "        [ 0.0555],\n",
      "        [ 0.0335],\n",
      "        [ 0.0222],\n",
      "        [ 0.0257],\n",
      "        [-0.0033],\n",
      "        [ 0.0246],\n",
      "        [ 0.0165],\n",
      "        [ 0.0555],\n",
      "        [ 0.0091],\n",
      "        [ 0.0814],\n",
      "        [ 0.0066],\n",
      "        [ 0.0341],\n",
      "        [ 0.0139]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0098, 0.0103, 0.0099, 0.0099, 0.0100, 0.0103, 0.0107, 0.0108, 0.0116,\n",
      "        0.0117, 0.0119, 0.0118, 0.0113, 0.0111, 0.0113, 0.0118, 0.0120, 0.0117,\n",
      "        0.0112, 0.0118, 0.0115, 0.0112, 0.0110, 0.0111, 0.0112, 0.0114, 0.0115,\n",
      "        0.0116, 0.0114, 0.0113, 0.0110, 0.0105], device='cuda:0')\n",
      "tensor([[ 0.0554],\n",
      "        [ 0.0264],\n",
      "        [ 0.0268],\n",
      "        [ 0.0823],\n",
      "        [ 0.0356],\n",
      "        [-0.0085],\n",
      "        [ 0.0866],\n",
      "        [ 0.0587],\n",
      "        [ 0.0855],\n",
      "        [ 0.0421],\n",
      "        [ 0.0380],\n",
      "        [ 0.0841],\n",
      "        [ 0.0737],\n",
      "        [ 0.0252],\n",
      "        [ 0.0381],\n",
      "        [ 0.0377],\n",
      "        [ 0.0202],\n",
      "        [ 0.0759],\n",
      "        [ 0.0019],\n",
      "        [ 0.0818],\n",
      "        [ 0.0211],\n",
      "        [-0.0054],\n",
      "        [ 0.0403],\n",
      "        [ 0.0285],\n",
      "        [ 0.0313],\n",
      "        [ 0.0411],\n",
      "        [ 0.0154],\n",
      "        [ 0.0081],\n",
      "        [ 0.0124],\n",
      "        [ 0.0079],\n",
      "        [ 0.1048],\n",
      "        [ 0.0743]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0105, 0.0100, 0.0100, 0.0104, 0.0108, 0.0113, 0.0117, 0.0116, 0.0111,\n",
      "        0.0114, 0.0112, 0.0112, 0.0110, 0.0110, 0.0107, 0.0107, 0.0107, 0.0112,\n",
      "        0.0112, 0.0111, 0.0112, 0.0111, 0.0112, 0.0116, 0.0118, 0.0122, 0.0127,\n",
      "        0.0133, 0.0128, 0.0129, 0.0127, 0.0130], device='cuda:0')\n",
      "tensor([[ 0.1333],\n",
      "        [ 0.0376],\n",
      "        [ 0.0118],\n",
      "        [ 0.0545],\n",
      "        [ 0.0073],\n",
      "        [ 0.0612],\n",
      "        [ 0.0916],\n",
      "        [ 0.0879],\n",
      "        [-0.0159],\n",
      "        [ 0.0776],\n",
      "        [ 0.0770],\n",
      "        [ 0.0819],\n",
      "        [ 0.0099],\n",
      "        [ 0.0609],\n",
      "        [ 0.0190],\n",
      "        [ 0.0194],\n",
      "        [ 0.0352],\n",
      "        [-0.0035],\n",
      "        [ 0.0424],\n",
      "        [-0.0338],\n",
      "        [ 0.0081],\n",
      "        [ 0.0905],\n",
      "        [ 0.0420],\n",
      "        [ 0.0588],\n",
      "        [-0.0177],\n",
      "        [ 0.0072],\n",
      "        [ 0.0373],\n",
      "        [ 0.0372],\n",
      "        [ 0.0477],\n",
      "        [ 0.0017],\n",
      "        [ 0.0097],\n",
      "        [ 0.0416]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0140, 0.0143, 0.0145, 0.0144, 0.0161, 0.0154, 0.0156, 0.0155, 0.0149,\n",
      "        0.0152, 0.0153, 0.0151, 0.0147, 0.0144, 0.0137, 0.0140, 0.0149, 0.0148,\n",
      "        0.0147, 0.0145, 0.0145, 0.0145, 0.0147, 0.0149, 0.0151, 0.0156, 0.0157,\n",
      "        0.0156, 0.0156, 0.0156, 0.0157, 0.0158], device='cuda:0')\n",
      "tensor([[0.0224],\n",
      "        [0.0190],\n",
      "        [0.0056],\n",
      "        [0.0287],\n",
      "        [0.0396],\n",
      "        [0.0762],\n",
      "        [0.1820],\n",
      "        [0.0385],\n",
      "        [0.0587],\n",
      "        [0.0747],\n",
      "        [0.0368],\n",
      "        [0.2018],\n",
      "        [0.0395],\n",
      "        [0.0486],\n",
      "        [0.0235],\n",
      "        [0.0052],\n",
      "        [0.0706],\n",
      "        [0.1554],\n",
      "        [0.0688],\n",
      "        [0.0439],\n",
      "        [0.0394],\n",
      "        [0.0185],\n",
      "        [0.1713],\n",
      "        [0.0557],\n",
      "        [0.0804],\n",
      "        [0.0386],\n",
      "        [0.0102],\n",
      "        [0.0344],\n",
      "        [0.0618],\n",
      "        [0.0997],\n",
      "        [0.0120],\n",
      "        [0.0723]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0166, 0.0170, 0.0164, 0.0166, 0.0163, 0.0162, 0.0159, 0.0162, 0.0165,\n",
      "        0.0165, 0.0165, 0.0170, 0.0176, 0.0178, 0.0175, 0.0175, 0.0172, 0.0171,\n",
      "        0.0169, 0.0173, 0.0174, 0.0177, 0.0178, 0.0178, 0.0182, 0.0182, 0.0184,\n",
      "        0.0184, 0.0183, 0.0178, 0.0175, 0.0176], device='cuda:0')\n",
      "tensor([[ 0.1982],\n",
      "        [ 0.0498],\n",
      "        [-0.0004],\n",
      "        [-0.0020],\n",
      "        [ 0.0598],\n",
      "        [-0.0585],\n",
      "        [ 0.0392],\n",
      "        [ 0.0247],\n",
      "        [ 0.0116],\n",
      "        [ 0.0267],\n",
      "        [ 0.0521],\n",
      "        [ 0.0254],\n",
      "        [ 0.0185],\n",
      "        [ 0.1002],\n",
      "        [ 0.0338],\n",
      "        [ 0.0396],\n",
      "        [ 0.0549],\n",
      "        [ 0.0166],\n",
      "        [ 0.0217],\n",
      "        [ 0.1459],\n",
      "        [ 0.0384],\n",
      "        [ 0.0211],\n",
      "        [-0.0062],\n",
      "        [ 0.0463],\n",
      "        [ 0.0288],\n",
      "        [ 0.0377],\n",
      "        [ 0.0073],\n",
      "        [ 0.0267],\n",
      "        [ 0.0169],\n",
      "        [ 0.0282],\n",
      "        [ 0.0359],\n",
      "        [ 0.0706]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0183, 0.0179, 0.0176, 0.0175, 0.0174, 0.0176, 0.0174, 0.0179, 0.0181,\n",
      "        0.0175, 0.0174, 0.0173, 0.0175, 0.0170, 0.0166, 0.0172, 0.0175, 0.0176,\n",
      "        0.0175, 0.0175, 0.0175, 0.0175, 0.0177, 0.0177, 0.0175, 0.0177, 0.0180,\n",
      "        0.0184, 0.0189, 0.0192, 0.0194, 0.0188], device='cuda:0')\n",
      "tensor([[ 0.0788],\n",
      "        [ 0.1135],\n",
      "        [ 0.1344],\n",
      "        [ 0.0979],\n",
      "        [ 0.0870],\n",
      "        [ 0.0236],\n",
      "        [ 0.0036],\n",
      "        [-0.0409],\n",
      "        [ 0.0734],\n",
      "        [ 0.0703],\n",
      "        [ 0.0111],\n",
      "        [ 0.1024],\n",
      "        [ 0.1593],\n",
      "        [ 0.0026],\n",
      "        [ 0.0029],\n",
      "        [-0.0189],\n",
      "        [-0.0024],\n",
      "        [ 0.0295],\n",
      "        [ 0.0401],\n",
      "        [ 0.0377],\n",
      "        [ 0.0291],\n",
      "        [ 0.0455],\n",
      "        [ 0.0114],\n",
      "        [ 0.0373],\n",
      "        [ 0.0090],\n",
      "        [ 0.0138],\n",
      "        [ 0.0191],\n",
      "        [ 0.0354],\n",
      "        [ 0.0532],\n",
      "        [ 0.0297],\n",
      "        [ 0.0328],\n",
      "        [ 0.0452]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0187, 0.0182, 0.0185, 0.0180, 0.0182, 0.0177, 0.0171, 0.0173, 0.0170,\n",
      "        0.0177, 0.0175, 0.0176, 0.0179, 0.0182, 0.0185, 0.0187, 0.0183, 0.0185,\n",
      "        0.0186, 0.0184, 0.0186, 0.0186, 0.0184, 0.0183, 0.0183, 0.0186, 0.0188,\n",
      "        0.0191, 0.0194, 0.0192, 0.0191, 0.0187], device='cuda:0')\n",
      "tensor([[ 0.0550],\n",
      "        [ 0.2146],\n",
      "        [ 0.0005],\n",
      "        [ 0.0936],\n",
      "        [ 0.0938],\n",
      "        [ 0.1314],\n",
      "        [ 0.0831],\n",
      "        [ 0.0102],\n",
      "        [ 0.0050],\n",
      "        [ 0.0031],\n",
      "        [ 0.0296],\n",
      "        [ 0.0217],\n",
      "        [-0.0047],\n",
      "        [ 0.0359],\n",
      "        [ 0.0228],\n",
      "        [ 0.0722],\n",
      "        [ 0.0531],\n",
      "        [ 0.0260],\n",
      "        [ 0.0546],\n",
      "        [ 0.0492],\n",
      "        [-0.0035],\n",
      "        [ 0.0830],\n",
      "        [ 0.0057],\n",
      "        [-0.0205],\n",
      "        [ 0.0244],\n",
      "        [ 0.0426],\n",
      "        [ 0.0521],\n",
      "        [ 0.0351],\n",
      "        [ 0.0887],\n",
      "        [ 0.0116],\n",
      "        [ 0.0492],\n",
      "        [ 0.0370]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0186, 0.0179, 0.0183, 0.0184, 0.0184, 0.0180, 0.0179, 0.0178, 0.0177,\n",
      "        0.0172, 0.0171, 0.0170, 0.0173, 0.0171, 0.0171, 0.0169, 0.0157, 0.0162,\n",
      "        0.0157, 0.0161, 0.0161, 0.0158, 0.0160, 0.0164, 0.0159, 0.0160, 0.0160,\n",
      "        0.0156, 0.0149, 0.0153, 0.0150, 0.0145], device='cuda:0')\n",
      "tensor([[ 0.0429],\n",
      "        [-0.0086],\n",
      "        [-0.0155],\n",
      "        [ 0.0528],\n",
      "        [ 0.1218],\n",
      "        [-0.0468],\n",
      "        [ 0.0696],\n",
      "        [ 0.0320],\n",
      "        [ 0.0694],\n",
      "        [ 0.0607],\n",
      "        [ 0.0444],\n",
      "        [ 0.0379],\n",
      "        [ 0.0555],\n",
      "        [ 0.0382],\n",
      "        [ 0.0617],\n",
      "        [ 0.0279],\n",
      "        [ 0.0140],\n",
      "        [ 0.0709],\n",
      "        [ 0.0081],\n",
      "        [ 0.0330],\n",
      "        [ 0.0831],\n",
      "        [ 0.0393],\n",
      "        [ 0.0323],\n",
      "        [ 0.0543],\n",
      "        [ 0.0193],\n",
      "        [ 0.0372],\n",
      "        [ 0.0266],\n",
      "        [ 0.0555],\n",
      "        [ 0.0377],\n",
      "        [ 0.0672],\n",
      "        [ 0.0027],\n",
      "        [-0.0109]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0144, 0.0146, 0.0152, 0.0154, 0.0154, 0.0155, 0.0157, 0.0157, 0.0154,\n",
      "        0.0150, 0.0143, 0.0142, 0.0132, 0.0135, 0.0143, 0.0149, 0.0142, 0.0143,\n",
      "        0.0142, 0.0146, 0.0147, 0.0153, 0.0150, 0.0152, 0.0151, 0.0150, 0.0148,\n",
      "        0.0146, 0.0142, 0.0142, 0.0145, 0.0147], device='cuda:0')\n",
      "tensor([[ 0.0190],\n",
      "        [ 0.0728],\n",
      "        [ 0.1475],\n",
      "        [ 0.0022],\n",
      "        [ 0.0019],\n",
      "        [ 0.0223],\n",
      "        [ 0.0661],\n",
      "        [ 0.0537],\n",
      "        [ 0.0044],\n",
      "        [ 0.0484],\n",
      "        [ 0.0205],\n",
      "        [ 0.0602],\n",
      "        [ 0.0245],\n",
      "        [ 0.0253],\n",
      "        [ 0.0363],\n",
      "        [ 0.1052],\n",
      "        [ 0.0341],\n",
      "        [ 0.0503],\n",
      "        [ 0.0376],\n",
      "        [ 0.0259],\n",
      "        [ 0.0343],\n",
      "        [ 0.0018],\n",
      "        [ 0.0387],\n",
      "        [ 0.0297],\n",
      "        [ 0.0269],\n",
      "        [ 0.0214],\n",
      "        [-0.0031],\n",
      "        [ 0.0277],\n",
      "        [ 0.0734],\n",
      "        [ 0.1590],\n",
      "        [ 0.1924],\n",
      "        [ 0.0527]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0144, 0.0139, 0.0139, 0.0142, 0.0147, 0.0144, 0.0141, 0.0141, 0.0140,\n",
      "        0.0139, 0.0134, 0.0135, 0.0137, 0.0138, 0.0138, 0.0136, 0.0136, 0.0137,\n",
      "        0.0137, 0.0137, 0.0137, 0.0137, 0.0138, 0.0143, 0.0147, 0.0147, 0.0139,\n",
      "        0.0139, 0.0142, 0.0140, 0.0137, 0.0136], device='cuda:0')\n",
      "tensor([[ 0.0661],\n",
      "        [ 0.0995],\n",
      "        [-0.0250],\n",
      "        [ 0.0517],\n",
      "        [ 0.0490],\n",
      "        [ 0.0145],\n",
      "        [ 0.0140],\n",
      "        [ 0.0221],\n",
      "        [ 0.1523],\n",
      "        [ 0.0212],\n",
      "        [ 0.0109],\n",
      "        [ 0.0289],\n",
      "        [-0.0074],\n",
      "        [ 0.0478],\n",
      "        [ 0.0257],\n",
      "        [ 0.0145],\n",
      "        [ 0.0203],\n",
      "        [ 0.0529],\n",
      "        [ 0.0084],\n",
      "        [ 0.0816],\n",
      "        [ 0.0253],\n",
      "        [ 0.0571],\n",
      "        [ 0.0292],\n",
      "        [ 0.0344],\n",
      "        [ 0.0161],\n",
      "        [ 0.0616],\n",
      "        [ 0.0511],\n",
      "        [ 0.0159],\n",
      "        [ 0.0369],\n",
      "        [-0.0057],\n",
      "        [ 0.0244],\n",
      "        [ 0.0340]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0135, 0.0132, 0.0128, 0.0128, 0.0132, 0.0136, 0.0135, 0.0128, 0.0128,\n",
      "        0.0129, 0.0133, 0.0131, 0.0131, 0.0131, 0.0132, 0.0134, 0.0134, 0.0133,\n",
      "        0.0131, 0.0133, 0.0132, 0.0130, 0.0131, 0.0130, 0.0126, 0.0125, 0.0129,\n",
      "        0.0136, 0.0142, 0.0140, 0.0140, 0.0141], device='cuda:0')\n",
      "tensor([[-0.0088],\n",
      "        [ 0.0270],\n",
      "        [ 0.0612],\n",
      "        [ 0.0199],\n",
      "        [ 0.0241],\n",
      "        [ 0.0124],\n",
      "        [ 0.0548],\n",
      "        [ 0.0178],\n",
      "        [ 0.0505],\n",
      "        [ 0.0683],\n",
      "        [ 0.0786],\n",
      "        [-0.0018],\n",
      "        [-0.0098],\n",
      "        [-0.0055],\n",
      "        [ 0.0179],\n",
      "        [ 0.0037],\n",
      "        [ 0.0180],\n",
      "        [ 0.0016],\n",
      "        [ 0.0522],\n",
      "        [ 0.0468],\n",
      "        [ 0.0248],\n",
      "        [ 0.0369],\n",
      "        [ 0.0411],\n",
      "        [ 0.0426],\n",
      "        [-0.0316],\n",
      "        [ 0.1500],\n",
      "        [ 0.0591],\n",
      "        [ 0.0672],\n",
      "        [ 0.0879],\n",
      "        [ 0.0981],\n",
      "        [-0.0119],\n",
      "        [ 0.0067]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0144, 0.0150, 0.0154, 0.0157, 0.0157, 0.0156, 0.0159, 0.0158, 0.0156,\n",
      "        0.0160, 0.0161, 0.0160, 0.0158, 0.0157, 0.0155, 0.0161, 0.0158, 0.0154,\n",
      "        0.0159, 0.0153, 0.0154, 0.0154, 0.0148, 0.0146, 0.0148, 0.0156, 0.0160,\n",
      "        0.0160, 0.0161, 0.0165, 0.0166, 0.0166], device='cuda:0')\n",
      "tensor([[ 0.0759],\n",
      "        [ 0.1806],\n",
      "        [ 0.0233],\n",
      "        [ 0.0881],\n",
      "        [ 0.0099],\n",
      "        [ 0.0215],\n",
      "        [ 0.0365],\n",
      "        [ 0.0772],\n",
      "        [-0.0054],\n",
      "        [ 0.0538],\n",
      "        [ 0.0365],\n",
      "        [ 0.0243],\n",
      "        [ 0.0703],\n",
      "        [ 0.0108],\n",
      "        [ 0.0750],\n",
      "        [ 0.0278],\n",
      "        [ 0.0189],\n",
      "        [ 0.0432],\n",
      "        [ 0.0082],\n",
      "        [ 0.0468],\n",
      "        [ 0.0321],\n",
      "        [ 0.0552],\n",
      "        [ 0.0798],\n",
      "        [ 0.0039],\n",
      "        [ 0.0198],\n",
      "        [ 0.0654],\n",
      "        [ 0.0408],\n",
      "        [ 0.0033],\n",
      "        [ 0.0439],\n",
      "        [ 0.0343],\n",
      "        [ 0.0312],\n",
      "        [-0.0162]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0166, 0.0164, 0.0161, 0.0163, 0.0165, 0.0170, 0.0167, 0.0169, 0.0173,\n",
      "        0.0175, 0.0173, 0.0172, 0.0173, 0.0172, 0.0172, 0.0170, 0.0169, 0.0166,\n",
      "        0.0161, 0.0165, 0.0165, 0.0165, 0.0166, 0.0167, 0.0169, 0.0167, 0.0166,\n",
      "        0.0168, 0.0177, 0.0177, 0.0179, 0.0179], device='cuda:0')\n",
      "tensor([[ 0.0088],\n",
      "        [ 0.0859],\n",
      "        [ 0.0307],\n",
      "        [ 0.0795],\n",
      "        [ 0.0924],\n",
      "        [ 0.0902],\n",
      "        [ 0.0621],\n",
      "        [ 0.0480],\n",
      "        [ 0.0005],\n",
      "        [ 0.0339],\n",
      "        [ 0.0447],\n",
      "        [ 0.0035],\n",
      "        [ 0.0333],\n",
      "        [ 0.0452],\n",
      "        [ 0.0189],\n",
      "        [ 0.0417],\n",
      "        [ 0.0347],\n",
      "        [ 0.0069],\n",
      "        [ 0.0807],\n",
      "        [ 0.0158],\n",
      "        [ 0.0232],\n",
      "        [ 0.0258],\n",
      "        [ 0.0957],\n",
      "        [ 0.0130],\n",
      "        [ 0.0836],\n",
      "        [ 0.0633],\n",
      "        [ 0.0162],\n",
      "        [ 0.1101],\n",
      "        [ 0.0317],\n",
      "        [-0.0709],\n",
      "        [ 0.0524],\n",
      "        [ 0.1531]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0179, 0.0184, 0.0184, 0.0182, 0.0185, 0.0185, 0.0184, 0.0184, 0.0184,\n",
      "        0.0185, 0.0189, 0.0188, 0.0189, 0.0189, 0.0193, 0.0189, 0.0184, 0.0185,\n",
      "        0.0189, 0.0188, 0.0186, 0.0181, 0.0182, 0.0184, 0.0180, 0.0176, 0.0169,\n",
      "        0.0178, 0.0175, 0.0175, 0.0184, 0.0176], device='cuda:0')\n",
      "tensor([[ 0.0020],\n",
      "        [ 0.0161],\n",
      "        [ 0.0439],\n",
      "        [ 0.0407],\n",
      "        [ 0.0609],\n",
      "        [ 0.0625],\n",
      "        [ 0.0404],\n",
      "        [ 0.0888],\n",
      "        [-0.0086],\n",
      "        [ 0.0294],\n",
      "        [ 0.0556],\n",
      "        [ 0.0133],\n",
      "        [ 0.1388],\n",
      "        [-0.0486],\n",
      "        [-0.0027],\n",
      "        [ 0.0212],\n",
      "        [ 0.0433],\n",
      "        [ 0.0565],\n",
      "        [ 0.0289],\n",
      "        [ 0.0101],\n",
      "        [ 0.0007],\n",
      "        [ 0.0339],\n",
      "        [ 0.1001],\n",
      "        [ 0.1461],\n",
      "        [ 0.0582],\n",
      "        [ 0.0046],\n",
      "        [ 0.0359],\n",
      "        [ 0.1474],\n",
      "        [ 0.1085],\n",
      "        [ 0.0745],\n",
      "        [ 0.0986],\n",
      "        [ 0.0398]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0181, 0.0178, 0.0181, 0.0180, 0.0176, 0.0168, 0.0164, 0.0165, 0.0163,\n",
      "        0.0168, 0.0167, 0.0172, 0.0171, 0.0170, 0.0168, 0.0167, 0.0166, 0.0159,\n",
      "        0.0156, 0.0162, 0.0168, 0.0170, 0.0173, 0.0170, 0.0168, 0.0175, 0.0177,\n",
      "        0.0175, 0.0174, 0.0177, 0.0179, 0.0181], device='cuda:0')\n",
      "tensor([[ 0.0483],\n",
      "        [ 0.0234],\n",
      "        [ 0.0733],\n",
      "        [ 0.0082],\n",
      "        [ 0.0426],\n",
      "        [ 0.0583],\n",
      "        [ 0.0530],\n",
      "        [ 0.0129],\n",
      "        [ 0.1776],\n",
      "        [ 0.0744],\n",
      "        [-0.0617],\n",
      "        [ 0.0435],\n",
      "        [ 0.0417],\n",
      "        [ 0.0409],\n",
      "        [ 0.0434],\n",
      "        [ 0.0166],\n",
      "        [ 0.0340],\n",
      "        [ 0.0803],\n",
      "        [ 0.0368],\n",
      "        [ 0.0126],\n",
      "        [ 0.0454],\n",
      "        [ 0.0020],\n",
      "        [ 0.0194],\n",
      "        [ 0.0592],\n",
      "        [-0.0176],\n",
      "        [ 0.0360],\n",
      "        [ 0.0514],\n",
      "        [ 0.0389],\n",
      "        [ 0.0106],\n",
      "        [ 0.0685],\n",
      "        [ 0.0093],\n",
      "        [ 0.0914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0181, 0.0174, 0.0172, 0.0170, 0.0174, 0.0174, 0.0173, 0.0178, 0.0182,\n",
      "        0.0184, 0.0182, 0.0185, 0.0189, 0.0186, 0.0188, 0.0188, 0.0187, 0.0188,\n",
      "        0.0193, 0.0195, 0.0195, 0.0194, 0.0195, 0.0193, 0.0195, 0.0197, 0.0202,\n",
      "        0.0200, 0.0200, 0.0201, 0.0201, 0.0200], device='cuda:0')\n",
      "tensor([[ 0.0458],\n",
      "        [ 0.0713],\n",
      "        [ 0.0386],\n",
      "        [ 0.0580],\n",
      "        [ 0.0035],\n",
      "        [-0.0015],\n",
      "        [ 0.0237],\n",
      "        [ 0.0430],\n",
      "        [ 0.0054],\n",
      "        [ 0.0357],\n",
      "        [ 0.0154],\n",
      "        [ 0.0193],\n",
      "        [ 0.0296],\n",
      "        [ 0.0919],\n",
      "        [ 0.0886],\n",
      "        [ 0.0535],\n",
      "        [ 0.1127],\n",
      "        [ 0.0612],\n",
      "        [-0.0126],\n",
      "        [ 0.0954],\n",
      "        [-0.0062],\n",
      "        [ 0.0198],\n",
      "        [ 0.0360],\n",
      "        [ 0.0415],\n",
      "        [ 0.0806],\n",
      "        [ 0.0011],\n",
      "        [ 0.0499],\n",
      "        [ 0.0163],\n",
      "        [ 0.0813],\n",
      "        [ 0.0394],\n",
      "        [-0.0217],\n",
      "        [ 0.0226]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0201, 0.0202, 0.0204, 0.0203, 0.0202, 0.0204, 0.0204, 0.0210, 0.0208,\n",
      "        0.0208, 0.0210, 0.0213, 0.0210, 0.0212, 0.0214, 0.0213, 0.0210, 0.0213,\n",
      "        0.0211, 0.0210, 0.0211, 0.0206, 0.0208, 0.0210, 0.0212, 0.0210, 0.0213,\n",
      "        0.0216, 0.0213, 0.0213, 0.0213, 0.0215], device='cuda:0')\n",
      "tensor([[ 2.9153e-02],\n",
      "        [ 8.8194e-02],\n",
      "        [ 3.4057e-02],\n",
      "        [-7.6768e-03],\n",
      "        [ 8.7785e-03],\n",
      "        [ 2.3190e-03],\n",
      "        [ 3.2402e-02],\n",
      "        [ 6.3612e-03],\n",
      "        [ 5.6035e-02],\n",
      "        [ 9.8788e-02],\n",
      "        [ 4.0646e-02],\n",
      "        [-3.2660e-04],\n",
      "        [ 2.6684e-02],\n",
      "        [ 1.9273e-02],\n",
      "        [ 3.9415e-02],\n",
      "        [ 4.3670e-02],\n",
      "        [ 6.2742e-02],\n",
      "        [ 7.1489e-02],\n",
      "        [ 3.8917e-03],\n",
      "        [ 1.3876e-02],\n",
      "        [ 6.3913e-02],\n",
      "        [ 5.9778e-02],\n",
      "        [ 1.0820e-02],\n",
      "        [ 1.8994e-02],\n",
      "        [ 7.0549e-02],\n",
      "        [ 1.1408e-02],\n",
      "        [-3.4933e-03],\n",
      "        [ 3.1607e-02],\n",
      "        [-6.4399e-03],\n",
      "        [ 4.2116e-03],\n",
      "        [ 1.4809e-01],\n",
      "        [-8.3238e-05]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0217, 0.0218, 0.0223, 0.0223, 0.0224, 0.0223, 0.0220, 0.0225, 0.0226,\n",
      "        0.0227, 0.0227, 0.0228, 0.0230, 0.0230, 0.0231, 0.0226, 0.0227, 0.0228,\n",
      "        0.0231, 0.0231, 0.0235, 0.0237, 0.0234, 0.0234, 0.0233, 0.0229, 0.0229,\n",
      "        0.0229, 0.0223, 0.0221, 0.0213, 0.0202], device='cuda:0')\n",
      "tensor([[ 0.1360],\n",
      "        [ 0.0981],\n",
      "        [ 0.1530],\n",
      "        [ 0.0410],\n",
      "        [ 0.3096],\n",
      "        [-0.0139],\n",
      "        [ 0.0469],\n",
      "        [ 0.0406],\n",
      "        [ 0.0018],\n",
      "        [ 0.0391],\n",
      "        [ 0.0053],\n",
      "        [ 0.1092],\n",
      "        [ 0.0426],\n",
      "        [ 0.0300],\n",
      "        [ 0.0568],\n",
      "        [-0.0013],\n",
      "        [ 0.0295],\n",
      "        [ 0.0556],\n",
      "        [ 0.0578],\n",
      "        [ 0.0342],\n",
      "        [ 0.0210],\n",
      "        [ 0.0581],\n",
      "        [ 0.0262],\n",
      "        [ 0.0308],\n",
      "        [ 0.0402],\n",
      "        [ 0.0016],\n",
      "        [ 0.0366],\n",
      "        [ 0.0268],\n",
      "        [ 0.0504],\n",
      "        [ 0.0556],\n",
      "        [ 0.0567],\n",
      "        [ 0.0358]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0206, 0.0202, 0.0208, 0.0210, 0.0213, 0.0215, 0.0214, 0.0206, 0.0197,\n",
      "        0.0200, 0.0200, 0.0202, 0.0206, 0.0205, 0.0200, 0.0201, 0.0203, 0.0199,\n",
      "        0.0201, 0.0200, 0.0196, 0.0195, 0.0197, 0.0199, 0.0199, 0.0198, 0.0199,\n",
      "        0.0197, 0.0200, 0.0198, 0.0195, 0.0188], device='cuda:0')\n",
      "tensor([[0.0445],\n",
      "        [0.0140],\n",
      "        [0.0247],\n",
      "        [0.0550],\n",
      "        [0.1131],\n",
      "        [0.0199],\n",
      "        [0.0995],\n",
      "        [0.0082],\n",
      "        [0.0054],\n",
      "        [0.1044],\n",
      "        [0.0199],\n",
      "        [0.0575],\n",
      "        [0.0115],\n",
      "        [0.0101],\n",
      "        [0.0802],\n",
      "        [0.0576],\n",
      "        [0.0438],\n",
      "        [0.0088],\n",
      "        [0.0262],\n",
      "        [0.0354],\n",
      "        [0.0303],\n",
      "        [0.0756],\n",
      "        [0.1030],\n",
      "        [0.0117],\n",
      "        [0.0670],\n",
      "        [0.0308],\n",
      "        [0.0362],\n",
      "        [0.0993],\n",
      "        [0.0118],\n",
      "        [0.0328],\n",
      "        [0.0195],\n",
      "        [0.0201]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0184, 0.0188, 0.0194, 0.0196, 0.0208, 0.0206, 0.0203, 0.0199, 0.0198,\n",
      "        0.0195, 0.0193, 0.0198, 0.0199, 0.0203, 0.0207, 0.0211, 0.0214, 0.0220,\n",
      "        0.0216, 0.0211, 0.0215, 0.0212, 0.0211, 0.0209, 0.0206, 0.0206, 0.0210,\n",
      "        0.0213, 0.0205, 0.0201, 0.0203, 0.0204], device='cuda:0')\n",
      "tensor([[ 0.0270],\n",
      "        [ 0.0327],\n",
      "        [ 0.0787],\n",
      "        [ 0.0149],\n",
      "        [-0.0274],\n",
      "        [ 0.0188],\n",
      "        [ 0.0054],\n",
      "        [ 0.0014],\n",
      "        [ 0.0351],\n",
      "        [ 0.0626],\n",
      "        [-0.0116],\n",
      "        [ 0.0309],\n",
      "        [ 0.0436],\n",
      "        [ 0.0613],\n",
      "        [-0.0042],\n",
      "        [ 0.0279],\n",
      "        [ 0.0678],\n",
      "        [ 0.0187],\n",
      "        [ 0.0447],\n",
      "        [ 0.1072],\n",
      "        [ 0.0358],\n",
      "        [ 0.0185],\n",
      "        [ 0.0460],\n",
      "        [ 0.0557],\n",
      "        [ 0.0220],\n",
      "        [ 0.0445],\n",
      "        [ 0.0838],\n",
      "        [ 0.1008],\n",
      "        [ 0.1159],\n",
      "        [ 0.2197],\n",
      "        [ 0.0543],\n",
      "        [ 0.0389]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0199, 0.0199, 0.0206, 0.0204, 0.0201, 0.0201, 0.0200, 0.0203, 0.0201,\n",
      "        0.0200, 0.0208, 0.0210, 0.0210, 0.0214, 0.0221, 0.0217, 0.0216, 0.0210,\n",
      "        0.0213, 0.0217, 0.0220, 0.0224, 0.0225, 0.0232, 0.0240, 0.0232, 0.0234,\n",
      "        0.0248, 0.0243, 0.0238, 0.0236, 0.0239], device='cuda:0')\n",
      "tensor([[-0.0048],\n",
      "        [ 0.0040],\n",
      "        [-0.0274],\n",
      "        [ 0.0226],\n",
      "        [ 0.0233],\n",
      "        [ 0.0019],\n",
      "        [ 0.0233],\n",
      "        [ 0.0075],\n",
      "        [ 0.0468],\n",
      "        [ 0.0242],\n",
      "        [ 0.0160],\n",
      "        [ 0.0138],\n",
      "        [ 0.0484],\n",
      "        [ 0.0435],\n",
      "        [ 0.0649],\n",
      "        [ 0.0706],\n",
      "        [ 0.0519],\n",
      "        [ 0.0465],\n",
      "        [ 0.0322],\n",
      "        [ 0.0152],\n",
      "        [ 0.0865],\n",
      "        [ 0.0519],\n",
      "        [-0.0144],\n",
      "        [ 0.0583],\n",
      "        [ 0.0341],\n",
      "        [ 0.0377],\n",
      "        [ 0.0483],\n",
      "        [ 0.0733],\n",
      "        [ 0.0433],\n",
      "        [ 0.0960],\n",
      "        [ 0.0184],\n",
      "        [ 0.0517]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0244, 0.0244, 0.0233, 0.0244, 0.0249, 0.0244, 0.0246, 0.0248, 0.0246,\n",
      "        0.0239, 0.0231, 0.0225, 0.0217, 0.0220, 0.0225, 0.0220, 0.0216, 0.0217,\n",
      "        0.0214, 0.0224, 0.0235, 0.0233, 0.0242, 0.0248, 0.0245, 0.0246, 0.0245,\n",
      "        0.0236, 0.0226, 0.0217, 0.0213, 0.0205], device='cuda:0')\n",
      "tensor([[ 0.0451],\n",
      "        [ 0.0633],\n",
      "        [ 0.0356],\n",
      "        [ 0.0974],\n",
      "        [ 0.1515],\n",
      "        [-0.0081],\n",
      "        [ 0.0791],\n",
      "        [ 0.0551],\n",
      "        [ 0.0148],\n",
      "        [ 0.0255],\n",
      "        [ 0.0042],\n",
      "        [ 0.0021],\n",
      "        [ 0.0054],\n",
      "        [ 0.0311],\n",
      "        [ 0.1226],\n",
      "        [ 0.1077],\n",
      "        [ 0.0674],\n",
      "        [ 0.0949],\n",
      "        [ 0.0431],\n",
      "        [ 0.0057],\n",
      "        [ 0.0337],\n",
      "        [ 0.0385],\n",
      "        [ 0.0538],\n",
      "        [ 0.0400],\n",
      "        [ 0.0292],\n",
      "        [ 0.0005],\n",
      "        [-0.0058],\n",
      "        [ 0.0432],\n",
      "        [ 0.0354],\n",
      "        [ 0.0494],\n",
      "        [ 0.0383],\n",
      "        [-0.0064]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0202, 0.0208, 0.0219, 0.0219, 0.0215, 0.0216, 0.0212, 0.0216, 0.0229,\n",
      "        0.0235, 0.0236, 0.0235, 0.0228, 0.0226, 0.0221, 0.0222, 0.0218, 0.0221,\n",
      "        0.0226, 0.0225, 0.0230, 0.0234, 0.0229, 0.0228, 0.0228, 0.0222, 0.0226,\n",
      "        0.0230, 0.0230, 0.0224, 0.0220, 0.0226], device='cuda:0')\n",
      "tensor([[ 0.0968],\n",
      "        [ 0.1281],\n",
      "        [ 0.0103],\n",
      "        [ 0.0308],\n",
      "        [ 0.0064],\n",
      "        [-0.0014],\n",
      "        [ 0.0124],\n",
      "        [ 0.0348],\n",
      "        [ 0.0222],\n",
      "        [ 0.0248],\n",
      "        [ 0.0672],\n",
      "        [ 0.0908],\n",
      "        [ 0.0682],\n",
      "        [ 0.0481],\n",
      "        [ 0.0699],\n",
      "        [ 0.0437],\n",
      "        [ 0.0747],\n",
      "        [ 0.0208],\n",
      "        [ 0.0370],\n",
      "        [ 0.0306],\n",
      "        [ 0.1478],\n",
      "        [ 0.0271],\n",
      "        [ 0.0463],\n",
      "        [-0.0064],\n",
      "        [ 0.0264],\n",
      "        [-0.0048],\n",
      "        [ 0.1304],\n",
      "        [ 0.0672],\n",
      "        [ 0.0177],\n",
      "        [ 0.0606],\n",
      "        [ 0.1325],\n",
      "        [ 0.0242]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0226, 0.0218, 0.0217, 0.0219, 0.0213, 0.0210, 0.0199, 0.0200, 0.0206,\n",
      "        0.0213, 0.0212, 0.0212, 0.0209, 0.0206, 0.0209, 0.0220, 0.0218, 0.0213,\n",
      "        0.0211, 0.0203, 0.0203, 0.0196, 0.0196, 0.0195, 0.0190, 0.0179, 0.0170,\n",
      "        0.0184, 0.0186, 0.0186, 0.0185, 0.0182], device='cuda:0')\n",
      "tensor([[ 0.0521],\n",
      "        [-0.0068],\n",
      "        [ 0.0257],\n",
      "        [ 0.0039],\n",
      "        [ 0.0561],\n",
      "        [ 0.0387],\n",
      "        [ 0.0817],\n",
      "        [ 0.0055],\n",
      "        [ 0.0390],\n",
      "        [ 0.0274],\n",
      "        [ 0.0602],\n",
      "        [ 0.2047],\n",
      "        [ 0.1432],\n",
      "        [ 0.1280],\n",
      "        [ 0.0149],\n",
      "        [-0.0016],\n",
      "        [ 0.0737],\n",
      "        [ 0.0315],\n",
      "        [ 0.0319],\n",
      "        [ 0.0863],\n",
      "        [ 0.0484],\n",
      "        [ 0.0290],\n",
      "        [ 0.0116],\n",
      "        [ 0.0459],\n",
      "        [ 0.0087],\n",
      "        [ 0.0721],\n",
      "        [ 0.0231],\n",
      "        [-0.0060],\n",
      "        [ 0.0243],\n",
      "        [ 0.0163],\n",
      "        [ 0.0384],\n",
      "        [ 0.0951]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0179, 0.0172, 0.0179, 0.0186, 0.0184, 0.0189, 0.0203, 0.0196, 0.0196,\n",
      "        0.0188, 0.0180, 0.0184, 0.0184, 0.0193, 0.0194, 0.0184, 0.0180, 0.0182,\n",
      "        0.0174, 0.0173, 0.0173, 0.0168, 0.0153, 0.0172, 0.0167, 0.0177, 0.0182,\n",
      "        0.0180, 0.0181, 0.0191, 0.0182, 0.0183], device='cuda:0')\n",
      "tensor([[-0.0219],\n",
      "        [-0.0012],\n",
      "        [ 0.0809],\n",
      "        [ 0.0236],\n",
      "        [ 0.0311],\n",
      "        [ 0.0441],\n",
      "        [ 0.0104],\n",
      "        [ 0.0011],\n",
      "        [ 0.0165],\n",
      "        [ 0.0598],\n",
      "        [ 0.0442],\n",
      "        [-0.0045],\n",
      "        [ 0.0280],\n",
      "        [ 0.0540],\n",
      "        [ 0.0392],\n",
      "        [ 0.0455],\n",
      "        [ 0.0418],\n",
      "        [ 0.0383],\n",
      "        [ 0.0053],\n",
      "        [ 0.0138],\n",
      "        [ 0.0547],\n",
      "        [ 0.0121],\n",
      "        [ 0.0139],\n",
      "        [ 0.0156],\n",
      "        [ 0.0009],\n",
      "        [-0.0072],\n",
      "        [ 0.1507],\n",
      "        [ 0.0746],\n",
      "        [ 0.0487],\n",
      "        [ 0.0588],\n",
      "        [ 0.0575],\n",
      "        [ 0.1737]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0188, 0.0188, 0.0196, 0.0196, 0.0201, 0.0203, 0.0199, 0.0209, 0.0214,\n",
      "        0.0213, 0.0216, 0.0219, 0.0220, 0.0224, 0.0223, 0.0220, 0.0224, 0.0231,\n",
      "        0.0229, 0.0226, 0.0218, 0.0218, 0.0228, 0.0240, 0.0245, 0.0248, 0.0251,\n",
      "        0.0244, 0.0241, 0.0247, 0.0251, 0.0258], device='cuda:0')\n",
      "tensor([[ 0.0783],\n",
      "        [-0.0020],\n",
      "        [ 0.0576],\n",
      "        [ 0.0687],\n",
      "        [-0.0017],\n",
      "        [ 0.0386],\n",
      "        [ 0.0398],\n",
      "        [ 0.0414],\n",
      "        [ 0.0445],\n",
      "        [ 0.0224],\n",
      "        [ 0.1122],\n",
      "        [ 0.0720],\n",
      "        [ 0.0667],\n",
      "        [ 0.0866],\n",
      "        [ 0.1096],\n",
      "        [ 0.0487],\n",
      "        [ 0.0461],\n",
      "        [ 0.0868],\n",
      "        [ 0.0846],\n",
      "        [ 0.0252],\n",
      "        [ 0.0148],\n",
      "        [ 0.0390],\n",
      "        [-0.0309],\n",
      "        [ 0.0295],\n",
      "        [ 0.0374],\n",
      "        [ 0.1264],\n",
      "        [-0.0100],\n",
      "        [ 0.0827],\n",
      "        [ 0.0348],\n",
      "        [ 0.1240],\n",
      "        [ 0.0929],\n",
      "        [ 0.0341]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0260, 0.0252, 0.0257, 0.0259, 0.0258, 0.0248, 0.0246, 0.0244, 0.0248,\n",
      "        0.0247, 0.0244, 0.0241, 0.0239, 0.0241, 0.0243, 0.0246, 0.0243, 0.0238,\n",
      "        0.0242, 0.0254, 0.0263, 0.0267, 0.0273, 0.0270, 0.0275, 0.0261, 0.0265,\n",
      "        0.0269, 0.0268, 0.0268, 0.0277, 0.0279], device='cuda:0')\n",
      "tensor([[ 0.0646],\n",
      "        [ 0.0649],\n",
      "        [ 0.1327],\n",
      "        [-0.0071],\n",
      "        [ 0.0371],\n",
      "        [ 0.0221],\n",
      "        [ 0.0156],\n",
      "        [ 0.0482],\n",
      "        [-0.0033],\n",
      "        [ 0.0657],\n",
      "        [ 0.0528],\n",
      "        [ 0.0168],\n",
      "        [-0.0041],\n",
      "        [ 0.0004],\n",
      "        [ 0.1008],\n",
      "        [ 0.0549],\n",
      "        [ 0.0599],\n",
      "        [ 0.0323],\n",
      "        [ 0.1012],\n",
      "        [ 0.0282],\n",
      "        [ 0.1448],\n",
      "        [ 0.0054],\n",
      "        [ 0.0168],\n",
      "        [ 0.0226],\n",
      "        [-0.0002],\n",
      "        [ 0.0602],\n",
      "        [ 0.0584],\n",
      "        [ 0.0049],\n",
      "        [ 0.0490],\n",
      "        [ 0.0423],\n",
      "        [ 0.0600],\n",
      "        [ 0.0955]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0275, 0.0276, 0.0281, 0.0285, 0.0279, 0.0271, 0.0275, 0.0278, 0.0277,\n",
      "        0.0277, 0.0291, 0.0296, 0.0296, 0.0303, 0.0312, 0.0319, 0.0311, 0.0309,\n",
      "        0.0307, 0.0308, 0.0306, 0.0309, 0.0299, 0.0315, 0.0327, 0.0328, 0.0327,\n",
      "        0.0327, 0.0326, 0.0323, 0.0323, 0.0327], device='cuda:0')\n",
      "tensor([[ 0.0793],\n",
      "        [ 0.0387],\n",
      "        [ 0.0376],\n",
      "        [ 0.0072],\n",
      "        [ 0.0239],\n",
      "        [ 0.0494],\n",
      "        [-0.0111],\n",
      "        [ 0.0059],\n",
      "        [ 0.0677],\n",
      "        [ 0.0563],\n",
      "        [ 0.0230],\n",
      "        [ 0.0348],\n",
      "        [ 0.0262],\n",
      "        [ 0.0305],\n",
      "        [ 0.0668],\n",
      "        [ 0.0353],\n",
      "        [ 0.0328],\n",
      "        [ 0.0621],\n",
      "        [-0.0276],\n",
      "        [-0.0474],\n",
      "        [ 0.1617],\n",
      "        [-0.0495],\n",
      "        [ 0.0469],\n",
      "        [ 0.0017],\n",
      "        [ 0.0293],\n",
      "        [ 0.0461],\n",
      "        [ 0.0454],\n",
      "        [ 0.0159],\n",
      "        [ 0.0614],\n",
      "        [ 0.0352],\n",
      "        [ 0.0186],\n",
      "        [ 0.0848]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0328, 0.0321, 0.0329, 0.0339, 0.0339, 0.0332, 0.0332, 0.0332, 0.0345,\n",
      "        0.0352, 0.0348, 0.0347, 0.0347, 0.0340, 0.0327, 0.0328, 0.0332, 0.0343,\n",
      "        0.0335, 0.0328, 0.0339, 0.0335, 0.0346, 0.0349, 0.0348, 0.0351, 0.0359,\n",
      "        0.0361, 0.0360, 0.0366, 0.0376, 0.0373], device='cuda:0')\n",
      "tensor([[ 0.0213],\n",
      "        [ 0.0871],\n",
      "        [ 0.0205],\n",
      "        [ 0.0505],\n",
      "        [ 0.0805],\n",
      "        [ 0.2340],\n",
      "        [ 0.0859],\n",
      "        [ 0.0342],\n",
      "        [ 0.0312],\n",
      "        [ 0.0390],\n",
      "        [-0.0429],\n",
      "        [ 0.0283],\n",
      "        [ 0.0240],\n",
      "        [ 0.1162],\n",
      "        [ 0.0464],\n",
      "        [-0.0073],\n",
      "        [ 0.0207],\n",
      "        [ 0.0204],\n",
      "        [ 0.0165],\n",
      "        [ 0.0060],\n",
      "        [ 0.0445],\n",
      "        [ 0.0177],\n",
      "        [ 0.0233],\n",
      "        [ 0.0422],\n",
      "        [ 0.0901],\n",
      "        [ 0.0253],\n",
      "        [ 0.0171],\n",
      "        [ 0.0184],\n",
      "        [ 0.0285],\n",
      "        [ 0.0428],\n",
      "        [ 0.0453],\n",
      "        [ 0.0394]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0394, 0.0394, 0.0377, 0.0377, 0.0377, 0.0376, 0.0375, 0.0368, 0.0352,\n",
      "        0.0358, 0.0359, 0.0359, 0.0355, 0.0367, 0.0368, 0.0369, 0.0365, 0.0365,\n",
      "        0.0356, 0.0356, 0.0366, 0.0362, 0.0362, 0.0358, 0.0369, 0.0361, 0.0357,\n",
      "        0.0371, 0.0374, 0.0378, 0.0381, 0.0383], device='cuda:0')\n",
      "tensor([[-0.0218],\n",
      "        [-0.0017],\n",
      "        [ 0.0100],\n",
      "        [ 0.0582],\n",
      "        [ 0.0497],\n",
      "        [ 0.0676],\n",
      "        [ 0.0840],\n",
      "        [ 0.0378],\n",
      "        [ 0.0753],\n",
      "        [ 0.0594],\n",
      "        [ 0.0837],\n",
      "        [-0.0150],\n",
      "        [ 0.0477],\n",
      "        [ 0.0142],\n",
      "        [ 0.0326],\n",
      "        [ 0.0442],\n",
      "        [-0.0045],\n",
      "        [ 0.0940],\n",
      "        [ 0.0551],\n",
      "        [ 0.0390],\n",
      "        [ 0.0156],\n",
      "        [ 0.0297],\n",
      "        [ 0.0296],\n",
      "        [ 0.0083],\n",
      "        [-0.0098],\n",
      "        [ 0.0044],\n",
      "        [-0.0089],\n",
      "        [ 0.0047],\n",
      "        [ 0.0627],\n",
      "        [ 0.0464],\n",
      "        [ 0.1759],\n",
      "        [-0.0079]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0388, 0.0397, 0.0397, 0.0397, 0.0395, 0.0395, 0.0394, 0.0394, 0.0400,\n",
      "        0.0410, 0.0402, 0.0397, 0.0397, 0.0395, 0.0397, 0.0400, 0.0399, 0.0399,\n",
      "        0.0402, 0.0405, 0.0401, 0.0402, 0.0401, 0.0402, 0.0401, 0.0393, 0.0395,\n",
      "        0.0396, 0.0392, 0.0387, 0.0397, 0.0404], device='cuda:0')\n",
      "tensor([[ 0.0336],\n",
      "        [ 0.0179],\n",
      "        [ 0.1182],\n",
      "        [ 0.0356],\n",
      "        [ 0.0606],\n",
      "        [ 0.0530],\n",
      "        [ 0.0227],\n",
      "        [ 0.0287],\n",
      "        [ 0.0870],\n",
      "        [ 0.1160],\n",
      "        [ 0.0503],\n",
      "        [ 0.0460],\n",
      "        [ 0.1073],\n",
      "        [ 0.0369],\n",
      "        [ 0.0928],\n",
      "        [ 0.0632],\n",
      "        [ 0.0474],\n",
      "        [ 0.0637],\n",
      "        [ 0.0540],\n",
      "        [ 0.0563],\n",
      "        [ 0.0407],\n",
      "        [-0.0014],\n",
      "        [-0.0045],\n",
      "        [ 0.0096],\n",
      "        [ 0.0092],\n",
      "        [ 0.0467],\n",
      "        [ 0.0737],\n",
      "        [ 0.0070],\n",
      "        [ 0.0319],\n",
      "        [ 0.0721],\n",
      "        [-0.0158],\n",
      "        [ 0.0341]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0405, 0.0407, 0.0415, 0.0409, 0.0407, 0.0409, 0.0409, 0.0410, 0.0404,\n",
      "        0.0392, 0.0388, 0.0385, 0.0386, 0.0391, 0.0388, 0.0395, 0.0395, 0.0391,\n",
      "        0.0393, 0.0388, 0.0381, 0.0381, 0.0387, 0.0389, 0.0397, 0.0398, 0.0400,\n",
      "        0.0403, 0.0401, 0.0402, 0.0413, 0.0418], device='cuda:0')\n",
      "tensor([[-0.0296],\n",
      "        [ 0.0916],\n",
      "        [ 0.0221],\n",
      "        [ 0.0028],\n",
      "        [ 0.0565],\n",
      "        [ 0.0266],\n",
      "        [ 0.0132],\n",
      "        [ 0.0226],\n",
      "        [ 0.0740],\n",
      "        [ 0.0727],\n",
      "        [ 0.0797],\n",
      "        [ 0.0612],\n",
      "        [ 0.0401],\n",
      "        [ 0.0803],\n",
      "        [ 0.0459],\n",
      "        [ 0.0521],\n",
      "        [ 0.0176],\n",
      "        [ 0.0081],\n",
      "        [ 0.1481],\n",
      "        [ 0.0178],\n",
      "        [ 0.0097],\n",
      "        [ 0.0155],\n",
      "        [ 0.0244],\n",
      "        [ 0.0884],\n",
      "        [ 0.0754],\n",
      "        [ 0.0901],\n",
      "        [ 0.0361],\n",
      "        [ 0.0499],\n",
      "        [ 0.0453],\n",
      "        [ 0.1312],\n",
      "        [ 0.0322],\n",
      "        [ 0.0384]], device='cuda:0', grad_fn=<AddmmBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([0.0418, 0.0411, 0.0411, 0.0414, 0.0418, 0.0414, 0.0446, 0.0448, 0.0460,\n",
      "        0.0451, 0.0454, 0.0457, 0.0455, 0.0448, 0.0456, 0.0456, 0.0478, 0.0478,\n",
      "        0.0482, 0.0480, 0.0492, 0.0492, 0.0499, 0.0496, 0.0487, 0.0498, 0.0506,\n",
      "        0.0513, 0.0505, 0.0504, 0.0503, 0.0509], device='cuda:0')\n",
      "tensor([[ 0.0589],\n",
      "        [ 0.0348],\n",
      "        [ 0.0004],\n",
      "        [ 0.0623],\n",
      "        [ 0.0238],\n",
      "        [ 0.0038],\n",
      "        [ 0.0224],\n",
      "        [ 0.0157],\n",
      "        [ 0.0412],\n",
      "        [-0.0013],\n",
      "        [ 0.0567],\n",
      "        [ 0.0047],\n",
      "        [-0.0087],\n",
      "        [ 0.0538],\n",
      "        [-0.0046],\n",
      "        [ 0.0161],\n",
      "        [ 0.0509],\n",
      "        [ 0.0030],\n",
      "        [ 0.0959],\n",
      "        [ 0.0677],\n",
      "        [ 0.0070],\n",
      "        [-0.0031],\n",
      "        [ 0.0495],\n",
      "        [ 0.0363],\n",
      "        [ 0.0499],\n",
      "        [ 0.0415],\n",
      "        [-0.0016],\n",
      "        [-0.0065],\n",
      "        [ 0.0424],\n",
      "        [ 0.0086],\n",
      "        [ 0.0242],\n",
      "        [ 0.0231]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0513, 0.0512, 0.0508, 0.0497, 0.0495, 0.0492, 0.0493, 0.0488, 0.0492,\n",
      "        0.0500, 0.0504, 0.0500, 0.0510, 0.0528, 0.0535, 0.0516, 0.0537, 0.0531,\n",
      "        0.0532, 0.0536, 0.0532, 0.0532, 0.0530, 0.0535, 0.0551, 0.0550, 0.0554,\n",
      "        0.0563, 0.0568, 0.0570, 0.0564, 0.0567], device='cuda:0')\n",
      "tensor([[ 0.0577],\n",
      "        [ 0.1243],\n",
      "        [ 0.1401],\n",
      "        [ 0.0695],\n",
      "        [ 0.0673],\n",
      "        [ 0.0874],\n",
      "        [-0.0241],\n",
      "        [ 0.2222],\n",
      "        [-0.0039],\n",
      "        [ 0.1208],\n",
      "        [ 0.0815],\n",
      "        [ 0.0134],\n",
      "        [ 0.0156],\n",
      "        [ 0.0491],\n",
      "        [ 0.0287],\n",
      "        [-0.0083],\n",
      "        [ 0.0445],\n",
      "        [ 0.0451],\n",
      "        [ 0.0332],\n",
      "        [ 0.1054],\n",
      "        [ 0.0812],\n",
      "        [ 0.0240],\n",
      "        [ 0.0335],\n",
      "        [ 0.0706],\n",
      "        [ 0.0315],\n",
      "        [ 0.0060],\n",
      "        [ 0.0889],\n",
      "        [ 0.0609],\n",
      "        [ 0.0494],\n",
      "        [ 0.0294],\n",
      "        [ 0.0217],\n",
      "        [ 0.0104]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0572, 0.0560, 0.0537, 0.0536, 0.0545, 0.0542, 0.0532, 0.0535, 0.0545,\n",
      "        0.0545, 0.0548, 0.0532, 0.0523, 0.0502, 0.0508, 0.0513, 0.0514, 0.0520,\n",
      "        0.0526, 0.0535, 0.0543, 0.0535, 0.0535, 0.0541, 0.0541, 0.0524, 0.0543,\n",
      "        0.0532, 0.0536, 0.0538, 0.0533, 0.0527], device='cuda:0')\n",
      "tensor([[ 0.0357],\n",
      "        [ 0.0438],\n",
      "        [ 0.0068],\n",
      "        [ 0.0158],\n",
      "        [ 0.0235],\n",
      "        [ 0.1268],\n",
      "        [ 0.0049],\n",
      "        [-0.0342],\n",
      "        [ 0.0316],\n",
      "        [ 0.0477],\n",
      "        [ 0.0240],\n",
      "        [ 0.0160],\n",
      "        [ 0.0373],\n",
      "        [ 0.1283],\n",
      "        [ 0.0170],\n",
      "        [ 0.0362],\n",
      "        [ 0.0320],\n",
      "        [ 0.0394],\n",
      "        [ 0.1278],\n",
      "        [ 0.0052],\n",
      "        [ 0.0455],\n",
      "        [ 0.0229],\n",
      "        [ 0.1043],\n",
      "        [ 0.0323],\n",
      "        [-0.0121],\n",
      "        [ 0.0380],\n",
      "        [ 0.0701],\n",
      "        [ 0.0615],\n",
      "        [ 0.0618],\n",
      "        [ 0.0717],\n",
      "        [ 0.0493],\n",
      "        [ 0.0803]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0509, 0.0515, 0.0511, 0.0507, 0.0500, 0.0507, 0.0491, 0.0482, 0.0482,\n",
      "        0.0498, 0.0499, 0.0489, 0.0498, 0.0510, 0.0515, 0.0504, 0.0501, 0.0509,\n",
      "        0.0504, 0.0492, 0.0489, 0.0471, 0.0480, 0.0501, 0.0498, 0.0492, 0.0508,\n",
      "        0.0510, 0.0505, 0.0484, 0.0503, 0.0505], device='cuda:0')\n",
      "tensor([[ 0.0190],\n",
      "        [ 0.0405],\n",
      "        [-0.0337],\n",
      "        [ 0.0624],\n",
      "        [ 0.0275],\n",
      "        [-0.0018],\n",
      "        [-0.0083],\n",
      "        [ 0.0222],\n",
      "        [ 0.0575],\n",
      "        [ 0.0388],\n",
      "        [ 0.0021],\n",
      "        [-0.0057],\n",
      "        [ 0.0607],\n",
      "        [ 0.0024],\n",
      "        [ 0.0395],\n",
      "        [ 0.0343],\n",
      "        [ 0.0666],\n",
      "        [ 0.0904],\n",
      "        [ 0.0069],\n",
      "        [ 0.0298],\n",
      "        [-0.0171],\n",
      "        [ 0.0575],\n",
      "        [ 0.0200],\n",
      "        [ 0.0298],\n",
      "        [ 0.0117],\n",
      "        [ 0.0827],\n",
      "        [ 0.0974],\n",
      "        [ 0.0364],\n",
      "        [ 0.0404],\n",
      "        [ 0.0239],\n",
      "        [ 0.0500],\n",
      "        [ 0.0184]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0494, 0.0500, 0.0492, 0.0499, 0.0501, 0.0509, 0.0513, 0.0516, 0.0531,\n",
      "        0.0552, 0.0557, 0.0562, 0.0560, 0.0551, 0.0565, 0.0564, 0.0574, 0.0573,\n",
      "        0.0569, 0.0567, 0.0563, 0.0559, 0.0558, 0.0581, 0.0578, 0.0582, 0.0585,\n",
      "        0.0597, 0.0607, 0.0617, 0.0629, 0.0620], device='cuda:0')\n",
      "tensor([[ 0.0260],\n",
      "        [ 0.0517],\n",
      "        [ 0.0908],\n",
      "        [ 0.0668],\n",
      "        [ 0.0357],\n",
      "        [ 0.0365],\n",
      "        [ 0.0068],\n",
      "        [ 0.0340],\n",
      "        [ 0.0772],\n",
      "        [-0.0096],\n",
      "        [-0.0229],\n",
      "        [ 0.1051],\n",
      "        [-0.0346],\n",
      "        [ 0.0216],\n",
      "        [ 0.1653],\n",
      "        [-0.0170],\n",
      "        [-0.0149],\n",
      "        [ 0.0561],\n",
      "        [ 0.0657],\n",
      "        [-0.0205],\n",
      "        [-0.0057],\n",
      "        [ 0.0181],\n",
      "        [ 0.0788],\n",
      "        [ 0.1474],\n",
      "        [ 0.1135],\n",
      "        [ 0.0885],\n",
      "        [ 0.0194],\n",
      "        [ 0.0415],\n",
      "        [ 0.0348],\n",
      "        [ 0.0534],\n",
      "        [-0.0011],\n",
      "        [ 0.0350]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0617, 0.0619, 0.0619, 0.0613, 0.0608, 0.0598, 0.0600, 0.0597, 0.0590,\n",
      "        0.0575, 0.0575, 0.0587, 0.0584, 0.0578, 0.0585, 0.0593, 0.0600, 0.0624,\n",
      "        0.0650, 0.0693, 0.0680, 0.0669, 0.0676, 0.0681, 0.0683, 0.0681, 0.0657,\n",
      "        0.0647, 0.0626, 0.0626, 0.0654, 0.0653], device='cuda:0')\n",
      "tensor([[ 0.0307],\n",
      "        [ 0.1617],\n",
      "        [ 0.0633],\n",
      "        [-0.0012],\n",
      "        [ 0.0660],\n",
      "        [ 0.0029],\n",
      "        [ 0.0824],\n",
      "        [ 0.0855],\n",
      "        [ 0.0075],\n",
      "        [ 0.0086],\n",
      "        [ 0.0695],\n",
      "        [ 0.0424],\n",
      "        [ 0.0620],\n",
      "        [ 0.0978],\n",
      "        [ 0.0305],\n",
      "        [ 0.0547],\n",
      "        [ 0.0681],\n",
      "        [ 0.0270],\n",
      "        [ 0.0457],\n",
      "        [ 0.0603],\n",
      "        [ 0.0274],\n",
      "        [ 0.0381],\n",
      "        [ 0.1048],\n",
      "        [ 0.0340],\n",
      "        [-0.0147],\n",
      "        [-0.0176],\n",
      "        [-0.0012],\n",
      "        [ 0.0198],\n",
      "        [ 0.0543],\n",
      "        [ 0.0016],\n",
      "        [ 0.0412],\n",
      "        [-0.0021]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0630, 0.0644, 0.0659, 0.0643, 0.0637, 0.0639, 0.0653, 0.0669, 0.0665,\n",
      "        0.0653, 0.0645, 0.0650, 0.0646, 0.0653, 0.0622, 0.0615, 0.0619, 0.0600,\n",
      "        0.0591, 0.0590, 0.0607, 0.0605, 0.0601, 0.0600, 0.0606, 0.0601, 0.0598,\n",
      "        0.0607, 0.0618, 0.0608, 0.0611, 0.0622], device='cuda:0')\n",
      "tensor([[ 0.0242],\n",
      "        [ 0.1199],\n",
      "        [ 0.0336],\n",
      "        [ 0.0421],\n",
      "        [ 0.1409],\n",
      "        [ 0.1163],\n",
      "        [ 0.0518],\n",
      "        [ 0.0388],\n",
      "        [-0.0047],\n",
      "        [ 0.0616],\n",
      "        [ 0.0479],\n",
      "        [-0.0116],\n",
      "        [ 0.0078],\n",
      "        [ 0.0223],\n",
      "        [ 0.0212],\n",
      "        [ 0.0578],\n",
      "        [ 0.0236],\n",
      "        [ 0.0401],\n",
      "        [ 0.0881],\n",
      "        [-0.0137],\n",
      "        [ 0.0398],\n",
      "        [ 0.0400],\n",
      "        [ 0.0678],\n",
      "        [-0.0133],\n",
      "        [ 0.0276],\n",
      "        [ 0.0145],\n",
      "        [ 0.0151],\n",
      "        [ 0.0032],\n",
      "        [ 0.0858],\n",
      "        [ 0.0741],\n",
      "        [-0.0233],\n",
      "        [ 0.0319]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0621, 0.0619, 0.0606, 0.0610, 0.0606, 0.0606, 0.0598, 0.0602, 0.0608,\n",
      "        0.0610, 0.0611, 0.0607, 0.0603, 0.0603, 0.0604, 0.0601, 0.0603, 0.0600,\n",
      "        0.0589, 0.0603, 0.0603, 0.0600, 0.0592, 0.0598, 0.0580, 0.0574, 0.0589,\n",
      "        0.0587, 0.0588, 0.0585, 0.0575, 0.0562], device='cuda:0')\n",
      "tensor([[ 0.0255],\n",
      "        [ 0.0262],\n",
      "        [-0.0029],\n",
      "        [-0.0108],\n",
      "        [ 0.0373],\n",
      "        [ 0.0757],\n",
      "        [ 0.0024],\n",
      "        [ 0.0117],\n",
      "        [ 0.0122],\n",
      "        [ 0.0196],\n",
      "        [ 0.0271],\n",
      "        [ 0.0533],\n",
      "        [ 0.0988],\n",
      "        [ 0.0055],\n",
      "        [ 0.0216],\n",
      "        [ 0.0389],\n",
      "        [ 0.0089],\n",
      "        [ 0.0132],\n",
      "        [ 0.0330],\n",
      "        [ 0.0150],\n",
      "        [ 0.0470],\n",
      "        [ 0.0622],\n",
      "        [ 0.0346],\n",
      "        [ 0.0811],\n",
      "        [ 0.0325],\n",
      "        [ 0.0581],\n",
      "        [ 0.0184],\n",
      "        [ 0.0603],\n",
      "        [-0.0047],\n",
      "        [ 0.0778],\n",
      "        [ 0.0946],\n",
      "        [ 0.1209]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0551, 0.0561, 0.0580, 0.0580, 0.0572, 0.0558, 0.0555, 0.0548, 0.0538,\n",
      "        0.0532, 0.0537, 0.0551, 0.0539, 0.0555, 0.0552, 0.0563, 0.0572, 0.0575,\n",
      "        0.0580, 0.0569, 0.0575, 0.0577, 0.0581, 0.0580, 0.0586, 0.0597, 0.0595,\n",
      "        0.0584, 0.0587, 0.0583, 0.0577, 0.0580], device='cuda:0')\n",
      "tensor([[ 0.0917],\n",
      "        [ 0.1211],\n",
      "        [ 0.1155],\n",
      "        [-0.0238],\n",
      "        [-0.0213],\n",
      "        [ 0.0024],\n",
      "        [ 0.0670],\n",
      "        [ 0.0333],\n",
      "        [ 0.0709],\n",
      "        [ 0.0332],\n",
      "        [ 0.0422],\n",
      "        [ 0.0079],\n",
      "        [ 0.0102],\n",
      "        [ 0.0656],\n",
      "        [ 0.0382],\n",
      "        [ 0.0537],\n",
      "        [-0.0069],\n",
      "        [ 0.0396],\n",
      "        [ 0.0516],\n",
      "        [ 0.0937],\n",
      "        [-0.0110],\n",
      "        [ 0.0591],\n",
      "        [ 0.0845],\n",
      "        [ 0.0072],\n",
      "        [ 0.0629],\n",
      "        [-0.0070],\n",
      "        [ 0.0125],\n",
      "        [ 0.0411],\n",
      "        [ 0.0928],\n",
      "        [ 0.0375],\n",
      "        [ 0.0276],\n",
      "        [ 0.0022]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0582, 0.0565, 0.0555, 0.0553, 0.0562, 0.0577, 0.0568, 0.0558, 0.0565,\n",
      "        0.0562, 0.0561, 0.0548, 0.0551, 0.0548, 0.0544, 0.0522, 0.0524, 0.0530,\n",
      "        0.0539, 0.0529, 0.0516, 0.0536, 0.0536, 0.0546, 0.0533, 0.0516, 0.0523,\n",
      "        0.0523, 0.0517, 0.0515, 0.0515, 0.0515], device='cuda:0')\n",
      "tensor([[0.0592],\n",
      "        [0.0477],\n",
      "        [0.0813],\n",
      "        [0.0200],\n",
      "        [0.0575],\n",
      "        [0.0803],\n",
      "        [0.0383],\n",
      "        [0.0366],\n",
      "        [0.0740],\n",
      "        [0.0201],\n",
      "        [0.0105],\n",
      "        [0.0494],\n",
      "        [0.0232],\n",
      "        [0.0309],\n",
      "        [0.0361],\n",
      "        [0.1492],\n",
      "        [0.0416],\n",
      "        [0.0430],\n",
      "        [0.0058],\n",
      "        [0.0194],\n",
      "        [0.0296],\n",
      "        [0.0638],\n",
      "        [0.0311],\n",
      "        [0.0137],\n",
      "        [0.0278],\n",
      "        [0.0182],\n",
      "        [0.0254],\n",
      "        [0.0491],\n",
      "        [0.0541],\n",
      "        [0.0320],\n",
      "        [0.0502],\n",
      "        [0.0730]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0507, 0.0508, 0.0507, 0.0504, 0.0507, 0.0508, 0.0509, 0.0511, 0.0523,\n",
      "        0.0529, 0.0540, 0.0536, 0.0516, 0.0516, 0.0505, 0.0505, 0.0508, 0.0507,\n",
      "        0.0512, 0.0506, 0.0500, 0.0506, 0.0510, 0.0518, 0.0518, 0.0515, 0.0524,\n",
      "        0.0523, 0.0515, 0.0503, 0.0506, 0.0520], device='cuda:0')\n",
      "tensor([[ 0.0495],\n",
      "        [ 0.0101],\n",
      "        [ 0.1392],\n",
      "        [-0.0020],\n",
      "        [ 0.0610],\n",
      "        [ 0.0411],\n",
      "        [ 0.0249],\n",
      "        [-0.0095],\n",
      "        [ 0.1015],\n",
      "        [ 0.0314],\n",
      "        [ 0.0520],\n",
      "        [ 0.0416],\n",
      "        [ 0.1126],\n",
      "        [ 0.0733],\n",
      "        [ 0.0366],\n",
      "        [ 0.0044],\n",
      "        [ 0.0414],\n",
      "        [ 0.0938],\n",
      "        [ 0.2271],\n",
      "        [-0.0296],\n",
      "        [ 0.0298],\n",
      "        [-0.0003],\n",
      "        [ 0.0035],\n",
      "        [ 0.0452],\n",
      "        [ 0.0347],\n",
      "        [ 0.0357],\n",
      "        [ 0.0337],\n",
      "        [ 0.0378],\n",
      "        [ 0.0451],\n",
      "        [ 0.0174],\n",
      "        [ 0.0472],\n",
      "        [ 0.0820]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0515, 0.0524, 0.0529, 0.0529, 0.0531, 0.0535, 0.0538, 0.0542, 0.0549,\n",
      "        0.0546, 0.0542, 0.0541, 0.0533, 0.0531, 0.0544, 0.0548, 0.0545, 0.0538,\n",
      "        0.0541, 0.0536, 0.0532, 0.0535, 0.0535, 0.0545, 0.0542, 0.0552, 0.0558,\n",
      "        0.0573, 0.0580, 0.0582, 0.0576, 0.0578], device='cuda:0')\n",
      "tensor([[ 0.1464],\n",
      "        [ 0.0132],\n",
      "        [ 0.2018],\n",
      "        [ 0.1051],\n",
      "        [ 0.1180],\n",
      "        [ 0.0877],\n",
      "        [ 0.0773],\n",
      "        [ 0.0458],\n",
      "        [ 0.0962],\n",
      "        [ 0.0545],\n",
      "        [-0.0006],\n",
      "        [ 0.0921],\n",
      "        [ 0.0604],\n",
      "        [-0.0106],\n",
      "        [ 0.0458],\n",
      "        [ 0.0781],\n",
      "        [ 0.1252],\n",
      "        [ 0.1140],\n",
      "        [ 0.0134],\n",
      "        [ 0.0251],\n",
      "        [ 0.0180],\n",
      "        [-0.0095],\n",
      "        [-0.0081],\n",
      "        [ 0.0568],\n",
      "        [-0.0273],\n",
      "        [ 0.0294],\n",
      "        [ 0.0372],\n",
      "        [ 0.0500],\n",
      "        [-0.0246],\n",
      "        [ 0.0134],\n",
      "        [ 0.0458],\n",
      "        [ 0.0824]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0581, 0.0590, 0.0584, 0.0586, 0.0580, 0.0578, 0.0590, 0.0596, 0.0587,\n",
      "        0.0588, 0.0573, 0.0562, 0.0569, 0.0570, 0.0580, 0.0580, 0.0568, 0.0567,\n",
      "        0.0561, 0.0562, 0.0558, 0.0561, 0.0558, 0.0551, 0.0545, 0.0540, 0.0538,\n",
      "        0.0535, 0.0543, 0.0548, 0.0549, 0.0549], device='cuda:0')\n",
      "tensor([[-0.0057],\n",
      "        [ 0.0262],\n",
      "        [ 0.0476],\n",
      "        [ 0.0439],\n",
      "        [ 0.0330],\n",
      "        [-0.0163],\n",
      "        [ 0.0102],\n",
      "        [ 0.0381],\n",
      "        [ 0.0526],\n",
      "        [ 0.0248],\n",
      "        [ 0.0543],\n",
      "        [ 0.1782],\n",
      "        [ 0.1768],\n",
      "        [ 0.1036],\n",
      "        [-0.0105],\n",
      "        [ 0.0138],\n",
      "        [ 0.0736],\n",
      "        [ 0.0174],\n",
      "        [ 0.0645],\n",
      "        [-0.0647],\n",
      "        [ 0.0673],\n",
      "        [-0.0321],\n",
      "        [ 0.0370],\n",
      "        [ 0.0428],\n",
      "        [ 0.0156],\n",
      "        [ 0.0895],\n",
      "        [ 0.0224],\n",
      "        [ 0.0334],\n",
      "        [ 0.0207],\n",
      "        [ 0.0532],\n",
      "        [ 0.0042],\n",
      "        [ 0.0856]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0549, 0.0545, 0.0552, 0.0576, 0.0564, 0.0586, 0.0590, 0.0605, 0.0604,\n",
      "        0.0629, 0.0637, 0.0629, 0.0601, 0.0595, 0.0580, 0.0590, 0.0567, 0.0571,\n",
      "        0.0583, 0.0581, 0.0570, 0.0559, 0.0564, 0.0556, 0.0555, 0.0547, 0.0546,\n",
      "        0.0552, 0.0574, 0.0585, 0.0579, 0.0597], device='cuda:0')\n",
      "tensor([[ 0.0946],\n",
      "        [ 0.0570],\n",
      "        [ 0.0205],\n",
      "        [-0.0056],\n",
      "        [ 0.0493],\n",
      "        [ 0.0402],\n",
      "        [ 0.0608],\n",
      "        [-0.0024],\n",
      "        [ 0.0065],\n",
      "        [ 0.0143],\n",
      "        [ 0.0265],\n",
      "        [ 0.0378],\n",
      "        [ 0.0073],\n",
      "        [ 0.0405],\n",
      "        [ 0.0604],\n",
      "        [ 0.0428],\n",
      "        [ 0.0859],\n",
      "        [ 0.0724],\n",
      "        [-0.0076],\n",
      "        [ 0.0522],\n",
      "        [ 0.0623],\n",
      "        [ 0.0220],\n",
      "        [ 0.0317],\n",
      "        [ 0.0240],\n",
      "        [ 0.0255],\n",
      "        [ 0.0076],\n",
      "        [ 0.0343],\n",
      "        [ 0.0311],\n",
      "        [-0.0283],\n",
      "        [ 0.0104],\n",
      "        [ 0.0383],\n",
      "        [ 0.0290]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0601, 0.0595, 0.0595, 0.0585, 0.0588, 0.0598, 0.0607, 0.0609, 0.0613,\n",
      "        0.0615, 0.0626, 0.0631, 0.0634, 0.0613, 0.0610, 0.0617, 0.0629, 0.0622,\n",
      "        0.0619, 0.0612, 0.0611, 0.0606, 0.0599, 0.0607, 0.0630, 0.0619, 0.0623,\n",
      "        0.0620, 0.0626, 0.0627, 0.0630, 0.0636], device='cuda:0')\n",
      "tensor([[ 0.0344],\n",
      "        [ 0.0248],\n",
      "        [ 0.0275],\n",
      "        [ 0.0340],\n",
      "        [ 0.0676],\n",
      "        [ 0.0893],\n",
      "        [ 0.0861],\n",
      "        [ 0.0869],\n",
      "        [ 0.0268],\n",
      "        [ 0.0411],\n",
      "        [ 0.1068],\n",
      "        [ 0.1548],\n",
      "        [ 0.0621],\n",
      "        [-0.0005],\n",
      "        [ 0.0024],\n",
      "        [ 0.0109],\n",
      "        [ 0.0333],\n",
      "        [ 0.0590],\n",
      "        [ 0.0372],\n",
      "        [ 0.0008],\n",
      "        [ 0.0812],\n",
      "        [ 0.0098],\n",
      "        [ 0.0676],\n",
      "        [ 0.0355],\n",
      "        [ 0.0009],\n",
      "        [ 0.0132],\n",
      "        [ 0.0366],\n",
      "        [ 0.0283],\n",
      "        [ 0.0409],\n",
      "        [ 0.1132],\n",
      "        [ 0.0961],\n",
      "        [ 0.0382]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0654, 0.0651, 0.0650, 0.0629, 0.0626, 0.0625, 0.0623, 0.0619, 0.0621,\n",
      "        0.0621, 0.0630, 0.0624, 0.0614, 0.0627, 0.0626, 0.0627, 0.0641, 0.0643,\n",
      "        0.0638, 0.0636, 0.0641, 0.0650, 0.0647, 0.0649, 0.0667, 0.0666, 0.0661,\n",
      "        0.0649, 0.0656, 0.0659, 0.0656, 0.0656], device='cuda:0')\n",
      "tensor([[ 0.0342],\n",
      "        [ 0.0339],\n",
      "        [-0.0050],\n",
      "        [ 0.0550],\n",
      "        [ 0.0643],\n",
      "        [ 0.0629],\n",
      "        [ 0.0123],\n",
      "        [ 0.1051],\n",
      "        [ 0.0197],\n",
      "        [ 0.0123],\n",
      "        [ 0.0746],\n",
      "        [ 0.0654],\n",
      "        [ 0.0292],\n",
      "        [ 0.0143],\n",
      "        [ 0.0093],\n",
      "        [ 0.0831],\n",
      "        [ 0.0619],\n",
      "        [ 0.1719],\n",
      "        [ 0.2304],\n",
      "        [-0.0349],\n",
      "        [ 0.0885],\n",
      "        [ 0.0394],\n",
      "        [ 0.0325],\n",
      "        [-0.0268],\n",
      "        [ 0.0185],\n",
      "        [ 0.0145],\n",
      "        [-0.0014],\n",
      "        [ 0.0499],\n",
      "        [ 0.0096],\n",
      "        [ 0.0271],\n",
      "        [ 0.0163],\n",
      "        [ 0.0316]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0659, 0.0659, 0.0669, 0.0673, 0.0676, 0.0674, 0.0668, 0.0665, 0.0663,\n",
      "        0.0665, 0.0655, 0.0645, 0.0636, 0.0624, 0.0625, 0.0634, 0.0650, 0.0657,\n",
      "        0.0648, 0.0646, 0.0650, 0.0650, 0.0647, 0.0648, 0.0647, 0.0647, 0.0656,\n",
      "        0.0653, 0.0642, 0.0637, 0.0658, 0.0673], device='cuda:0')\n",
      "tensor([[ 0.0400],\n",
      "        [ 0.0541],\n",
      "        [ 0.0338],\n",
      "        [ 0.0438],\n",
      "        [ 0.1012],\n",
      "        [ 0.0414],\n",
      "        [ 0.0140],\n",
      "        [ 0.0287],\n",
      "        [ 0.0322],\n",
      "        [ 0.0420],\n",
      "        [ 0.0311],\n",
      "        [ 0.0381],\n",
      "        [ 0.0230],\n",
      "        [ 0.0035],\n",
      "        [ 0.0967],\n",
      "        [-0.0279],\n",
      "        [ 0.0173],\n",
      "        [ 0.0872],\n",
      "        [ 0.0376],\n",
      "        [ 0.0812],\n",
      "        [ 0.0740],\n",
      "        [ 0.0749],\n",
      "        [ 0.0412],\n",
      "        [ 0.0546],\n",
      "        [ 0.0461],\n",
      "        [ 0.0331],\n",
      "        [ 0.1511],\n",
      "        [ 0.0045],\n",
      "        [-0.0357],\n",
      "        [ 0.0712],\n",
      "        [ 0.1424],\n",
      "        [ 0.1705]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0659, 0.0637, 0.0646, 0.0660, 0.0653, 0.0656, 0.0668, 0.0669, 0.0677,\n",
      "        0.0678, 0.0678, 0.0680, 0.0679, 0.0676, 0.0691, 0.0690, 0.0708, 0.0680,\n",
      "        0.0634, 0.0649, 0.0646, 0.0648, 0.0648, 0.0630, 0.0623, 0.0613, 0.0607,\n",
      "        0.0599, 0.0617, 0.0618, 0.0618, 0.0607], device='cuda:0')\n",
      "tensor([[ 0.1201],\n",
      "        [ 0.0202],\n",
      "        [ 0.0227],\n",
      "        [ 0.0542],\n",
      "        [ 0.0145],\n",
      "        [ 0.0564],\n",
      "        [ 0.0692],\n",
      "        [ 0.0379],\n",
      "        [ 0.0636],\n",
      "        [-0.0170],\n",
      "        [ 0.0069],\n",
      "        [ 0.0675],\n",
      "        [ 0.0256],\n",
      "        [ 0.0343],\n",
      "        [ 0.0606],\n",
      "        [ 0.0914],\n",
      "        [ 0.0037],\n",
      "        [ 0.0719],\n",
      "        [ 0.0608],\n",
      "        [ 0.0118],\n",
      "        [ 0.0875],\n",
      "        [ 0.0461],\n",
      "        [ 0.0234],\n",
      "        [ 0.0380],\n",
      "        [ 0.0387],\n",
      "        [ 0.0290],\n",
      "        [ 0.0511],\n",
      "        [-0.0039],\n",
      "        [ 0.0748],\n",
      "        [ 0.0568],\n",
      "        [ 0.0718],\n",
      "        [ 0.0292]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0621, 0.0633, 0.0624, 0.0646, 0.0639, 0.0631, 0.0632, 0.0633, 0.0637,\n",
      "        0.0639, 0.0633, 0.0621, 0.0622, 0.0620, 0.0611, 0.0600, 0.0594, 0.0586,\n",
      "        0.0585, 0.0575, 0.0555, 0.0578, 0.0583, 0.0584, 0.0573, 0.0563, 0.0569,\n",
      "        0.0568, 0.0569, 0.0562, 0.0568, 0.0582], device='cuda:0')\n",
      "tensor([[ 0.0124],\n",
      "        [-0.0027],\n",
      "        [ 0.0388],\n",
      "        [ 0.0409],\n",
      "        [ 0.0026],\n",
      "        [ 0.0773],\n",
      "        [ 0.1288],\n",
      "        [ 0.1609],\n",
      "        [-0.0286],\n",
      "        [ 0.1517],\n",
      "        [ 0.0186],\n",
      "        [ 0.0580],\n",
      "        [ 0.1163],\n",
      "        [ 0.0953],\n",
      "        [ 0.0180],\n",
      "        [ 0.0385],\n",
      "        [ 0.0782],\n",
      "        [ 0.0890],\n",
      "        [ 0.0340],\n",
      "        [ 0.0358],\n",
      "        [ 0.0327],\n",
      "        [ 0.0033],\n",
      "        [ 0.0169],\n",
      "        [ 0.0498],\n",
      "        [ 0.0469],\n",
      "        [-0.0057],\n",
      "        [ 0.0918],\n",
      "        [ 0.0164],\n",
      "        [ 0.0112],\n",
      "        [ 0.0393],\n",
      "        [ 0.0002],\n",
      "        [ 0.0174]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0594, 0.0594, 0.0603, 0.0607, 0.0605, 0.0591, 0.0578, 0.0564, 0.0563,\n",
      "        0.0572, 0.0577, 0.0590, 0.0580, 0.0574, 0.0571, 0.0565, 0.0569, 0.0574,\n",
      "        0.0565, 0.0546, 0.0539, 0.0537, 0.0519, 0.0493, 0.0516, 0.0511, 0.0508,\n",
      "        0.0476, 0.0476, 0.0486, 0.0492, 0.0493], device='cuda:0')\n",
      "tensor([[ 0.0407],\n",
      "        [ 0.0620],\n",
      "        [ 0.0209],\n",
      "        [ 0.0035],\n",
      "        [ 0.0130],\n",
      "        [ 0.0243],\n",
      "        [ 0.0711],\n",
      "        [ 0.0168],\n",
      "        [-0.0158],\n",
      "        [-0.0066],\n",
      "        [ 0.0325],\n",
      "        [-0.0038],\n",
      "        [-0.0008],\n",
      "        [ 0.0674],\n",
      "        [-0.0155],\n",
      "        [ 0.0099],\n",
      "        [ 0.0447],\n",
      "        [-0.0214],\n",
      "        [ 0.0132],\n",
      "        [ 0.1022],\n",
      "        [ 0.1865],\n",
      "        [ 0.1576],\n",
      "        [ 0.0624],\n",
      "        [ 0.0347],\n",
      "        [ 0.0473],\n",
      "        [ 0.0196],\n",
      "        [-0.0110],\n",
      "        [ 0.0233],\n",
      "        [ 0.0152],\n",
      "        [ 0.0376],\n",
      "        [ 0.0585],\n",
      "        [ 0.0127]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0482, 0.0474, 0.0457, 0.0441, 0.0447, 0.0445, 0.0418, 0.0399, 0.0387,\n",
      "        0.0393, 0.0376, 0.0379, 0.0419, 0.0438, 0.0464, 0.0485, 0.0476, 0.0476,\n",
      "        0.0448, 0.0445, 0.0436, 0.0441, 0.0434, 0.0420, 0.0419, 0.0419, 0.0447,\n",
      "        0.0435, 0.0450, 0.0446, 0.0441, 0.0415], device='cuda:0')\n",
      "tensor([[ 0.0255],\n",
      "        [ 0.1136],\n",
      "        [ 0.0043],\n",
      "        [ 0.0807],\n",
      "        [ 0.0261],\n",
      "        [-0.0087],\n",
      "        [ 0.0050],\n",
      "        [ 0.0092],\n",
      "        [ 0.0906],\n",
      "        [ 0.0395],\n",
      "        [ 0.0010],\n",
      "        [ 0.0501],\n",
      "        [ 0.1172],\n",
      "        [ 0.1053],\n",
      "        [ 0.0291],\n",
      "        [ 0.0209],\n",
      "        [ 0.0490],\n",
      "        [ 0.0353],\n",
      "        [ 0.0514],\n",
      "        [ 0.0322],\n",
      "        [ 0.0406],\n",
      "        [ 0.1772],\n",
      "        [ 0.1019],\n",
      "        [ 0.1126],\n",
      "        [ 0.0571],\n",
      "        [ 0.1043],\n",
      "        [ 0.0096],\n",
      "        [ 0.0114],\n",
      "        [-0.0079],\n",
      "        [ 0.0105],\n",
      "        [-0.0336],\n",
      "        [ 0.0019]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0410, 0.0417, 0.0415, 0.0415, 0.0398, 0.0407, 0.0399, 0.0385, 0.0380,\n",
      "        0.0404, 0.0408, 0.0398, 0.0392, 0.0401, 0.0402, 0.0407, 0.0420, 0.0417,\n",
      "        0.0416, 0.0407, 0.0414, 0.0407, 0.0405, 0.0404, 0.0404, 0.0406, 0.0403,\n",
      "        0.0396, 0.0398, 0.0397, 0.0394, 0.0387], device='cuda:0')\n",
      "tensor([[-2.3749e-02],\n",
      "        [-1.1380e-02],\n",
      "        [ 1.9466e-02],\n",
      "        [ 4.2410e-02],\n",
      "        [ 8.6497e-02],\n",
      "        [-3.4898e-02],\n",
      "        [ 8.9078e-02],\n",
      "        [-8.2668e-02],\n",
      "        [ 1.9607e-01],\n",
      "        [ 6.9031e-02],\n",
      "        [ 4.0406e-02],\n",
      "        [ 3.5680e-03],\n",
      "        [-9.7759e-05],\n",
      "        [ 8.1351e-02],\n",
      "        [ 6.7582e-02],\n",
      "        [ 1.0829e-01],\n",
      "        [ 1.2224e-01],\n",
      "        [ 6.7678e-02],\n",
      "        [ 9.1635e-02],\n",
      "        [ 1.8361e-02],\n",
      "        [ 1.8824e-02],\n",
      "        [ 4.7173e-02],\n",
      "        [ 3.4875e-02],\n",
      "        [-3.5702e-03],\n",
      "        [ 1.9581e-02],\n",
      "        [ 3.9772e-02],\n",
      "        [ 4.9415e-02],\n",
      "        [ 2.6941e-02],\n",
      "        [-4.0854e-03],\n",
      "        [ 3.1413e-02],\n",
      "        [ 3.4088e-02],\n",
      "        [ 2.7859e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0375, 0.0370, 0.0352, 0.0334, 0.0350, 0.0363, 0.0373, 0.0373, 0.0385,\n",
      "        0.0396, 0.0428, 0.0431, 0.0430, 0.0434, 0.0448, 0.0436, 0.0430, 0.0431,\n",
      "        0.0444, 0.0450, 0.0457, 0.0452, 0.0441, 0.0442, 0.0435, 0.0436, 0.0447,\n",
      "        0.0460, 0.0469, 0.0458, 0.0453, 0.0471], device='cuda:0')\n",
      "tensor([[ 0.0464],\n",
      "        [ 0.0416],\n",
      "        [ 0.0479],\n",
      "        [ 0.0271],\n",
      "        [ 0.0735],\n",
      "        [ 0.0216],\n",
      "        [ 0.0512],\n",
      "        [ 0.0999],\n",
      "        [ 0.0495],\n",
      "        [ 0.0298],\n",
      "        [ 0.0600],\n",
      "        [ 0.0693],\n",
      "        [ 0.1365],\n",
      "        [ 0.0345],\n",
      "        [ 0.0814],\n",
      "        [ 0.0429],\n",
      "        [ 0.1088],\n",
      "        [ 0.1641],\n",
      "        [-0.0633],\n",
      "        [-0.0262],\n",
      "        [ 0.0445],\n",
      "        [ 0.0810],\n",
      "        [-0.0188],\n",
      "        [ 0.0132],\n",
      "        [-0.0021],\n",
      "        [ 0.0086],\n",
      "        [-0.0020],\n",
      "        [-0.0067],\n",
      "        [ 0.0266],\n",
      "        [ 0.0488],\n",
      "        [ 0.0442],\n",
      "        [ 0.0210]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0489, 0.0489, 0.0492, 0.0496, 0.0496, 0.0509, 0.0514, 0.0532, 0.0533,\n",
      "        0.0529, 0.0512, 0.0507, 0.0493, 0.0497, 0.0496, 0.0499, 0.0494, 0.0479,\n",
      "        0.0495, 0.0490, 0.0487, 0.0504, 0.0492, 0.0495, 0.0508, 0.0512, 0.0502,\n",
      "        0.0515, 0.0507, 0.0507, 0.0498, 0.0502], device='cuda:0')\n",
      "tensor([[ 0.0356],\n",
      "        [ 0.0124],\n",
      "        [ 0.0044],\n",
      "        [ 0.0074],\n",
      "        [-0.0021],\n",
      "        [ 0.0354],\n",
      "        [ 0.0098],\n",
      "        [ 0.0258],\n",
      "        [ 0.0263],\n",
      "        [ 0.0085],\n",
      "        [-0.0018],\n",
      "        [ 0.0769],\n",
      "        [-0.0468],\n",
      "        [ 0.1448],\n",
      "        [ 0.0155],\n",
      "        [ 0.0156],\n",
      "        [ 0.0305],\n",
      "        [ 0.0139],\n",
      "        [ 0.0796],\n",
      "        [ 0.0122],\n",
      "        [ 0.0296],\n",
      "        [ 0.1580],\n",
      "        [ 0.0737],\n",
      "        [ 0.0419],\n",
      "        [ 0.0678],\n",
      "        [ 0.0606],\n",
      "        [ 0.0561],\n",
      "        [ 0.0314],\n",
      "        [-0.0257],\n",
      "        [ 0.0270],\n",
      "        [ 0.1141],\n",
      "        [ 0.0238]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0510, 0.0513, 0.0509, 0.0509, 0.0500, 0.0500, 0.0499, 0.0493, 0.0495,\n",
      "        0.0508, 0.0513, 0.0516, 0.0513, 0.0536, 0.0533, 0.0535, 0.0549, 0.0543,\n",
      "        0.0544, 0.0554, 0.0554, 0.0557, 0.0557, 0.0556, 0.0541, 0.0542, 0.0546,\n",
      "        0.0546, 0.0552, 0.0557, 0.0554, 0.0545], device='cuda:0')\n",
      "tensor([[ 0.1028],\n",
      "        [ 0.0277],\n",
      "        [ 0.0360],\n",
      "        [ 0.0302],\n",
      "        [ 0.0339],\n",
      "        [ 0.0237],\n",
      "        [ 0.0514],\n",
      "        [ 0.0405],\n",
      "        [ 0.0312],\n",
      "        [ 0.0408],\n",
      "        [ 0.0527],\n",
      "        [ 0.0548],\n",
      "        [-0.0335],\n",
      "        [ 0.0559],\n",
      "        [ 0.0260],\n",
      "        [ 0.1052],\n",
      "        [-0.0204],\n",
      "        [-0.0108],\n",
      "        [ 0.0161],\n",
      "        [ 0.0313],\n",
      "        [ 0.0263],\n",
      "        [ 0.0140],\n",
      "        [-0.0093],\n",
      "        [ 0.0216],\n",
      "        [ 0.0317],\n",
      "        [ 0.0584],\n",
      "        [ 0.0901],\n",
      "        [-0.0002],\n",
      "        [ 0.0292],\n",
      "        [ 0.0905],\n",
      "        [ 0.0265],\n",
      "        [ 0.0636]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0551, 0.0559, 0.0564, 0.0562, 0.0558, 0.0546, 0.0554, 0.0558, 0.0554,\n",
      "        0.0550, 0.0545, 0.0553, 0.0553, 0.0550, 0.0539, 0.0544, 0.0546, 0.0551,\n",
      "        0.0552, 0.0555, 0.0567, 0.0577, 0.0569, 0.0557, 0.0576, 0.0580, 0.0581,\n",
      "        0.0583, 0.0588, 0.0602, 0.0612, 0.0607], device='cuda:0')\n",
      "tensor([[ 0.0167],\n",
      "        [ 0.0775],\n",
      "        [ 0.0501],\n",
      "        [ 0.0547],\n",
      "        [ 0.0372],\n",
      "        [ 0.0532],\n",
      "        [ 0.0496],\n",
      "        [ 0.0107],\n",
      "        [-0.0203],\n",
      "        [ 0.0240],\n",
      "        [ 0.1949],\n",
      "        [ 0.0680],\n",
      "        [ 0.1190],\n",
      "        [ 0.1376],\n",
      "        [ 0.0453],\n",
      "        [ 0.0396],\n",
      "        [ 0.0132],\n",
      "        [ 0.0491],\n",
      "        [ 0.0075],\n",
      "        [ 0.0267],\n",
      "        [ 0.0264],\n",
      "        [ 0.0062],\n",
      "        [ 0.0321],\n",
      "        [ 0.0328],\n",
      "        [ 0.0132],\n",
      "        [ 0.0396],\n",
      "        [ 0.0113],\n",
      "        [ 0.0579],\n",
      "        [ 0.0636],\n",
      "        [ 0.1127],\n",
      "        [ 0.0395],\n",
      "        [ 0.0155]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0604, 0.0607, 0.0609, 0.0614, 0.0602, 0.0585, 0.0582, 0.0588, 0.0599,\n",
      "        0.0606, 0.0596, 0.0602, 0.0608, 0.0606, 0.0604, 0.0612, 0.0623, 0.0630,\n",
      "        0.0631, 0.0631, 0.0629, 0.0643, 0.0666, 0.0663, 0.0666, 0.0660, 0.0659,\n",
      "        0.0654, 0.0647, 0.0646, 0.0648, 0.0653], device='cuda:0')\n",
      "tensor([[ 0.0356],\n",
      "        [ 0.0447],\n",
      "        [-0.0217],\n",
      "        [ 0.0117],\n",
      "        [ 0.0641],\n",
      "        [-0.0183],\n",
      "        [ 0.0320],\n",
      "        [ 0.0904],\n",
      "        [ 0.0432],\n",
      "        [ 0.0415],\n",
      "        [ 0.0437],\n",
      "        [ 0.1347],\n",
      "        [ 0.0561],\n",
      "        [ 0.0156],\n",
      "        [ 0.0151],\n",
      "        [ 0.0292],\n",
      "        [ 0.0293],\n",
      "        [ 0.0446],\n",
      "        [ 0.0187],\n",
      "        [ 0.0649],\n",
      "        [-0.0257],\n",
      "        [ 0.0058],\n",
      "        [ 0.1111],\n",
      "        [ 0.0225],\n",
      "        [-0.0083],\n",
      "        [ 0.0110],\n",
      "        [ 0.0232],\n",
      "        [ 0.0930],\n",
      "        [ 0.0165],\n",
      "        [-0.0239],\n",
      "        [ 0.1085],\n",
      "        [ 0.1264]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0649, 0.0650, 0.0652, 0.0648, 0.0653, 0.0659, 0.0660, 0.0660, 0.0650,\n",
      "        0.0650, 0.0653, 0.0655, 0.0649, 0.0639, 0.0643, 0.0648, 0.0641, 0.0639,\n",
      "        0.0646, 0.0648, 0.0653, 0.0660, 0.0662, 0.0652, 0.0642, 0.0642, 0.0641,\n",
      "        0.0638, 0.0627, 0.0621, 0.0616, 0.0616], device='cuda:0')\n",
      "tensor([[ 0.0017],\n",
      "        [ 0.0658],\n",
      "        [ 0.0610],\n",
      "        [ 0.0259],\n",
      "        [ 0.0038],\n",
      "        [ 0.0219],\n",
      "        [ 0.0785],\n",
      "        [ 0.1660],\n",
      "        [ 0.0036],\n",
      "        [ 0.0362],\n",
      "        [ 0.0734],\n",
      "        [ 0.0693],\n",
      "        [ 0.0965],\n",
      "        [ 0.0387],\n",
      "        [ 0.0241],\n",
      "        [ 0.0977],\n",
      "        [ 0.0884],\n",
      "        [ 0.0363],\n",
      "        [ 0.0348],\n",
      "        [-0.0161],\n",
      "        [ 0.0067],\n",
      "        [-0.0035],\n",
      "        [ 0.0604],\n",
      "        [ 0.0224],\n",
      "        [ 0.0477],\n",
      "        [ 0.0460],\n",
      "        [ 0.0085],\n",
      "        [ 0.1705],\n",
      "        [ 0.1030],\n",
      "        [ 0.0105],\n",
      "        [-0.0091],\n",
      "        [ 0.0247]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0611, 0.0600, 0.0596, 0.0606, 0.0615, 0.0629, 0.0620, 0.0613, 0.0603,\n",
      "        0.0604, 0.0596, 0.0580, 0.0584, 0.0578, 0.0566, 0.0573, 0.0558, 0.0545,\n",
      "        0.0559, 0.0567, 0.0574, 0.0560, 0.0567, 0.0571, 0.0565, 0.0552, 0.0549,\n",
      "        0.0551, 0.0552, 0.0546, 0.0542, 0.0544], device='cuda:0')\n",
      "tensor([[ 0.0008],\n",
      "        [ 0.0176],\n",
      "        [ 0.0551],\n",
      "        [ 0.0129],\n",
      "        [ 0.0336],\n",
      "        [ 0.0298],\n",
      "        [ 0.0282],\n",
      "        [ 0.1087],\n",
      "        [ 0.1148],\n",
      "        [ 0.1119],\n",
      "        [ 0.0166],\n",
      "        [ 0.0255],\n",
      "        [ 0.0049],\n",
      "        [ 0.0008],\n",
      "        [ 0.0479],\n",
      "        [-0.0119],\n",
      "        [ 0.0954],\n",
      "        [-0.0212],\n",
      "        [-0.0264],\n",
      "        [-0.0108],\n",
      "        [ 0.0138],\n",
      "        [ 0.0457],\n",
      "        [ 0.0546],\n",
      "        [-0.0032],\n",
      "        [ 0.0004],\n",
      "        [ 0.0431],\n",
      "        [ 0.0520],\n",
      "        [ 0.0142],\n",
      "        [ 0.0018],\n",
      "        [ 0.0163],\n",
      "        [ 0.0961],\n",
      "        [ 0.0072]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0549, 0.0556, 0.0558, 0.0561, 0.0555, 0.0543, 0.0542, 0.0554, 0.0551,\n",
      "        0.0520, 0.0516, 0.0511, 0.0503, 0.0508, 0.0513, 0.0520, 0.0515, 0.0511,\n",
      "        0.0508, 0.0499, 0.0515, 0.0508, 0.0495, 0.0501, 0.0492, 0.0485, 0.0485,\n",
      "        0.0482, 0.0478, 0.0483, 0.0495, 0.0508], device='cuda:0')\n",
      "tensor([[ 0.0563],\n",
      "        [ 0.0800],\n",
      "        [ 0.0552],\n",
      "        [ 0.0179],\n",
      "        [ 0.0236],\n",
      "        [ 0.0634],\n",
      "        [ 0.1476],\n",
      "        [ 0.0592],\n",
      "        [ 0.0726],\n",
      "        [ 0.0405],\n",
      "        [ 0.0222],\n",
      "        [ 0.0269],\n",
      "        [ 0.0264],\n",
      "        [ 0.0469],\n",
      "        [ 0.0387],\n",
      "        [ 0.0472],\n",
      "        [ 0.0719],\n",
      "        [ 0.0930],\n",
      "        [-0.0236],\n",
      "        [ 0.1320],\n",
      "        [ 0.0846],\n",
      "        [ 0.0021],\n",
      "        [ 0.0122],\n",
      "        [ 0.0281],\n",
      "        [ 0.0332],\n",
      "        [ 0.0687],\n",
      "        [ 0.1238],\n",
      "        [ 0.0229],\n",
      "        [ 0.0314],\n",
      "        [ 0.0156],\n",
      "        [ 0.0123],\n",
      "        [ 0.0184]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0504, 0.0549, 0.0553, 0.0540, 0.0532, 0.0537, 0.0551, 0.0559, 0.0551,\n",
      "        0.0549, 0.0552, 0.0540, 0.0525, 0.0519, 0.0515, 0.0534, 0.0539, 0.0541,\n",
      "        0.0531, 0.0528, 0.0516, 0.0515, 0.0523, 0.0518, 0.0518, 0.0525, 0.0529,\n",
      "        0.0534, 0.0528, 0.0527, 0.0525, 0.0526], device='cuda:0')\n",
      "tensor([[ 0.0031],\n",
      "        [ 0.0273],\n",
      "        [ 0.0695],\n",
      "        [ 0.0559],\n",
      "        [-0.0045],\n",
      "        [-0.0156],\n",
      "        [-0.0021],\n",
      "        [ 0.0257],\n",
      "        [ 0.0507],\n",
      "        [ 0.0240],\n",
      "        [ 0.0118],\n",
      "        [ 0.0680],\n",
      "        [ 0.0373],\n",
      "        [ 0.0414],\n",
      "        [ 0.1639],\n",
      "        [ 0.0183],\n",
      "        [ 0.0258],\n",
      "        [ 0.0667],\n",
      "        [ 0.0418],\n",
      "        [-0.0356],\n",
      "        [ 0.0128],\n",
      "        [ 0.0179],\n",
      "        [ 0.0700],\n",
      "        [ 0.1500],\n",
      "        [ 0.2039],\n",
      "        [ 0.0025],\n",
      "        [ 0.1022],\n",
      "        [ 0.0311],\n",
      "        [ 0.0199],\n",
      "        [ 0.0030],\n",
      "        [ 0.0260],\n",
      "        [ 0.0360]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0522, 0.0525, 0.0530, 0.0531, 0.0534, 0.0537, 0.0536, 0.0527, 0.0529,\n",
      "        0.0551, 0.0538, 0.0534, 0.0536, 0.0537, 0.0537, 0.0528, 0.0525, 0.0520,\n",
      "        0.0520, 0.0513, 0.0509, 0.0512, 0.0517, 0.0498, 0.0505, 0.0523, 0.0516,\n",
      "        0.0516, 0.0514, 0.0513, 0.0509, 0.0497], device='cuda:0')\n",
      "tensor([[ 3.3038e-02],\n",
      "        [-3.4604e-02],\n",
      "        [ 6.5075e-03],\n",
      "        [ 8.6805e-02],\n",
      "        [ 4.0400e-02],\n",
      "        [ 1.3276e-01],\n",
      "        [-6.8757e-03],\n",
      "        [-1.0385e-03],\n",
      "        [ 4.7788e-02],\n",
      "        [-2.0298e-02],\n",
      "        [-5.6605e-03],\n",
      "        [-4.5166e-02],\n",
      "        [-2.4082e-03],\n",
      "        [-2.2958e-02],\n",
      "        [-2.1383e-06],\n",
      "        [ 2.9184e-02],\n",
      "        [ 4.6395e-02],\n",
      "        [ 9.9690e-02],\n",
      "        [ 9.7282e-02],\n",
      "        [ 3.8795e-02],\n",
      "        [ 2.9754e-02],\n",
      "        [ 1.2847e-02],\n",
      "        [-1.4244e-02],\n",
      "        [ 2.7390e-02],\n",
      "        [-2.5712e-02],\n",
      "        [ 4.8657e-02],\n",
      "        [-2.9641e-02],\n",
      "        [ 8.9051e-02],\n",
      "        [ 1.3469e-01],\n",
      "        [ 1.0848e-01],\n",
      "        [ 7.1477e-02],\n",
      "        [ 9.5519e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0502, 0.0502, 0.0520, 0.0518, 0.0503, 0.0500, 0.0496, 0.0493, 0.0496,\n",
      "        0.0513, 0.0521, 0.0529, 0.0539, 0.0538, 0.0565, 0.0547, 0.0556, 0.0548,\n",
      "        0.0557, 0.0574, 0.0573, 0.0563, 0.0580, 0.0608, 0.0608, 0.0614, 0.0624,\n",
      "        0.0613, 0.0601, 0.0595, 0.0608, 0.0603], device='cuda:0')\n",
      "tensor([[ 6.3652e-02],\n",
      "        [ 7.7293e-02],\n",
      "        [ 1.3672e-01],\n",
      "        [ 9.1790e-02],\n",
      "        [ 3.5487e-02],\n",
      "        [ 1.3014e-01],\n",
      "        [ 3.9725e-02],\n",
      "        [ 5.5056e-03],\n",
      "        [ 2.1009e-02],\n",
      "        [ 3.8713e-05],\n",
      "        [ 6.8711e-03],\n",
      "        [ 3.1038e-02],\n",
      "        [ 3.4649e-02],\n",
      "        [-1.0915e-03],\n",
      "        [ 4.7921e-02],\n",
      "        [ 7.4596e-02],\n",
      "        [ 4.3254e-02],\n",
      "        [ 5.9667e-02],\n",
      "        [ 2.8259e-02],\n",
      "        [ 5.5884e-02],\n",
      "        [ 9.1518e-02],\n",
      "        [ 8.1610e-02],\n",
      "        [ 1.6553e-02],\n",
      "        [-1.1807e-02],\n",
      "        [ 6.9197e-02],\n",
      "        [ 5.7442e-02],\n",
      "        [ 1.2254e-02],\n",
      "        [ 4.2203e-03],\n",
      "        [ 4.1047e-02],\n",
      "        [ 3.9332e-02],\n",
      "        [ 3.3728e-02],\n",
      "        [-6.9089e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0598, 0.0602, 0.0594, 0.0610, 0.0613, 0.0613, 0.0607, 0.0606, 0.0613,\n",
      "        0.0616, 0.0613, 0.0634, 0.0633, 0.0633, 0.0642, 0.0666, 0.0677, 0.0659,\n",
      "        0.0672, 0.0678, 0.0677, 0.0677, 0.0676, 0.0679, 0.0689, 0.0689, 0.0680,\n",
      "        0.0678, 0.0686, 0.0690, 0.0686, 0.0690], device='cuda:0')\n",
      "tensor([[-0.0091],\n",
      "        [-0.0011],\n",
      "        [ 0.0752],\n",
      "        [-0.0310],\n",
      "        [ 0.0202],\n",
      "        [ 0.0203],\n",
      "        [ 0.0154],\n",
      "        [ 0.0687],\n",
      "        [ 0.0331],\n",
      "        [ 0.0447],\n",
      "        [ 0.0035],\n",
      "        [ 0.0288],\n",
      "        [ 0.0886],\n",
      "        [ 0.0011],\n",
      "        [ 0.0221],\n",
      "        [ 0.0328],\n",
      "        [ 0.0302],\n",
      "        [ 0.1037],\n",
      "        [ 0.0575],\n",
      "        [ 0.0356],\n",
      "        [ 0.1298],\n",
      "        [ 0.0579],\n",
      "        [ 0.1127],\n",
      "        [ 0.0193],\n",
      "        [ 0.0475],\n",
      "        [-0.0719],\n",
      "        [ 0.1236],\n",
      "        [ 0.0542],\n",
      "        [ 0.0076],\n",
      "        [ 0.0001],\n",
      "        [ 0.0437],\n",
      "        [ 0.0474]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0679, 0.0680, 0.0680, 0.0676, 0.0678, 0.0678, 0.0679, 0.0669, 0.0687,\n",
      "        0.0674, 0.0678, 0.0687, 0.0696, 0.0699, 0.0705, 0.0714, 0.0709, 0.0712,\n",
      "        0.0701, 0.0689, 0.0685, 0.0688, 0.0688, 0.0698, 0.0697, 0.0696, 0.0699,\n",
      "        0.0710, 0.0711, 0.0717, 0.0716, 0.0705], device='cuda:0')\n",
      "tensor([[ 0.0421],\n",
      "        [ 0.0092],\n",
      "        [ 0.0562],\n",
      "        [ 0.0407],\n",
      "        [ 0.0388],\n",
      "        [ 0.0591],\n",
      "        [ 0.0507],\n",
      "        [ 0.0534],\n",
      "        [ 0.0840],\n",
      "        [ 0.0941],\n",
      "        [ 0.0236],\n",
      "        [ 0.0501],\n",
      "        [ 0.0211],\n",
      "        [ 0.1040],\n",
      "        [ 0.0464],\n",
      "        [ 0.0380],\n",
      "        [ 0.0359],\n",
      "        [ 0.0360],\n",
      "        [ 0.1533],\n",
      "        [ 0.0519],\n",
      "        [ 0.0442],\n",
      "        [ 0.1812],\n",
      "        [ 0.0234],\n",
      "        [ 0.0281],\n",
      "        [ 0.0964],\n",
      "        [-0.0117],\n",
      "        [ 0.0190],\n",
      "        [ 0.0083],\n",
      "        [ 0.0216],\n",
      "        [-0.0042],\n",
      "        [ 0.0168],\n",
      "        [ 0.0231]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0710, 0.0718, 0.0726, 0.0733, 0.0731, 0.0727, 0.0730, 0.0730, 0.0746,\n",
      "        0.0738, 0.0740, 0.0740, 0.0742, 0.0731, 0.0723, 0.0717, 0.0717, 0.0708,\n",
      "        0.0705, 0.0707, 0.0719, 0.0711, 0.0705, 0.0702, 0.0715, 0.0725, 0.0719,\n",
      "        0.0703, 0.0714, 0.0713, 0.0709, 0.0720], device='cuda:0')\n",
      "tensor([[ 0.0983],\n",
      "        [ 0.0263],\n",
      "        [ 0.0508],\n",
      "        [ 0.0873],\n",
      "        [ 0.0139],\n",
      "        [ 0.0008],\n",
      "        [ 0.0187],\n",
      "        [ 0.0446],\n",
      "        [ 0.0920],\n",
      "        [ 0.2016],\n",
      "        [ 0.2047],\n",
      "        [ 0.0516],\n",
      "        [ 0.1279],\n",
      "        [ 0.1220],\n",
      "        [ 0.0411],\n",
      "        [-0.0096],\n",
      "        [ 0.0072],\n",
      "        [-0.0112],\n",
      "        [ 0.0939],\n",
      "        [ 0.0580],\n",
      "        [-0.0192],\n",
      "        [ 0.0405],\n",
      "        [ 0.0702],\n",
      "        [-0.0346],\n",
      "        [ 0.0092],\n",
      "        [ 0.0446],\n",
      "        [ 0.0345],\n",
      "        [ 0.0154],\n",
      "        [ 0.0025],\n",
      "        [ 0.0223],\n",
      "        [ 0.0158],\n",
      "        [ 0.0622]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0714, 0.0727, 0.0739, 0.0743, 0.0754, 0.0757, 0.0759, 0.0761, 0.0761,\n",
      "        0.0741, 0.0747, 0.0750, 0.0748, 0.0739, 0.0735, 0.0741, 0.0735, 0.0731,\n",
      "        0.0723, 0.0735, 0.0751, 0.0746, 0.0749, 0.0744, 0.0745, 0.0746, 0.0742,\n",
      "        0.0740, 0.0734, 0.0734, 0.0730, 0.0732], device='cuda:0')\n",
      "tensor([[ 0.0383],\n",
      "        [ 0.0840],\n",
      "        [ 0.0553],\n",
      "        [-0.0071],\n",
      "        [ 0.0520],\n",
      "        [-0.0177],\n",
      "        [ 0.0317],\n",
      "        [-0.0156],\n",
      "        [ 0.0387],\n",
      "        [ 0.0863],\n",
      "        [ 0.0211],\n",
      "        [ 0.0113],\n",
      "        [ 0.0514],\n",
      "        [ 0.1151],\n",
      "        [ 0.0546],\n",
      "        [ 0.1878],\n",
      "        [ 0.1391],\n",
      "        [ 0.0883],\n",
      "        [-0.0017],\n",
      "        [ 0.0031],\n",
      "        [ 0.0318],\n",
      "        [ 0.0430],\n",
      "        [ 0.0359],\n",
      "        [ 0.0280],\n",
      "        [ 0.0318],\n",
      "        [ 0.0469],\n",
      "        [ 0.0267],\n",
      "        [ 0.0996],\n",
      "        [ 0.0596],\n",
      "        [ 0.1156],\n",
      "        [ 0.1909],\n",
      "        [ 0.0814]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0733, 0.0740, 0.0752, 0.0761, 0.0761, 0.0750, 0.0745, 0.0742, 0.0732,\n",
      "        0.0736, 0.0724, 0.0725, 0.0728, 0.0730, 0.0744, 0.0749, 0.0747, 0.0739,\n",
      "        0.0745, 0.0747, 0.0754, 0.0776, 0.0773, 0.0788, 0.0790, 0.0794, 0.0795,\n",
      "        0.0807, 0.0807, 0.0812, 0.0810, 0.0800], device='cuda:0')\n",
      "tensor([[ 0.1521],\n",
      "        [ 0.1158],\n",
      "        [-0.0127],\n",
      "        [ 0.1973],\n",
      "        [ 0.1072],\n",
      "        [ 0.0338],\n",
      "        [ 0.0232],\n",
      "        [ 0.0198],\n",
      "        [-0.0543],\n",
      "        [ 0.0360],\n",
      "        [ 0.0240],\n",
      "        [ 0.0234],\n",
      "        [ 0.0138],\n",
      "        [ 0.0333],\n",
      "        [ 0.0222],\n",
      "        [ 0.0091],\n",
      "        [ 0.0149],\n",
      "        [ 0.0079],\n",
      "        [ 0.0359],\n",
      "        [ 0.0613],\n",
      "        [-0.0185],\n",
      "        [ 0.0053],\n",
      "        [ 0.0028],\n",
      "        [ 0.0429],\n",
      "        [-0.0116],\n",
      "        [ 0.0404],\n",
      "        [-0.0061],\n",
      "        [ 0.0248],\n",
      "        [ 0.0028],\n",
      "        [ 0.0019],\n",
      "        [ 0.0302],\n",
      "        [-0.0149]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0790, 0.0783, 0.0779, 0.0777, 0.0782, 0.0783, 0.0769, 0.0766, 0.0762,\n",
      "        0.0773, 0.0771, 0.0772, 0.0767, 0.0763, 0.0755, 0.0751, 0.0749, 0.0744,\n",
      "        0.0740, 0.0747, 0.0751, 0.0747, 0.0743, 0.0745, 0.0753, 0.0751, 0.0748,\n",
      "        0.0748, 0.0748, 0.0768, 0.0762, 0.0767], device='cuda:0')\n",
      "tensor([[ 0.0315],\n",
      "        [ 0.0084],\n",
      "        [ 0.0479],\n",
      "        [ 0.0344],\n",
      "        [ 0.0532],\n",
      "        [ 0.0659],\n",
      "        [ 0.0819],\n",
      "        [ 0.0406],\n",
      "        [ 0.0597],\n",
      "        [ 0.0214],\n",
      "        [ 0.0376],\n",
      "        [ 0.0457],\n",
      "        [ 0.0441],\n",
      "        [ 0.0366],\n",
      "        [-0.0324],\n",
      "        [-0.0380],\n",
      "        [ 0.1082],\n",
      "        [ 0.0027],\n",
      "        [ 0.0472],\n",
      "        [ 0.0374],\n",
      "        [ 0.0452],\n",
      "        [ 0.0775],\n",
      "        [ 0.0352],\n",
      "        [ 0.0482],\n",
      "        [-0.0064],\n",
      "        [ 0.0336],\n",
      "        [ 0.0053],\n",
      "        [ 0.0669],\n",
      "        [ 0.0749],\n",
      "        [ 0.0251],\n",
      "        [ 0.0590],\n",
      "        [ 0.0122]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0764, 0.0768, 0.0760, 0.0740, 0.0755, 0.0753, 0.0738, 0.0730, 0.0715,\n",
      "        0.0702, 0.0668, 0.0682, 0.0702, 0.0701, 0.0721, 0.0730, 0.0727, 0.0713,\n",
      "        0.0699, 0.0702, 0.0704, 0.0718, 0.0727, 0.0731, 0.0723, 0.0707, 0.0696,\n",
      "        0.0685, 0.0686, 0.0697, 0.0724, 0.0715], device='cuda:0')\n",
      "tensor([[ 0.0149],\n",
      "        [ 0.1371],\n",
      "        [ 0.0018],\n",
      "        [ 0.0423],\n",
      "        [ 0.0143],\n",
      "        [ 0.0152],\n",
      "        [ 0.0542],\n",
      "        [ 0.0509],\n",
      "        [ 0.0376],\n",
      "        [ 0.0740],\n",
      "        [ 0.0309],\n",
      "        [ 0.0254],\n",
      "        [ 0.0134],\n",
      "        [ 0.0173],\n",
      "        [ 0.0269],\n",
      "        [ 0.1188],\n",
      "        [-0.0075],\n",
      "        [ 0.0457],\n",
      "        [ 0.0519],\n",
      "        [ 0.0310],\n",
      "        [-0.0275],\n",
      "        [ 0.0115],\n",
      "        [ 0.0279],\n",
      "        [-0.0178],\n",
      "        [ 0.0275],\n",
      "        [-0.0333],\n",
      "        [ 0.0418],\n",
      "        [ 0.0915],\n",
      "        [ 0.0685],\n",
      "        [ 0.0306],\n",
      "        [ 0.0545],\n",
      "        [ 0.0486]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0717, 0.0714, 0.0717, 0.0722, 0.0738, 0.0726, 0.0718, 0.0710, 0.0721,\n",
      "        0.0731, 0.0747, 0.0753, 0.0747, 0.0745, 0.0744, 0.0759, 0.0762, 0.0750,\n",
      "        0.0743, 0.0741, 0.0748, 0.0739, 0.0728, 0.0727, 0.0718, 0.0730, 0.0732,\n",
      "        0.0750, 0.0757, 0.0773, 0.0774, 0.0780], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.3789e-02],\n",
      "        [ 9.0400e-03],\n",
      "        [ 9.2730e-02],\n",
      "        [ 1.7282e-02],\n",
      "        [ 3.1584e-02],\n",
      "        [ 5.5483e-02],\n",
      "        [ 8.1326e-02],\n",
      "        [ 2.1969e-02],\n",
      "        [ 2.7078e-02],\n",
      "        [-1.8497e-02],\n",
      "        [ 5.0597e-03],\n",
      "        [ 4.3253e-03],\n",
      "        [ 4.0593e-02],\n",
      "        [ 5.0652e-02],\n",
      "        [ 2.2261e-02],\n",
      "        [ 3.3154e-02],\n",
      "        [ 3.5737e-02],\n",
      "        [ 4.9603e-02],\n",
      "        [ 2.4359e-02],\n",
      "        [ 6.9923e-02],\n",
      "        [ 4.0582e-02],\n",
      "        [ 4.8958e-02],\n",
      "        [ 2.0964e-01],\n",
      "        [-4.8347e-02],\n",
      "        [-1.9933e-04],\n",
      "        [ 1.3480e-01],\n",
      "        [ 3.8664e-02],\n",
      "        [ 1.6121e-02],\n",
      "        [ 2.8727e-02],\n",
      "        [ 4.5971e-02],\n",
      "        [ 6.6273e-02],\n",
      "        [-9.0129e-04]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0796, 0.0796, 0.0793, 0.0779, 0.0788, 0.0799, 0.0807, 0.0805, 0.0809,\n",
      "        0.0820, 0.0844, 0.0837, 0.0856, 0.0837, 0.0841, 0.0850, 0.0844, 0.0836,\n",
      "        0.0820, 0.0822, 0.0823, 0.0841, 0.0843, 0.0840, 0.0861, 0.0866, 0.0872,\n",
      "        0.0860, 0.0850, 0.0849, 0.0863, 0.0855], device='cuda:0')\n",
      "tensor([[ 0.0852],\n",
      "        [-0.0012],\n",
      "        [-0.0004],\n",
      "        [-0.0246],\n",
      "        [ 0.0173],\n",
      "        [ 0.0559],\n",
      "        [ 0.1104],\n",
      "        [ 0.0891],\n",
      "        [-0.0266],\n",
      "        [ 0.0352],\n",
      "        [ 0.0795],\n",
      "        [ 0.0453],\n",
      "        [ 0.0062],\n",
      "        [ 0.0292],\n",
      "        [ 0.0488],\n",
      "        [ 0.0062],\n",
      "        [ 0.0147],\n",
      "        [ 0.0281],\n",
      "        [ 0.0822],\n",
      "        [ 0.0110],\n",
      "        [ 0.0167],\n",
      "        [ 0.0072],\n",
      "        [ 0.0074],\n",
      "        [ 0.0578],\n",
      "        [ 0.0268],\n",
      "        [-0.0048],\n",
      "        [ 0.0487],\n",
      "        [ 0.0328],\n",
      "        [-0.0100],\n",
      "        [ 0.0051],\n",
      "        [ 0.0973],\n",
      "        [ 0.0032]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0856, 0.0831, 0.0825, 0.0806, 0.0826, 0.0816, 0.0851, 0.0843, 0.0840,\n",
      "        0.0849, 0.0848, 0.0845, 0.0852, 0.0858, 0.0867, 0.0856, 0.0855, 0.0841,\n",
      "        0.0841, 0.0824, 0.0812, 0.0818, 0.0829, 0.0840, 0.0833, 0.0843, 0.0826,\n",
      "        0.0818, 0.0809, 0.0806, 0.0806, 0.0807], device='cuda:0')\n",
      "tensor([[ 0.0217],\n",
      "        [ 0.0063],\n",
      "        [ 0.0055],\n",
      "        [ 0.1044],\n",
      "        [ 0.0138],\n",
      "        [ 0.0322],\n",
      "        [ 0.0357],\n",
      "        [ 0.0667],\n",
      "        [ 0.0678],\n",
      "        [ 0.0262],\n",
      "        [ 0.0067],\n",
      "        [-0.0003],\n",
      "        [ 0.1111],\n",
      "        [ 0.0091],\n",
      "        [ 0.0318],\n",
      "        [ 0.0725],\n",
      "        [ 0.0237],\n",
      "        [ 0.0649],\n",
      "        [-0.0335],\n",
      "        [ 0.0164],\n",
      "        [-0.0045],\n",
      "        [ 0.0354],\n",
      "        [ 0.0782],\n",
      "        [ 0.1163],\n",
      "        [ 0.0035],\n",
      "        [ 0.0241],\n",
      "        [ 0.0230],\n",
      "        [ 0.0684],\n",
      "        [ 0.0630],\n",
      "        [ 0.0210],\n",
      "        [ 0.1102],\n",
      "        [ 0.0008]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0822, 0.0833, 0.0823, 0.0828, 0.0822, 0.0812, 0.0811, 0.0828, 0.0820,\n",
      "        0.0812, 0.0788, 0.0770, 0.0775, 0.0764, 0.0771, 0.0788, 0.0788, 0.0809,\n",
      "        0.0803, 0.0792, 0.0804, 0.0785, 0.0777, 0.0765, 0.0743, 0.0752, 0.0752,\n",
      "        0.0745, 0.0726, 0.0721, 0.0728, 0.0728], device='cuda:0')\n",
      "tensor([[ 0.0855],\n",
      "        [ 0.0293],\n",
      "        [ 0.0041],\n",
      "        [ 0.0701],\n",
      "        [ 0.0363],\n",
      "        [ 0.0231],\n",
      "        [ 0.0900],\n",
      "        [ 0.0334],\n",
      "        [ 0.0614],\n",
      "        [ 0.0572],\n",
      "        [ 0.0644],\n",
      "        [ 0.1082],\n",
      "        [ 0.0498],\n",
      "        [ 0.0131],\n",
      "        [ 0.0785],\n",
      "        [ 0.0454],\n",
      "        [ 0.1046],\n",
      "        [ 0.1223],\n",
      "        [-0.0260],\n",
      "        [ 0.0283],\n",
      "        [ 0.0146],\n",
      "        [ 0.0051],\n",
      "        [ 0.0313],\n",
      "        [ 0.0004],\n",
      "        [ 0.0339],\n",
      "        [ 0.0244],\n",
      "        [ 0.0343],\n",
      "        [ 0.0541],\n",
      "        [ 0.0147],\n",
      "        [ 0.0603],\n",
      "        [ 0.0400],\n",
      "        [ 0.0240]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0753, 0.0771, 0.0762, 0.0749, 0.0736, 0.0722, 0.0722, 0.0743, 0.0737,\n",
      "        0.0758, 0.0764, 0.0761, 0.0779, 0.0780, 0.0755, 0.0747, 0.0734, 0.0746,\n",
      "        0.0756, 0.0739, 0.0742, 0.0719, 0.0731, 0.0732, 0.0751, 0.0743, 0.0708,\n",
      "        0.0688, 0.0693, 0.0694, 0.0709, 0.0734], device='cuda:0')\n",
      "tensor([[ 0.0464],\n",
      "        [ 0.0689],\n",
      "        [ 0.0646],\n",
      "        [ 0.0393],\n",
      "        [ 0.1109],\n",
      "        [ 0.1416],\n",
      "        [ 0.0854],\n",
      "        [ 0.0580],\n",
      "        [ 0.0073],\n",
      "        [ 0.0076],\n",
      "        [ 0.0403],\n",
      "        [ 0.0482],\n",
      "        [ 0.0341],\n",
      "        [-0.0226],\n",
      "        [ 0.0381],\n",
      "        [ 0.1103],\n",
      "        [ 0.0420],\n",
      "        [ 0.0899],\n",
      "        [ 0.1007],\n",
      "        [ 0.0421],\n",
      "        [ 0.0410],\n",
      "        [ 0.0143],\n",
      "        [ 0.0533],\n",
      "        [ 0.0228],\n",
      "        [ 0.0167],\n",
      "        [ 0.1107],\n",
      "        [ 0.0002],\n",
      "        [ 0.0673],\n",
      "        [ 0.0186],\n",
      "        [ 0.0262],\n",
      "        [ 0.0049],\n",
      "        [ 0.0289]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0752, 0.0733, 0.0722, 0.0749, 0.0722, 0.0735, 0.0737, 0.0737, 0.0731,\n",
      "        0.0728, 0.0749, 0.0748, 0.0746, 0.0754, 0.0736, 0.0727, 0.0731, 0.0727,\n",
      "        0.0725, 0.0717, 0.0705, 0.0703, 0.0697, 0.0697, 0.0692, 0.0700, 0.0694,\n",
      "        0.0694, 0.0692, 0.0686, 0.0686, 0.0691], device='cuda:0')\n",
      "tensor([[ 0.0241],\n",
      "        [ 0.0270],\n",
      "        [ 0.0193],\n",
      "        [ 0.0392],\n",
      "        [ 0.0312],\n",
      "        [ 0.0499],\n",
      "        [ 0.1189],\n",
      "        [ 0.0857],\n",
      "        [ 0.0249],\n",
      "        [ 0.1155],\n",
      "        [ 0.1143],\n",
      "        [-0.0211],\n",
      "        [ 0.0506],\n",
      "        [ 0.0344],\n",
      "        [-0.0446],\n",
      "        [ 0.0073],\n",
      "        [ 0.0768],\n",
      "        [ 0.0125],\n",
      "        [ 0.0213],\n",
      "        [ 0.1164],\n",
      "        [ 0.0554],\n",
      "        [ 0.0206],\n",
      "        [ 0.0390],\n",
      "        [ 0.0635],\n",
      "        [-0.0379],\n",
      "        [ 0.0472],\n",
      "        [-0.0032],\n",
      "        [ 0.0330],\n",
      "        [ 0.0117],\n",
      "        [ 0.0217],\n",
      "        [ 0.0493],\n",
      "        [ 0.0247]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0688, 0.0706, 0.0705, 0.0705, 0.0702, 0.0696, 0.0684, 0.0686, 0.0688,\n",
      "        0.0681, 0.0673, 0.0652, 0.0665, 0.0670, 0.0687, 0.0610, 0.0573, 0.0607,\n",
      "        0.0601, 0.0575, 0.0550, 0.0573, 0.0576, 0.0575, 0.0569, 0.0568, 0.0562,\n",
      "        0.0541, 0.0550, 0.0573, 0.0580, 0.0580], device='cuda:0')\n",
      "tensor([[ 0.0799],\n",
      "        [ 0.1703],\n",
      "        [-0.0112],\n",
      "        [ 0.0621],\n",
      "        [-0.0044],\n",
      "        [ 0.0553],\n",
      "        [ 0.0639],\n",
      "        [ 0.1099],\n",
      "        [ 0.0182],\n",
      "        [ 0.1365],\n",
      "        [ 0.0339],\n",
      "        [ 0.0271],\n",
      "        [ 0.0250],\n",
      "        [ 0.0204],\n",
      "        [ 0.0649],\n",
      "        [ 0.0267],\n",
      "        [-0.0141],\n",
      "        [ 0.0222],\n",
      "        [ 0.0354],\n",
      "        [ 0.0339],\n",
      "        [ 0.0791],\n",
      "        [ 0.0310],\n",
      "        [ 0.0520],\n",
      "        [ 0.0297],\n",
      "        [ 0.0066],\n",
      "        [ 0.0448],\n",
      "        [ 0.0089],\n",
      "        [-0.0163],\n",
      "        [ 0.0485],\n",
      "        [ 0.0928],\n",
      "        [ 0.0322],\n",
      "        [ 0.0226]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0616, 0.0637, 0.0640, 0.0632, 0.0639, 0.0643, 0.0656, 0.0668, 0.0634,\n",
      "        0.0652, 0.0656, 0.0660, 0.0650, 0.0649, 0.0629, 0.0635, 0.0638, 0.0635,\n",
      "        0.0624, 0.0622, 0.0624, 0.0640, 0.0629, 0.0646, 0.0663, 0.0655, 0.0634,\n",
      "        0.0647, 0.0622, 0.0610, 0.0624, 0.0612], device='cuda:0')\n",
      "tensor([[ 0.1250],\n",
      "        [ 0.0098],\n",
      "        [ 0.0656],\n",
      "        [ 0.0620],\n",
      "        [ 0.0120],\n",
      "        [ 0.0224],\n",
      "        [ 0.0407],\n",
      "        [ 0.0216],\n",
      "        [ 0.0512],\n",
      "        [ 0.0323],\n",
      "        [ 0.0352],\n",
      "        [ 0.0524],\n",
      "        [ 0.0762],\n",
      "        [ 0.0018],\n",
      "        [ 0.0248],\n",
      "        [ 0.0628],\n",
      "        [-0.0155],\n",
      "        [ 0.0362],\n",
      "        [ 0.0305],\n",
      "        [ 0.0313],\n",
      "        [-0.0196],\n",
      "        [ 0.0185],\n",
      "        [ 0.0580],\n",
      "        [ 0.0068],\n",
      "        [ 0.0339],\n",
      "        [ 0.0335],\n",
      "        [ 0.0266],\n",
      "        [ 0.0564],\n",
      "        [ 0.0327],\n",
      "        [ 0.0957],\n",
      "        [ 0.1032],\n",
      "        [ 0.0183]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0593, 0.0585, 0.0602, 0.0593, 0.0590, 0.0570, 0.0561, 0.0555, 0.0577,\n",
      "        0.0590, 0.0584, 0.0550, 0.0547, 0.0551, 0.0533, 0.0516, 0.0544, 0.0548,\n",
      "        0.0525, 0.0517, 0.0508, 0.0541, 0.0560, 0.0543, 0.0536, 0.0524, 0.0514,\n",
      "        0.0488, 0.0478, 0.0480, 0.0480, 0.0483], device='cuda:0')\n",
      "tensor([[ 0.0432],\n",
      "        [-0.0163],\n",
      "        [-0.0039],\n",
      "        [ 0.0477],\n",
      "        [ 0.0319],\n",
      "        [ 0.0606],\n",
      "        [ 0.0350],\n",
      "        [ 0.0465],\n",
      "        [ 0.0811],\n",
      "        [ 0.1949],\n",
      "        [ 0.0475],\n",
      "        [-0.0189],\n",
      "        [ 0.1048],\n",
      "        [ 0.1187],\n",
      "        [ 0.0127],\n",
      "        [ 0.0523],\n",
      "        [ 0.0085],\n",
      "        [ 0.0202],\n",
      "        [-0.0077],\n",
      "        [ 0.0201],\n",
      "        [ 0.0054],\n",
      "        [ 0.0031],\n",
      "        [ 0.0553],\n",
      "        [ 0.0318],\n",
      "        [ 0.0172],\n",
      "        [-0.0157],\n",
      "        [ 0.0773],\n",
      "        [-0.0081],\n",
      "        [ 0.0833],\n",
      "        [ 0.0825],\n",
      "        [ 0.0320],\n",
      "        [ 0.0530]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0516, 0.0507, 0.0513, 0.0527, 0.0548, 0.0533, 0.0531, 0.0545, 0.0539,\n",
      "        0.0535, 0.0536, 0.0529, 0.0525, 0.0534, 0.0531, 0.0519, 0.0507, 0.0506,\n",
      "        0.0508, 0.0505, 0.0495, 0.0480, 0.0481, 0.0484, 0.0476, 0.0497, 0.0491,\n",
      "        0.0502, 0.0508, 0.0505, 0.0503, 0.0509], device='cuda:0')\n",
      "tensor([[ 0.0276],\n",
      "        [ 0.0443],\n",
      "        [ 0.0366],\n",
      "        [-0.0081],\n",
      "        [ 0.0285],\n",
      "        [ 0.0305],\n",
      "        [ 0.0067],\n",
      "        [ 0.0362],\n",
      "        [ 0.0257],\n",
      "        [ 0.0494],\n",
      "        [ 0.0304],\n",
      "        [ 0.0168],\n",
      "        [ 0.0395],\n",
      "        [ 0.1088],\n",
      "        [ 0.0418],\n",
      "        [ 0.1364],\n",
      "        [ 0.0784],\n",
      "        [ 0.1011],\n",
      "        [ 0.0682],\n",
      "        [ 0.0270],\n",
      "        [ 0.0386],\n",
      "        [ 0.0555],\n",
      "        [ 0.0003],\n",
      "        [ 0.0137],\n",
      "        [ 0.0468],\n",
      "        [ 0.0270],\n",
      "        [ 0.0177],\n",
      "        [-0.0023],\n",
      "        [ 0.0457],\n",
      "        [-0.0555],\n",
      "        [ 0.0623],\n",
      "        [-0.0066]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0507, 0.0510, 0.0504, 0.0506, 0.0521, 0.0528, 0.0515, 0.0517, 0.0535,\n",
      "        0.0544, 0.0545, 0.0542, 0.0543, 0.0538, 0.0533, 0.0534, 0.0525, 0.0526,\n",
      "        0.0538, 0.0545, 0.0528, 0.0515, 0.0503, 0.0486, 0.0498, 0.0514, 0.0516,\n",
      "        0.0497, 0.0488, 0.0495, 0.0487, 0.0485], device='cuda:0')\n",
      "tensor([[ 0.0157],\n",
      "        [ 0.0539],\n",
      "        [ 0.0327],\n",
      "        [ 0.0346],\n",
      "        [ 0.0420],\n",
      "        [ 0.0340],\n",
      "        [ 0.0065],\n",
      "        [ 0.0456],\n",
      "        [ 0.0726],\n",
      "        [ 0.0541],\n",
      "        [ 0.0420],\n",
      "        [ 0.0058],\n",
      "        [ 0.0648],\n",
      "        [ 0.0141],\n",
      "        [ 0.0564],\n",
      "        [ 0.1030],\n",
      "        [ 0.0548],\n",
      "        [ 0.0931],\n",
      "        [ 0.0163],\n",
      "        [ 0.0204],\n",
      "        [-0.0007],\n",
      "        [ 0.0228],\n",
      "        [-0.0273],\n",
      "        [ 0.0171],\n",
      "        [ 0.0112],\n",
      "        [ 0.0271],\n",
      "        [ 0.0136],\n",
      "        [ 0.0314],\n",
      "        [ 0.1455],\n",
      "        [ 0.0746],\n",
      "        [ 0.0483],\n",
      "        [ 0.0470]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0488, 0.0499, 0.0499, 0.0501, 0.0491, 0.0488, 0.0478, 0.0467, 0.0462,\n",
      "        0.0473, 0.0470, 0.0478, 0.0486, 0.0484, 0.0475, 0.0469, 0.0481, 0.0474,\n",
      "        0.0488, 0.0469, 0.0461, 0.0466, 0.0464, 0.0457, 0.0452, 0.0452, 0.0449,\n",
      "        0.0445, 0.0446, 0.0453, 0.0448, 0.0429], device='cuda:0')\n",
      "tensor([[ 0.0455],\n",
      "        [ 0.0353],\n",
      "        [ 0.0131],\n",
      "        [ 0.0291],\n",
      "        [ 0.0482],\n",
      "        [ 0.0421],\n",
      "        [ 0.0352],\n",
      "        [ 0.0339],\n",
      "        [ 0.0203],\n",
      "        [-0.0202],\n",
      "        [ 0.0978],\n",
      "        [ 0.0019],\n",
      "        [ 0.1167],\n",
      "        [ 0.0606],\n",
      "        [ 0.0656],\n",
      "        [ 0.0418],\n",
      "        [ 0.0024],\n",
      "        [ 0.0876],\n",
      "        [ 0.0073],\n",
      "        [ 0.0388],\n",
      "        [ 0.0449],\n",
      "        [ 0.1148],\n",
      "        [ 0.0222],\n",
      "        [ 0.0537],\n",
      "        [ 0.0020],\n",
      "        [ 0.0100],\n",
      "        [ 0.0207],\n",
      "        [ 0.0068],\n",
      "        [ 0.0092],\n",
      "        [ 0.0414],\n",
      "        [ 0.0422],\n",
      "        [ 0.0575]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0440, 0.0435, 0.0454, 0.0458, 0.0458, 0.0479, 0.0484, 0.0487, 0.0476,\n",
      "        0.0471, 0.0479, 0.0465, 0.0453, 0.0445, 0.0446, 0.0438, 0.0436, 0.0444,\n",
      "        0.0461, 0.0446, 0.0433, 0.0435, 0.0435, 0.0432, 0.0427, 0.0415, 0.0395,\n",
      "        0.0403, 0.0391, 0.0394, 0.0442, 0.0454], device='cuda:0')\n",
      "tensor([[ 0.0432],\n",
      "        [ 0.0449],\n",
      "        [ 0.0158],\n",
      "        [ 0.0465],\n",
      "        [ 0.1963],\n",
      "        [-0.0072],\n",
      "        [ 0.0860],\n",
      "        [ 0.0905],\n",
      "        [ 0.0810],\n",
      "        [ 0.0642],\n",
      "        [ 0.1031],\n",
      "        [ 0.0723],\n",
      "        [ 0.0279],\n",
      "        [ 0.0691],\n",
      "        [-0.0018],\n",
      "        [-0.0190],\n",
      "        [-0.0211],\n",
      "        [-0.0152],\n",
      "        [ 0.0064],\n",
      "        [ 0.0334],\n",
      "        [ 0.0319],\n",
      "        [ 0.0408],\n",
      "        [ 0.0260],\n",
      "        [ 0.0663],\n",
      "        [ 0.0256],\n",
      "        [ 0.0779],\n",
      "        [ 0.0789],\n",
      "        [ 0.0048],\n",
      "        [ 0.0068],\n",
      "        [ 0.0575],\n",
      "        [ 0.0220],\n",
      "        [ 0.0592]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0438, 0.0450, 0.0448, 0.0450, 0.0456, 0.0463, 0.0460, 0.0441, 0.0416,\n",
      "        0.0407, 0.0420, 0.0402, 0.0403, 0.0400, 0.0410, 0.0424, 0.0441, 0.0423,\n",
      "        0.0423, 0.0407, 0.0404, 0.0398, 0.0398, 0.0393, 0.0388, 0.0397, 0.0374,\n",
      "        0.0376, 0.0368, 0.0379, 0.0374, 0.0372], device='cuda:0')\n",
      "tensor([[ 0.0645],\n",
      "        [ 0.0156],\n",
      "        [ 0.0466],\n",
      "        [ 0.0072],\n",
      "        [ 0.0384],\n",
      "        [ 0.0525],\n",
      "        [ 0.0437],\n",
      "        [ 0.0295],\n",
      "        [-0.0109],\n",
      "        [ 0.0305],\n",
      "        [ 0.0342],\n",
      "        [ 0.0619],\n",
      "        [ 0.0195],\n",
      "        [ 0.0502],\n",
      "        [ 0.1423],\n",
      "        [-0.0254],\n",
      "        [ 0.0237],\n",
      "        [ 0.0140],\n",
      "        [ 0.0448],\n",
      "        [ 0.1587],\n",
      "        [ 0.1053],\n",
      "        [ 0.1076],\n",
      "        [ 0.0360],\n",
      "        [ 0.0715],\n",
      "        [ 0.0240],\n",
      "        [ 0.0306],\n",
      "        [ 0.0667],\n",
      "        [ 0.0482],\n",
      "        [ 0.0212],\n",
      "        [ 0.0328],\n",
      "        [ 0.0621],\n",
      "        [ 0.0062]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0364, 0.0374, 0.0349, 0.0339, 0.0345, 0.0336, 0.0318, 0.0314, 0.0295,\n",
      "        0.0269, 0.0256, 0.0279, 0.0285, 0.0299, 0.0311, 0.0314, 0.0307, 0.0300,\n",
      "        0.0294, 0.0291, 0.0282, 0.0277, 0.0280, 0.0278, 0.0273, 0.0269, 0.0292,\n",
      "        0.0286, 0.0315, 0.0327, 0.0333, 0.0336], device='cuda:0')\n",
      "tensor([[ 0.0431],\n",
      "        [ 0.0065],\n",
      "        [ 0.0202],\n",
      "        [ 0.0564],\n",
      "        [ 0.0841],\n",
      "        [ 0.0172],\n",
      "        [ 0.0497],\n",
      "        [ 0.0167],\n",
      "        [ 0.0439],\n",
      "        [ 0.1020],\n",
      "        [-0.0008],\n",
      "        [ 0.0467],\n",
      "        [ 0.0521],\n",
      "        [ 0.1289],\n",
      "        [ 0.0847],\n",
      "        [ 0.0196],\n",
      "        [ 0.1095],\n",
      "        [ 0.0422],\n",
      "        [ 0.0465],\n",
      "        [ 0.0577],\n",
      "        [ 0.0367],\n",
      "        [ 0.0391],\n",
      "        [ 0.0151],\n",
      "        [ 0.0223],\n",
      "        [ 0.0427],\n",
      "        [ 0.0514],\n",
      "        [ 0.0327],\n",
      "        [ 0.0146],\n",
      "        [ 0.0789],\n",
      "        [ 0.0550],\n",
      "        [-0.0373],\n",
      "        [ 0.0684]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0331, 0.0330, 0.0339, 0.0351, 0.0376, 0.0362, 0.0345, 0.0342, 0.0331,\n",
      "        0.0341, 0.0373, 0.0377, 0.0366, 0.0373, 0.0367, 0.0386, 0.0350, 0.0360,\n",
      "        0.0370, 0.0368, 0.0353, 0.0353, 0.0345, 0.0339, 0.0321, 0.0308, 0.0305,\n",
      "        0.0314, 0.0311, 0.0321, 0.0330, 0.0333], device='cuda:0')\n",
      "tensor([[-0.0190],\n",
      "        [-0.0458],\n",
      "        [ 0.0251],\n",
      "        [ 0.0386],\n",
      "        [ 0.0632],\n",
      "        [ 0.0063],\n",
      "        [-0.0017],\n",
      "        [ 0.0315],\n",
      "        [-0.0093],\n",
      "        [-0.0599],\n",
      "        [ 0.0238],\n",
      "        [ 0.0206],\n",
      "        [ 0.0021],\n",
      "        [ 0.0358],\n",
      "        [ 0.0810],\n",
      "        [ 0.0476],\n",
      "        [ 0.0108],\n",
      "        [ 0.0171],\n",
      "        [ 0.0148],\n",
      "        [ 0.0194],\n",
      "        [ 0.0412],\n",
      "        [ 0.0465],\n",
      "        [ 0.0239],\n",
      "        [ 0.0392],\n",
      "        [ 0.1476],\n",
      "        [ 0.0385],\n",
      "        [ 0.0598],\n",
      "        [ 0.0075],\n",
      "        [ 0.0550],\n",
      "        [ 0.0478],\n",
      "        [ 0.0288],\n",
      "        [ 0.0489]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0331, 0.0311, 0.0304, 0.0308, 0.0298, 0.0293, 0.0305, 0.0315, 0.0314,\n",
      "        0.0308, 0.0301, 0.0295, 0.0314, 0.0309, 0.0306, 0.0308, 0.0297, 0.0301,\n",
      "        0.0294, 0.0286, 0.0292, 0.0303, 0.0306, 0.0302, 0.0299, 0.0297, 0.0289,\n",
      "        0.0305, 0.0313, 0.0307, 0.0304, 0.0290], device='cuda:0')\n",
      "tensor([[ 0.0283],\n",
      "        [-0.0010],\n",
      "        [-0.0045],\n",
      "        [-0.0015],\n",
      "        [ 0.0986],\n",
      "        [-0.0031],\n",
      "        [ 0.0913],\n",
      "        [ 0.0694],\n",
      "        [ 0.0591],\n",
      "        [ 0.0148],\n",
      "        [ 0.0437],\n",
      "        [ 0.0239],\n",
      "        [ 0.0182],\n",
      "        [ 0.0810],\n",
      "        [ 0.0603],\n",
      "        [ 0.0431],\n",
      "        [ 0.0136],\n",
      "        [ 0.1490],\n",
      "        [ 0.0658],\n",
      "        [ 0.0119],\n",
      "        [ 0.0692],\n",
      "        [ 0.0141],\n",
      "        [ 0.0250],\n",
      "        [ 0.0627],\n",
      "        [ 0.0131],\n",
      "        [ 0.1196],\n",
      "        [ 0.1120],\n",
      "        [ 0.0434],\n",
      "        [ 0.0554],\n",
      "        [ 0.0234],\n",
      "        [-0.0195],\n",
      "        [ 0.0469]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0282, 0.0274, 0.0280, 0.0279, 0.0290, 0.0288, 0.0288, 0.0288, 0.0338,\n",
      "        0.0360, 0.0347, 0.0363, 0.0377, 0.0373, 0.0397, 0.0386, 0.0391, 0.0394,\n",
      "        0.0402, 0.0428, 0.0443, 0.0457, 0.0433, 0.0450, 0.0450, 0.0452, 0.0433,\n",
      "        0.0420, 0.0433, 0.0434, 0.0443, 0.0457], device='cuda:0')\n",
      "tensor([[ 0.0612],\n",
      "        [ 0.0476],\n",
      "        [ 0.0283],\n",
      "        [ 0.0547],\n",
      "        [ 0.1329],\n",
      "        [ 0.0398],\n",
      "        [ 0.0816],\n",
      "        [ 0.0790],\n",
      "        [ 0.0629],\n",
      "        [ 0.0494],\n",
      "        [ 0.0251],\n",
      "        [ 0.0320],\n",
      "        [ 0.0437],\n",
      "        [ 0.0455],\n",
      "        [ 0.0052],\n",
      "        [ 0.0230],\n",
      "        [ 0.0454],\n",
      "        [ 0.0017],\n",
      "        [ 0.0222],\n",
      "        [ 0.1459],\n",
      "        [ 0.0296],\n",
      "        [ 0.0317],\n",
      "        [ 0.0398],\n",
      "        [ 0.0140],\n",
      "        [-0.0058],\n",
      "        [ 0.0684],\n",
      "        [ 0.0613],\n",
      "        [-0.0315],\n",
      "        [ 0.0254],\n",
      "        [ 0.0619],\n",
      "        [ 0.1287],\n",
      "        [ 0.1183]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0440, 0.0443, 0.0455, 0.0448, 0.0455, 0.0443, 0.0436, 0.0448, 0.0443,\n",
      "        0.0453, 0.0441, 0.0440, 0.0426, 0.0425, 0.0411, 0.0427, 0.0427, 0.0420,\n",
      "        0.0417, 0.0416, 0.0409, 0.0392, 0.0392, 0.0391, 0.0402, 0.0426, 0.0422,\n",
      "        0.0412, 0.0426, 0.0426, 0.0435, 0.0435], device='cuda:0')\n",
      "tensor([[ 0.0601],\n",
      "        [ 0.0554],\n",
      "        [ 0.0240],\n",
      "        [ 0.0447],\n",
      "        [ 0.0256],\n",
      "        [ 0.0175],\n",
      "        [ 0.0354],\n",
      "        [ 0.0367],\n",
      "        [ 0.0842],\n",
      "        [ 0.1533],\n",
      "        [ 0.0694],\n",
      "        [ 0.0470],\n",
      "        [-0.0368],\n",
      "        [ 0.0025],\n",
      "        [ 0.0042],\n",
      "        [ 0.0159],\n",
      "        [ 0.0552],\n",
      "        [ 0.0391],\n",
      "        [ 0.0226],\n",
      "        [ 0.0147],\n",
      "        [ 0.0208],\n",
      "        [ 0.0356],\n",
      "        [ 0.0470],\n",
      "        [ 0.0329],\n",
      "        [ 0.0960],\n",
      "        [ 0.0177],\n",
      "        [ 0.0541],\n",
      "        [ 0.0488],\n",
      "        [ 0.1025],\n",
      "        [ 0.0622],\n",
      "        [ 0.0047],\n",
      "        [ 0.0226]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0425, 0.0438, 0.0433, 0.0421, 0.0418, 0.0415, 0.0405, 0.0404, 0.0427,\n",
      "        0.0425, 0.0420, 0.0438, 0.0426, 0.0434, 0.0426, 0.0440, 0.0445, 0.0467,\n",
      "        0.0467, 0.0449, 0.0447, 0.0454, 0.0445, 0.0435, 0.0439, 0.0453, 0.0445,\n",
      "        0.0437, 0.0435, 0.0442, 0.0451, 0.0452], device='cuda:0')\n",
      "tensor([[ 0.0455],\n",
      "        [ 0.0578],\n",
      "        [ 0.0234],\n",
      "        [ 0.0604],\n",
      "        [ 0.0839],\n",
      "        [ 0.0760],\n",
      "        [ 0.1361],\n",
      "        [ 0.0365],\n",
      "        [ 0.0707],\n",
      "        [ 0.0101],\n",
      "        [ 0.0103],\n",
      "        [ 0.1295],\n",
      "        [ 0.0839],\n",
      "        [ 0.0302],\n",
      "        [-0.0388],\n",
      "        [ 0.0527],\n",
      "        [ 0.0129],\n",
      "        [ 0.0100],\n",
      "        [ 0.0126],\n",
      "        [ 0.0778],\n",
      "        [ 0.1212],\n",
      "        [ 0.0313],\n",
      "        [ 0.0383],\n",
      "        [ 0.0066],\n",
      "        [ 0.0175],\n",
      "        [ 0.0158],\n",
      "        [ 0.0198],\n",
      "        [ 0.0642],\n",
      "        [ 0.0306],\n",
      "        [ 0.0229],\n",
      "        [ 0.0013],\n",
      "        [ 0.0256]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0447, 0.0451, 0.0438, 0.0433, 0.0432, 0.0428, 0.0423, 0.0416, 0.0422,\n",
      "        0.0408, 0.0410, 0.0422, 0.0417, 0.0436, 0.0432, 0.0429, 0.0425, 0.0424,\n",
      "        0.0424, 0.0423, 0.0418, 0.0417, 0.0410, 0.0416, 0.0426, 0.0412, 0.0414,\n",
      "        0.0421, 0.0418, 0.0411, 0.0405, 0.0403], device='cuda:0')\n",
      "tensor([[ 0.1398],\n",
      "        [ 0.0775],\n",
      "        [ 0.0681],\n",
      "        [ 0.0147],\n",
      "        [ 0.0445],\n",
      "        [ 0.0752],\n",
      "        [-0.0040],\n",
      "        [-0.0045],\n",
      "        [ 0.0067],\n",
      "        [ 0.1236],\n",
      "        [-0.0535],\n",
      "        [ 0.0404],\n",
      "        [ 0.0368],\n",
      "        [ 0.0283],\n",
      "        [ 0.0190],\n",
      "        [ 0.0415],\n",
      "        [-0.0239],\n",
      "        [ 0.0072],\n",
      "        [ 0.0309],\n",
      "        [ 0.1189],\n",
      "        [-0.0027],\n",
      "        [ 0.0422],\n",
      "        [ 0.0457],\n",
      "        [ 0.0214],\n",
      "        [-0.0325],\n",
      "        [ 0.0508],\n",
      "        [ 0.0118],\n",
      "        [ 0.0132],\n",
      "        [ 0.0449],\n",
      "        [ 0.0439],\n",
      "        [ 0.0895],\n",
      "        [ 0.0531]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0401, 0.0390, 0.0377, 0.0381, 0.0370, 0.0370, 0.0374, 0.0383, 0.0369,\n",
      "        0.0366, 0.0362, 0.0352, 0.0356, 0.0348, 0.0339, 0.0349, 0.0345, 0.0331,\n",
      "        0.0338, 0.0345, 0.0345, 0.0333, 0.0328, 0.0331, 0.0339, 0.0345, 0.0333,\n",
      "        0.0342, 0.0357, 0.0357, 0.0342, 0.0347], device='cuda:0')\n",
      "tensor([[ 0.0306],\n",
      "        [ 0.0567],\n",
      "        [ 0.0573],\n",
      "        [-0.0026],\n",
      "        [ 0.0105],\n",
      "        [ 0.0254],\n",
      "        [ 0.1096],\n",
      "        [-0.0012],\n",
      "        [ 0.0560],\n",
      "        [ 0.0773],\n",
      "        [ 0.0413],\n",
      "        [ 0.0396],\n",
      "        [ 0.0071],\n",
      "        [ 0.0118],\n",
      "        [ 0.0191],\n",
      "        [ 0.0126],\n",
      "        [ 0.0646],\n",
      "        [ 0.0369],\n",
      "        [ 0.0178],\n",
      "        [ 0.1040],\n",
      "        [ 0.0153],\n",
      "        [ 0.0965],\n",
      "        [ 0.0391],\n",
      "        [ 0.0190],\n",
      "        [ 0.0333],\n",
      "        [-0.0305],\n",
      "        [ 0.0491],\n",
      "        [ 0.0463],\n",
      "        [ 0.0831],\n",
      "        [ 0.0538],\n",
      "        [ 0.0433],\n",
      "        [ 0.1172]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0345, 0.0339, 0.0349, 0.0336, 0.0339, 0.0342, 0.0339, 0.0338, 0.0333,\n",
      "        0.0338, 0.0357, 0.0366, 0.0358, 0.0364, 0.0371, 0.0374, 0.0386, 0.0370,\n",
      "        0.0363, 0.0349, 0.0364, 0.0384, 0.0401, 0.0401, 0.0415, 0.0413, 0.0415,\n",
      "        0.0429, 0.0423, 0.0424, 0.0425, 0.0419], device='cuda:0')\n",
      "tensor([[ 0.0953],\n",
      "        [ 0.0841],\n",
      "        [ 0.0498],\n",
      "        [ 0.0958],\n",
      "        [-0.0149],\n",
      "        [-0.0455],\n",
      "        [ 0.0149],\n",
      "        [ 0.0516],\n",
      "        [ 0.0525],\n",
      "        [ 0.0974],\n",
      "        [ 0.0369],\n",
      "        [ 0.0773],\n",
      "        [ 0.0654],\n",
      "        [-0.0052],\n",
      "        [ 0.0307],\n",
      "        [ 0.0335],\n",
      "        [ 0.0337],\n",
      "        [ 0.0367],\n",
      "        [ 0.0376],\n",
      "        [ 0.0448],\n",
      "        [ 0.0288],\n",
      "        [ 0.0155],\n",
      "        [ 0.0083],\n",
      "        [ 0.0164],\n",
      "        [ 0.0504],\n",
      "        [ 0.0629],\n",
      "        [ 0.0091],\n",
      "        [ 0.1704],\n",
      "        [ 0.0447],\n",
      "        [ 0.0246],\n",
      "        [-0.0124],\n",
      "        [-0.0009]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0432, 0.0436, 0.0437, 0.0443, 0.0424, 0.0431, 0.0442, 0.0430, 0.0431,\n",
      "        0.0434, 0.0431, 0.0438, 0.0444, 0.0448, 0.0446, 0.0447, 0.0456, 0.0471,\n",
      "        0.0461, 0.0464, 0.0471, 0.0458, 0.0455, 0.0460, 0.0462, 0.0463, 0.0470,\n",
      "        0.0471, 0.0476, 0.0469, 0.0459, 0.0454], device='cuda:0')\n",
      "tensor([[ 0.0459],\n",
      "        [ 0.0256],\n",
      "        [ 0.0147],\n",
      "        [ 0.0184],\n",
      "        [ 0.0389],\n",
      "        [ 0.0799],\n",
      "        [ 0.1515],\n",
      "        [ 0.1056],\n",
      "        [ 0.0415],\n",
      "        [ 0.0398],\n",
      "        [ 0.0555],\n",
      "        [ 0.0031],\n",
      "        [-0.0103],\n",
      "        [ 0.0210],\n",
      "        [ 0.0356],\n",
      "        [ 0.0317],\n",
      "        [ 0.0272],\n",
      "        [-0.0116],\n",
      "        [ 0.0144],\n",
      "        [ 0.0178],\n",
      "        [ 0.0482],\n",
      "        [ 0.0539],\n",
      "        [ 0.0267],\n",
      "        [ 0.0344],\n",
      "        [ 0.0400],\n",
      "        [ 0.0086],\n",
      "        [-0.0038],\n",
      "        [ 0.0141],\n",
      "        [ 0.0822],\n",
      "        [ 0.0264],\n",
      "        [ 0.1585],\n",
      "        [ 0.0382]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0457, 0.0441, 0.0442, 0.0445, 0.0449, 0.0441, 0.0444, 0.0447, 0.0456,\n",
      "        0.0456, 0.0455, 0.0450, 0.0445, 0.0457, 0.0466, 0.0466, 0.0464, 0.0466,\n",
      "        0.0469, 0.0476, 0.0486, 0.0484, 0.0482, 0.0487, 0.0490, 0.0503, 0.0499,\n",
      "        0.0519, 0.0515, 0.0522, 0.0545, 0.0554], device='cuda:0')\n",
      "tensor([[ 8.6388e-02],\n",
      "        [ 1.8646e-02],\n",
      "        [ 9.3258e-02],\n",
      "        [ 7.8660e-02],\n",
      "        [ 2.0319e-01],\n",
      "        [-2.9139e-02],\n",
      "        [ 6.0762e-02],\n",
      "        [ 1.2052e-01],\n",
      "        [ 5.2806e-03],\n",
      "        [ 5.2393e-03],\n",
      "        [ 1.4775e-02],\n",
      "        [ 1.5853e-02],\n",
      "        [ 1.5318e-04],\n",
      "        [ 5.3126e-02],\n",
      "        [ 5.8127e-02],\n",
      "        [ 2.8728e-03],\n",
      "        [ 1.3316e-02],\n",
      "        [ 6.3447e-02],\n",
      "        [ 9.3136e-02],\n",
      "        [ 1.3255e-02],\n",
      "        [ 1.1529e-04],\n",
      "        [ 1.6895e-03],\n",
      "        [ 4.3155e-02],\n",
      "        [-2.0048e-02],\n",
      "        [ 7.2817e-02],\n",
      "        [ 4.7554e-04],\n",
      "        [ 1.7130e-02],\n",
      "        [-6.9537e-03],\n",
      "        [ 4.8369e-02],\n",
      "        [-4.1027e-05],\n",
      "        [ 1.4230e-01],\n",
      "        [ 3.7531e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0538, 0.0545, 0.0558, 0.0558, 0.0545, 0.0548, 0.0564, 0.0568, 0.0573,\n",
      "        0.0578, 0.0586, 0.0569, 0.0557, 0.0556, 0.0569, 0.0561, 0.0553, 0.0557,\n",
      "        0.0555, 0.0562, 0.0579, 0.0581, 0.0576, 0.0582, 0.0575, 0.0563, 0.0562,\n",
      "        0.0573, 0.0573, 0.0573, 0.0564, 0.0567], device='cuda:0')\n",
      "tensor([[ 0.0254],\n",
      "        [ 0.0583],\n",
      "        [ 0.0333],\n",
      "        [-0.0023],\n",
      "        [ 0.0058],\n",
      "        [-0.0021],\n",
      "        [ 0.0283],\n",
      "        [ 0.0466],\n",
      "        [ 0.0415],\n",
      "        [ 0.0175],\n",
      "        [ 0.0604],\n",
      "        [ 0.0249],\n",
      "        [ 0.0402],\n",
      "        [-0.0109],\n",
      "        [ 0.0352],\n",
      "        [ 0.0170],\n",
      "        [ 0.0401],\n",
      "        [ 0.0533],\n",
      "        [ 0.0086],\n",
      "        [ 0.0060],\n",
      "        [ 0.0095],\n",
      "        [ 0.0594],\n",
      "        [-0.0026],\n",
      "        [ 0.0368],\n",
      "        [ 0.1445],\n",
      "        [ 0.0803],\n",
      "        [ 0.1041],\n",
      "        [ 0.0954],\n",
      "        [ 0.1261],\n",
      "        [ 0.0173],\n",
      "        [ 0.0878],\n",
      "        [ 0.0450]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0575, 0.0571, 0.0580, 0.0592, 0.0579, 0.0574, 0.0580, 0.0569, 0.0569,\n",
      "        0.0571, 0.0570, 0.0581, 0.0580, 0.0570, 0.0573, 0.0576, 0.0576, 0.0581,\n",
      "        0.0580, 0.0595, 0.0610, 0.0604, 0.0601, 0.0599, 0.0598, 0.0580, 0.0585,\n",
      "        0.0562, 0.0564, 0.0572, 0.0579, 0.0576], device='cuda:0')\n",
      "tensor([[ 0.0444],\n",
      "        [ 0.0480],\n",
      "        [ 0.0617],\n",
      "        [ 0.0126],\n",
      "        [ 0.0437],\n",
      "        [ 0.0820],\n",
      "        [ 0.0186],\n",
      "        [ 0.0433],\n",
      "        [ 0.0603],\n",
      "        [ 0.0606],\n",
      "        [ 0.0740],\n",
      "        [ 0.0787],\n",
      "        [-0.0729],\n",
      "        [ 0.0051],\n",
      "        [ 0.1043],\n",
      "        [ 0.0822],\n",
      "        [ 0.0523],\n",
      "        [ 0.0961],\n",
      "        [ 0.0707],\n",
      "        [ 0.0158],\n",
      "        [ 0.0424],\n",
      "        [ 0.0277],\n",
      "        [ 0.0676],\n",
      "        [ 0.0218],\n",
      "        [ 0.0164],\n",
      "        [ 0.0519],\n",
      "        [ 0.0475],\n",
      "        [ 0.0465],\n",
      "        [ 0.0510],\n",
      "        [ 0.0465],\n",
      "        [ 0.0558],\n",
      "        [ 0.0650]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0575, 0.0571, 0.0573, 0.0563, 0.0563, 0.0556, 0.0555, 0.0542, 0.0553,\n",
      "        0.0545, 0.0544, 0.0547, 0.0569, 0.0564, 0.0566, 0.0562, 0.0552, 0.0552,\n",
      "        0.0554, 0.0556, 0.0566, 0.0556, 0.0545, 0.0548, 0.0545, 0.0555, 0.0565,\n",
      "        0.0557, 0.0567, 0.0563, 0.0554, 0.0555], device='cuda:0')\n",
      "tensor([[ 0.0071],\n",
      "        [-0.0231],\n",
      "        [ 0.0219],\n",
      "        [-0.0095],\n",
      "        [ 0.0942],\n",
      "        [-0.0169],\n",
      "        [ 0.0520],\n",
      "        [ 0.0857],\n",
      "        [ 0.0139],\n",
      "        [ 0.0591],\n",
      "        [ 0.0408],\n",
      "        [ 0.0677],\n",
      "        [ 0.0007],\n",
      "        [ 0.0326],\n",
      "        [ 0.0457],\n",
      "        [ 0.0621],\n",
      "        [ 0.1163],\n",
      "        [ 0.0672],\n",
      "        [ 0.0518],\n",
      "        [ 0.0290],\n",
      "        [ 0.0295],\n",
      "        [ 0.0923],\n",
      "        [ 0.0497],\n",
      "        [ 0.0607],\n",
      "        [ 0.0200],\n",
      "        [ 0.0013],\n",
      "        [ 0.0030],\n",
      "        [ 0.0140],\n",
      "        [ 0.0420],\n",
      "        [ 0.0377],\n",
      "        [ 0.0688],\n",
      "        [ 0.0763]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0554, 0.0555, 0.0562, 0.0568, 0.0576, 0.0572, 0.0581, 0.0601, 0.0593,\n",
      "        0.0606, 0.0601, 0.0610, 0.0620, 0.0618, 0.0615, 0.0621, 0.0624, 0.0618,\n",
      "        0.0622, 0.0619, 0.0628, 0.0624, 0.0628, 0.0633, 0.0627, 0.0624, 0.0623,\n",
      "        0.0617, 0.0610, 0.0606, 0.0607, 0.0612], device='cuda:0')\n",
      "tensor([[ 0.0067],\n",
      "        [ 0.0611],\n",
      "        [ 0.0715],\n",
      "        [ 0.0518],\n",
      "        [ 0.0406],\n",
      "        [ 0.0236],\n",
      "        [ 0.0318],\n",
      "        [ 0.0602],\n",
      "        [ 0.0378],\n",
      "        [ 0.0258],\n",
      "        [ 0.0162],\n",
      "        [ 0.0446],\n",
      "        [ 0.0753],\n",
      "        [ 0.0766],\n",
      "        [ 0.0358],\n",
      "        [ 0.0297],\n",
      "        [ 0.0513],\n",
      "        [-0.0006],\n",
      "        [ 0.0711],\n",
      "        [ 0.0062],\n",
      "        [ 0.0984],\n",
      "        [ 0.1457],\n",
      "        [ 0.0279],\n",
      "        [ 0.0681],\n",
      "        [ 0.0146],\n",
      "        [ 0.1140],\n",
      "        [ 0.0119],\n",
      "        [ 0.1399],\n",
      "        [ 0.0420],\n",
      "        [-0.0081],\n",
      "        [ 0.0392],\n",
      "        [ 0.0277]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0613, 0.0621, 0.0611, 0.0613, 0.0613, 0.0611, 0.0610, 0.0622, 0.0624,\n",
      "        0.0618, 0.0620, 0.0618, 0.0629, 0.0626, 0.0626, 0.0629, 0.0632, 0.0634,\n",
      "        0.0632, 0.0620, 0.0613, 0.0615, 0.0603, 0.0610, 0.0601, 0.0604, 0.0611,\n",
      "        0.0615, 0.0625, 0.0623, 0.0629, 0.0634], device='cuda:0')\n",
      "tensor([[ 0.0247],\n",
      "        [ 0.0179],\n",
      "        [ 0.0242],\n",
      "        [ 0.0741],\n",
      "        [ 0.0570],\n",
      "        [ 0.0290],\n",
      "        [ 0.0353],\n",
      "        [ 0.0279],\n",
      "        [ 0.0252],\n",
      "        [ 0.0081],\n",
      "        [ 0.0180],\n",
      "        [ 0.0977],\n",
      "        [ 0.0499],\n",
      "        [ 0.0831],\n",
      "        [ 0.1781],\n",
      "        [ 0.1103],\n",
      "        [ 0.0453],\n",
      "        [ 0.0474],\n",
      "        [ 0.0209],\n",
      "        [ 0.0204],\n",
      "        [ 0.0891],\n",
      "        [ 0.0773],\n",
      "        [-0.0139],\n",
      "        [ 0.1157],\n",
      "        [ 0.0721],\n",
      "        [ 0.0336],\n",
      "        [ 0.0299],\n",
      "        [ 0.0141],\n",
      "        [ 0.0260],\n",
      "        [ 0.0654],\n",
      "        [ 0.0971],\n",
      "        [ 0.2088]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0625, 0.0628, 0.0632, 0.0627, 0.0628, 0.0629, 0.0646, 0.0646, 0.0646,\n",
      "        0.0657, 0.0650, 0.0646, 0.0645, 0.0654, 0.0645, 0.0638, 0.0638, 0.0635,\n",
      "        0.0634, 0.0631, 0.0632, 0.0638, 0.0629, 0.0628, 0.0610, 0.0612, 0.0588,\n",
      "        0.0582, 0.0586, 0.0585, 0.0585, 0.0567], device='cuda:0')\n",
      "tensor([[-1.1604e-02],\n",
      "        [ 2.8440e-02],\n",
      "        [-1.7197e-02],\n",
      "        [ 6.1408e-02],\n",
      "        [ 2.2638e-03],\n",
      "        [ 2.4353e-04],\n",
      "        [ 4.1275e-02],\n",
      "        [ 4.5784e-03],\n",
      "        [ 1.9106e-02],\n",
      "        [ 9.2370e-02],\n",
      "        [ 8.1041e-02],\n",
      "        [ 1.5937e-02],\n",
      "        [ 4.5366e-02],\n",
      "        [ 1.9182e-02],\n",
      "        [ 6.8599e-02],\n",
      "        [ 1.2300e-01],\n",
      "        [ 2.0753e-02],\n",
      "        [ 3.2702e-02],\n",
      "        [ 4.2970e-02],\n",
      "        [ 2.5684e-02],\n",
      "        [ 6.1632e-02],\n",
      "        [ 1.7047e-02],\n",
      "        [ 3.2728e-02],\n",
      "        [ 7.1775e-02],\n",
      "        [-1.0462e-04],\n",
      "        [ 8.5350e-02],\n",
      "        [ 4.5870e-02],\n",
      "        [ 1.6761e-02],\n",
      "        [ 9.2510e-02],\n",
      "        [ 2.2676e-02],\n",
      "        [-5.7326e-03],\n",
      "        [ 3.5742e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0564, 0.0573, 0.0585, 0.0593, 0.0594, 0.0610, 0.0608, 0.0598, 0.0597,\n",
      "        0.0581, 0.0573, 0.0576, 0.0578, 0.0588, 0.0581, 0.0587, 0.0585, 0.0597,\n",
      "        0.0607, 0.0604, 0.0609, 0.0602, 0.0611, 0.0617, 0.0608, 0.0607, 0.0603,\n",
      "        0.0603, 0.0610, 0.0613, 0.0607, 0.0612], device='cuda:0')\n",
      "tensor([[ 0.0308],\n",
      "        [ 0.0411],\n",
      "        [ 0.0555],\n",
      "        [ 0.0166],\n",
      "        [ 0.0087],\n",
      "        [ 0.0303],\n",
      "        [ 0.0121],\n",
      "        [ 0.0231],\n",
      "        [ 0.0314],\n",
      "        [ 0.0254],\n",
      "        [-0.0095],\n",
      "        [ 0.0389],\n",
      "        [-0.0177],\n",
      "        [ 0.0524],\n",
      "        [-0.0064],\n",
      "        [ 0.0158],\n",
      "        [ 0.0459],\n",
      "        [ 0.1789],\n",
      "        [-0.0011],\n",
      "        [ 0.0943],\n",
      "        [ 0.0419],\n",
      "        [ 0.0327],\n",
      "        [ 0.0103],\n",
      "        [ 0.0327],\n",
      "        [ 0.0329],\n",
      "        [ 0.0583],\n",
      "        [ 0.0581],\n",
      "        [ 0.0423],\n",
      "        [ 0.0317],\n",
      "        [ 0.0246],\n",
      "        [ 0.0147],\n",
      "        [ 0.0355]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0609, 0.0607, 0.0604, 0.0604, 0.0601, 0.0596, 0.0590, 0.0592, 0.0605,\n",
      "        0.0605, 0.0609, 0.0626, 0.0629, 0.0624, 0.0635, 0.0631, 0.0624, 0.0613,\n",
      "        0.0616, 0.0616, 0.0610, 0.0608, 0.0601, 0.0601, 0.0606, 0.0606, 0.0613,\n",
      "        0.0620, 0.0626, 0.0613, 0.0616, 0.0610], device='cuda:0')\n",
      "tensor([[ 0.0198],\n",
      "        [ 0.0750],\n",
      "        [ 0.0306],\n",
      "        [ 0.0569],\n",
      "        [ 0.0500],\n",
      "        [ 0.1018],\n",
      "        [ 0.0377],\n",
      "        [ 0.0362],\n",
      "        [ 0.0191],\n",
      "        [ 0.0481],\n",
      "        [ 0.0661],\n",
      "        [ 0.0298],\n",
      "        [ 0.0367],\n",
      "        [ 0.0967],\n",
      "        [-0.0252],\n",
      "        [ 0.0900],\n",
      "        [ 0.0081],\n",
      "        [ 0.0073],\n",
      "        [-0.0068],\n",
      "        [ 0.0113],\n",
      "        [ 0.0182],\n",
      "        [ 0.0586],\n",
      "        [ 0.0448],\n",
      "        [ 0.0136],\n",
      "        [ 0.0100],\n",
      "        [ 0.0230],\n",
      "        [ 0.0475],\n",
      "        [ 0.0652],\n",
      "        [ 0.0543],\n",
      "        [ 0.0250],\n",
      "        [ 0.0226],\n",
      "        [ 0.0788]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0604, 0.0599, 0.0600, 0.0612, 0.0620, 0.0624, 0.0617, 0.0608, 0.0601,\n",
      "        0.0606, 0.0604, 0.0598, 0.0601, 0.0595, 0.0617, 0.0611, 0.0609, 0.0606,\n",
      "        0.0605, 0.0621, 0.0623, 0.0621, 0.0621, 0.0622, 0.0625, 0.0624, 0.0629,\n",
      "        0.0628, 0.0635, 0.0634, 0.0633, 0.0647], device='cuda:0')\n",
      "tensor([[ 0.0576],\n",
      "        [ 0.0884],\n",
      "        [ 0.0487],\n",
      "        [ 0.0366],\n",
      "        [ 0.0723],\n",
      "        [ 0.0625],\n",
      "        [ 0.0523],\n",
      "        [-0.0122],\n",
      "        [ 0.1216],\n",
      "        [ 0.0521],\n",
      "        [ 0.0309],\n",
      "        [ 0.0432],\n",
      "        [ 0.0341],\n",
      "        [ 0.0463],\n",
      "        [ 0.0376],\n",
      "        [ 0.0362],\n",
      "        [ 0.0540],\n",
      "        [-0.0297],\n",
      "        [ 0.0329],\n",
      "        [-0.0114],\n",
      "        [-0.0004],\n",
      "        [-0.0073],\n",
      "        [-0.0044],\n",
      "        [ 0.0576],\n",
      "        [-0.0334],\n",
      "        [ 0.0318],\n",
      "        [ 0.0264],\n",
      "        [ 0.0597],\n",
      "        [ 0.0490],\n",
      "        [ 0.0254],\n",
      "        [ 0.0058],\n",
      "        [-0.0464]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0643, 0.0646, 0.0649, 0.0646, 0.0644, 0.0644, 0.0643, 0.0650, 0.0641,\n",
      "        0.0634, 0.0626, 0.0632, 0.0636, 0.0624, 0.0624, 0.0628, 0.0621, 0.0618,\n",
      "        0.0621, 0.0624, 0.0624, 0.0630, 0.0615, 0.0610, 0.0612, 0.0610, 0.0608,\n",
      "        0.0604, 0.0587, 0.0569, 0.0570, 0.0573], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0367],\n",
      "        [ 0.0556],\n",
      "        [ 0.0237],\n",
      "        [ 0.1946],\n",
      "        [-0.0256],\n",
      "        [ 0.0888],\n",
      "        [ 0.0316],\n",
      "        [-0.0170],\n",
      "        [ 0.0719],\n",
      "        [ 0.0341],\n",
      "        [ 0.0691],\n",
      "        [ 0.0474],\n",
      "        [ 0.0247],\n",
      "        [ 0.0291],\n",
      "        [ 0.0684],\n",
      "        [ 0.0804],\n",
      "        [-0.0076],\n",
      "        [ 0.0324],\n",
      "        [ 0.0375],\n",
      "        [ 0.0248],\n",
      "        [ 0.0274],\n",
      "        [ 0.0177],\n",
      "        [ 0.0359],\n",
      "        [ 0.0312],\n",
      "        [ 0.0506],\n",
      "        [ 0.0542],\n",
      "        [-0.0004],\n",
      "        [ 0.0244],\n",
      "        [ 0.0325],\n",
      "        [ 0.1067],\n",
      "        [-0.0002],\n",
      "        [ 0.0576]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0579, 0.0574, 0.0571, 0.0575, 0.0579, 0.0583, 0.0576, 0.0564, 0.0561,\n",
      "        0.0561, 0.0553, 0.0552, 0.0555, 0.0555, 0.0561, 0.0557, 0.0552, 0.0545,\n",
      "        0.0532, 0.0538, 0.0537, 0.0542, 0.0531, 0.0532, 0.0539, 0.0535, 0.0548,\n",
      "        0.0547, 0.0554, 0.0554, 0.0549, 0.0550], device='cuda:0')\n",
      "tensor([[-0.0269],\n",
      "        [ 0.0458],\n",
      "        [ 0.0502],\n",
      "        [-0.0140],\n",
      "        [ 0.0856],\n",
      "        [ 0.0372],\n",
      "        [ 0.0432],\n",
      "        [ 0.0437],\n",
      "        [ 0.0315],\n",
      "        [ 0.0087],\n",
      "        [ 0.0419],\n",
      "        [ 0.0088],\n",
      "        [ 0.0483],\n",
      "        [ 0.0242],\n",
      "        [ 0.0755],\n",
      "        [ 0.0896],\n",
      "        [ 0.0372],\n",
      "        [ 0.0753],\n",
      "        [ 0.0515],\n",
      "        [ 0.1204],\n",
      "        [ 0.0303],\n",
      "        [ 0.1397],\n",
      "        [ 0.0940],\n",
      "        [ 0.0646],\n",
      "        [ 0.0722],\n",
      "        [-0.0222],\n",
      "        [ 0.0082],\n",
      "        [ 0.0607],\n",
      "        [ 0.1116],\n",
      "        [ 0.0826],\n",
      "        [-0.0214],\n",
      "        [ 0.0637]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0556, 0.0570, 0.0571, 0.0567, 0.0567, 0.0575, 0.0574, 0.0576, 0.0581,\n",
      "        0.0593, 0.0596, 0.0587, 0.0590, 0.0587, 0.0580, 0.0579, 0.0574, 0.0579,\n",
      "        0.0572, 0.0574, 0.0573, 0.0578, 0.0605, 0.0616, 0.0619, 0.0613, 0.0613,\n",
      "        0.0614, 0.0616, 0.0609, 0.0597, 0.0595], device='cuda:0')\n",
      "tensor([[ 0.0547],\n",
      "        [ 0.1347],\n",
      "        [-0.0185],\n",
      "        [ 0.0919],\n",
      "        [ 0.0550],\n",
      "        [ 0.0846],\n",
      "        [ 0.0103],\n",
      "        [ 0.0146],\n",
      "        [ 0.0231],\n",
      "        [ 0.0507],\n",
      "        [ 0.0134],\n",
      "        [-0.0102],\n",
      "        [ 0.0010],\n",
      "        [ 0.0223],\n",
      "        [ 0.0261],\n",
      "        [ 0.0248],\n",
      "        [ 0.0678],\n",
      "        [ 0.0395],\n",
      "        [ 0.0097],\n",
      "        [ 0.0368],\n",
      "        [ 0.0386],\n",
      "        [ 0.0375],\n",
      "        [ 0.0395],\n",
      "        [ 0.0470],\n",
      "        [-0.0128],\n",
      "        [ 0.0532],\n",
      "        [ 0.0212],\n",
      "        [-0.0030],\n",
      "        [ 0.0455],\n",
      "        [ 0.0398],\n",
      "        [ 0.0486],\n",
      "        [ 0.0186]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0599, 0.0604, 0.0602, 0.0604, 0.0601, 0.0594, 0.0587, 0.0591, 0.0599,\n",
      "        0.0593, 0.0593, 0.0602, 0.0598, 0.0601, 0.0600, 0.0602, 0.0608, 0.0605,\n",
      "        0.0598, 0.0596, 0.0597, 0.0603, 0.0594, 0.0600, 0.0596, 0.0600, 0.0600,\n",
      "        0.0598, 0.0591, 0.0583, 0.0583, 0.0583], device='cuda:0')\n",
      "tensor([[ 0.0051],\n",
      "        [ 0.0182],\n",
      "        [ 0.1216],\n",
      "        [ 0.0516],\n",
      "        [ 0.0667],\n",
      "        [ 0.0510],\n",
      "        [-0.0059],\n",
      "        [ 0.1052],\n",
      "        [ 0.0506],\n",
      "        [ 0.0530],\n",
      "        [ 0.0548],\n",
      "        [ 0.0240],\n",
      "        [ 0.0044],\n",
      "        [ 0.0272],\n",
      "        [ 0.0276],\n",
      "        [ 0.0295],\n",
      "        [ 0.0911],\n",
      "        [ 0.0307],\n",
      "        [ 0.0079],\n",
      "        [ 0.0263],\n",
      "        [ 0.0343],\n",
      "        [ 0.0361],\n",
      "        [ 0.0169],\n",
      "        [ 0.0540],\n",
      "        [ 0.0243],\n",
      "        [ 0.0294],\n",
      "        [ 0.0442],\n",
      "        [ 0.0161],\n",
      "        [ 0.0680],\n",
      "        [ 0.0777],\n",
      "        [ 0.0303],\n",
      "        [ 0.0609]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0584, 0.0583, 0.0573, 0.0562, 0.0572, 0.0564, 0.0568, 0.0566, 0.0573,\n",
      "        0.0570, 0.0573, 0.0576, 0.0578, 0.0582, 0.0572, 0.0567, 0.0569, 0.0567,\n",
      "        0.0569, 0.0564, 0.0561, 0.0567, 0.0569, 0.0571, 0.0567, 0.0563, 0.0568,\n",
      "        0.0571, 0.0571, 0.0567, 0.0576, 0.0576], device='cuda:0')\n",
      "tensor([[ 0.0413],\n",
      "        [ 0.0021],\n",
      "        [ 0.0036],\n",
      "        [ 0.0551],\n",
      "        [ 0.0397],\n",
      "        [ 0.0286],\n",
      "        [ 0.0423],\n",
      "        [ 0.0026],\n",
      "        [ 0.1093],\n",
      "        [ 0.0816],\n",
      "        [ 0.0139],\n",
      "        [-0.0040],\n",
      "        [ 0.0487],\n",
      "        [ 0.0584],\n",
      "        [ 0.0658],\n",
      "        [ 0.0619],\n",
      "        [ 0.0236],\n",
      "        [ 0.0584],\n",
      "        [ 0.0483],\n",
      "        [ 0.0181],\n",
      "        [ 0.0151],\n",
      "        [ 0.0267],\n",
      "        [ 0.0864],\n",
      "        [ 0.1021],\n",
      "        [ 0.0331],\n",
      "        [ 0.0675],\n",
      "        [ 0.0144],\n",
      "        [ 0.1013],\n",
      "        [ 0.0541],\n",
      "        [-0.0533],\n",
      "        [-0.0059],\n",
      "        [ 0.0599]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0571, 0.0567, 0.0562, 0.0544, 0.0545, 0.0554, 0.0551, 0.0548, 0.0553,\n",
      "        0.0573, 0.0575, 0.0570, 0.0578, 0.0569, 0.0569, 0.0576, 0.0576, 0.0593,\n",
      "        0.0600, 0.0601, 0.0595, 0.0583, 0.0587, 0.0584, 0.0588, 0.0584, 0.0576,\n",
      "        0.0578, 0.0582, 0.0588, 0.0584, 0.0587], device='cuda:0')\n",
      "tensor([[ 0.0246],\n",
      "        [ 0.0641],\n",
      "        [ 0.0230],\n",
      "        [-0.0051],\n",
      "        [ 0.0281],\n",
      "        [ 0.0475],\n",
      "        [ 0.0265],\n",
      "        [ 0.0069],\n",
      "        [ 0.0496],\n",
      "        [ 0.0042],\n",
      "        [-0.0105],\n",
      "        [ 0.0212],\n",
      "        [ 0.0323],\n",
      "        [ 0.0956],\n",
      "        [ 0.1398],\n",
      "        [ 0.0861],\n",
      "        [ 0.0409],\n",
      "        [ 0.0137],\n",
      "        [ 0.0334],\n",
      "        [ 0.0336],\n",
      "        [ 0.0512],\n",
      "        [-0.0233],\n",
      "        [ 0.0518],\n",
      "        [ 0.0137],\n",
      "        [ 0.0449],\n",
      "        [ 0.0240],\n",
      "        [ 0.0606],\n",
      "        [ 0.0313],\n",
      "        [ 0.0603],\n",
      "        [-0.0010],\n",
      "        [-0.0074],\n",
      "        [ 0.0258]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0593, 0.0589, 0.0586, 0.0584, 0.0587, 0.0593, 0.0597, 0.0605, 0.0605,\n",
      "        0.0607, 0.0612, 0.0615, 0.0601, 0.0607, 0.0595, 0.0595, 0.0601, 0.0595,\n",
      "        0.0593, 0.0594, 0.0593, 0.0597, 0.0601, 0.0602, 0.0597, 0.0593, 0.0591,\n",
      "        0.0593, 0.0592, 0.0587, 0.0590, 0.0595], device='cuda:0')\n",
      "tensor([[-3.5036e-02],\n",
      "        [ 4.2444e-02],\n",
      "        [-1.7111e-02],\n",
      "        [-1.5536e-04],\n",
      "        [ 9.3027e-02],\n",
      "        [ 1.4265e-02],\n",
      "        [ 5.0930e-02],\n",
      "        [ 7.0770e-02],\n",
      "        [ 4.8200e-03],\n",
      "        [ 4.0047e-02],\n",
      "        [ 4.3881e-02],\n",
      "        [ 4.5602e-02],\n",
      "        [ 1.2321e-02],\n",
      "        [ 1.1119e-02],\n",
      "        [ 2.8291e-02],\n",
      "        [ 5.0374e-02],\n",
      "        [ 4.3897e-02],\n",
      "        [ 2.9076e-02],\n",
      "        [-7.9919e-05],\n",
      "        [ 9.7837e-04],\n",
      "        [-1.4274e-02],\n",
      "        [ 6.0571e-02],\n",
      "        [ 7.0687e-02],\n",
      "        [ 4.9103e-02],\n",
      "        [-1.0014e-02],\n",
      "        [ 2.5125e-02],\n",
      "        [ 7.7777e-02],\n",
      "        [ 1.6225e-01],\n",
      "        [ 1.0410e-01],\n",
      "        [ 5.0383e-02],\n",
      "        [ 9.1670e-02],\n",
      "        [ 4.0262e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0591, 0.0591, 0.0584, 0.0571, 0.0570, 0.0577, 0.0575, 0.0574, 0.0569,\n",
      "        0.0570, 0.0567, 0.0567, 0.0563, 0.0561, 0.0561, 0.0559, 0.0563, 0.0565,\n",
      "        0.0556, 0.0549, 0.0550, 0.0542, 0.0531, 0.0518, 0.0530, 0.0534, 0.0528,\n",
      "        0.0524, 0.0513, 0.0522, 0.0516, 0.0525], device='cuda:0')\n",
      "tensor([[ 0.0330],\n",
      "        [ 0.0321],\n",
      "        [ 0.0405],\n",
      "        [ 0.0467],\n",
      "        [ 0.0284],\n",
      "        [ 0.0305],\n",
      "        [ 0.0334],\n",
      "        [-0.0126],\n",
      "        [ 0.0307],\n",
      "        [ 0.0577],\n",
      "        [ 0.0446],\n",
      "        [ 0.0185],\n",
      "        [ 0.0630],\n",
      "        [ 0.0379],\n",
      "        [ 0.0446],\n",
      "        [ 0.0921],\n",
      "        [ 0.0273],\n",
      "        [ 0.0132],\n",
      "        [ 0.0261],\n",
      "        [ 0.0177],\n",
      "        [ 0.0507],\n",
      "        [ 0.0155],\n",
      "        [ 0.0105],\n",
      "        [ 0.0463],\n",
      "        [ 0.0462],\n",
      "        [ 0.0916],\n",
      "        [ 0.0948],\n",
      "        [ 0.1711],\n",
      "        [ 0.0996],\n",
      "        [ 0.0630],\n",
      "        [ 0.0240],\n",
      "        [ 0.1067]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0527, 0.0518, 0.0514, 0.0514, 0.0515, 0.0511, 0.0515, 0.0511, 0.0510,\n",
      "        0.0502, 0.0505, 0.0510, 0.0520, 0.0518, 0.0518, 0.0519, 0.0515, 0.0505,\n",
      "        0.0514, 0.0526, 0.0549, 0.0549, 0.0554, 0.0556, 0.0557, 0.0569, 0.0580,\n",
      "        0.0582, 0.0579, 0.0593, 0.0595, 0.0593], device='cuda:0')\n",
      "tensor([[ 2.2118e-01],\n",
      "        [ 1.4245e-01],\n",
      "        [ 7.5294e-02],\n",
      "        [ 8.1265e-02],\n",
      "        [ 7.6281e-02],\n",
      "        [ 2.9512e-02],\n",
      "        [ 7.4982e-03],\n",
      "        [ 2.5184e-03],\n",
      "        [ 5.8675e-02],\n",
      "        [ 3.2654e-02],\n",
      "        [ 7.7382e-02],\n",
      "        [-3.7928e-03],\n",
      "        [ 2.8623e-02],\n",
      "        [ 2.2211e-02],\n",
      "        [ 9.9165e-02],\n",
      "        [ 6.0615e-02],\n",
      "        [ 5.3812e-02],\n",
      "        [ 3.4869e-02],\n",
      "        [ 2.2364e-02],\n",
      "        [-3.1549e-02],\n",
      "        [ 4.1701e-02],\n",
      "        [ 9.4367e-02],\n",
      "        [ 5.1894e-02],\n",
      "        [ 1.8579e-03],\n",
      "        [ 6.1384e-02],\n",
      "        [-2.4393e-02],\n",
      "        [ 5.2414e-02],\n",
      "        [ 7.0937e-05],\n",
      "        [ 4.7317e-02],\n",
      "        [ 7.6500e-02],\n",
      "        [ 9.8941e-02],\n",
      "        [ 5.5539e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0584, 0.0577, 0.0582, 0.0574, 0.0576, 0.0574, 0.0590, 0.0583, 0.0593,\n",
      "        0.0596, 0.0593, 0.0588, 0.0581, 0.0595, 0.0584, 0.0582, 0.0579, 0.0577,\n",
      "        0.0578, 0.0570, 0.0566, 0.0577, 0.0592, 0.0593, 0.0590, 0.0598, 0.0601,\n",
      "        0.0598, 0.0617, 0.0608, 0.0604, 0.0593], device='cuda:0')\n",
      "tensor([[0.0608],\n",
      "        [0.0419],\n",
      "        [0.1306],\n",
      "        [0.0378],\n",
      "        [0.0148],\n",
      "        [0.0104],\n",
      "        [0.0743],\n",
      "        [0.0511],\n",
      "        [0.0433],\n",
      "        [0.0453],\n",
      "        [0.0427],\n",
      "        [0.0466],\n",
      "        [0.0952],\n",
      "        [0.0754],\n",
      "        [0.0038],\n",
      "        [0.0507],\n",
      "        [0.0514],\n",
      "        [0.0466],\n",
      "        [0.0174],\n",
      "        [0.0310],\n",
      "        [0.0248],\n",
      "        [0.0244],\n",
      "        [0.0090],\n",
      "        [0.0863],\n",
      "        [0.0379],\n",
      "        [0.0778],\n",
      "        [0.0227],\n",
      "        [0.1169],\n",
      "        [0.0716],\n",
      "        [0.0772],\n",
      "        [0.1018],\n",
      "        [0.0834]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0602, 0.0592, 0.0598, 0.0594, 0.0582, 0.0570, 0.0577, 0.0580, 0.0574,\n",
      "        0.0567, 0.0565, 0.0569, 0.0570, 0.0576, 0.0575, 0.0571, 0.0570, 0.0573,\n",
      "        0.0597, 0.0593, 0.0588, 0.0604, 0.0599, 0.0605, 0.0607, 0.0613, 0.0615,\n",
      "        0.0623, 0.0630, 0.0637, 0.0631, 0.0672], device='cuda:0')\n",
      "tensor([[ 0.0783],\n",
      "        [-0.0006],\n",
      "        [ 0.0580],\n",
      "        [ 0.0402],\n",
      "        [ 0.1567],\n",
      "        [ 0.0659],\n",
      "        [ 0.0949],\n",
      "        [ 0.0669],\n",
      "        [ 0.1271],\n",
      "        [-0.0211],\n",
      "        [ 0.0252],\n",
      "        [ 0.0169],\n",
      "        [ 0.0061],\n",
      "        [ 0.0417],\n",
      "        [ 0.0481],\n",
      "        [ 0.0287],\n",
      "        [ 0.0366],\n",
      "        [-0.0044],\n",
      "        [ 0.0098],\n",
      "        [ 0.0448],\n",
      "        [ 0.0191],\n",
      "        [ 0.0006],\n",
      "        [ 0.0218],\n",
      "        [ 0.0278],\n",
      "        [ 0.0562],\n",
      "        [ 0.1358],\n",
      "        [ 0.0636],\n",
      "        [ 0.0179],\n",
      "        [ 0.0376],\n",
      "        [ 0.0538],\n",
      "        [ 0.0770],\n",
      "        [-0.0267]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0649, 0.0659, 0.0652, 0.0663, 0.0660, 0.0656, 0.0660, 0.0659, 0.0668,\n",
      "        0.0683, 0.0679, 0.0674, 0.0673, 0.0683, 0.0686, 0.0684, 0.0685, 0.0678,\n",
      "        0.0671, 0.0672, 0.0669, 0.0674, 0.0696, 0.0693, 0.0691, 0.0706, 0.0691,\n",
      "        0.0695, 0.0678, 0.0674, 0.0663, 0.0660], device='cuda:0')\n",
      "tensor([[-0.0069],\n",
      "        [-0.0670],\n",
      "        [ 0.0114],\n",
      "        [ 0.1038],\n",
      "        [ 0.0368],\n",
      "        [ 0.0804],\n",
      "        [ 0.0542],\n",
      "        [ 0.0220],\n",
      "        [ 0.0342],\n",
      "        [ 0.0640],\n",
      "        [ 0.0153],\n",
      "        [ 0.0009],\n",
      "        [-0.0063],\n",
      "        [ 0.0237],\n",
      "        [ 0.0171],\n",
      "        [ 0.0080],\n",
      "        [ 0.0070],\n",
      "        [ 0.0670],\n",
      "        [ 0.0582],\n",
      "        [ 0.0359],\n",
      "        [ 0.0357],\n",
      "        [ 0.1377],\n",
      "        [ 0.0177],\n",
      "        [ 0.0610],\n",
      "        [ 0.0322],\n",
      "        [ 0.0548],\n",
      "        [ 0.0558],\n",
      "        [ 0.0034],\n",
      "        [ 0.0338],\n",
      "        [ 0.0369],\n",
      "        [ 0.0108],\n",
      "        [ 0.0240]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0653, 0.0647, 0.0646, 0.0646, 0.0635, 0.0637, 0.0619, 0.0625, 0.0625,\n",
      "        0.0635, 0.0624, 0.0640, 0.0631, 0.0630, 0.0643, 0.0638, 0.0665, 0.0655,\n",
      "        0.0652, 0.0631, 0.0631, 0.0633, 0.0622, 0.0625, 0.0628, 0.0619, 0.0615,\n",
      "        0.0612, 0.0603, 0.0613, 0.0587, 0.0622], device='cuda:0')\n",
      "tensor([[ 1.2530e-02],\n",
      "        [ 2.2630e-02],\n",
      "        [ 4.9521e-02],\n",
      "        [ 8.3829e-03],\n",
      "        [ 1.4381e-02],\n",
      "        [ 4.1717e-02],\n",
      "        [ 3.6181e-02],\n",
      "        [ 5.2237e-02],\n",
      "        [ 3.4075e-02],\n",
      "        [ 3.4866e-03],\n",
      "        [ 6.3392e-02],\n",
      "        [ 3.4775e-02],\n",
      "        [ 7.9923e-02],\n",
      "        [ 8.4804e-02],\n",
      "        [ 1.3857e-01],\n",
      "        [-5.8978e-03],\n",
      "        [ 2.4291e-02],\n",
      "        [ 2.9501e-02],\n",
      "        [ 3.4352e-02],\n",
      "        [ 5.3293e-02],\n",
      "        [ 5.2992e-02],\n",
      "        [ 1.0886e-01],\n",
      "        [ 3.6997e-02],\n",
      "        [ 2.1925e-02],\n",
      "        [ 4.0839e-02],\n",
      "        [ 9.7057e-02],\n",
      "        [ 5.9654e-02],\n",
      "        [ 8.3472e-02],\n",
      "        [ 6.2781e-02],\n",
      "        [ 6.2421e-05],\n",
      "        [-2.5453e-02],\n",
      "        [ 5.1938e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0602, 0.0600, 0.0587, 0.0581, 0.0592, 0.0586, 0.0586, 0.0574, 0.0575,\n",
      "        0.0570, 0.0578, 0.0578, 0.0586, 0.0587, 0.0598, 0.0602, 0.0608, 0.0598,\n",
      "        0.0591, 0.0603, 0.0614, 0.0615, 0.0628, 0.0628, 0.0622, 0.0617, 0.0628,\n",
      "        0.0622, 0.0617, 0.0617, 0.0620, 0.0605], device='cuda:0')\n",
      "tensor([[ 0.1104],\n",
      "        [ 0.0245],\n",
      "        [ 0.0552],\n",
      "        [ 0.0057],\n",
      "        [ 0.0053],\n",
      "        [ 0.0241],\n",
      "        [ 0.0685],\n",
      "        [ 0.0532],\n",
      "        [ 0.0139],\n",
      "        [ 0.2222],\n",
      "        [ 0.0123],\n",
      "        [ 0.1111],\n",
      "        [ 0.0647],\n",
      "        [ 0.0858],\n",
      "        [-0.0075],\n",
      "        [ 0.0260],\n",
      "        [-0.0024],\n",
      "        [ 0.0291],\n",
      "        [ 0.0093],\n",
      "        [-0.0078],\n",
      "        [ 0.0275],\n",
      "        [ 0.0735],\n",
      "        [ 0.0592],\n",
      "        [ 0.0513],\n",
      "        [ 0.0582],\n",
      "        [ 0.0310],\n",
      "        [ 0.0911],\n",
      "        [ 0.0263],\n",
      "        [ 0.0485],\n",
      "        [ 0.0155],\n",
      "        [ 0.0149],\n",
      "        [ 0.0067]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0642, 0.0647, 0.0645, 0.0678, 0.0721, 0.0700, 0.0705, 0.0688, 0.0703,\n",
      "        0.0712, 0.0708, 0.0711, 0.0706, 0.0711, 0.0709, 0.0727, 0.0731, 0.0739,\n",
      "        0.0721, 0.0723, 0.0725, 0.0712, 0.0727, 0.0726, 0.0718, 0.0728, 0.0731,\n",
      "        0.0726, 0.0728, 0.0719, 0.0725, 0.0717], device='cuda:0')\n",
      "tensor([[ 0.0084],\n",
      "        [ 0.0315],\n",
      "        [ 0.0206],\n",
      "        [-0.0052],\n",
      "        [ 0.0524],\n",
      "        [ 0.0675],\n",
      "        [ 0.0096],\n",
      "        [ 0.1459],\n",
      "        [ 0.0984],\n",
      "        [ 0.1041],\n",
      "        [ 0.0417],\n",
      "        [ 0.0284],\n",
      "        [ 0.0160],\n",
      "        [ 0.0663],\n",
      "        [ 0.0599],\n",
      "        [ 0.0483],\n",
      "        [ 0.0289],\n",
      "        [ 0.0077],\n",
      "        [ 0.0564],\n",
      "        [ 0.0301],\n",
      "        [ 0.0794],\n",
      "        [ 0.0362],\n",
      "        [ 0.0290],\n",
      "        [ 0.0349],\n",
      "        [ 0.0116],\n",
      "        [ 0.0322],\n",
      "        [ 0.0654],\n",
      "        [ 0.0449],\n",
      "        [ 0.0341],\n",
      "        [ 0.0449],\n",
      "        [ 0.0695],\n",
      "        [ 0.0370]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0710, 0.0703, 0.0688, 0.0692, 0.0698, 0.0712, 0.0717, 0.0709, 0.0717,\n",
      "        0.0712, 0.0717, 0.0711, 0.0704, 0.0700, 0.0705, 0.0690, 0.0693, 0.0696,\n",
      "        0.0695, 0.0711, 0.0704, 0.0707, 0.0719, 0.0716, 0.0722, 0.0718, 0.0715,\n",
      "        0.0713, 0.0719, 0.0724, 0.0724, 0.0740], device='cuda:0')\n",
      "tensor([[ 2.7756e-02],\n",
      "        [ 2.4475e-03],\n",
      "        [ 1.4799e-02],\n",
      "        [ 3.1541e-02],\n",
      "        [ 5.8075e-02],\n",
      "        [ 8.4707e-02],\n",
      "        [ 1.1992e-01],\n",
      "        [ 4.5072e-02],\n",
      "        [ 5.5350e-02],\n",
      "        [ 5.4534e-02],\n",
      "        [ 7.6960e-02],\n",
      "        [ 3.6176e-02],\n",
      "        [ 3.7604e-02],\n",
      "        [-5.6150e-03],\n",
      "        [ 4.2221e-02],\n",
      "        [ 1.6996e-02],\n",
      "        [ 2.3497e-02],\n",
      "        [ 2.8998e-02],\n",
      "        [ 3.9961e-05],\n",
      "        [ 2.5294e-02],\n",
      "        [ 9.2548e-02],\n",
      "        [ 1.9863e-02],\n",
      "        [ 1.1194e-01],\n",
      "        [ 1.4394e-01],\n",
      "        [ 5.7200e-02],\n",
      "        [ 5.0690e-02],\n",
      "        [-9.5608e-03],\n",
      "        [-1.8006e-02],\n",
      "        [ 1.4339e-02],\n",
      "        [-1.6957e-02],\n",
      "        [ 5.9881e-03],\n",
      "        [ 4.8299e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0740, 0.0737, 0.0729, 0.0754, 0.0745, 0.0745, 0.0739, 0.0735, 0.0750,\n",
      "        0.0745, 0.0754, 0.0748, 0.0749, 0.0752, 0.0728, 0.0728, 0.0727, 0.0730,\n",
      "        0.0728, 0.0719, 0.0713, 0.0722, 0.0723, 0.0728, 0.0719, 0.0724, 0.0735,\n",
      "        0.0739, 0.0746, 0.0751, 0.0726, 0.0719], device='cuda:0')\n",
      "tensor([[ 0.0520],\n",
      "        [ 0.0937],\n",
      "        [ 0.1193],\n",
      "        [ 0.0261],\n",
      "        [ 0.1105],\n",
      "        [ 0.0168],\n",
      "        [ 0.0295],\n",
      "        [ 0.0423],\n",
      "        [ 0.0339],\n",
      "        [ 0.0205],\n",
      "        [ 0.0660],\n",
      "        [ 0.0228],\n",
      "        [ 0.0303],\n",
      "        [ 0.0241],\n",
      "        [ 0.0212],\n",
      "        [ 0.0342],\n",
      "        [ 0.0537],\n",
      "        [ 0.0417],\n",
      "        [-0.0065],\n",
      "        [-0.0025],\n",
      "        [-0.0078],\n",
      "        [ 0.0448],\n",
      "        [ 0.0520],\n",
      "        [ 0.0268],\n",
      "        [ 0.0170],\n",
      "        [ 0.1463],\n",
      "        [ 0.1747],\n",
      "        [ 0.0248],\n",
      "        [ 0.0816],\n",
      "        [ 0.0157],\n",
      "        [ 0.0243],\n",
      "        [ 0.0535]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0728, 0.0722, 0.0714, 0.0718, 0.0717, 0.0708, 0.0713, 0.0721, 0.0715,\n",
      "        0.0717, 0.0719, 0.0711, 0.0713, 0.0713, 0.0714, 0.0704, 0.0705, 0.0708,\n",
      "        0.0705, 0.0727, 0.0722, 0.0727, 0.0721, 0.0722, 0.0728, 0.0697, 0.0688,\n",
      "        0.0684, 0.0666, 0.0665, 0.0669, 0.0675], device='cuda:0')\n",
      "tensor([[ 0.0152],\n",
      "        [ 0.1966],\n",
      "        [-0.0348],\n",
      "        [ 0.0526],\n",
      "        [ 0.0247],\n",
      "        [ 0.0579],\n",
      "        [ 0.0990],\n",
      "        [ 0.0341],\n",
      "        [ 0.0149],\n",
      "        [ 0.0449],\n",
      "        [ 0.0533],\n",
      "        [ 0.0325],\n",
      "        [ 0.0324],\n",
      "        [ 0.0273],\n",
      "        [ 0.0386],\n",
      "        [ 0.0274],\n",
      "        [ 0.0355],\n",
      "        [ 0.0373],\n",
      "        [ 0.0657],\n",
      "        [ 0.0842],\n",
      "        [ 0.0904],\n",
      "        [ 0.0156],\n",
      "        [ 0.0480],\n",
      "        [ 0.0234],\n",
      "        [ 0.0438],\n",
      "        [ 0.0612],\n",
      "        [-0.0238],\n",
      "        [ 0.0509],\n",
      "        [ 0.0070],\n",
      "        [ 0.0124],\n",
      "        [ 0.0292],\n",
      "        [ 0.0583]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0683, 0.0680, 0.0666, 0.0675, 0.0680, 0.0674, 0.0662, 0.0662, 0.0659,\n",
      "        0.0677, 0.0675, 0.0660, 0.0653, 0.0635, 0.0634, 0.0640, 0.0625, 0.0628,\n",
      "        0.0628, 0.0631, 0.0624, 0.0621, 0.0628, 0.0616, 0.0616, 0.0624, 0.0631,\n",
      "        0.0634, 0.0629, 0.0621, 0.0625, 0.0643], device='cuda:0')\n",
      "tensor([[ 0.0306],\n",
      "        [-0.0171],\n",
      "        [ 0.0023],\n",
      "        [ 0.0251],\n",
      "        [ 0.1156],\n",
      "        [ 0.0223],\n",
      "        [ 0.0207],\n",
      "        [ 0.0244],\n",
      "        [ 0.0421],\n",
      "        [ 0.0402],\n",
      "        [ 0.0746],\n",
      "        [ 0.1120],\n",
      "        [ 0.0228],\n",
      "        [ 0.0193],\n",
      "        [ 0.0566],\n",
      "        [ 0.0244],\n",
      "        [ 0.0173],\n",
      "        [ 0.0899],\n",
      "        [ 0.0078],\n",
      "        [ 0.0460],\n",
      "        [ 0.0372],\n",
      "        [ 0.0251],\n",
      "        [ 0.0421],\n",
      "        [ 0.0280],\n",
      "        [ 0.0186],\n",
      "        [ 0.0481],\n",
      "        [ 0.0139],\n",
      "        [-0.0424],\n",
      "        [ 0.0906],\n",
      "        [ 0.1685],\n",
      "        [ 0.0078],\n",
      "        [ 0.0190]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0626, 0.0621, 0.0638, 0.0637, 0.0637, 0.0660, 0.0653, 0.0649, 0.0653,\n",
      "        0.0644, 0.0640, 0.0629, 0.0629, 0.0634, 0.0634, 0.0629, 0.0628, 0.0634,\n",
      "        0.0618, 0.0613, 0.0606, 0.0607, 0.0604, 0.0593, 0.0590, 0.0595, 0.0609,\n",
      "        0.0616, 0.0609, 0.0607, 0.0649, 0.0634], device='cuda:0')\n",
      "tensor([[ 0.0338],\n",
      "        [ 0.0006],\n",
      "        [ 0.0980],\n",
      "        [ 0.2557],\n",
      "        [ 0.1144],\n",
      "        [ 0.0244],\n",
      "        [ 0.1047],\n",
      "        [ 0.0227],\n",
      "        [ 0.0005],\n",
      "        [ 0.0651],\n",
      "        [ 0.0453],\n",
      "        [ 0.0256],\n",
      "        [ 0.0268],\n",
      "        [ 0.0264],\n",
      "        [ 0.0314],\n",
      "        [ 0.0263],\n",
      "        [ 0.0392],\n",
      "        [ 0.0538],\n",
      "        [ 0.0583],\n",
      "        [ 0.1317],\n",
      "        [-0.0070],\n",
      "        [ 0.0285],\n",
      "        [ 0.0449],\n",
      "        [ 0.0143],\n",
      "        [-0.0258],\n",
      "        [-0.0120],\n",
      "        [ 0.0642],\n",
      "        [ 0.0055],\n",
      "        [ 0.0118],\n",
      "        [ 0.0415],\n",
      "        [ 0.0144],\n",
      "        [ 0.0305]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0609, 0.0618, 0.0612, 0.0613, 0.0607, 0.0606, 0.0613, 0.0613, 0.0618,\n",
      "        0.0621, 0.0603, 0.0587, 0.0607, 0.0593, 0.0584, 0.0579, 0.0564, 0.0554,\n",
      "        0.0550, 0.0538, 0.0545, 0.0548, 0.0545, 0.0541, 0.0542, 0.0545, 0.0563,\n",
      "        0.0544, 0.0557, 0.0554, 0.0553, 0.0548], device='cuda:0')\n",
      "tensor([[ 0.0625],\n",
      "        [ 0.0106],\n",
      "        [-0.0033],\n",
      "        [-0.0038],\n",
      "        [ 0.0674],\n",
      "        [ 0.1000],\n",
      "        [ 0.0564],\n",
      "        [-0.0096],\n",
      "        [ 0.0501],\n",
      "        [ 0.0034],\n",
      "        [ 0.0357],\n",
      "        [ 0.0073],\n",
      "        [ 0.0357],\n",
      "        [ 0.0476],\n",
      "        [ 0.0029],\n",
      "        [ 0.0729],\n",
      "        [-0.0065],\n",
      "        [ 0.0290],\n",
      "        [ 0.0428],\n",
      "        [ 0.1273],\n",
      "        [-0.0462],\n",
      "        [ 0.0393],\n",
      "        [ 0.0687],\n",
      "        [-0.0047],\n",
      "        [ 0.0406],\n",
      "        [ 0.0412],\n",
      "        [ 0.0686],\n",
      "        [ 0.0278],\n",
      "        [ 0.0064],\n",
      "        [ 0.0707],\n",
      "        [ 0.0955],\n",
      "        [-0.0380]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0533, 0.0538, 0.0536, 0.0550, 0.0542, 0.0545, 0.0545, 0.0539, 0.0538,\n",
      "        0.0535, 0.0535, 0.0539, 0.0570, 0.0569, 0.0584, 0.0584, 0.0578, 0.0575,\n",
      "        0.0579, 0.0584, 0.0601, 0.0594, 0.0591, 0.0582, 0.0578, 0.0575, 0.0587,\n",
      "        0.0579, 0.0563, 0.0567, 0.0576, 0.0563], device='cuda:0')\n",
      "tensor([[ 0.0796],\n",
      "        [ 0.0428],\n",
      "        [ 0.0121],\n",
      "        [ 0.0137],\n",
      "        [ 0.1005],\n",
      "        [-0.0166],\n",
      "        [ 0.0382],\n",
      "        [ 0.0320],\n",
      "        [ 0.0507],\n",
      "        [ 0.0238],\n",
      "        [-0.0352],\n",
      "        [-0.0120],\n",
      "        [ 0.0905],\n",
      "        [ 0.0440],\n",
      "        [ 0.0890],\n",
      "        [ 0.0707],\n",
      "        [ 0.0223],\n",
      "        [ 0.0672],\n",
      "        [ 0.0548],\n",
      "        [ 0.0573],\n",
      "        [ 0.1665],\n",
      "        [ 0.0450],\n",
      "        [ 0.1088],\n",
      "        [ 0.0510],\n",
      "        [-0.0192],\n",
      "        [ 0.0561],\n",
      "        [ 0.0151],\n",
      "        [ 0.0083],\n",
      "        [ 0.0904],\n",
      "        [ 0.0489],\n",
      "        [ 0.0497],\n",
      "        [ 0.0555]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0573, 0.0573, 0.0572, 0.0566, 0.0567, 0.0545, 0.0557, 0.0556, 0.0553,\n",
      "        0.0603, 0.0579, 0.0604, 0.0598, 0.0597, 0.0635, 0.0634, 0.0625, 0.0629,\n",
      "        0.0622, 0.0622, 0.0649, 0.0641, 0.0635, 0.0646, 0.0638, 0.0638, 0.0618,\n",
      "        0.0626, 0.0624, 0.0629, 0.0615, 0.0600], device='cuda:0')\n",
      "tensor([[ 0.0764],\n",
      "        [ 0.0163],\n",
      "        [ 0.0881],\n",
      "        [ 0.0192],\n",
      "        [ 0.0194],\n",
      "        [ 0.0476],\n",
      "        [ 0.0496],\n",
      "        [ 0.0517],\n",
      "        [ 0.2010],\n",
      "        [ 0.0718],\n",
      "        [ 0.0664],\n",
      "        [ 0.0665],\n",
      "        [ 0.0189],\n",
      "        [ 0.0659],\n",
      "        [ 0.0428],\n",
      "        [ 0.0363],\n",
      "        [ 0.0218],\n",
      "        [-0.0495],\n",
      "        [ 0.0151],\n",
      "        [ 0.0371],\n",
      "        [ 0.0345],\n",
      "        [ 0.0119],\n",
      "        [ 0.0081],\n",
      "        [ 0.0730],\n",
      "        [ 0.0077],\n",
      "        [ 0.0364],\n",
      "        [ 0.0172],\n",
      "        [-0.0155],\n",
      "        [ 0.0433],\n",
      "        [-0.0024],\n",
      "        [ 0.0045],\n",
      "        [ 0.0176]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0601, 0.0595, 0.0621, 0.0626, 0.0612, 0.0606, 0.0598, 0.0601, 0.0590,\n",
      "        0.0587, 0.0576, 0.0575, 0.0539, 0.0556, 0.0557, 0.0548, 0.0554, 0.0539,\n",
      "        0.0529, 0.0528, 0.0535, 0.0542, 0.0532, 0.0517, 0.0514, 0.0505, 0.0511,\n",
      "        0.0502, 0.0495, 0.0477, 0.0446, 0.0454], device='cuda:0')\n",
      "tensor([[-0.0053],\n",
      "        [ 0.0387],\n",
      "        [ 0.0878],\n",
      "        [ 0.0583],\n",
      "        [ 0.0959],\n",
      "        [ 0.0922],\n",
      "        [ 0.0330],\n",
      "        [-0.0070],\n",
      "        [ 0.0185],\n",
      "        [ 0.0207],\n",
      "        [ 0.0340],\n",
      "        [ 0.0157],\n",
      "        [ 0.0102],\n",
      "        [ 0.0158],\n",
      "        [ 0.0201],\n",
      "        [ 0.0186],\n",
      "        [ 0.0016],\n",
      "        [ 0.0395],\n",
      "        [ 0.0779],\n",
      "        [ 0.0440],\n",
      "        [ 0.0407],\n",
      "        [ 0.0743],\n",
      "        [ 0.0323],\n",
      "        [ 0.1112],\n",
      "        [ 0.0007],\n",
      "        [ 0.0981],\n",
      "        [ 0.0213],\n",
      "        [ 0.0281],\n",
      "        [ 0.0554],\n",
      "        [-0.0005],\n",
      "        [ 0.0844],\n",
      "        [ 0.0447]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0433, 0.0486, 0.0467, 0.0466, 0.0455, 0.0463, 0.0455, 0.0438, 0.0439,\n",
      "        0.0452, 0.0448, 0.0439, 0.0433, 0.0421, 0.0411, 0.0412, 0.0412, 0.0412,\n",
      "        0.0443, 0.0439, 0.0442, 0.0461, 0.0451, 0.0455, 0.0455, 0.0449, 0.0445,\n",
      "        0.0461, 0.0455, 0.0458, 0.0443, 0.0423], device='cuda:0')\n",
      "tensor([[ 0.0231],\n",
      "        [ 0.0320],\n",
      "        [ 0.0094],\n",
      "        [-0.0011],\n",
      "        [-0.0236],\n",
      "        [ 0.0714],\n",
      "        [ 0.0150],\n",
      "        [-0.0050],\n",
      "        [ 0.0060],\n",
      "        [-0.0392],\n",
      "        [-0.0093],\n",
      "        [ 0.0591],\n",
      "        [ 0.0486],\n",
      "        [ 0.0326],\n",
      "        [ 0.0014],\n",
      "        [ 0.0521],\n",
      "        [ 0.1115],\n",
      "        [ 0.0139],\n",
      "        [ 0.0296],\n",
      "        [ 0.0479],\n",
      "        [ 0.0095],\n",
      "        [ 0.1500],\n",
      "        [ 0.0564],\n",
      "        [ 0.0253],\n",
      "        [ 0.0188],\n",
      "        [ 0.0249],\n",
      "        [ 0.0175],\n",
      "        [ 0.0582],\n",
      "        [ 0.0273],\n",
      "        [ 0.1120],\n",
      "        [ 0.0219],\n",
      "        [ 0.0519]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0424, 0.0436, 0.0433, 0.0427, 0.0433, 0.0438, 0.0430, 0.0432, 0.0442,\n",
      "        0.0454, 0.0460, 0.0473, 0.0449, 0.0461, 0.0469, 0.0473, 0.0494, 0.0480,\n",
      "        0.0482, 0.0477, 0.0486, 0.0492, 0.0492, 0.0502, 0.0520, 0.0502, 0.0511,\n",
      "        0.0491, 0.0491, 0.0502, 0.0508, 0.0513], device='cuda:0')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[ 0.0695],\n",
      "        [ 0.0732],\n",
      "        [-0.0193],\n",
      "        [ 0.0055],\n",
      "        [ 0.0239],\n",
      "        [ 0.0216],\n",
      "        [ 0.0278],\n",
      "        [ 0.0207],\n",
      "        [ 0.0192],\n",
      "        [ 0.0240],\n",
      "        [ 0.0502],\n",
      "        [ 0.0453],\n",
      "        [ 0.0328],\n",
      "        [ 0.0094],\n",
      "        [ 0.0307],\n",
      "        [ 0.0826],\n",
      "        [ 0.0785],\n",
      "        [ 0.0264],\n",
      "        [ 0.0060],\n",
      "        [ 0.0362],\n",
      "        [ 0.0658],\n",
      "        [ 0.0843],\n",
      "        [-0.0010],\n",
      "        [ 0.0456],\n",
      "        [ 0.0273],\n",
      "        [ 0.0198],\n",
      "        [ 0.0842],\n",
      "        [ 0.0161],\n",
      "        [-0.0042],\n",
      "        [ 0.0207],\n",
      "        [ 0.0592],\n",
      "        [ 0.0672]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0507, 0.0513, 0.0501, 0.0510, 0.0523, 0.0529, 0.0539, 0.0536, 0.0533,\n",
      "        0.0535, 0.0548, 0.0575, 0.0560, 0.0566, 0.0582, 0.0576, 0.0587, 0.0576,\n",
      "        0.0573, 0.0572, 0.0567, 0.0575, 0.0576, 0.0581, 0.0578, 0.0576, 0.0572,\n",
      "        0.0566, 0.0582, 0.0584, 0.0578, 0.0595], device='cuda:0')\n",
      "tensor([[ 0.0653],\n",
      "        [ 0.0348],\n",
      "        [ 0.0782],\n",
      "        [ 0.0546],\n",
      "        [ 0.1191],\n",
      "        [ 0.0665],\n",
      "        [ 0.0032],\n",
      "        [ 0.0927],\n",
      "        [ 0.0981],\n",
      "        [ 0.0361],\n",
      "        [ 0.0503],\n",
      "        [ 0.0477],\n",
      "        [-0.0480],\n",
      "        [-0.0031],\n",
      "        [ 0.0354],\n",
      "        [ 0.0366],\n",
      "        [ 0.0681],\n",
      "        [ 0.0686],\n",
      "        [ 0.1141],\n",
      "        [ 0.0351],\n",
      "        [ 0.0453],\n",
      "        [ 0.0212],\n",
      "        [ 0.0150],\n",
      "        [-0.0206],\n",
      "        [ 0.0128],\n",
      "        [ 0.0910],\n",
      "        [ 0.0008],\n",
      "        [ 0.0080],\n",
      "        [-0.0227],\n",
      "        [ 0.0476],\n",
      "        [ 0.0270],\n",
      "        [ 0.0425]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0595, 0.0595, 0.0621, 0.0619, 0.0591, 0.0587, 0.0597, 0.0604, 0.0603,\n",
      "        0.0600, 0.0595, 0.0585, 0.0575, 0.0581, 0.0588, 0.0604, 0.0594, 0.0593,\n",
      "        0.0566, 0.0588, 0.0584, 0.0591, 0.0585, 0.0588, 0.0582, 0.0601, 0.0593,\n",
      "        0.0598, 0.0612, 0.0597, 0.0604, 0.0588], device='cuda:0')\n",
      "tensor([[0.0310],\n",
      "        [0.0457],\n",
      "        [0.0478],\n",
      "        [0.0500],\n",
      "        [0.0352],\n",
      "        [0.0931],\n",
      "        [0.0752],\n",
      "        [0.0318],\n",
      "        [0.1000],\n",
      "        [0.0084],\n",
      "        [0.0177],\n",
      "        [0.1034],\n",
      "        [0.0687],\n",
      "        [0.1770],\n",
      "        [0.0333],\n",
      "        [0.0220],\n",
      "        [0.0813],\n",
      "        [0.0262],\n",
      "        [0.0474],\n",
      "        [0.0500],\n",
      "        [0.0581],\n",
      "        [0.0696],\n",
      "        [0.0383],\n",
      "        [0.0853],\n",
      "        [0.1299],\n",
      "        [0.0598],\n",
      "        [0.0674],\n",
      "        [0.0293],\n",
      "        [0.0218],\n",
      "        [0.0649],\n",
      "        [0.0114],\n",
      "        [0.0314]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0570, 0.0560, 0.0564, 0.0570, 0.0579, 0.0590, 0.0610, 0.0607, 0.0634,\n",
      "        0.0635, 0.0625, 0.0640, 0.0631, 0.0638, 0.0618, 0.0610, 0.0616, 0.0610,\n",
      "        0.0607, 0.0585, 0.0594, 0.0588, 0.0594, 0.0581, 0.0576, 0.0594, 0.0604,\n",
      "        0.0616, 0.0593, 0.0600, 0.0601, 0.0600], device='cuda:0')\n",
      "tensor([[ 0.0192],\n",
      "        [ 0.0526],\n",
      "        [ 0.0277],\n",
      "        [ 0.0319],\n",
      "        [-0.0021],\n",
      "        [ 0.1397],\n",
      "        [ 0.1051],\n",
      "        [ 0.0416],\n",
      "        [ 0.1069],\n",
      "        [ 0.1739],\n",
      "        [ 0.0362],\n",
      "        [ 0.0245],\n",
      "        [ 0.0037],\n",
      "        [-0.0150],\n",
      "        [ 0.1059],\n",
      "        [ 0.1161],\n",
      "        [ 0.0958],\n",
      "        [-0.0590],\n",
      "        [ 0.0222],\n",
      "        [ 0.0304],\n",
      "        [-0.0061],\n",
      "        [ 0.0548],\n",
      "        [ 0.0296],\n",
      "        [ 0.0666],\n",
      "        [-0.0125],\n",
      "        [ 0.0402],\n",
      "        [ 0.0140],\n",
      "        [ 0.0337],\n",
      "        [ 0.0073],\n",
      "        [ 0.0539],\n",
      "        [ 0.0586],\n",
      "        [ 0.0156]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0644, 0.0649, 0.0653, 0.0653, 0.0657, 0.0650, 0.0657, 0.0638, 0.0638,\n",
      "        0.0628, 0.0619, 0.0612, 0.0593, 0.0609, 0.0610, 0.0615, 0.0604, 0.0591,\n",
      "        0.0588, 0.0560, 0.0569, 0.0584, 0.0569, 0.0590, 0.0578, 0.0559, 0.0570,\n",
      "        0.0600, 0.0601, 0.0616, 0.0622, 0.0610], device='cuda:0')\n",
      "tensor([[ 0.0632],\n",
      "        [ 0.0578],\n",
      "        [ 0.0116],\n",
      "        [ 0.1700],\n",
      "        [ 0.0270],\n",
      "        [ 0.0865],\n",
      "        [ 0.0342],\n",
      "        [ 0.0523],\n",
      "        [ 0.0998],\n",
      "        [ 0.1177],\n",
      "        [ 0.0498],\n",
      "        [ 0.0180],\n",
      "        [ 0.0547],\n",
      "        [-0.0265],\n",
      "        [-0.0037],\n",
      "        [ 0.0228],\n",
      "        [ 0.0146],\n",
      "        [ 0.0261],\n",
      "        [ 0.0080],\n",
      "        [ 0.0583],\n",
      "        [ 0.0427],\n",
      "        [ 0.0297],\n",
      "        [-0.0151],\n",
      "        [ 0.0746],\n",
      "        [ 0.0446],\n",
      "        [ 0.0399],\n",
      "        [ 0.0108],\n",
      "        [-0.0119],\n",
      "        [ 0.0796],\n",
      "        [ 0.0197],\n",
      "        [ 0.0021],\n",
      "        [ 0.0477]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0618, 0.0609, 0.0624, 0.0637, 0.0652, 0.0628, 0.0606, 0.0603, 0.0595,\n",
      "        0.0593, 0.0595, 0.0584, 0.0597, 0.0594, 0.0575, 0.0576, 0.0578, 0.0575,\n",
      "        0.0575, 0.0581, 0.0570, 0.0573, 0.0567, 0.0556, 0.0566, 0.0569, 0.0563,\n",
      "        0.0566, 0.0557, 0.0551, 0.0547, 0.0536], device='cuda:0')\n",
      "tensor([[ 0.0239],\n",
      "        [ 0.0329],\n",
      "        [-0.0369],\n",
      "        [ 0.0480],\n",
      "        [ 0.0539],\n",
      "        [ 0.0325],\n",
      "        [ 0.0096],\n",
      "        [ 0.0392],\n",
      "        [ 0.0169],\n",
      "        [ 0.0534],\n",
      "        [ 0.0044],\n",
      "        [ 0.0075],\n",
      "        [ 0.0965],\n",
      "        [ 0.1104],\n",
      "        [ 0.0615],\n",
      "        [ 0.0238],\n",
      "        [ 0.0229],\n",
      "        [-0.0072],\n",
      "        [ 0.0886],\n",
      "        [ 0.0475],\n",
      "        [ 0.0139],\n",
      "        [ 0.0233],\n",
      "        [ 0.0266],\n",
      "        [ 0.0592],\n",
      "        [ 0.0467],\n",
      "        [ 0.0635],\n",
      "        [ 0.0598],\n",
      "        [ 0.1253],\n",
      "        [ 0.0141],\n",
      "        [ 0.0490],\n",
      "        [ 0.0540],\n",
      "        [ 0.0503]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0536, 0.0539, 0.0539, 0.0531, 0.0522, 0.0539, 0.0541, 0.0566, 0.0572,\n",
      "        0.0566, 0.0559, 0.0545, 0.0538, 0.0539, 0.0538, 0.0551, 0.0545, 0.0542,\n",
      "        0.0563, 0.0554, 0.0570, 0.0566, 0.0572, 0.0560, 0.0553, 0.0550, 0.0542,\n",
      "        0.0562, 0.0553, 0.0536, 0.0533, 0.0544], device='cuda:0')\n",
      "tensor([[ 0.0419],\n",
      "        [ 0.0475],\n",
      "        [ 0.0039],\n",
      "        [-0.0083],\n",
      "        [ 0.0292],\n",
      "        [ 0.0898],\n",
      "        [ 0.0120],\n",
      "        [ 0.0319],\n",
      "        [ 0.0109],\n",
      "        [ 0.0250],\n",
      "        [ 0.0151],\n",
      "        [ 0.0585],\n",
      "        [ 0.1005],\n",
      "        [ 0.0675],\n",
      "        [ 0.0041],\n",
      "        [ 0.0296],\n",
      "        [ 0.0426],\n",
      "        [ 0.1022],\n",
      "        [ 0.0955],\n",
      "        [ 0.0502],\n",
      "        [ 0.0141],\n",
      "        [ 0.0640],\n",
      "        [-0.0251],\n",
      "        [ 0.0798],\n",
      "        [ 0.0192],\n",
      "        [ 0.0785],\n",
      "        [ 0.0592],\n",
      "        [ 0.0511],\n",
      "        [ 0.0404],\n",
      "        [ 0.0738],\n",
      "        [ 0.0524],\n",
      "        [ 0.0350]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0551, 0.0541, 0.0529, 0.0520, 0.0516, 0.0516, 0.0536, 0.0525, 0.0517,\n",
      "        0.0505, 0.0511, 0.0516, 0.0535, 0.0522, 0.0520, 0.0520, 0.0523, 0.0529,\n",
      "        0.0520, 0.0511, 0.0500, 0.0505, 0.0497, 0.0489, 0.0491, 0.0485, 0.0491,\n",
      "        0.0469, 0.0477, 0.0477, 0.0476, 0.0473], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0496],\n",
      "        [ 0.0736],\n",
      "        [ 0.0652],\n",
      "        [ 0.0660],\n",
      "        [ 0.0322],\n",
      "        [ 0.0423],\n",
      "        [ 0.0060],\n",
      "        [-0.0119],\n",
      "        [ 0.0236],\n",
      "        [-0.0111],\n",
      "        [ 0.0110],\n",
      "        [ 0.0493],\n",
      "        [ 0.0726],\n",
      "        [ 0.0673],\n",
      "        [ 0.2765],\n",
      "        [ 0.1035],\n",
      "        [ 0.0849],\n",
      "        [ 0.0400],\n",
      "        [ 0.0106],\n",
      "        [ 0.0107],\n",
      "        [ 0.0465],\n",
      "        [ 0.0325],\n",
      "        [ 0.0097],\n",
      "        [ 0.0267],\n",
      "        [ 0.0289],\n",
      "        [ 0.0738],\n",
      "        [ 0.0389],\n",
      "        [ 0.0647],\n",
      "        [ 0.0847],\n",
      "        [-0.0070],\n",
      "        [ 0.0310],\n",
      "        [ 0.0817]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0477, 0.0476, 0.0473, 0.0464, 0.0463, 0.0470, 0.0491, 0.0492, 0.0501,\n",
      "        0.0519, 0.0514, 0.0505, 0.0492, 0.0497, 0.0495, 0.0485, 0.0491, 0.0504,\n",
      "        0.0508, 0.0514, 0.0502, 0.0498, 0.0488, 0.0486, 0.0494, 0.0508, 0.0510,\n",
      "        0.0504, 0.0501, 0.0491, 0.0491, 0.0479], device='cuda:0')\n",
      "tensor([[ 0.0542],\n",
      "        [ 0.0340],\n",
      "        [ 0.0133],\n",
      "        [ 0.0527],\n",
      "        [-0.0541],\n",
      "        [ 0.0610],\n",
      "        [ 0.0326],\n",
      "        [ 0.0228],\n",
      "        [ 0.0935],\n",
      "        [ 0.0040],\n",
      "        [ 0.0198],\n",
      "        [ 0.0469],\n",
      "        [ 0.0431],\n",
      "        [ 0.0438],\n",
      "        [ 0.0402],\n",
      "        [ 0.0127],\n",
      "        [-0.0118],\n",
      "        [-0.0068],\n",
      "        [ 0.0754],\n",
      "        [ 0.0491],\n",
      "        [ 0.0772],\n",
      "        [ 0.0186],\n",
      "        [-0.0063],\n",
      "        [ 0.0269],\n",
      "        [ 0.1065],\n",
      "        [ 0.0551],\n",
      "        [ 0.0641],\n",
      "        [ 0.1446],\n",
      "        [ 0.1204],\n",
      "        [ 0.0342],\n",
      "        [ 0.0274],\n",
      "        [ 0.0317]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0479, 0.0480, 0.0480, 0.0476, 0.0476, 0.0473, 0.0467, 0.0479, 0.0476,\n",
      "        0.0476, 0.0470, 0.0461, 0.0463, 0.0458, 0.0455, 0.0457, 0.0464, 0.0461,\n",
      "        0.0461, 0.0473, 0.0470, 0.0474, 0.0495, 0.0497, 0.0479, 0.0480, 0.0491,\n",
      "        0.0501, 0.0491, 0.0495, 0.0492, 0.0477], device='cuda:0')\n",
      "tensor([[-0.0038],\n",
      "        [-0.0258],\n",
      "        [ 0.0656],\n",
      "        [ 0.0909],\n",
      "        [ 0.0624],\n",
      "        [ 0.0446],\n",
      "        [ 0.0443],\n",
      "        [ 0.0514],\n",
      "        [ 0.0177],\n",
      "        [ 0.0512],\n",
      "        [ 0.0362],\n",
      "        [ 0.0324],\n",
      "        [ 0.1396],\n",
      "        [ 0.0355],\n",
      "        [ 0.0783],\n",
      "        [ 0.0404],\n",
      "        [ 0.0091],\n",
      "        [-0.0023],\n",
      "        [ 0.0529],\n",
      "        [ 0.0724],\n",
      "        [ 0.0878],\n",
      "        [-0.0109],\n",
      "        [ 0.0855],\n",
      "        [ 0.0530],\n",
      "        [ 0.0980],\n",
      "        [ 0.0284],\n",
      "        [ 0.0631],\n",
      "        [ 0.0354],\n",
      "        [ 0.0464],\n",
      "        [ 0.0413],\n",
      "        [ 0.0302],\n",
      "        [ 0.0498]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0476, 0.0480, 0.0483, 0.0479, 0.0467, 0.0467, 0.0463, 0.0460, 0.0467,\n",
      "        0.0458, 0.0469, 0.0466, 0.0452, 0.0445, 0.0445, 0.0446, 0.0454, 0.0466,\n",
      "        0.0467, 0.0463, 0.0455, 0.0446, 0.0445, 0.0455, 0.0449, 0.0451, 0.0452,\n",
      "        0.0440, 0.0455, 0.0436, 0.0446, 0.0445], device='cuda:0')\n",
      "tensor([[ 0.0036],\n",
      "        [ 0.0591],\n",
      "        [ 0.0049],\n",
      "        [ 0.0180],\n",
      "        [ 0.0196],\n",
      "        [ 0.0193],\n",
      "        [ 0.0444],\n",
      "        [ 0.0299],\n",
      "        [ 0.0498],\n",
      "        [ 0.0409],\n",
      "        [ 0.0730],\n",
      "        [ 0.0337],\n",
      "        [ 0.0641],\n",
      "        [ 0.0948],\n",
      "        [ 0.1038],\n",
      "        [ 0.1049],\n",
      "        [ 0.0592],\n",
      "        [ 0.0547],\n",
      "        [ 0.0170],\n",
      "        [ 0.0489],\n",
      "        [-0.0064],\n",
      "        [-0.0253],\n",
      "        [ 0.0185],\n",
      "        [ 0.0912],\n",
      "        [ 0.1127],\n",
      "        [ 0.0608],\n",
      "        [ 0.1351],\n",
      "        [ 0.1055],\n",
      "        [ 0.1583],\n",
      "        [ 0.0103],\n",
      "        [ 0.0412],\n",
      "        [-0.0004]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0457, 0.0458, 0.0448, 0.0457, 0.0463, 0.0467, 0.0463, 0.0442, 0.0427,\n",
      "        0.0424, 0.0412, 0.0412, 0.0417, 0.0414, 0.0411, 0.0410, 0.0405, 0.0407,\n",
      "        0.0392, 0.0386, 0.0415, 0.0433, 0.0433, 0.0426, 0.0415, 0.0408, 0.0417,\n",
      "        0.0424, 0.0427, 0.0430, 0.0417, 0.0410], device='cuda:0')\n",
      "tensor([[ 0.0346],\n",
      "        [ 0.0122],\n",
      "        [ 0.0465],\n",
      "        [-0.0120],\n",
      "        [ 0.0705],\n",
      "        [ 0.0377],\n",
      "        [ 0.0049],\n",
      "        [ 0.0021],\n",
      "        [-0.0216],\n",
      "        [ 0.1099],\n",
      "        [ 0.0569],\n",
      "        [ 0.0094],\n",
      "        [ 0.1711],\n",
      "        [ 0.1509],\n",
      "        [ 0.1510],\n",
      "        [ 0.0196],\n",
      "        [ 0.0130],\n",
      "        [-0.0063],\n",
      "        [-0.0011],\n",
      "        [ 0.0057],\n",
      "        [ 0.0006],\n",
      "        [ 0.0395],\n",
      "        [ 0.0421],\n",
      "        [ 0.0318],\n",
      "        [ 0.0321],\n",
      "        [ 0.0325],\n",
      "        [ 0.0170],\n",
      "        [ 0.0160],\n",
      "        [ 0.0799],\n",
      "        [ 0.0999],\n",
      "        [ 0.0757],\n",
      "        [ 0.0121]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0410, 0.0402, 0.0402, 0.0405, 0.0404, 0.0424, 0.0429, 0.0451, 0.0451,\n",
      "        0.0446, 0.0433, 0.0445, 0.0452, 0.0439, 0.0436, 0.0443, 0.0452, 0.0449,\n",
      "        0.0438, 0.0440, 0.0446, 0.0466, 0.0477, 0.0473, 0.0479, 0.0470, 0.0480,\n",
      "        0.0474, 0.0469, 0.0483, 0.0479, 0.0495], device='cuda:0')\n",
      "tensor([[ 0.0091],\n",
      "        [ 0.0768],\n",
      "        [ 0.0180],\n",
      "        [-0.0228],\n",
      "        [ 0.0478],\n",
      "        [ 0.0354],\n",
      "        [ 0.0252],\n",
      "        [ 0.0415],\n",
      "        [ 0.0248],\n",
      "        [ 0.0728],\n",
      "        [ 0.0457],\n",
      "        [-0.0007],\n",
      "        [ 0.0150],\n",
      "        [ 0.0712],\n",
      "        [ 0.0216],\n",
      "        [ 0.0909],\n",
      "        [ 0.1331],\n",
      "        [ 0.1031],\n",
      "        [ 0.0583],\n",
      "        [ 0.0309],\n",
      "        [ 0.0129],\n",
      "        [ 0.0141],\n",
      "        [ 0.0610],\n",
      "        [ 0.0072],\n",
      "        [ 0.0240],\n",
      "        [ 0.0533],\n",
      "        [ 0.1102],\n",
      "        [ 0.0457],\n",
      "        [ 0.0279],\n",
      "        [ 0.0959],\n",
      "        [ 0.0991],\n",
      "        [ 0.1233]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0480, 0.0477, 0.0477, 0.0477, 0.0477, 0.0486, 0.0485, 0.0502, 0.0513,\n",
      "        0.0538, 0.0528, 0.0533, 0.0545, 0.0535, 0.0539, 0.0536, 0.0547, 0.0567,\n",
      "        0.0559, 0.0547, 0.0551, 0.0548, 0.0554, 0.0554, 0.0533, 0.0532, 0.0538,\n",
      "        0.0531, 0.0528, 0.0542, 0.0542, 0.0548], device='cuda:0')\n",
      "tensor([[ 0.0539],\n",
      "        [-0.0570],\n",
      "        [ 0.0241],\n",
      "        [ 0.0386],\n",
      "        [ 0.1116],\n",
      "        [ 0.0446],\n",
      "        [ 0.0262],\n",
      "        [ 0.0474],\n",
      "        [ 0.0557],\n",
      "        [ 0.0048],\n",
      "        [-0.0237],\n",
      "        [ 0.0498],\n",
      "        [ 0.0234],\n",
      "        [ 0.0311],\n",
      "        [ 0.0760],\n",
      "        [ 0.0932],\n",
      "        [ 0.1525],\n",
      "        [ 0.0554],\n",
      "        [-0.0223],\n",
      "        [ 0.0404],\n",
      "        [-0.0032],\n",
      "        [ 0.0174],\n",
      "        [ 0.0188],\n",
      "        [ 0.0721],\n",
      "        [ 0.0251],\n",
      "        [-0.0120],\n",
      "        [ 0.0233],\n",
      "        [ 0.0549],\n",
      "        [-0.0059],\n",
      "        [ 0.0782],\n",
      "        [ 0.0441],\n",
      "        [ 0.0977]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0544, 0.0520, 0.0526, 0.0539, 0.0535, 0.0538, 0.0541, 0.0528, 0.0514,\n",
      "        0.0505, 0.0498, 0.0486, 0.0500, 0.0504, 0.0495, 0.0491, 0.0502, 0.0485,\n",
      "        0.0485, 0.0491, 0.0488, 0.0505, 0.0510, 0.0505, 0.0513, 0.0504, 0.0514,\n",
      "        0.0520, 0.0513, 0.0528, 0.0533, 0.0533], device='cuda:0')\n",
      "tensor([[-0.0110],\n",
      "        [ 0.0291],\n",
      "        [ 0.0167],\n",
      "        [ 0.0449],\n",
      "        [ 0.0537],\n",
      "        [ 0.0426],\n",
      "        [ 0.0049],\n",
      "        [ 0.0348],\n",
      "        [-0.0176],\n",
      "        [ 0.0466],\n",
      "        [ 0.0639],\n",
      "        [ 0.0433],\n",
      "        [ 0.1271],\n",
      "        [ 0.1085],\n",
      "        [ 0.0278],\n",
      "        [ 0.0176],\n",
      "        [ 0.0319],\n",
      "        [ 0.1376],\n",
      "        [ 0.1174],\n",
      "        [ 0.0572],\n",
      "        [ 0.0138],\n",
      "        [-0.0275],\n",
      "        [-0.0455],\n",
      "        [ 0.0575],\n",
      "        [-0.0046],\n",
      "        [ 0.0075],\n",
      "        [-0.0118],\n",
      "        [ 0.0112],\n",
      "        [-0.0177],\n",
      "        [ 0.0781],\n",
      "        [ 0.1257],\n",
      "        [ 0.0270]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0536, 0.0536, 0.0542, 0.0541, 0.0539, 0.0559, 0.0570, 0.0569, 0.0560,\n",
      "        0.0554, 0.0562, 0.0567, 0.0584, 0.0587, 0.0576, 0.0573, 0.0564, 0.0566,\n",
      "        0.0569, 0.0572, 0.0576, 0.0573, 0.0572, 0.0562, 0.0567, 0.0562, 0.0559,\n",
      "        0.0559, 0.0550, 0.0548, 0.0545, 0.0551], device='cuda:0')\n",
      "tensor([[ 0.0306],\n",
      "        [ 0.0398],\n",
      "        [-0.0141],\n",
      "        [ 0.0590],\n",
      "        [ 0.0291],\n",
      "        [ 0.0119],\n",
      "        [ 0.0161],\n",
      "        [ 0.0498],\n",
      "        [-0.0036],\n",
      "        [ 0.0361],\n",
      "        [ 0.0411],\n",
      "        [ 0.0256],\n",
      "        [ 0.0318],\n",
      "        [ 0.0023],\n",
      "        [ 0.0117],\n",
      "        [ 0.0302],\n",
      "        [ 0.0009],\n",
      "        [ 0.0218],\n",
      "        [ 0.0439],\n",
      "        [ 0.0334],\n",
      "        [ 0.0091],\n",
      "        [ 0.0439],\n",
      "        [ 0.0564],\n",
      "        [ 0.0238],\n",
      "        [ 0.0118],\n",
      "        [ 0.0410],\n",
      "        [ 0.0109],\n",
      "        [ 0.0341],\n",
      "        [ 0.1178],\n",
      "        [ 0.1210],\n",
      "        [ 0.0875],\n",
      "        [ 0.0074]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0547, 0.0542, 0.0538, 0.0539, 0.0539, 0.0533, 0.0536, 0.0539, 0.0533,\n",
      "        0.0519, 0.0516, 0.0495, 0.0494, 0.0501, 0.0511, 0.0505, 0.0513, 0.0510,\n",
      "        0.0498, 0.0497, 0.0500, 0.0514, 0.0529, 0.0522, 0.0519, 0.0529, 0.0529,\n",
      "        0.0523, 0.0523, 0.0516, 0.0520, 0.0528], device='cuda:0')\n",
      "tensor([[-0.0006],\n",
      "        [ 0.0186],\n",
      "        [ 0.0368],\n",
      "        [ 0.0655],\n",
      "        [-0.0028],\n",
      "        [ 0.0503],\n",
      "        [ 0.0703],\n",
      "        [ 0.1701],\n",
      "        [ 0.0851],\n",
      "        [ 0.1164],\n",
      "        [ 0.0388],\n",
      "        [ 0.0938],\n",
      "        [ 0.0190],\n",
      "        [ 0.0689],\n",
      "        [ 0.0572],\n",
      "        [ 0.0302],\n",
      "        [ 0.0291],\n",
      "        [-0.0236],\n",
      "        [ 0.0012],\n",
      "        [ 0.0257],\n",
      "        [-0.0023],\n",
      "        [ 0.0039],\n",
      "        [ 0.0142],\n",
      "        [ 0.0302],\n",
      "        [ 0.0135],\n",
      "        [ 0.0373],\n",
      "        [ 0.1703],\n",
      "        [ 0.0890],\n",
      "        [ 0.0500],\n",
      "        [ 0.0968],\n",
      "        [ 0.0005],\n",
      "        [ 0.0254]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0533, 0.0545, 0.0597, 0.0569, 0.0597, 0.0595, 0.0595, 0.0585, 0.0603,\n",
      "        0.0604, 0.0594, 0.0593, 0.0585, 0.0581, 0.0573, 0.0581, 0.0582, 0.0595,\n",
      "        0.0587, 0.0582, 0.0562, 0.0553, 0.0554, 0.0551, 0.0544, 0.0542, 0.0550,\n",
      "        0.0550, 0.0587, 0.0584, 0.0587, 0.0613], device='cuda:0')\n",
      "tensor([[ 0.0693],\n",
      "        [-0.0419],\n",
      "        [ 0.0264],\n",
      "        [-0.0152],\n",
      "        [ 0.1203],\n",
      "        [ 0.0172],\n",
      "        [ 0.0288],\n",
      "        [ 0.0600],\n",
      "        [ 0.0353],\n",
      "        [ 0.0024],\n",
      "        [ 0.0204],\n",
      "        [ 0.0430],\n",
      "        [ 0.0154],\n",
      "        [ 0.0372],\n",
      "        [ 0.0886],\n",
      "        [ 0.0634],\n",
      "        [ 0.0708],\n",
      "        [ 0.0010],\n",
      "        [ 0.0169],\n",
      "        [ 0.0271],\n",
      "        [ 0.0529],\n",
      "        [ 0.0236],\n",
      "        [ 0.0779],\n",
      "        [-0.0064],\n",
      "        [ 0.0019],\n",
      "        [ 0.1090],\n",
      "        [ 0.0130],\n",
      "        [ 0.0647],\n",
      "        [ 0.0641],\n",
      "        [ 0.0205],\n",
      "        [ 0.0681],\n",
      "        [ 0.0201]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0626, 0.0615, 0.0624, 0.0624, 0.0622, 0.0632, 0.0640, 0.0631, 0.0650,\n",
      "        0.0659, 0.0663, 0.0663, 0.0656, 0.0650, 0.0668, 0.0663, 0.0674, 0.0683,\n",
      "        0.0683, 0.0690, 0.0714, 0.0699, 0.0709, 0.0705, 0.0712, 0.0708, 0.0690,\n",
      "        0.0674, 0.0683, 0.0687, 0.0694, 0.0740], device='cuda:0')\n",
      "tensor([[-0.0061],\n",
      "        [-0.0317],\n",
      "        [ 0.1585],\n",
      "        [ 0.0366],\n",
      "        [ 0.0600],\n",
      "        [ 0.1183],\n",
      "        [ 0.0968],\n",
      "        [ 0.2642],\n",
      "        [ 0.1101],\n",
      "        [ 0.1310],\n",
      "        [ 0.0578],\n",
      "        [ 0.0264],\n",
      "        [ 0.0101],\n",
      "        [ 0.0310],\n",
      "        [ 0.0135],\n",
      "        [ 0.0499],\n",
      "        [ 0.0130],\n",
      "        [ 0.1008],\n",
      "        [ 0.0313],\n",
      "        [ 0.0699],\n",
      "        [ 0.0491],\n",
      "        [ 0.0587],\n",
      "        [-0.0123],\n",
      "        [ 0.0387],\n",
      "        [ 0.0359],\n",
      "        [ 0.0247],\n",
      "        [ 0.0728],\n",
      "        [ 0.0388],\n",
      "        [ 0.0254],\n",
      "        [ 0.0523],\n",
      "        [ 0.0028],\n",
      "        [ 0.0050]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0756, 0.0765, 0.0793, 0.0784, 0.0793, 0.0753, 0.0746, 0.0787, 0.0777,\n",
      "        0.0805, 0.0808, 0.0784, 0.0752, 0.0776, 0.0771, 0.0748, 0.0750, 0.0770,\n",
      "        0.0774, 0.0814, 0.0799, 0.0802, 0.0792, 0.0820, 0.0804, 0.0815, 0.0815,\n",
      "        0.0779, 0.0777, 0.0799, 0.0796, 0.0793], device='cuda:0')\n",
      "tensor([[ 0.0742],\n",
      "        [ 0.0888],\n",
      "        [ 0.0642],\n",
      "        [ 0.0077],\n",
      "        [ 0.0513],\n",
      "        [ 0.0620],\n",
      "        [ 0.0086],\n",
      "        [ 0.0594],\n",
      "        [ 0.0524],\n",
      "        [ 0.0561],\n",
      "        [ 0.0220],\n",
      "        [ 0.0329],\n",
      "        [ 0.0628],\n",
      "        [ 0.0386],\n",
      "        [ 0.1637],\n",
      "        [ 0.1407],\n",
      "        [-0.0106],\n",
      "        [ 0.1247],\n",
      "        [ 0.0906],\n",
      "        [ 0.0362],\n",
      "        [-0.0259],\n",
      "        [ 0.1028],\n",
      "        [-0.0041],\n",
      "        [ 0.0522],\n",
      "        [-0.0048],\n",
      "        [ 0.0425],\n",
      "        [ 0.0382],\n",
      "        [ 0.0223],\n",
      "        [ 0.0564],\n",
      "        [ 0.0153],\n",
      "        [ 0.0160],\n",
      "        [ 0.0260]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0758, 0.0767, 0.0784, 0.0792, 0.0781, 0.0829, 0.0829, 0.0849, 0.0849,\n",
      "        0.0902, 0.0931, 0.0923, 0.0913, 0.0902, 0.0916, 0.0882, 0.0863, 0.0879,\n",
      "        0.0910, 0.0900, 0.0938, 0.0911, 0.0913, 0.0945, 0.0931, 0.0948, 0.0942,\n",
      "        0.0944, 0.0905, 0.0936, 0.0941, 0.0960], device='cuda:0')\n",
      "tensor([[ 0.0152],\n",
      "        [ 0.0976],\n",
      "        [ 0.0598],\n",
      "        [ 0.0047],\n",
      "        [ 0.0768],\n",
      "        [ 0.0234],\n",
      "        [ 0.1116],\n",
      "        [ 0.0371],\n",
      "        [ 0.1611],\n",
      "        [ 0.0642],\n",
      "        [ 0.0358],\n",
      "        [ 0.0514],\n",
      "        [ 0.0894],\n",
      "        [ 0.0538],\n",
      "        [ 0.0161],\n",
      "        [ 0.0449],\n",
      "        [ 0.0113],\n",
      "        [ 0.0220],\n",
      "        [ 0.0861],\n",
      "        [ 0.0116],\n",
      "        [ 0.0604],\n",
      "        [ 0.0469],\n",
      "        [ 0.0186],\n",
      "        [ 0.0303],\n",
      "        [ 0.0915],\n",
      "        [ 0.0076],\n",
      "        [ 0.0470],\n",
      "        [-0.0231],\n",
      "        [ 0.0575],\n",
      "        [ 0.0223],\n",
      "        [-0.0088],\n",
      "        [ 0.0203]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0948, 0.0964, 0.0964, 0.0966, 0.0972, 0.0978, 0.0979, 0.0984, 0.0970,\n",
      "        0.0963, 0.0925, 0.0916, 0.0941, 0.0931, 0.0960, 0.0957, 0.0975, 0.0953,\n",
      "        0.0941, 0.0935, 0.0957, 0.0954, 0.0931, 0.0923, 0.0945, 0.0945, 0.0976,\n",
      "        0.0975, 0.0969, 0.0969, 0.0972, 0.0954], device='cuda:0')\n",
      "tensor([[ 0.0381],\n",
      "        [ 0.0408],\n",
      "        [ 0.0087],\n",
      "        [ 0.0095],\n",
      "        [ 0.0785],\n",
      "        [ 0.0228],\n",
      "        [ 0.0903],\n",
      "        [ 0.0586],\n",
      "        [ 0.0262],\n",
      "        [ 0.0209],\n",
      "        [ 0.1713],\n",
      "        [ 0.0135],\n",
      "        [ 0.0650],\n",
      "        [ 0.1239],\n",
      "        [ 0.0508],\n",
      "        [ 0.0353],\n",
      "        [ 0.0915],\n",
      "        [ 0.0809],\n",
      "        [ 0.0434],\n",
      "        [ 0.0216],\n",
      "        [ 0.1707],\n",
      "        [-0.0091],\n",
      "        [ 0.0984],\n",
      "        [ 0.0468],\n",
      "        [ 0.0547],\n",
      "        [ 0.0311],\n",
      "        [ 0.0666],\n",
      "        [ 0.0221],\n",
      "        [ 0.0214],\n",
      "        [ 0.0163],\n",
      "        [ 0.0260],\n",
      "        [ 0.1060]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0973, 0.0998, 0.0993, 0.0976, 0.1009, 0.1013, 0.1010, 0.1015, 0.1024,\n",
      "        0.0998, 0.1015, 0.0991, 0.0997, 0.0994, 0.0998, 0.0975, 0.0975, 0.0987,\n",
      "        0.0997, 0.0990, 0.1013, 0.1015, 0.1013, 0.1016, 0.1022, 0.1038, 0.1009,\n",
      "        0.1016, 0.1012, 0.1019, 0.1026, 0.1034], device='cuda:0')\n",
      "tensor([[ 0.0517],\n",
      "        [ 0.0618],\n",
      "        [ 0.0182],\n",
      "        [ 0.0173],\n",
      "        [ 0.0623],\n",
      "        [ 0.0949],\n",
      "        [ 0.0314],\n",
      "        [ 0.0287],\n",
      "        [ 0.1600],\n",
      "        [ 0.0448],\n",
      "        [ 0.0281],\n",
      "        [ 0.0719],\n",
      "        [ 0.0756],\n",
      "        [ 0.1348],\n",
      "        [ 0.0562],\n",
      "        [-0.0143],\n",
      "        [ 0.1067],\n",
      "        [ 0.0016],\n",
      "        [ 0.0418],\n",
      "        [ 0.0056],\n",
      "        [ 0.0558],\n",
      "        [ 0.0068],\n",
      "        [ 0.0350],\n",
      "        [ 0.0518],\n",
      "        [ 0.0236],\n",
      "        [-0.0137],\n",
      "        [ 0.0198],\n",
      "        [-0.0367],\n",
      "        [-0.0466],\n",
      "        [ 0.0958],\n",
      "        [ 0.0515],\n",
      "        [ 0.1442]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1066, 0.1071, 0.1091, 0.1100, 0.1108, 0.1137, 0.1124, 0.1167, 0.1165,\n",
      "        0.1192, 0.1159, 0.1190, 0.1177, 0.1192, 0.1189, 0.1165, 0.1171, 0.1183,\n",
      "        0.1174, 0.1196, 0.1195, 0.1187, 0.1171, 0.1171, 0.1183, 0.1168, 0.1153,\n",
      "        0.1153, 0.1121, 0.1115, 0.1136, 0.1161], device='cuda:0')\n",
      "tensor([[ 0.0234],\n",
      "        [-0.0064],\n",
      "        [ 0.0021],\n",
      "        [ 0.0178],\n",
      "        [ 0.0149],\n",
      "        [ 0.0491],\n",
      "        [ 0.0022],\n",
      "        [-0.0199],\n",
      "        [ 0.0261],\n",
      "        [ 0.0532],\n",
      "        [ 0.0011],\n",
      "        [ 0.0003],\n",
      "        [ 0.0155],\n",
      "        [ 0.0194],\n",
      "        [ 0.0099],\n",
      "        [ 0.0290],\n",
      "        [ 0.0046],\n",
      "        [ 0.0294],\n",
      "        [ 0.0400],\n",
      "        [ 0.0306],\n",
      "        [ 0.1368],\n",
      "        [ 0.0151],\n",
      "        [ 0.0798],\n",
      "        [ 0.0489],\n",
      "        [ 0.0605],\n",
      "        [ 0.0330],\n",
      "        [ 0.0304],\n",
      "        [ 0.0398],\n",
      "        [ 0.0910],\n",
      "        [ 0.0034],\n",
      "        [ 0.0235],\n",
      "        [ 0.0068]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1173, 0.1158, 0.1142, 0.1121, 0.1128, 0.1148, 0.1153, 0.1174, 0.1143,\n",
      "        0.1146, 0.1150, 0.1156, 0.1192, 0.1201, 0.1236, 0.1245, 0.1238, 0.1248,\n",
      "        0.1261, 0.1266, 0.1263, 0.1260, 0.1235, 0.1201, 0.1224, 0.1227, 0.1236,\n",
      "        0.1215, 0.1243, 0.1221, 0.1242, 0.1263], device='cuda:0')\n",
      "tensor([[ 0.0385],\n",
      "        [ 0.0282],\n",
      "        [ 0.0176],\n",
      "        [ 0.0485],\n",
      "        [ 0.0033],\n",
      "        [ 0.0465],\n",
      "        [ 0.0228],\n",
      "        [ 0.1043],\n",
      "        [ 0.0282],\n",
      "        [ 0.0629],\n",
      "        [ 0.0076],\n",
      "        [ 0.0648],\n",
      "        [ 0.0920],\n",
      "        [ 0.0143],\n",
      "        [ 0.1071],\n",
      "        [ 0.0857],\n",
      "        [ 0.0143],\n",
      "        [ 0.0370],\n",
      "        [ 0.1329],\n",
      "        [ 0.0359],\n",
      "        [ 0.0477],\n",
      "        [ 0.0373],\n",
      "        [ 0.0710],\n",
      "        [ 0.0186],\n",
      "        [-0.0266],\n",
      "        [-0.0042],\n",
      "        [ 0.0134],\n",
      "        [ 0.0461],\n",
      "        [ 0.0633],\n",
      "        [ 0.0270],\n",
      "        [ 0.0491],\n",
      "        [ 0.0129]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1235, 0.1239, 0.1248, 0.1226, 0.1223, 0.1235, 0.1288, 0.1289, 0.1276,\n",
      "        0.1294, 0.1292, 0.1264, 0.1248, 0.1229, 0.1233, 0.1230, 0.1239, 0.1218,\n",
      "        0.1221, 0.1212, 0.1202, 0.1202, 0.1198, 0.1207, 0.1230, 0.1243, 0.1260,\n",
      "        0.1243, 0.1254, 0.1239, 0.1217, 0.1183], device='cuda:0')\n",
      "tensor([[ 0.0198],\n",
      "        [ 0.0561],\n",
      "        [ 0.0256],\n",
      "        [ 0.0608],\n",
      "        [ 0.1981],\n",
      "        [-0.0053],\n",
      "        [ 0.1671],\n",
      "        [ 0.0355],\n",
      "        [ 0.0175],\n",
      "        [ 0.0207],\n",
      "        [-0.0016],\n",
      "        [ 0.0099],\n",
      "        [ 0.0462],\n",
      "        [ 0.0504],\n",
      "        [ 0.0304],\n",
      "        [ 0.0186],\n",
      "        [ 0.0296],\n",
      "        [ 0.0391],\n",
      "        [-0.0015],\n",
      "        [ 0.0279],\n",
      "        [ 0.0088],\n",
      "        [ 0.0434],\n",
      "        [ 0.0118],\n",
      "        [ 0.0314],\n",
      "        [ 0.0784],\n",
      "        [ 0.0498],\n",
      "        [ 0.1293],\n",
      "        [ 0.1218],\n",
      "        [ 0.0401],\n",
      "        [ 0.0549],\n",
      "        [ 0.0530],\n",
      "        [-0.0086]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1180, 0.1199, 0.1212, 0.1193, 0.1218, 0.1208, 0.1221, 0.1246, 0.1252,\n",
      "        0.1251, 0.1251, 0.1242, 0.1248, 0.1258, 0.1245, 0.1261, 0.1269, 0.1270,\n",
      "        0.1260, 0.1279, 0.1302, 0.1326, 0.1317, 0.1328, 0.1317, 0.1305, 0.1320,\n",
      "        0.1341, 0.1356, 0.1367, 0.1369, 0.1393], device='cuda:0')\n",
      "tensor([[ 0.0735],\n",
      "        [ 0.0402],\n",
      "        [ 0.1300],\n",
      "        [ 0.1100],\n",
      "        [ 0.0455],\n",
      "        [ 0.1053],\n",
      "        [ 0.0423],\n",
      "        [ 0.0482],\n",
      "        [ 0.0707],\n",
      "        [ 0.0382],\n",
      "        [ 0.0544],\n",
      "        [-0.0140],\n",
      "        [ 0.1101],\n",
      "        [ 0.0788],\n",
      "        [ 0.0192],\n",
      "        [ 0.0105],\n",
      "        [ 0.0892],\n",
      "        [-0.0090],\n",
      "        [ 0.0305],\n",
      "        [ 0.0315],\n",
      "        [ 0.0100],\n",
      "        [ 0.0055],\n",
      "        [-0.0300],\n",
      "        [ 0.0486],\n",
      "        [ 0.0901],\n",
      "        [-0.0329],\n",
      "        [ 0.0525],\n",
      "        [ 0.0098],\n",
      "        [ 0.0152],\n",
      "        [ 0.0305],\n",
      "        [ 0.0523],\n",
      "        [ 0.0012]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1378, 0.1373, 0.1385, 0.1363, 0.1363, 0.1328, 0.1348, 0.1339, 0.1307,\n",
      "        0.1322, 0.1325, 0.1319, 0.1335, 0.1319, 0.1304, 0.1304, 0.1301, 0.1270,\n",
      "        0.1251, 0.1249, 0.1251, 0.1267, 0.1286, 0.1305, 0.1313, 0.1277, 0.1280,\n",
      "        0.1264, 0.1266, 0.1286, 0.1260, 0.1235], device='cuda:0')\n",
      "tensor([[ 0.0498],\n",
      "        [ 0.0810],\n",
      "        [ 0.0178],\n",
      "        [ 0.0199],\n",
      "        [ 0.0385],\n",
      "        [ 0.0814],\n",
      "        [-0.0376],\n",
      "        [ 0.0373],\n",
      "        [ 0.0473],\n",
      "        [ 0.0358],\n",
      "        [ 0.0348],\n",
      "        [ 0.0062],\n",
      "        [ 0.0693],\n",
      "        [ 0.0425],\n",
      "        [ 0.0014],\n",
      "        [ 0.1313],\n",
      "        [ 0.2009],\n",
      "        [ 0.0753],\n",
      "        [ 0.0700],\n",
      "        [ 0.0145],\n",
      "        [-0.0208],\n",
      "        [ 0.0155],\n",
      "        [ 0.0341],\n",
      "        [ 0.0605],\n",
      "        [ 0.0317],\n",
      "        [ 0.0304],\n",
      "        [ 0.0334],\n",
      "        [ 0.0952],\n",
      "        [-0.0270],\n",
      "        [ 0.0160],\n",
      "        [ 0.0310],\n",
      "        [ 0.0585]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1236, 0.1215, 0.1243, 0.1193, 0.1211, 0.1199, 0.1208, 0.1196, 0.1215,\n",
      "        0.1212, 0.1251, 0.1271, 0.1249, 0.1235, 0.1218, 0.1235, 0.1239, 0.1245,\n",
      "        0.1267, 0.1258, 0.1267, 0.1279, 0.1274, 0.1261, 0.1248, 0.1245, 0.1270,\n",
      "        0.1274, 0.1266, 0.1263, 0.1251, 0.1251], device='cuda:0')\n",
      "tensor([[ 0.0714],\n",
      "        [ 0.0721],\n",
      "        [ 0.0626],\n",
      "        [ 0.0084],\n",
      "        [ 0.0341],\n",
      "        [ 0.0098],\n",
      "        [ 0.0790],\n",
      "        [ 0.0268],\n",
      "        [ 0.0053],\n",
      "        [ 0.1164],\n",
      "        [ 0.0541],\n",
      "        [ 0.0581],\n",
      "        [ 0.0671],\n",
      "        [ 0.0500],\n",
      "        [ 0.0786],\n",
      "        [ 0.0315],\n",
      "        [ 0.0991],\n",
      "        [ 0.0300],\n",
      "        [ 0.0159],\n",
      "        [ 0.0609],\n",
      "        [ 0.0505],\n",
      "        [-0.0028],\n",
      "        [-0.0064],\n",
      "        [ 0.0575],\n",
      "        [ 0.0355],\n",
      "        [ 0.0348],\n",
      "        [ 0.0561],\n",
      "        [-0.0191],\n",
      "        [ 0.0263],\n",
      "        [ 0.0346],\n",
      "        [ 0.0444],\n",
      "        [-0.0017]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1239, 0.1212, 0.1230, 0.1236, 0.1230, 0.1211, 0.1189, 0.1179, 0.1186,\n",
      "        0.1170, 0.1161, 0.1164, 0.1152, 0.1155, 0.1150, 0.1158, 0.1115, 0.1091,\n",
      "        0.1112, 0.1080, 0.1094, 0.1105, 0.1094, 0.1117, 0.1102, 0.1102, 0.1103,\n",
      "        0.1099, 0.1096, 0.1097, 0.1121, 0.1140], device='cuda:0')\n",
      "tensor([[-0.0362],\n",
      "        [ 0.0113],\n",
      "        [ 0.0759],\n",
      "        [-0.0044],\n",
      "        [ 0.1030],\n",
      "        [-0.0032],\n",
      "        [ 0.0209],\n",
      "        [ 0.0117],\n",
      "        [ 0.0362],\n",
      "        [ 0.0126],\n",
      "        [ 0.0352],\n",
      "        [ 0.1479],\n",
      "        [-0.0203],\n",
      "        [-0.0206],\n",
      "        [ 0.0146],\n",
      "        [ 0.0538],\n",
      "        [ 0.0187],\n",
      "        [ 0.0417],\n",
      "        [ 0.0764],\n",
      "        [ 0.0662],\n",
      "        [ 0.0939],\n",
      "        [ 0.0646],\n",
      "        [ 0.0639],\n",
      "        [ 0.0099],\n",
      "        [ 0.0191],\n",
      "        [ 0.0219],\n",
      "        [ 0.0338],\n",
      "        [-0.0049],\n",
      "        [ 0.0253],\n",
      "        [ 0.0111],\n",
      "        [-0.0079],\n",
      "        [ 0.1792]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1106, 0.1109, 0.1124, 0.1130, 0.1118, 0.1097, 0.1078, 0.1088, 0.1083,\n",
      "        0.1109, 0.1114, 0.1118, 0.1130, 0.1150, 0.1153, 0.1162, 0.1153, 0.1139,\n",
      "        0.1133, 0.1133, 0.1152, 0.1170, 0.1150, 0.1152, 0.1130, 0.1130, 0.1118,\n",
      "        0.1091, 0.1103, 0.1102, 0.1106, 0.1093], device='cuda:0')\n",
      "tensor([[ 0.0481],\n",
      "        [ 0.0582],\n",
      "        [ 0.0594],\n",
      "        [ 0.0680],\n",
      "        [ 0.0686],\n",
      "        [ 0.0717],\n",
      "        [ 0.0328],\n",
      "        [ 0.0664],\n",
      "        [ 0.0570],\n",
      "        [ 0.0270],\n",
      "        [ 0.0133],\n",
      "        [ 0.0492],\n",
      "        [-0.0025],\n",
      "        [ 0.0392],\n",
      "        [ 0.0104],\n",
      "        [ 0.0967],\n",
      "        [ 0.0944],\n",
      "        [ 0.2557],\n",
      "        [ 0.2350],\n",
      "        [ 0.0434],\n",
      "        [-0.0046],\n",
      "        [ 0.0222],\n",
      "        [ 0.0291],\n",
      "        [ 0.0789],\n",
      "        [-0.0078],\n",
      "        [ 0.0095],\n",
      "        [ 0.0048],\n",
      "        [ 0.0308],\n",
      "        [-0.0075],\n",
      "        [ 0.0347],\n",
      "        [ 0.0241],\n",
      "        [-0.0164]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1136, 0.1121, 0.1139, 0.1133, 0.1119, 0.1115, 0.1105, 0.1115, 0.1128,\n",
      "        0.1145, 0.1145, 0.1150, 0.1183, 0.1180, 0.1173, 0.1139, 0.1145, 0.1156,\n",
      "        0.1140, 0.1134, 0.1121, 0.1133, 0.1142, 0.1128, 0.1112, 0.1099, 0.1090,\n",
      "        0.1081, 0.1080, 0.1068, 0.1074, 0.1066], device='cuda:0')\n",
      "tensor([[ 0.0512],\n",
      "        [ 0.0479],\n",
      "        [ 0.0809],\n",
      "        [-0.0311],\n",
      "        [-0.0310],\n",
      "        [ 0.0131],\n",
      "        [ 0.0271],\n",
      "        [ 0.0522],\n",
      "        [ 0.0273],\n",
      "        [ 0.0612],\n",
      "        [ 0.0863],\n",
      "        [ 0.0089],\n",
      "        [ 0.0167],\n",
      "        [ 0.0335],\n",
      "        [ 0.0577],\n",
      "        [ 0.0266],\n",
      "        [ 0.0825],\n",
      "        [ 0.0659],\n",
      "        [ 0.0340],\n",
      "        [ 0.0003],\n",
      "        [ 0.0238],\n",
      "        [ 0.1602],\n",
      "        [ 0.0519],\n",
      "        [ 0.0802],\n",
      "        [ 0.0463],\n",
      "        [ 0.0429],\n",
      "        [-0.0365],\n",
      "        [ 0.0540],\n",
      "        [ 0.0401],\n",
      "        [ 0.1510],\n",
      "        [ 0.0331],\n",
      "        [ 0.0468]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1077, 0.1080, 0.1081, 0.1086, 0.1052, 0.1056, 0.1055, 0.1056, 0.1038,\n",
      "        0.1041, 0.1040, 0.0997, 0.0978, 0.1009, 0.1019, 0.1013, 0.1057, 0.1050,\n",
      "        0.1053, 0.1037, 0.1025, 0.1049, 0.1056, 0.1056, 0.1072, 0.1062, 0.1056,\n",
      "        0.1074, 0.1072, 0.1050, 0.1040, 0.1050], device='cuda:0')\n",
      "tensor([[-5.7473e-03],\n",
      "        [ 6.5572e-02],\n",
      "        [ 6.8694e-02],\n",
      "        [ 4.6453e-02],\n",
      "        [-3.6497e-02],\n",
      "        [ 5.1033e-02],\n",
      "        [ 3.4139e-02],\n",
      "        [ 4.6070e-02],\n",
      "        [-3.5205e-04],\n",
      "        [ 1.8013e-02],\n",
      "        [ 1.2611e-01],\n",
      "        [ 3.4010e-02],\n",
      "        [ 9.8478e-03],\n",
      "        [ 3.2954e-02],\n",
      "        [ 1.4183e-02],\n",
      "        [-9.5888e-03],\n",
      "        [ 3.5366e-02],\n",
      "        [ 7.2624e-02],\n",
      "        [ 5.6804e-02],\n",
      "        [ 1.7218e-01],\n",
      "        [ 2.3308e-01],\n",
      "        [ 8.1071e-02],\n",
      "        [ 4.0547e-02],\n",
      "        [ 1.1719e-01],\n",
      "        [ 2.4197e-02],\n",
      "        [-6.2412e-03],\n",
      "        [ 1.4646e-04],\n",
      "        [ 3.7669e-02],\n",
      "        [ 3.9798e-03],\n",
      "        [ 9.6633e-03],\n",
      "        [ 1.4621e-02],\n",
      "        [ 1.9029e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1074, 0.1084, 0.1074, 0.1068, 0.1071, 0.1060, 0.1052, 0.1072, 0.1086,\n",
      "        0.1094, 0.1087, 0.1114, 0.1140, 0.1164, 0.1227, 0.1245, 0.1239, 0.1207,\n",
      "        0.1257, 0.1238, 0.1251, 0.1239, 0.1246, 0.1261, 0.1260, 0.1263, 0.1294,\n",
      "        0.1271, 0.1282, 0.1289, 0.1280, 0.1288], device='cuda:0')\n",
      "tensor([[ 0.0454],\n",
      "        [ 0.0165],\n",
      "        [ 0.0839],\n",
      "        [ 0.0560],\n",
      "        [ 0.0484],\n",
      "        [ 0.0267],\n",
      "        [-0.0013],\n",
      "        [-0.0198],\n",
      "        [ 0.0420],\n",
      "        [ 0.0271],\n",
      "        [ 0.0179],\n",
      "        [ 0.0270],\n",
      "        [ 0.0068],\n",
      "        [ 0.0163],\n",
      "        [ 0.0076],\n",
      "        [ 0.0437],\n",
      "        [ 0.1558],\n",
      "        [ 0.1887],\n",
      "        [ 0.0421],\n",
      "        [ 0.1133],\n",
      "        [ 0.0663],\n",
      "        [ 0.0428],\n",
      "        [ 0.0002],\n",
      "        [ 0.0472],\n",
      "        [ 0.0339],\n",
      "        [-0.0206],\n",
      "        [ 0.0086],\n",
      "        [-0.0155],\n",
      "        [ 0.0524],\n",
      "        [-0.0706],\n",
      "        [-0.0087],\n",
      "        [ 0.0237]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1274, 0.1267, 0.1269, 0.1254, 0.1254, 0.1264, 0.1243, 0.1257, 0.1251,\n",
      "        0.1254, 0.1297, 0.1304, 0.1314, 0.1302, 0.1294, 0.1295, 0.1274, 0.1269,\n",
      "        0.1271, 0.1279, 0.1292, 0.1274, 0.1255, 0.1245, 0.1239, 0.1246, 0.1239,\n",
      "        0.1236, 0.1230, 0.1243, 0.1227, 0.1246], device='cuda:0')\n",
      "tensor([[-0.0162],\n",
      "        [ 0.0386],\n",
      "        [ 0.0600],\n",
      "        [ 0.0155],\n",
      "        [ 0.0239],\n",
      "        [ 0.0349],\n",
      "        [ 0.0216],\n",
      "        [ 0.0047],\n",
      "        [ 0.0766],\n",
      "        [ 0.0865],\n",
      "        [ 0.0423],\n",
      "        [ 0.1099],\n",
      "        [ 0.0507],\n",
      "        [ 0.0367],\n",
      "        [ 0.0373],\n",
      "        [ 0.0079],\n",
      "        [-0.0082],\n",
      "        [ 0.1246],\n",
      "        [ 0.0165],\n",
      "        [ 0.0410],\n",
      "        [ 0.0428],\n",
      "        [ 0.0317],\n",
      "        [ 0.0911],\n",
      "        [ 0.0443],\n",
      "        [ 0.0926],\n",
      "        [ 0.0887],\n",
      "        [ 0.1207],\n",
      "        [ 0.0171],\n",
      "        [ 0.1221],\n",
      "        [ 0.0040],\n",
      "        [-0.0242],\n",
      "        [ 0.0685]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1254, 0.1239, 0.1246, 0.1295, 0.1285, 0.1292, 0.1302, 0.1304, 0.1283,\n",
      "        0.1273, 0.1282, 0.1304, 0.1279, 0.1295, 0.1294, 0.1304, 0.1313, 0.1292,\n",
      "        0.1292, 0.1263, 0.1271, 0.1257, 0.1261, 0.1257, 0.1242, 0.1224, 0.1239,\n",
      "        0.1236, 0.1255, 0.1255, 0.1280, 0.1261], device='cuda:0')\n",
      "tensor([[ 0.0621],\n",
      "        [ 0.0309],\n",
      "        [ 0.0212],\n",
      "        [ 0.0124],\n",
      "        [ 0.0328],\n",
      "        [ 0.0144],\n",
      "        [ 0.0323],\n",
      "        [ 0.0496],\n",
      "        [ 0.0530],\n",
      "        [ 0.1008],\n",
      "        [ 0.0527],\n",
      "        [ 0.0685],\n",
      "        [ 0.0222],\n",
      "        [ 0.0175],\n",
      "        [ 0.0533],\n",
      "        [-0.0078],\n",
      "        [ 0.0145],\n",
      "        [ 0.0234],\n",
      "        [ 0.1122],\n",
      "        [ 0.0469],\n",
      "        [ 0.0977],\n",
      "        [ 0.1300],\n",
      "        [ 0.0936],\n",
      "        [ 0.0322],\n",
      "        [-0.0087],\n",
      "        [ 0.0051],\n",
      "        [ 0.0201],\n",
      "        [ 0.0314],\n",
      "        [ 0.0635],\n",
      "        [ 0.0733],\n",
      "        [ 0.0584],\n",
      "        [ 0.0429]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1248, 0.1245, 0.1224, 0.1227, 0.1199, 0.1207, 0.1190, 0.1199, 0.1214,\n",
      "        0.1209, 0.1198, 0.1209, 0.1212, 0.1261, 0.1260, 0.1252, 0.1269, 0.1274,\n",
      "        0.1269, 0.1261, 0.1266, 0.1261, 0.1236, 0.1224, 0.1221, 0.1229, 0.1221,\n",
      "        0.1229, 0.1269, 0.1257, 0.1280, 0.1279], device='cuda:0')\n",
      "tensor([[ 0.0678],\n",
      "        [ 0.0258],\n",
      "        [ 0.0114],\n",
      "        [ 0.0298],\n",
      "        [-0.0028],\n",
      "        [ 0.0395],\n",
      "        [ 0.0416],\n",
      "        [-0.0078],\n",
      "        [ 0.0474],\n",
      "        [ 0.0198],\n",
      "        [ 0.1134],\n",
      "        [ 0.0824],\n",
      "        [ 0.0813],\n",
      "        [ 0.0810],\n",
      "        [ 0.0493],\n",
      "        [ 0.0774],\n",
      "        [ 0.0515],\n",
      "        [ 0.0085],\n",
      "        [-0.0136],\n",
      "        [-0.0152],\n",
      "        [ 0.0008],\n",
      "        [ 0.0041],\n",
      "        [ 0.0186],\n",
      "        [ 0.1671],\n",
      "        [ 0.1206],\n",
      "        [ 0.0498],\n",
      "        [-0.0029],\n",
      "        [ 0.0572],\n",
      "        [-0.0208],\n",
      "        [ 0.0369],\n",
      "        [-0.0175],\n",
      "        [ 0.0878]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1270, 0.1267, 0.1273, 0.1322, 0.1338, 0.1372, 0.1379, 0.1381, 0.1397,\n",
      "        0.1425, 0.1421, 0.1418, 0.1409, 0.1432, 0.1419, 0.1406, 0.1426, 0.1428,\n",
      "        0.1384, 0.1363, 0.1387, 0.1366, 0.1359, 0.1364, 0.1387, 0.1387, 0.1376,\n",
      "        0.1388, 0.1395, 0.1379, 0.1390, 0.1412], device='cuda:0')\n",
      "tensor([[ 1.6003e-02],\n",
      "        [ 8.5222e-02],\n",
      "        [ 6.7894e-02],\n",
      "        [-3.9982e-02],\n",
      "        [-1.2992e-04],\n",
      "        [ 8.6612e-02],\n",
      "        [ 1.3243e-01],\n",
      "        [ 1.0949e-02],\n",
      "        [-1.1447e-02],\n",
      "        [ 6.6809e-02],\n",
      "        [ 5.4044e-02],\n",
      "        [ 7.1651e-02],\n",
      "        [ 9.9952e-02],\n",
      "        [ 1.4202e-02],\n",
      "        [ 8.4511e-03],\n",
      "        [-1.2516e-02],\n",
      "        [ 3.4754e-02],\n",
      "        [ 3.1318e-02],\n",
      "        [ 5.3818e-02],\n",
      "        [ 3.8020e-02],\n",
      "        [ 1.1088e-02],\n",
      "        [ 1.0769e-01],\n",
      "        [ 3.3708e-02],\n",
      "        [ 2.5182e-02],\n",
      "        [ 2.4232e-02],\n",
      "        [ 8.2678e-02],\n",
      "        [ 4.2717e-02],\n",
      "        [-5.9118e-03],\n",
      "        [ 5.2305e-03],\n",
      "        [-1.4471e-02],\n",
      "        [ 1.4262e-02],\n",
      "        [ 1.3413e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1401, 0.1401, 0.1376, 0.1344, 0.1338, 0.1360, 0.1364, 0.1342, 0.1329,\n",
      "        0.1326, 0.1323, 0.1348, 0.1335, 0.1328, 0.1316, 0.1277, 0.1288, 0.1300,\n",
      "        0.1302, 0.1307, 0.1320, 0.1316, 0.1301, 0.1307, 0.1270, 0.1279, 0.1294,\n",
      "        0.1307, 0.1319, 0.1333, 0.1339, 0.1338], device='cuda:0')\n",
      "tensor([[ 0.0057],\n",
      "        [ 0.0007],\n",
      "        [ 0.0005],\n",
      "        [ 0.1064],\n",
      "        [ 0.0452],\n",
      "        [ 0.0257],\n",
      "        [ 0.0788],\n",
      "        [ 0.1398],\n",
      "        [ 0.0326],\n",
      "        [ 0.0652],\n",
      "        [ 0.0253],\n",
      "        [ 0.0151],\n",
      "        [ 0.0450],\n",
      "        [ 0.0691],\n",
      "        [ 0.0644],\n",
      "        [ 0.0605],\n",
      "        [ 0.1158],\n",
      "        [ 0.0773],\n",
      "        [ 0.0677],\n",
      "        [ 0.0258],\n",
      "        [ 0.0352],\n",
      "        [ 0.1249],\n",
      "        [ 0.0741],\n",
      "        [ 0.0605],\n",
      "        [ 0.0323],\n",
      "        [ 0.0360],\n",
      "        [ 0.0085],\n",
      "        [ 0.0521],\n",
      "        [ 0.0768],\n",
      "        [ 0.0216],\n",
      "        [-0.0138],\n",
      "        [ 0.0063]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1313, 0.1314, 0.1316, 0.1331, 0.1326, 0.1329, 0.1308, 0.1298, 0.1301,\n",
      "        0.1291, 0.1288, 0.1283, 0.1280, 0.1292, 0.1308, 0.1317, 0.1344, 0.1345,\n",
      "        0.1319, 0.1325, 0.1331, 0.1351, 0.1378, 0.1378, 0.1373, 0.1359, 0.1353,\n",
      "        0.1347, 0.1339, 0.1319, 0.1326, 0.1332], device='cuda:0')\n",
      "tensor([[-0.0034],\n",
      "        [ 0.0040],\n",
      "        [ 0.0579],\n",
      "        [ 0.0307],\n",
      "        [ 0.0534],\n",
      "        [ 0.0794],\n",
      "        [ 0.0079],\n",
      "        [ 0.0508],\n",
      "        [ 0.0358],\n",
      "        [ 0.0539],\n",
      "        [ 0.0492],\n",
      "        [ 0.0653],\n",
      "        [ 0.1238],\n",
      "        [ 0.0690],\n",
      "        [-0.0699],\n",
      "        [-0.0407],\n",
      "        [ 0.0440],\n",
      "        [ 0.0926],\n",
      "        [ 0.0365],\n",
      "        [ 0.0147],\n",
      "        [ 0.0635],\n",
      "        [ 0.0729],\n",
      "        [ 0.1210],\n",
      "        [ 0.0992],\n",
      "        [ 0.1250],\n",
      "        [ 0.0577],\n",
      "        [ 0.0509],\n",
      "        [ 0.0261],\n",
      "        [ 0.0339],\n",
      "        [ 0.0564],\n",
      "        [ 0.0294],\n",
      "        [ 0.0474]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1339, 0.1325, 0.1339, 0.1311, 0.1314, 0.1295, 0.1233, 0.1208, 0.1238,\n",
      "        0.1226, 0.1223, 0.1217, 0.1209, 0.1217, 0.1235, 0.1248, 0.1261, 0.1271,\n",
      "        0.1269, 0.1282, 0.1276, 0.1269, 0.1277, 0.1266, 0.1239, 0.1260, 0.1269,\n",
      "        0.1274, 0.1289, 0.1325, 0.1335, 0.1328], device='cuda:0')\n",
      "tensor([[ 0.0304],\n",
      "        [ 0.0620],\n",
      "        [ 0.0011],\n",
      "        [ 0.1391],\n",
      "        [ 0.1199],\n",
      "        [ 0.0906],\n",
      "        [ 0.0510],\n",
      "        [ 0.0802],\n",
      "        [ 0.0783],\n",
      "        [ 0.1041],\n",
      "        [ 0.0946],\n",
      "        [ 0.0394],\n",
      "        [-0.0011],\n",
      "        [ 0.0456],\n",
      "        [ 0.0803],\n",
      "        [ 0.0151],\n",
      "        [ 0.0323],\n",
      "        [ 0.0092],\n",
      "        [ 0.0127],\n",
      "        [ 0.0837],\n",
      "        [-0.0005],\n",
      "        [ 0.0856],\n",
      "        [ 0.1273],\n",
      "        [ 0.0080],\n",
      "        [-0.0122],\n",
      "        [ 0.0240],\n",
      "        [ 0.1456],\n",
      "        [ 0.0155],\n",
      "        [ 0.0194],\n",
      "        [ 0.0166],\n",
      "        [ 0.0391],\n",
      "        [ 0.0372]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1333, 0.1341, 0.1335, 0.1332, 0.1345, 0.1366, 0.1338, 0.1348, 0.1359,\n",
      "        0.1372, 0.1362, 0.1357, 0.1335, 0.1333, 0.1323, 0.1311, 0.1308, 0.1302,\n",
      "        0.1304, 0.1300, 0.1292, 0.1294, 0.1313, 0.1323, 0.1302, 0.1305, 0.1322,\n",
      "        0.1322, 0.1319, 0.1313, 0.1302, 0.1308], device='cuda:0')\n",
      "tensor([[ 0.0477],\n",
      "        [-0.0187],\n",
      "        [-0.0283],\n",
      "        [-0.0180],\n",
      "        [ 0.0742],\n",
      "        [ 0.0456],\n",
      "        [ 0.0252],\n",
      "        [ 0.0770],\n",
      "        [ 0.0297],\n",
      "        [ 0.0339],\n",
      "        [ 0.0054],\n",
      "        [ 0.0848],\n",
      "        [ 0.0959],\n",
      "        [ 0.0404],\n",
      "        [ 0.0056],\n",
      "        [ 0.0241],\n",
      "        [ 0.0421],\n",
      "        [ 0.0380],\n",
      "        [ 0.0237],\n",
      "        [ 0.0259],\n",
      "        [ 0.0785],\n",
      "        [-0.0153],\n",
      "        [ 0.0536],\n",
      "        [ 0.0482],\n",
      "        [ 0.0353],\n",
      "        [ 0.0311],\n",
      "        [ 0.0118],\n",
      "        [ 0.0397],\n",
      "        [ 0.0798],\n",
      "        [ 0.0408],\n",
      "        [ 0.0425],\n",
      "        [ 0.0914]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1310, 0.1323, 0.1332, 0.1335, 0.1317, 0.1310, 0.1308, 0.1313, 0.1323,\n",
      "        0.1304, 0.1313, 0.1319, 0.1304, 0.1320, 0.1304, 0.1271, 0.1269, 0.1270,\n",
      "        0.1302, 0.1276, 0.1276, 0.1266, 0.1274, 0.1276, 0.1274, 0.1276, 0.1291,\n",
      "        0.1319, 0.1319, 0.1335, 0.1325, 0.1314], device='cuda:0')\n",
      "tensor([[ 8.5507e-02],\n",
      "        [-1.5901e-03],\n",
      "        [ 2.1092e-02],\n",
      "        [ 1.0845e-04],\n",
      "        [ 3.5964e-02],\n",
      "        [ 1.3725e-03],\n",
      "        [ 1.0024e-02],\n",
      "        [ 6.7116e-02],\n",
      "        [ 1.0987e-01],\n",
      "        [ 8.2104e-02],\n",
      "        [ 6.1475e-02],\n",
      "        [ 7.0526e-02],\n",
      "        [ 3.4778e-02],\n",
      "        [ 3.0727e-02],\n",
      "        [-1.2773e-02],\n",
      "        [ 2.8536e-02],\n",
      "        [ 1.2092e-01],\n",
      "        [ 3.4178e-02],\n",
      "        [ 4.4232e-02],\n",
      "        [ 2.0707e-02],\n",
      "        [ 1.6294e-02],\n",
      "        [ 7.4176e-02],\n",
      "        [ 2.5955e-02],\n",
      "        [ 3.5757e-02],\n",
      "        [ 1.6807e-01],\n",
      "        [-8.1385e-03],\n",
      "        [ 9.3647e-02],\n",
      "        [ 7.0972e-02],\n",
      "        [ 6.0105e-02],\n",
      "        [ 1.0540e-02],\n",
      "        [ 9.2073e-03],\n",
      "        [-9.6172e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1313, 0.1332, 0.1348, 0.1326, 0.1319, 0.1335, 0.1348, 0.1356, 0.1341,\n",
      "        0.1353, 0.1369, 0.1382, 0.1376, 0.1367, 0.1372, 0.1397, 0.1406, 0.1401,\n",
      "        0.1421, 0.1422, 0.1443, 0.1440, 0.1449, 0.1463, 0.1455, 0.1449, 0.1449,\n",
      "        0.1463, 0.1457, 0.1435, 0.1444, 0.1483], device='cuda:0')\n",
      "tensor([[-0.0042],\n",
      "        [-0.0062],\n",
      "        [ 0.0173],\n",
      "        [-0.0063],\n",
      "        [ 0.0143],\n",
      "        [ 0.0036],\n",
      "        [ 0.0202],\n",
      "        [ 0.0510],\n",
      "        [ 0.1076],\n",
      "        [ 0.0698],\n",
      "        [ 0.0389],\n",
      "        [ 0.1369],\n",
      "        [ 0.0946],\n",
      "        [ 0.1587],\n",
      "        [ 0.0483],\n",
      "        [ 0.0020],\n",
      "        [ 0.0880],\n",
      "        [ 0.0121],\n",
      "        [ 0.0125],\n",
      "        [ 0.0072],\n",
      "        [-0.0408],\n",
      "        [ 0.0160],\n",
      "        [ 0.0339],\n",
      "        [-0.0240],\n",
      "        [ 0.0333],\n",
      "        [ 0.0202],\n",
      "        [-0.0384],\n",
      "        [ 0.1560],\n",
      "        [-0.0192],\n",
      "        [ 0.1375],\n",
      "        [-0.0223],\n",
      "        [-0.0270]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1469, 0.1481, 0.1515, 0.1539, 0.1567, 0.1562, 0.1581, 0.1605, 0.1608,\n",
      "        0.1612, 0.1623, 0.1629, 0.1626, 0.1611, 0.1617, 0.1642, 0.1676, 0.1643,\n",
      "        0.1602, 0.1630, 0.1630, 0.1645, 0.1565, 0.1583, 0.1561, 0.1567, 0.1570,\n",
      "        0.1609, 0.1649, 0.1589, 0.1571, 0.1573], device='cuda:0')\n",
      "tensor([[ 0.0475],\n",
      "        [ 0.0881],\n",
      "        [ 0.0790],\n",
      "        [ 0.0465],\n",
      "        [ 0.0606],\n",
      "        [ 0.1606],\n",
      "        [ 0.0058],\n",
      "        [ 0.0268],\n",
      "        [-0.0103],\n",
      "        [ 0.0353],\n",
      "        [ 0.0258],\n",
      "        [ 0.0127],\n",
      "        [-0.0036],\n",
      "        [ 0.0608],\n",
      "        [ 0.0878],\n",
      "        [ 0.0247],\n",
      "        [ 0.0753],\n",
      "        [ 0.0989],\n",
      "        [ 0.0160],\n",
      "        [ 0.0703],\n",
      "        [ 0.0279],\n",
      "        [ 0.0059],\n",
      "        [ 0.0239],\n",
      "        [ 0.0860],\n",
      "        [-0.0080],\n",
      "        [ 0.0769],\n",
      "        [ 0.0716],\n",
      "        [ 0.0403],\n",
      "        [ 0.0425],\n",
      "        [-0.0320],\n",
      "        [ 0.1122],\n",
      "        [ 0.2068]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1511, 0.1555, 0.1578, 0.1574, 0.1599, 0.1590, 0.1573, 0.1596, 0.1633,\n",
      "        0.1626, 0.1636, 0.1638, 0.1646, 0.1664, 0.1658, 0.1638, 0.1645, 0.1652,\n",
      "        0.1683, 0.1667, 0.1686, 0.1694, 0.1683, 0.1667, 0.1676, 0.1648, 0.1589,\n",
      "        0.1593, 0.1576, 0.1559, 0.1540, 0.1531], device='cuda:0')\n",
      "tensor([[ 0.1618],\n",
      "        [-0.0338],\n",
      "        [-0.0428],\n",
      "        [-0.0143],\n",
      "        [ 0.0569],\n",
      "        [ 0.0217],\n",
      "        [ 0.0423],\n",
      "        [ 0.0625],\n",
      "        [ 0.0189],\n",
      "        [ 0.1069],\n",
      "        [ 0.0424],\n",
      "        [ 0.0212],\n",
      "        [ 0.0493],\n",
      "        [-0.0131],\n",
      "        [ 0.0505],\n",
      "        [ 0.0197],\n",
      "        [-0.0197],\n",
      "        [ 0.0863],\n",
      "        [ 0.0092],\n",
      "        [ 0.0604],\n",
      "        [ 0.0842],\n",
      "        [ 0.0452],\n",
      "        [ 0.0361],\n",
      "        [ 0.0078],\n",
      "        [ 0.0222],\n",
      "        [ 0.0348],\n",
      "        [ 0.0428],\n",
      "        [ 0.0476],\n",
      "        [ 0.0499],\n",
      "        [ 0.0275],\n",
      "        [ 0.0502],\n",
      "        [ 0.2204]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1561, 0.1602, 0.1567, 0.1584, 0.1583, 0.1589, 0.1607, 0.1598, 0.1580,\n",
      "        0.1567, 0.1565, 0.1555, 0.1550, 0.1568, 0.1596, 0.1568, 0.1590, 0.1574,\n",
      "        0.1558, 0.1573, 0.1602, 0.1570, 0.1581, 0.1576, 0.1607, 0.1609, 0.1635,\n",
      "        0.1633, 0.1609, 0.1636, 0.1614, 0.1640], device='cuda:0')\n",
      "tensor([[ 0.0249],\n",
      "        [ 0.0545],\n",
      "        [ 0.0539],\n",
      "        [ 0.0094],\n",
      "        [ 0.0116],\n",
      "        [ 0.0062],\n",
      "        [ 0.0079],\n",
      "        [ 0.0697],\n",
      "        [ 0.0244],\n",
      "        [-0.0030],\n",
      "        [ 0.0230],\n",
      "        [ 0.0117],\n",
      "        [ 0.0834],\n",
      "        [ 0.0762],\n",
      "        [ 0.0762],\n",
      "        [-0.0018],\n",
      "        [ 0.0583],\n",
      "        [ 0.0113],\n",
      "        [ 0.0510],\n",
      "        [ 0.0582],\n",
      "        [ 0.0951],\n",
      "        [ 0.0742],\n",
      "        [ 0.0067],\n",
      "        [ 0.0040],\n",
      "        [ 0.0582],\n",
      "        [ 0.0198],\n",
      "        [ 0.0505],\n",
      "        [-0.0075],\n",
      "        [ 0.1218],\n",
      "        [-0.0028],\n",
      "        [ 0.1243],\n",
      "        [ 0.0936]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1669, 0.1691, 0.1713, 0.1689, 0.1652, 0.1660, 0.1627, 0.1645, 0.1629,\n",
      "        0.1593, 0.1567, 0.1576, 0.1578, 0.1565, 0.1556, 0.1524, 0.1518, 0.1509,\n",
      "        0.1534, 0.1514, 0.1500, 0.1506, 0.1543, 0.1595, 0.1612, 0.1607, 0.1605,\n",
      "        0.1611, 0.1578, 0.1587, 0.1577, 0.1540], device='cuda:0')\n",
      "tensor([[ 0.1673],\n",
      "        [ 0.0635],\n",
      "        [ 0.0341],\n",
      "        [ 0.0379],\n",
      "        [-0.0267],\n",
      "        [-0.0052],\n",
      "        [ 0.0144],\n",
      "        [ 0.0274],\n",
      "        [ 0.0405],\n",
      "        [ 0.0128],\n",
      "        [ 0.0202],\n",
      "        [ 0.0472],\n",
      "        [ 0.0370],\n",
      "        [ 0.0363],\n",
      "        [ 0.0715],\n",
      "        [ 0.0313],\n",
      "        [ 0.0388],\n",
      "        [ 0.0255],\n",
      "        [-0.0118],\n",
      "        [ 0.0409],\n",
      "        [ 0.0668],\n",
      "        [ 0.0858],\n",
      "        [ 0.0613],\n",
      "        [ 0.0031],\n",
      "        [ 0.0384],\n",
      "        [ 0.0150],\n",
      "        [ 0.0273],\n",
      "        [ 0.0536],\n",
      "        [ 0.0517],\n",
      "        [-0.0349],\n",
      "        [ 0.1415],\n",
      "        [ 0.1918]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1559, 0.1568, 0.1555, 0.1574, 0.1561, 0.1542, 0.1536, 0.1519, 0.1549,\n",
      "        0.1521, 0.1537, 0.1549, 0.1540, 0.1543, 0.1537, 0.1562, 0.1573, 0.1567,\n",
      "        0.1522, 0.1515, 0.1511, 0.1528, 0.1497, 0.1452, 0.1410, 0.1379, 0.1366,\n",
      "        0.1363, 0.1364, 0.1385, 0.1379, 0.1379], device='cuda:0')\n",
      "tensor([[ 0.1351],\n",
      "        [ 0.0186],\n",
      "        [ 0.0622],\n",
      "        [ 0.0060],\n",
      "        [ 0.0725],\n",
      "        [-0.0055],\n",
      "        [ 0.0355],\n",
      "        [ 0.0295],\n",
      "        [ 0.0053],\n",
      "        [ 0.0341],\n",
      "        [-0.0323],\n",
      "        [ 0.0197],\n",
      "        [ 0.0369],\n",
      "        [ 0.0322],\n",
      "        [ 0.0233],\n",
      "        [ 0.0940],\n",
      "        [ 0.0249],\n",
      "        [ 0.0438],\n",
      "        [ 0.0334],\n",
      "        [ 0.1031],\n",
      "        [ 0.0520],\n",
      "        [ 0.1092],\n",
      "        [ 0.0982],\n",
      "        [ 0.0538],\n",
      "        [ 0.1072],\n",
      "        [ 0.0260],\n",
      "        [ 0.0932],\n",
      "        [ 0.1320],\n",
      "        [ 0.0602],\n",
      "        [ 0.0323],\n",
      "        [ 0.0256],\n",
      "        [-0.0144]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1391, 0.1370, 0.1357, 0.1369, 0.1372, 0.1359, 0.1362, 0.1353, 0.1356,\n",
      "        0.1354, 0.1342, 0.1354, 0.1372, 0.1390, 0.1393, 0.1379, 0.1406, 0.1422,\n",
      "        0.1452, 0.1437, 0.1437, 0.1449, 0.1474, 0.1474, 0.1460, 0.1446, 0.1413,\n",
      "        0.1415, 0.1453, 0.1465, 0.1505, 0.1506], device='cuda:0')\n",
      "tensor([[-0.0011],\n",
      "        [ 0.0370],\n",
      "        [ 0.0153],\n",
      "        [ 0.0250],\n",
      "        [-0.0208],\n",
      "        [ 0.2136],\n",
      "        [ 0.0352],\n",
      "        [ 0.0831],\n",
      "        [ 0.0181],\n",
      "        [-0.0234],\n",
      "        [ 0.0039],\n",
      "        [-0.0121],\n",
      "        [ 0.0177],\n",
      "        [ 0.0387],\n",
      "        [ 0.0187],\n",
      "        [ 0.0460],\n",
      "        [ 0.0410],\n",
      "        [ 0.0264],\n",
      "        [ 0.0536],\n",
      "        [ 0.0194],\n",
      "        [ 0.0861],\n",
      "        [ 0.0263],\n",
      "        [-0.0138],\n",
      "        [ 0.0256],\n",
      "        [ 0.0211],\n",
      "        [ 0.0515],\n",
      "        [ 0.0268],\n",
      "        [-0.0061],\n",
      "        [ 0.0921],\n",
      "        [-0.0124],\n",
      "        [-0.0247],\n",
      "        [ 0.0093]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1509, 0.1452, 0.1429, 0.1425, 0.1440, 0.1432, 0.1441, 0.1424, 0.1444,\n",
      "        0.1452, 0.1431, 0.1410, 0.1407, 0.1393, 0.1395, 0.1378, 0.1378, 0.1353,\n",
      "        0.1384, 0.1320, 0.1313, 0.1248, 0.1267, 0.1248, 0.1235, 0.1260, 0.1238,\n",
      "        0.1246, 0.1227, 0.1240, 0.1229, 0.1242], device='cuda:0')\n",
      "tensor([[ 0.0208],\n",
      "        [ 0.0313],\n",
      "        [ 0.0785],\n",
      "        [ 0.0584],\n",
      "        [ 0.0027],\n",
      "        [ 0.0034],\n",
      "        [ 0.0447],\n",
      "        [ 0.0602],\n",
      "        [ 0.0478],\n",
      "        [ 0.0171],\n",
      "        [ 0.0287],\n",
      "        [ 0.0101],\n",
      "        [ 0.1174],\n",
      "        [ 0.0586],\n",
      "        [ 0.1082],\n",
      "        [ 0.0177],\n",
      "        [ 0.0039],\n",
      "        [ 0.0219],\n",
      "        [ 0.0439],\n",
      "        [ 0.0561],\n",
      "        [-0.0142],\n",
      "        [ 0.0458],\n",
      "        [ 0.0528],\n",
      "        [ 0.0133],\n",
      "        [-0.0033],\n",
      "        [ 0.0799],\n",
      "        [ 0.0565],\n",
      "        [ 0.0918],\n",
      "        [ 0.0533],\n",
      "        [-0.0081],\n",
      "        [ 0.0800],\n",
      "        [ 0.1296]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1240, 0.1249, 0.1233, 0.1235, 0.1248, 0.1267, 0.1300, 0.1294, 0.1261,\n",
      "        0.1240, 0.1242, 0.1261, 0.1269, 0.1257, 0.1223, 0.1240, 0.1248, 0.1230,\n",
      "        0.1260, 0.1266, 0.1263, 0.1279, 0.1308, 0.1295, 0.1308, 0.1311, 0.1341,\n",
      "        0.1326, 0.1316, 0.1302, 0.1316, 0.1305], device='cuda:0')\n",
      "tensor([[ 0.0197],\n",
      "        [ 0.0174],\n",
      "        [ 0.0246],\n",
      "        [ 0.0543],\n",
      "        [-0.0058],\n",
      "        [ 0.0410],\n",
      "        [ 0.0345],\n",
      "        [-0.0080],\n",
      "        [ 0.0239],\n",
      "        [ 0.0353],\n",
      "        [ 0.0031],\n",
      "        [ 0.0553],\n",
      "        [ 0.0867],\n",
      "        [ 0.1495],\n",
      "        [-0.0249],\n",
      "        [ 0.0583],\n",
      "        [ 0.0876],\n",
      "        [ 0.0055],\n",
      "        [ 0.0446],\n",
      "        [-0.0347],\n",
      "        [ 0.0251],\n",
      "        [ 0.0608],\n",
      "        [ 0.0050],\n",
      "        [ 0.0485],\n",
      "        [ 0.0669],\n",
      "        [ 0.0245],\n",
      "        [ 0.0648],\n",
      "        [ 0.0639],\n",
      "        [ 0.0587],\n",
      "        [ 0.0575],\n",
      "        [ 0.0345],\n",
      "        [ 0.0978]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1319, 0.1319, 0.1301, 0.1314, 0.1320, 0.1304, 0.1288, 0.1285, 0.1261,\n",
      "        0.1230, 0.1248, 0.1248, 0.1232, 0.1235, 0.1224, 0.1248, 0.1267, 0.1260,\n",
      "        0.1266, 0.1258, 0.1251, 0.1229, 0.1183, 0.1208, 0.1224, 0.1224, 0.1286,\n",
      "        0.1257, 0.1257, 0.1311, 0.1298, 0.1310], device='cuda:0')\n",
      "tensor([[ 0.0270],\n",
      "        [-0.0061],\n",
      "        [ 0.0252],\n",
      "        [ 0.1074],\n",
      "        [ 0.0138],\n",
      "        [ 0.0389],\n",
      "        [ 0.0366],\n",
      "        [ 0.0599],\n",
      "        [ 0.0266],\n",
      "        [ 0.0471],\n",
      "        [ 0.0436],\n",
      "        [ 0.0814],\n",
      "        [ 0.0528],\n",
      "        [ 0.0530],\n",
      "        [ 0.0670],\n",
      "        [ 0.0321],\n",
      "        [ 0.0541],\n",
      "        [ 0.0288],\n",
      "        [ 0.1009],\n",
      "        [ 0.0324],\n",
      "        [ 0.0215],\n",
      "        [ 0.0384],\n",
      "        [ 0.0067],\n",
      "        [ 0.1015],\n",
      "        [ 0.0251],\n",
      "        [ 0.0148],\n",
      "        [ 0.0520],\n",
      "        [ 0.0652],\n",
      "        [ 0.0055],\n",
      "        [ 0.0902],\n",
      "        [ 0.0684],\n",
      "        [ 0.0157]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1335, 0.1342, 0.1326, 0.1328, 0.1369, 0.1378, 0.1403, 0.1424, 0.1410,\n",
      "        0.1387, 0.1382, 0.1390, 0.1373, 0.1395, 0.1441, 0.1437, 0.1450, 0.1456,\n",
      "        0.1500, 0.1496, 0.1481, 0.1453, 0.1455, 0.1443, 0.1438, 0.1459, 0.1465,\n",
      "        0.1453, 0.1447, 0.1494, 0.1481, 0.1511], device='cuda:0')\n",
      "tensor([[ 0.0419],\n",
      "        [ 0.0352],\n",
      "        [ 0.0197],\n",
      "        [ 0.0305],\n",
      "        [ 0.0403],\n",
      "        [-0.0002],\n",
      "        [ 0.0043],\n",
      "        [ 0.0257],\n",
      "        [ 0.0716],\n",
      "        [-0.0097],\n",
      "        [ 0.0515],\n",
      "        [ 0.0860],\n",
      "        [ 0.0460],\n",
      "        [ 0.0404],\n",
      "        [ 0.0639],\n",
      "        [-0.0113],\n",
      "        [ 0.0091],\n",
      "        [ 0.0823],\n",
      "        [ 0.1035],\n",
      "        [ 0.1370],\n",
      "        [ 0.0857],\n",
      "        [ 0.0918],\n",
      "        [ 0.0187],\n",
      "        [ 0.0914],\n",
      "        [ 0.1207],\n",
      "        [-0.0313],\n",
      "        [ 0.0575],\n",
      "        [ 0.1237],\n",
      "        [ 0.0413],\n",
      "        [ 0.0296],\n",
      "        [ 0.0675],\n",
      "        [ 0.0942]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1518, 0.1515, 0.1545, 0.1534, 0.1543, 0.1562, 0.1576, 0.1612, 0.1645,\n",
      "        0.1626, 0.1587, 0.1607, 0.1580, 0.1592, 0.1555, 0.1573, 0.1571, 0.1537,\n",
      "        0.1546, 0.1508, 0.1519, 0.1550, 0.1556, 0.1589, 0.1578, 0.1578, 0.1661,\n",
      "        0.1629, 0.1629, 0.1599, 0.1629, 0.1640], device='cuda:0')\n",
      "tensor([[ 0.0568],\n",
      "        [ 0.0343],\n",
      "        [ 0.0016],\n",
      "        [ 0.1057],\n",
      "        [ 0.0904],\n",
      "        [ 0.0722],\n",
      "        [ 0.1619],\n",
      "        [ 0.1272],\n",
      "        [ 0.0203],\n",
      "        [ 0.0484],\n",
      "        [ 0.1222],\n",
      "        [ 0.0285],\n",
      "        [ 0.0143],\n",
      "        [ 0.0111],\n",
      "        [ 0.0357],\n",
      "        [ 0.0201],\n",
      "        [-0.0085],\n",
      "        [ 0.0612],\n",
      "        [ 0.0475],\n",
      "        [ 0.0605],\n",
      "        [ 0.0585],\n",
      "        [-0.0206],\n",
      "        [ 0.0197],\n",
      "        [ 0.0006],\n",
      "        [ 0.0446],\n",
      "        [ 0.0009],\n",
      "        [ 0.0338],\n",
      "        [ 0.0003],\n",
      "        [ 0.0128],\n",
      "        [ 0.0492],\n",
      "        [-0.0461],\n",
      "        [-0.0107]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1680, 0.1698, 0.1704, 0.1732, 0.1778, 0.1776, 0.1754, 0.1741, 0.1732,\n",
      "        0.1760, 0.1770, 0.1757, 0.1704, 0.1708, 0.1658, 0.1657, 0.1664, 0.1657,\n",
      "        0.1704, 0.1708, 0.1728, 0.1697, 0.1692, 0.1664, 0.1700, 0.1713, 0.1697,\n",
      "        0.1711, 0.1695, 0.1670, 0.1669, 0.1657], device='cuda:0')\n",
      "tensor([[0.0443],\n",
      "        [0.0408],\n",
      "        [0.0781],\n",
      "        [0.0798],\n",
      "        [0.0298],\n",
      "        [0.0246],\n",
      "        [0.0195],\n",
      "        [0.0468],\n",
      "        [0.0407],\n",
      "        [0.0497],\n",
      "        [0.0140],\n",
      "        [0.0820],\n",
      "        [0.1282],\n",
      "        [0.1338],\n",
      "        [0.0426],\n",
      "        [0.0365],\n",
      "        [0.0183],\n",
      "        [0.0057],\n",
      "        [0.1056],\n",
      "        [0.0559],\n",
      "        [0.0328],\n",
      "        [0.0466],\n",
      "        [0.0289],\n",
      "        [0.0337],\n",
      "        [0.1901],\n",
      "        [0.0924],\n",
      "        [0.0353],\n",
      "        [0.0052],\n",
      "        [0.0455],\n",
      "        [0.1906],\n",
      "        [0.0793],\n",
      "        [0.0997]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1692, 0.1720, 0.1713, 0.1707, 0.1713, 0.1735, 0.1754, 0.1769, 0.1790,\n",
      "        0.1773, 0.1760, 0.1726, 0.1744, 0.1747, 0.1757, 0.1742, 0.1776, 0.1770,\n",
      "        0.1779, 0.1813, 0.1785, 0.1791, 0.1793, 0.1779, 0.1751, 0.1729, 0.1713,\n",
      "        0.1698, 0.1711, 0.1722, 0.1711, 0.1714], device='cuda:0')\n",
      "tensor([[ 0.0610],\n",
      "        [ 0.0157],\n",
      "        [ 0.0535],\n",
      "        [ 0.0632],\n",
      "        [ 0.0276],\n",
      "        [ 0.0559],\n",
      "        [ 0.0335],\n",
      "        [ 0.0722],\n",
      "        [-0.0333],\n",
      "        [ 0.0118],\n",
      "        [ 0.0051],\n",
      "        [ 0.0727],\n",
      "        [-0.0408],\n",
      "        [ 0.0409],\n",
      "        [ 0.0871],\n",
      "        [ 0.0102],\n",
      "        [ 0.0365],\n",
      "        [ 0.0971],\n",
      "        [ 0.0434],\n",
      "        [ 0.0752],\n",
      "        [ 0.0702],\n",
      "        [ 0.0734],\n",
      "        [ 0.0250],\n",
      "        [ 0.0313],\n",
      "        [ 0.0464],\n",
      "        [ 0.0638],\n",
      "        [ 0.1128],\n",
      "        [ 0.0924],\n",
      "        [ 0.0145],\n",
      "        [ 0.0839],\n",
      "        [ 0.0503],\n",
      "        [ 0.0571]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1725, 0.1708, 0.1688, 0.1689, 0.1700, 0.1732, 0.1748, 0.1776, 0.1803,\n",
      "        0.1819, 0.1855, 0.1853, 0.1868, 0.1849, 0.1846, 0.1871, 0.1871, 0.1869,\n",
      "        0.1838, 0.1790, 0.1770, 0.1773, 0.1795, 0.1731, 0.1726, 0.1716, 0.1705,\n",
      "        0.1670, 0.1664, 0.1670, 0.1710, 0.1720], device='cuda:0')\n",
      "tensor([[ 0.0863],\n",
      "        [ 0.0318],\n",
      "        [ 0.0022],\n",
      "        [ 0.0620],\n",
      "        [-0.0106],\n",
      "        [ 0.0650],\n",
      "        [ 0.0277],\n",
      "        [ 0.0569],\n",
      "        [ 0.0260],\n",
      "        [-0.0160],\n",
      "        [ 0.0771],\n",
      "        [ 0.0372],\n",
      "        [ 0.0211],\n",
      "        [ 0.0243],\n",
      "        [ 0.0790],\n",
      "        [ 0.0050],\n",
      "        [ 0.0394],\n",
      "        [ 0.0156],\n",
      "        [ 0.0380],\n",
      "        [ 0.0401],\n",
      "        [ 0.0321],\n",
      "        [ 0.0594],\n",
      "        [-0.0138],\n",
      "        [ 0.0175],\n",
      "        [-0.0104],\n",
      "        [ 0.0459],\n",
      "        [ 0.0391],\n",
      "        [ 0.0251],\n",
      "        [ 0.0342],\n",
      "        [ 0.1687],\n",
      "        [ 0.0204],\n",
      "        [ 0.0361]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1667, 0.1657, 0.1671, 0.1642, 0.1584, 0.1646, 0.1629, 0.1648, 0.1649,\n",
      "        0.1611, 0.1584, 0.1587, 0.1633, 0.1640, 0.1655, 0.1590, 0.1611, 0.1596,\n",
      "        0.1548, 0.1573, 0.1564, 0.1522, 0.1462, 0.1401, 0.1026, 0.1165, 0.1257,\n",
      "        0.1224, 0.1233, 0.1130, 0.1201, 0.1201], device='cuda:0')\n",
      "tensor([[ 0.0477],\n",
      "        [ 0.0575],\n",
      "        [-0.0362],\n",
      "        [ 0.0804],\n",
      "        [ 0.0065],\n",
      "        [ 0.0236],\n",
      "        [ 0.0781],\n",
      "        [ 0.0324],\n",
      "        [ 0.1402],\n",
      "        [ 0.0252],\n",
      "        [ 0.1111],\n",
      "        [-0.0080],\n",
      "        [ 0.0273],\n",
      "        [ 0.0195],\n",
      "        [-0.0283],\n",
      "        [ 0.0664],\n",
      "        [ 0.0150],\n",
      "        [ 0.0749],\n",
      "        [ 0.0520],\n",
      "        [ 0.0293],\n",
      "        [ 0.0293],\n",
      "        [ 0.0417],\n",
      "        [ 0.0218],\n",
      "        [ 0.0132],\n",
      "        [-0.0083],\n",
      "        [-0.0191],\n",
      "        [ 0.0532],\n",
      "        [ 0.0518],\n",
      "        [ 0.1129],\n",
      "        [-0.0009],\n",
      "        [ 0.0086],\n",
      "        [ 0.0407]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1227, 0.1254, 0.1277, 0.1246, 0.1232, 0.1269, 0.1218, 0.1202, 0.1198,\n",
      "        0.1215, 0.1251, 0.1243, 0.1224, 0.1198, 0.1205, 0.1173, 0.1198, 0.1195,\n",
      "        0.1207, 0.1196, 0.1164, 0.1115, 0.1121, 0.1112, 0.1065, 0.1080, 0.1100,\n",
      "        0.1124, 0.1153, 0.1118, 0.1108, 0.1167], device='cuda:0')\n",
      "tensor([[ 0.0375],\n",
      "        [ 0.0509],\n",
      "        [ 0.0515],\n",
      "        [ 0.0310],\n",
      "        [ 0.0624],\n",
      "        [ 0.0308],\n",
      "        [ 0.0682],\n",
      "        [ 0.0990],\n",
      "        [-0.0071],\n",
      "        [ 0.0240],\n",
      "        [ 0.0431],\n",
      "        [ 0.0321],\n",
      "        [-0.0035],\n",
      "        [ 0.0445],\n",
      "        [-0.0229],\n",
      "        [-0.0064],\n",
      "        [ 0.0288],\n",
      "        [-0.0010],\n",
      "        [ 0.0940],\n",
      "        [ 0.0651],\n",
      "        [ 0.0968],\n",
      "        [ 0.0093],\n",
      "        [ 0.0542],\n",
      "        [ 0.0487],\n",
      "        [ 0.0175],\n",
      "        [ 0.0535],\n",
      "        [ 0.0855],\n",
      "        [ 0.0489],\n",
      "        [ 0.0481],\n",
      "        [ 0.0935],\n",
      "        [ 0.0848],\n",
      "        [ 0.0989]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1177, 0.1211, 0.1171, 0.1192, 0.1204, 0.1204, 0.1218, 0.1223, 0.1174,\n",
      "        0.1177, 0.1189, 0.1171, 0.1233, 0.1246, 0.1258, 0.1264, 0.1164, 0.1198,\n",
      "        0.1168, 0.1179, 0.1176, 0.1212, 0.1198, 0.1127, 0.1111, 0.1118, 0.1112,\n",
      "        0.1145, 0.1128, 0.1139, 0.1150, 0.1134], device='cuda:0')\n",
      "tensor([[-0.0328],\n",
      "        [-0.0110],\n",
      "        [ 0.0181],\n",
      "        [ 0.0595],\n",
      "        [ 0.0437],\n",
      "        [ 0.0443],\n",
      "        [ 0.0373],\n",
      "        [ 0.0877],\n",
      "        [ 0.0838],\n",
      "        [-0.0168],\n",
      "        [ 0.0551],\n",
      "        [ 0.0274],\n",
      "        [ 0.0666],\n",
      "        [ 0.0179],\n",
      "        [ 0.0413],\n",
      "        [ 0.0778],\n",
      "        [ 0.0239],\n",
      "        [ 0.0295],\n",
      "        [ 0.0347],\n",
      "        [ 0.1132],\n",
      "        [ 0.0272],\n",
      "        [ 0.0490],\n",
      "        [ 0.0838],\n",
      "        [ 0.0546],\n",
      "        [ 0.0047],\n",
      "        [ 0.0594],\n",
      "        [ 0.0218],\n",
      "        [ 0.0484],\n",
      "        [-0.0086],\n",
      "        [-0.0107],\n",
      "        [ 0.0301],\n",
      "        [ 0.0206]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1106, 0.1105, 0.1094, 0.1090, 0.1083, 0.1080, 0.1096, 0.1125, 0.1121,\n",
      "        0.1130, 0.1150, 0.1139, 0.1136, 0.1146, 0.1168, 0.1170, 0.1179, 0.1159,\n",
      "        0.1174, 0.1195, 0.1189, 0.1192, 0.1183, 0.1187, 0.1192, 0.1196, 0.1184,\n",
      "        0.1150, 0.1171, 0.1171, 0.1153, 0.1168], device='cuda:0')\n",
      "tensor([[ 0.0738],\n",
      "        [ 0.0639],\n",
      "        [ 0.0348],\n",
      "        [ 0.0625],\n",
      "        [ 0.0298],\n",
      "        [ 0.0397],\n",
      "        [ 0.0510],\n",
      "        [ 0.0631],\n",
      "        [-0.0137],\n",
      "        [ 0.0308],\n",
      "        [ 0.0312],\n",
      "        [-0.0077],\n",
      "        [ 0.0827],\n",
      "        [ 0.1018],\n",
      "        [ 0.0395],\n",
      "        [ 0.0603],\n",
      "        [ 0.0140],\n",
      "        [ 0.0079],\n",
      "        [ 0.0634],\n",
      "        [ 0.0214],\n",
      "        [ 0.0541],\n",
      "        [ 0.0388],\n",
      "        [ 0.0948],\n",
      "        [ 0.1724],\n",
      "        [ 0.0697],\n",
      "        [ 0.1116],\n",
      "        [ 0.0455],\n",
      "        [ 0.0452],\n",
      "        [ 0.0277],\n",
      "        [ 0.0540],\n",
      "        [ 0.0358],\n",
      "        [ 0.0468]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1164, 0.1156, 0.1150, 0.1143, 0.1125, 0.1106, 0.1071, 0.1084, 0.1057,\n",
      "        0.1049, 0.1078, 0.1077, 0.1077, 0.1102, 0.1097, 0.1125, 0.1146, 0.1149,\n",
      "        0.1179, 0.1122, 0.1155, 0.1153, 0.1143, 0.1140, 0.1134, 0.1150, 0.1152,\n",
      "        0.1156, 0.1153, 0.1143, 0.1146, 0.1155], device='cuda:0')\n",
      "tensor([[ 0.0222],\n",
      "        [ 0.0416],\n",
      "        [ 0.0224],\n",
      "        [ 0.0099],\n",
      "        [ 0.0311],\n",
      "        [ 0.0278],\n",
      "        [ 0.0108],\n",
      "        [ 0.0828],\n",
      "        [ 0.0391],\n",
      "        [-0.0551],\n",
      "        [ 0.0942],\n",
      "        [ 0.0166],\n",
      "        [ 0.0307],\n",
      "        [ 0.0314],\n",
      "        [ 0.0247],\n",
      "        [ 0.0123],\n",
      "        [ 0.0162],\n",
      "        [ 0.0548],\n",
      "        [ 0.0249],\n",
      "        [ 0.0722],\n",
      "        [ 0.0681],\n",
      "        [-0.0101],\n",
      "        [ 0.0654],\n",
      "        [ 0.0525],\n",
      "        [ 0.0564],\n",
      "        [ 0.0879],\n",
      "        [ 0.1059],\n",
      "        [ 0.0678],\n",
      "        [ 0.1356],\n",
      "        [ 0.0043],\n",
      "        [ 0.1481],\n",
      "        [ 0.1250]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1161, 0.1145, 0.1121, 0.1112, 0.1112, 0.1117, 0.1091, 0.1091, 0.1111,\n",
      "        0.1125, 0.1108, 0.1093, 0.1112, 0.1100, 0.1091, 0.1097, 0.1088, 0.1086,\n",
      "        0.1083, 0.1136, 0.1143, 0.1137, 0.1145, 0.1158, 0.1150, 0.1184, 0.1170,\n",
      "        0.1177, 0.1189, 0.1209, 0.1211, 0.1190], device='cuda:0')\n",
      "tensor([[-0.0123],\n",
      "        [ 0.0357],\n",
      "        [ 0.0949],\n",
      "        [ 0.0188],\n",
      "        [ 0.0124],\n",
      "        [ 0.0920],\n",
      "        [ 0.0088],\n",
      "        [ 0.0424],\n",
      "        [ 0.0359],\n",
      "        [ 0.1433],\n",
      "        [ 0.0593],\n",
      "        [ 0.0734],\n",
      "        [ 0.0380],\n",
      "        [ 0.0687],\n",
      "        [ 0.0157],\n",
      "        [ 0.0200],\n",
      "        [ 0.0583],\n",
      "        [ 0.0066],\n",
      "        [ 0.0675],\n",
      "        [ 0.0513],\n",
      "        [ 0.0428],\n",
      "        [ 0.0392],\n",
      "        [ 0.0564],\n",
      "        [ 0.0213],\n",
      "        [ 0.0087],\n",
      "        [ 0.0208],\n",
      "        [ 0.0136],\n",
      "        [-0.0220],\n",
      "        [-0.0276],\n",
      "        [ 0.0597],\n",
      "        [-0.0267],\n",
      "        [-0.0290]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1195, 0.1190, 0.1227, 0.1260, 0.1292, 0.1285, 0.1283, 0.1307, 0.1307,\n",
      "        0.1311, 0.1302, 0.1333, 0.1305, 0.1314, 0.1300, 0.1304, 0.1286, 0.1286,\n",
      "        0.1280, 0.1301, 0.1285, 0.1271, 0.1271, 0.1245, 0.1226, 0.1252, 0.1255,\n",
      "        0.1238, 0.1269, 0.1292, 0.1298, 0.1292], device='cuda:0')\n",
      "tensor([[ 0.0340],\n",
      "        [ 0.0487],\n",
      "        [ 0.0062],\n",
      "        [ 0.0438],\n",
      "        [ 0.1242],\n",
      "        [ 0.2083],\n",
      "        [ 0.0443],\n",
      "        [ 0.0158],\n",
      "        [ 0.0155],\n",
      "        [ 0.0326],\n",
      "        [-0.0310],\n",
      "        [ 0.1344],\n",
      "        [ 0.0677],\n",
      "        [ 0.0390],\n",
      "        [ 0.0562],\n",
      "        [ 0.1099],\n",
      "        [ 0.0797],\n",
      "        [ 0.0780],\n",
      "        [ 0.0554],\n",
      "        [-0.0483],\n",
      "        [ 0.0156],\n",
      "        [ 0.0330],\n",
      "        [ 0.0219],\n",
      "        [ 0.0158],\n",
      "        [-0.0044],\n",
      "        [ 0.0336],\n",
      "        [ 0.0248],\n",
      "        [ 0.1033],\n",
      "        [ 0.0276],\n",
      "        [ 0.0271],\n",
      "        [ 0.0235],\n",
      "        [ 0.1536]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1292, 0.1274, 0.1270, 0.1261, 0.1243, 0.1211, 0.1212, 0.1201, 0.1167,\n",
      "        0.1174, 0.1161, 0.1161, 0.1139, 0.1115, 0.1117, 0.1139, 0.1125, 0.1133,\n",
      "        0.1146, 0.1140, 0.1124, 0.1109, 0.1153, 0.1140, 0.1127, 0.1131, 0.1158,\n",
      "        0.1149, 0.1165, 0.1161, 0.1150, 0.1156], device='cuda:0')\n",
      "tensor([[-0.0028],\n",
      "        [-0.0041],\n",
      "        [ 0.0102],\n",
      "        [ 0.0240],\n",
      "        [ 0.0959],\n",
      "        [ 0.0671],\n",
      "        [ 0.1487],\n",
      "        [-0.0088],\n",
      "        [ 0.0282],\n",
      "        [ 0.0155],\n",
      "        [ 0.0407],\n",
      "        [ 0.0337],\n",
      "        [ 0.0067],\n",
      "        [ 0.0542],\n",
      "        [ 0.0042],\n",
      "        [ 0.0276],\n",
      "        [-0.0165],\n",
      "        [ 0.0799],\n",
      "        [ 0.0398],\n",
      "        [ 0.0259],\n",
      "        [-0.0051],\n",
      "        [ 0.0983],\n",
      "        [ 0.0897],\n",
      "        [ 0.0188],\n",
      "        [ 0.1562],\n",
      "        [ 0.0024],\n",
      "        [ 0.0800],\n",
      "        [ 0.0112],\n",
      "        [ 0.0221],\n",
      "        [ 0.0419],\n",
      "        [-0.0854],\n",
      "        [ 0.0966]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1139, 0.1139, 0.1145, 0.1130, 0.1140, 0.1133, 0.1145, 0.1152, 0.1170,\n",
      "        0.1170, 0.1164, 0.1159, 0.1152, 0.1153, 0.1177, 0.1179, 0.1209, 0.1195,\n",
      "        0.1208, 0.1221, 0.1238, 0.1276, 0.1252, 0.1282, 0.1276, 0.1261, 0.1258,\n",
      "        0.1243, 0.1227, 0.1233, 0.1255, 0.1271], device='cuda:0')\n",
      "tensor([[ 0.0490],\n",
      "        [ 0.1056],\n",
      "        [ 0.0116],\n",
      "        [ 0.0518],\n",
      "        [-0.0013],\n",
      "        [ 0.0399],\n",
      "        [ 0.0468],\n",
      "        [-0.0216],\n",
      "        [ 0.0651],\n",
      "        [ 0.0185],\n",
      "        [ 0.1069],\n",
      "        [ 0.0620],\n",
      "        [ 0.1081],\n",
      "        [ 0.0690],\n",
      "        [ 0.0462],\n",
      "        [-0.0014],\n",
      "        [ 0.0601],\n",
      "        [ 0.0557],\n",
      "        [ 0.0080],\n",
      "        [ 0.0279],\n",
      "        [ 0.0484],\n",
      "        [ 0.0438],\n",
      "        [ 0.0361],\n",
      "        [ 0.1101],\n",
      "        [ 0.0285],\n",
      "        [ 0.0555],\n",
      "        [ 0.0219],\n",
      "        [ 0.1009],\n",
      "        [ 0.1507],\n",
      "        [ 0.0183],\n",
      "        [ 0.0195],\n",
      "        [ 0.0458]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1258, 0.1251, 0.1227, 0.1214, 0.1221, 0.1223, 0.1221, 0.1184, 0.1190,\n",
      "        0.1195, 0.1171, 0.1171, 0.1174, 0.1173, 0.1189, 0.1201, 0.1177, 0.1211,\n",
      "        0.1217, 0.1207, 0.1204, 0.1215, 0.1235, 0.1249, 0.1236, 0.1217, 0.1229,\n",
      "        0.1230, 0.1233, 0.1230, 0.1236, 0.1239], device='cuda:0')\n",
      "tensor([[ 0.0669],\n",
      "        [ 0.0184],\n",
      "        [-0.0070],\n",
      "        [ 0.0014],\n",
      "        [ 0.0115],\n",
      "        [ 0.0669],\n",
      "        [ 0.2210],\n",
      "        [ 0.0572],\n",
      "        [-0.0149],\n",
      "        [ 0.0293],\n",
      "        [-0.0300],\n",
      "        [ 0.0304],\n",
      "        [ 0.0140],\n",
      "        [-0.0194],\n",
      "        [ 0.0975],\n",
      "        [ 0.0621],\n",
      "        [ 0.0518],\n",
      "        [ 0.0710],\n",
      "        [ 0.0173],\n",
      "        [ 0.0407],\n",
      "        [ 0.0621],\n",
      "        [ 0.0316],\n",
      "        [ 0.0215],\n",
      "        [ 0.0301],\n",
      "        [ 0.0286],\n",
      "        [ 0.1103],\n",
      "        [ 0.0508],\n",
      "        [ 0.0297],\n",
      "        [ 0.0903],\n",
      "        [ 0.0369],\n",
      "        [ 0.1322],\n",
      "        [ 0.0974]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1257, 0.1263, 0.1260, 0.1254, 0.1264, 0.1261, 0.1254, 0.1263, 0.1246,\n",
      "        0.1236, 0.1254, 0.1251, 0.1246, 0.1248, 0.1238, 0.1251, 0.1261, 0.1264,\n",
      "        0.1274, 0.1270, 0.1283, 0.1274, 0.1267, 0.1252, 0.1274, 0.1263, 0.1295,\n",
      "        0.1305, 0.1328, 0.1350, 0.1338, 0.1323], device='cuda:0')\n",
      "tensor([[ 0.2516],\n",
      "        [ 0.1730],\n",
      "        [ 0.0614],\n",
      "        [ 0.1030],\n",
      "        [ 0.0844],\n",
      "        [ 0.0365],\n",
      "        [ 0.0395],\n",
      "        [ 0.0045],\n",
      "        [-0.0154],\n",
      "        [ 0.0066],\n",
      "        [ 0.0302],\n",
      "        [ 0.0338],\n",
      "        [ 0.0649],\n",
      "        [ 0.0228],\n",
      "        [ 0.0453],\n",
      "        [ 0.0170],\n",
      "        [ 0.0343],\n",
      "        [-0.0010],\n",
      "        [ 0.0615],\n",
      "        [ 0.0924],\n",
      "        [ 0.0436],\n",
      "        [ 0.0831],\n",
      "        [ 0.0288],\n",
      "        [ 0.0368],\n",
      "        [ 0.0226],\n",
      "        [-0.0087],\n",
      "        [ 0.0226],\n",
      "        [ 0.0741],\n",
      "        [ 0.0614],\n",
      "        [ 0.0190],\n",
      "        [ 0.0721],\n",
      "        [ 0.0408]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1316, 0.1302, 0.1314, 0.1307, 0.1300, 0.1283, 0.1295, 0.1280, 0.1307,\n",
      "        0.1294, 0.1286, 0.1289, 0.1264, 0.1264, 0.1238, 0.1243, 0.1242, 0.1223,\n",
      "        0.1230, 0.1235, 0.1242, 0.1223, 0.1220, 0.1208, 0.1204, 0.1211, 0.1199,\n",
      "        0.1189, 0.1202, 0.1136, 0.1100, 0.1108], device='cuda:0')\n",
      "tensor([[ 0.0365],\n",
      "        [ 0.0386],\n",
      "        [ 0.0601],\n",
      "        [ 0.1496],\n",
      "        [ 0.0026],\n",
      "        [ 0.0120],\n",
      "        [ 0.0103],\n",
      "        [-0.0014],\n",
      "        [ 0.0566],\n",
      "        [ 0.0419],\n",
      "        [ 0.0074],\n",
      "        [ 0.0002],\n",
      "        [-0.0186],\n",
      "        [ 0.0714],\n",
      "        [ 0.0829],\n",
      "        [-0.0260],\n",
      "        [ 0.0059],\n",
      "        [ 0.0598],\n",
      "        [ 0.0053],\n",
      "        [ 0.0732],\n",
      "        [ 0.0089],\n",
      "        [ 0.0319],\n",
      "        [ 0.0537],\n",
      "        [ 0.0428],\n",
      "        [ 0.0562],\n",
      "        [ 0.0781],\n",
      "        [-0.0032],\n",
      "        [ 0.1143],\n",
      "        [ 0.1262],\n",
      "        [ 0.0884],\n",
      "        [ 0.0827],\n",
      "        [-0.0241]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1097, 0.1102, 0.1108, 0.1106, 0.1102, 0.1091, 0.1096, 0.1088, 0.1072,\n",
      "        0.1080, 0.1083, 0.1103, 0.1106, 0.1119, 0.1119, 0.1097, 0.1117, 0.1122,\n",
      "        0.1142, 0.1134, 0.1134, 0.1148, 0.1148, 0.1159, 0.1159, 0.1161, 0.1155,\n",
      "        0.1146, 0.1134, 0.1124, 0.1114, 0.1099], device='cuda:0')\n",
      "tensor([[ 0.0315],\n",
      "        [ 0.0482],\n",
      "        [-0.0410],\n",
      "        [ 0.0070],\n",
      "        [ 0.0921],\n",
      "        [-0.0081],\n",
      "        [ 0.0183],\n",
      "        [ 0.1084],\n",
      "        [ 0.0368],\n",
      "        [ 0.0667],\n",
      "        [ 0.1422],\n",
      "        [ 0.0338],\n",
      "        [ 0.0597],\n",
      "        [-0.0198],\n",
      "        [ 0.0672],\n",
      "        [ 0.0488],\n",
      "        [ 0.0247],\n",
      "        [ 0.0504],\n",
      "        [ 0.0383],\n",
      "        [-0.0271],\n",
      "        [ 0.0246],\n",
      "        [ 0.0154],\n",
      "        [ 0.0005],\n",
      "        [ 0.0457],\n",
      "        [ 0.0233],\n",
      "        [-0.0057],\n",
      "        [ 0.0024],\n",
      "        [ 0.0303],\n",
      "        [ 0.0514],\n",
      "        [ 0.0368],\n",
      "        [ 0.0555],\n",
      "        [ 0.0334]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1100, 0.1103, 0.1102, 0.1096, 0.1115, 0.1139, 0.1122, 0.1124, 0.1130,\n",
      "        0.1119, 0.1105, 0.1100, 0.1103, 0.1102, 0.1100, 0.1086, 0.1102, 0.1106,\n",
      "        0.1108, 0.1094, 0.1102, 0.1100, 0.1097, 0.1087, 0.1093, 0.1118, 0.1111,\n",
      "        0.1099, 0.1100, 0.1111, 0.1100, 0.1103], device='cuda:0')\n",
      "tensor([[ 0.0092],\n",
      "        [ 0.0538],\n",
      "        [ 0.0199],\n",
      "        [ 0.0314],\n",
      "        [ 0.0178],\n",
      "        [ 0.0767],\n",
      "        [ 0.0433],\n",
      "        [ 0.0303],\n",
      "        [ 0.0910],\n",
      "        [ 0.1301],\n",
      "        [ 0.0530],\n",
      "        [ 0.0647],\n",
      "        [-0.0042],\n",
      "        [ 0.0947],\n",
      "        [ 0.1137],\n",
      "        [ 0.0296],\n",
      "        [ 0.0095],\n",
      "        [ 0.0298],\n",
      "        [ 0.0539],\n",
      "        [ 0.0896],\n",
      "        [ 0.0714],\n",
      "        [ 0.0769],\n",
      "        [ 0.0333],\n",
      "        [ 0.0092],\n",
      "        [ 0.0303],\n",
      "        [ 0.0321],\n",
      "        [ 0.0804],\n",
      "        [ 0.0509],\n",
      "        [ 0.1064],\n",
      "        [-0.0279],\n",
      "        [ 0.0213],\n",
      "        [-0.0085]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1096, 0.1117, 0.1130, 0.1158, 0.1152, 0.1124, 0.1128, 0.1133, 0.1130,\n",
      "        0.1125, 0.1131, 0.1161, 0.1152, 0.1162, 0.1164, 0.1162, 0.1177, 0.1162,\n",
      "        0.1158, 0.1139, 0.1155, 0.1148, 0.1139, 0.1136, 0.1142, 0.1146, 0.1165,\n",
      "        0.1161, 0.1153, 0.1150, 0.1171, 0.1193], device='cuda:0')\n",
      "tensor([[ 0.0889],\n",
      "        [ 0.0369],\n",
      "        [ 0.0531],\n",
      "        [ 0.0963],\n",
      "        [ 0.0684],\n",
      "        [ 0.2533],\n",
      "        [ 0.1042],\n",
      "        [ 0.1317],\n",
      "        [ 0.0854],\n",
      "        [ 0.0123],\n",
      "        [ 0.0132],\n",
      "        [ 0.0930],\n",
      "        [ 0.0141],\n",
      "        [ 0.0172],\n",
      "        [ 0.0982],\n",
      "        [ 0.1585],\n",
      "        [ 0.1149],\n",
      "        [ 0.0735],\n",
      "        [ 0.0180],\n",
      "        [ 0.0668],\n",
      "        [ 0.0271],\n",
      "        [ 0.0304],\n",
      "        [-0.0037],\n",
      "        [-0.0280],\n",
      "        [ 0.0430],\n",
      "        [ 0.0076],\n",
      "        [ 0.0376],\n",
      "        [ 0.0348],\n",
      "        [ 0.0421],\n",
      "        [ 0.0052],\n",
      "        [ 0.0603],\n",
      "        [ 0.0800]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1204, 0.1190, 0.1195, 0.1171, 0.1179, 0.1180, 0.1171, 0.1162, 0.1167,\n",
      "        0.1142, 0.1149, 0.1153, 0.1177, 0.1179, 0.1201, 0.1181, 0.1187, 0.1190,\n",
      "        0.1193, 0.1198, 0.1186, 0.1180, 0.1177, 0.1180, 0.1187, 0.1170, 0.1174,\n",
      "        0.1171, 0.1179, 0.1177, 0.1177, 0.1179], device='cuda:0')\n",
      "tensor([[-0.0051],\n",
      "        [ 0.0473],\n",
      "        [-0.0197],\n",
      "        [-0.0016],\n",
      "        [ 0.1005],\n",
      "        [ 0.0328],\n",
      "        [ 0.0622],\n",
      "        [ 0.1523],\n",
      "        [ 0.1490],\n",
      "        [ 0.0703],\n",
      "        [-0.0480],\n",
      "        [ 0.1090],\n",
      "        [ 0.1055],\n",
      "        [ 0.0366],\n",
      "        [ 0.0395],\n",
      "        [ 0.0145],\n",
      "        [ 0.0373],\n",
      "        [ 0.0384],\n",
      "        [ 0.0161],\n",
      "        [ 0.0207],\n",
      "        [ 0.0534],\n",
      "        [ 0.0813],\n",
      "        [ 0.0770],\n",
      "        [-0.0126],\n",
      "        [ 0.0343],\n",
      "        [-0.0247],\n",
      "        [ 0.0220],\n",
      "        [ 0.1033],\n",
      "        [ 0.0011],\n",
      "        [ 0.0091],\n",
      "        [ 0.0493],\n",
      "        [ 0.0436]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1183, 0.1180, 0.1195, 0.1124, 0.1094, 0.1097, 0.1090, 0.1059, 0.1086,\n",
      "        0.1077, 0.1077, 0.1097, 0.1086, 0.1080, 0.1078, 0.1012, 0.1024, 0.1015,\n",
      "        0.1009, 0.1037, 0.1038, 0.1029, 0.1024, 0.1010, 0.0997, 0.0987, 0.0982,\n",
      "        0.0991, 0.0988, 0.0963, 0.0970, 0.0948], device='cuda:0')\n",
      "tensor([[ 0.0084],\n",
      "        [ 0.0444],\n",
      "        [ 0.1248],\n",
      "        [-0.0244],\n",
      "        [-0.0363],\n",
      "        [ 0.1169],\n",
      "        [ 0.1275],\n",
      "        [ 0.0537],\n",
      "        [ 0.0335],\n",
      "        [ 0.0446],\n",
      "        [ 0.0224],\n",
      "        [ 0.0740],\n",
      "        [ 0.0587],\n",
      "        [ 0.1225],\n",
      "        [ 0.0369],\n",
      "        [ 0.1073],\n",
      "        [ 0.0945],\n",
      "        [ 0.0363],\n",
      "        [ 0.0304],\n",
      "        [ 0.0317],\n",
      "        [-0.0130],\n",
      "        [ 0.0068],\n",
      "        [ 0.0291],\n",
      "        [ 0.1388],\n",
      "        [ 0.1027],\n",
      "        [ 0.0121],\n",
      "        [ 0.0398],\n",
      "        [ 0.0235],\n",
      "        [ 0.0552],\n",
      "        [ 0.0078],\n",
      "        [ 0.0170],\n",
      "        [ 0.0718]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0957, 0.0950, 0.0957, 0.0966, 0.0967, 0.0964, 0.0963, 0.0954, 0.0978,\n",
      "        0.0973, 0.0982, 0.0990, 0.0993, 0.0981, 0.0975, 0.0962, 0.0960, 0.0954,\n",
      "        0.0979, 0.0984, 0.0972, 0.0964, 0.0951, 0.0942, 0.0953, 0.0939, 0.0931,\n",
      "        0.0929, 0.0913, 0.0926, 0.0925, 0.0931], device='cuda:0')\n",
      "tensor([[ 0.0062],\n",
      "        [ 0.1099],\n",
      "        [ 0.0624],\n",
      "        [-0.0134],\n",
      "        [ 0.0359],\n",
      "        [-0.0090],\n",
      "        [ 0.0337],\n",
      "        [ 0.0485],\n",
      "        [ 0.0944],\n",
      "        [ 0.0090],\n",
      "        [ 0.0587],\n",
      "        [ 0.0772],\n",
      "        [-0.0167],\n",
      "        [ 0.1872],\n",
      "        [ 0.1460],\n",
      "        [ 0.0436],\n",
      "        [ 0.0314],\n",
      "        [ 0.0226],\n",
      "        [ 0.0438],\n",
      "        [ 0.0743],\n",
      "        [-0.0253],\n",
      "        [ 0.0611],\n",
      "        [ 0.0332],\n",
      "        [ 0.0236],\n",
      "        [ 0.0347],\n",
      "        [ 0.1336],\n",
      "        [ 0.0731],\n",
      "        [ 0.0406],\n",
      "        [ 0.0339],\n",
      "        [ 0.0134],\n",
      "        [ 0.0367],\n",
      "        [ 0.0174]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0933, 0.0923, 0.0926, 0.0919, 0.0919, 0.0964, 0.0975, 0.0988, 0.0985,\n",
      "        0.0993, 0.0981, 0.0976, 0.0987, 0.0963, 0.0966, 0.0990, 0.0975, 0.0982,\n",
      "        0.0972, 0.0948, 0.0950, 0.0959, 0.0939, 0.0951, 0.0956, 0.0956, 0.0972,\n",
      "        0.0962, 0.0969, 0.0984, 0.1000, 0.1025], device='cuda:0')\n",
      "tensor([[ 0.0414],\n",
      "        [ 0.0431],\n",
      "        [-0.0086],\n",
      "        [ 0.2026],\n",
      "        [ 0.1934],\n",
      "        [ 0.0467],\n",
      "        [ 0.0576],\n",
      "        [ 0.0749],\n",
      "        [ 0.0645],\n",
      "        [ 0.0029],\n",
      "        [ 0.0312],\n",
      "        [ 0.0294],\n",
      "        [ 0.0113],\n",
      "        [ 0.0324],\n",
      "        [ 0.0525],\n",
      "        [ 0.1226],\n",
      "        [-0.0171],\n",
      "        [ 0.0220],\n",
      "        [ 0.1130],\n",
      "        [-0.0234],\n",
      "        [ 0.0302],\n",
      "        [-0.0144],\n",
      "        [ 0.0196],\n",
      "        [ 0.0148],\n",
      "        [ 0.0679],\n",
      "        [ 0.0114],\n",
      "        [ 0.0449],\n",
      "        [ 0.0721],\n",
      "        [ 0.1018],\n",
      "        [ 0.1094],\n",
      "        [ 0.0362],\n",
      "        [ 0.0428]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1021, 0.1018, 0.1001, 0.1026, 0.1032, 0.1032, 0.1029, 0.1022, 0.1046,\n",
      "        0.1026, 0.1019, 0.1035, 0.1032, 0.1034, 0.1035, 0.1046, 0.1047, 0.1056,\n",
      "        0.1053, 0.1071, 0.1065, 0.1080, 0.1062, 0.1062, 0.1071, 0.1090, 0.1094,\n",
      "        0.1083, 0.1074, 0.1065, 0.1047, 0.1037], device='cuda:0')\n",
      "tensor([[ 0.1262],\n",
      "        [ 0.0280],\n",
      "        [ 0.0305],\n",
      "        [ 0.1312],\n",
      "        [-0.0585],\n",
      "        [-0.0125],\n",
      "        [ 0.0185],\n",
      "        [ 0.0180],\n",
      "        [ 0.0063],\n",
      "        [ 0.0082],\n",
      "        [ 0.0354],\n",
      "        [ 0.0503],\n",
      "        [ 0.0341],\n",
      "        [ 0.0235],\n",
      "        [ 0.0102],\n",
      "        [ 0.0165],\n",
      "        [ 0.0043],\n",
      "        [ 0.0362],\n",
      "        [ 0.0565],\n",
      "        [ 0.0961],\n",
      "        [ 0.1619],\n",
      "        [ 0.0751],\n",
      "        [ 0.0774],\n",
      "        [ 0.0286],\n",
      "        [ 0.0623],\n",
      "        [ 0.0186],\n",
      "        [-0.0038],\n",
      "        [ 0.0277],\n",
      "        [ 0.0582],\n",
      "        [ 0.0578],\n",
      "        [ 0.0217],\n",
      "        [ 0.0305]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1041, 0.1057, 0.1059, 0.1060, 0.1057, 0.1066, 0.1065, 0.1060, 0.1057,\n",
      "        0.1053, 0.1057, 0.1063, 0.1072, 0.1117, 0.1119, 0.1105, 0.1096, 0.1099,\n",
      "        0.1099, 0.1093, 0.1099, 0.1091, 0.1075, 0.1094, 0.1083, 0.1096, 0.1097,\n",
      "        0.1112, 0.1112, 0.1115, 0.1121, 0.1134], device='cuda:0')\n",
      "tensor([[-0.0162],\n",
      "        [-0.0079],\n",
      "        [ 0.0369],\n",
      "        [ 0.0198],\n",
      "        [ 0.0459],\n",
      "        [ 0.0336],\n",
      "        [ 0.1655],\n",
      "        [ 0.0341],\n",
      "        [ 0.0378],\n",
      "        [ 0.0169],\n",
      "        [ 0.0415],\n",
      "        [ 0.0278],\n",
      "        [ 0.0783],\n",
      "        [ 0.0594],\n",
      "        [ 0.0108],\n",
      "        [ 0.0143],\n",
      "        [ 0.0330],\n",
      "        [ 0.0753],\n",
      "        [ 0.0547],\n",
      "        [ 0.1209],\n",
      "        [ 0.0136],\n",
      "        [ 0.0522],\n",
      "        [ 0.0368],\n",
      "        [ 0.0266],\n",
      "        [ 0.0640],\n",
      "        [ 0.1299],\n",
      "        [-0.0131],\n",
      "        [ 0.0287],\n",
      "        [ 0.0478],\n",
      "        [-0.0018],\n",
      "        [ 0.1787],\n",
      "        [ 0.0048]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1153, 0.1156, 0.1173, 0.1170, 0.1179, 0.1170, 0.1189, 0.1198, 0.1209,\n",
      "        0.1209, 0.1180, 0.1221, 0.1235, 0.1224, 0.1218, 0.1229, 0.1233, 0.1232,\n",
      "        0.1232, 0.1209, 0.1223, 0.1227, 0.1240, 0.1235, 0.1229, 0.1208, 0.1209,\n",
      "        0.1201, 0.1214, 0.1180, 0.1184, 0.1186], device='cuda:0')\n",
      "tensor([[ 0.0257],\n",
      "        [ 0.0587],\n",
      "        [ 0.0641],\n",
      "        [ 0.0476],\n",
      "        [ 0.0303],\n",
      "        [ 0.0153],\n",
      "        [ 0.0124],\n",
      "        [ 0.0003],\n",
      "        [ 0.0106],\n",
      "        [-0.0041],\n",
      "        [ 0.0290],\n",
      "        [-0.0102],\n",
      "        [ 0.0400],\n",
      "        [ 0.0128],\n",
      "        [ 0.0477],\n",
      "        [ 0.0511],\n",
      "        [ 0.0783],\n",
      "        [ 0.0748],\n",
      "        [ 0.0240],\n",
      "        [ 0.1253],\n",
      "        [ 0.0373],\n",
      "        [ 0.0199],\n",
      "        [ 0.0781],\n",
      "        [ 0.0753],\n",
      "        [ 0.1031],\n",
      "        [ 0.1333],\n",
      "        [ 0.0254],\n",
      "        [ 0.0261],\n",
      "        [ 0.0445],\n",
      "        [-0.0002],\n",
      "        [ 0.0276],\n",
      "        [ 0.1710]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1201, 0.1196, 0.1195, 0.1207, 0.1196, 0.1193, 0.1201, 0.1212, 0.1198,\n",
      "        0.1214, 0.1224, 0.1236, 0.1252, 0.1233, 0.1223, 0.1224, 0.1196, 0.1176,\n",
      "        0.1162, 0.1162, 0.1143, 0.1122, 0.1131, 0.1124, 0.1125, 0.1103, 0.1084,\n",
      "        0.1034, 0.1024, 0.1025, 0.1026, 0.1012], device='cuda:0')\n",
      "tensor([[ 0.0078],\n",
      "        [-0.0287],\n",
      "        [ 0.0492],\n",
      "        [ 0.1097],\n",
      "        [-0.0097],\n",
      "        [ 0.0182],\n",
      "        [ 0.0221],\n",
      "        [ 0.0429],\n",
      "        [ 0.0485],\n",
      "        [ 0.0234],\n",
      "        [ 0.0359],\n",
      "        [ 0.0157],\n",
      "        [ 0.0263],\n",
      "        [ 0.1061],\n",
      "        [ 0.0315],\n",
      "        [ 0.1133],\n",
      "        [ 0.0540],\n",
      "        [ 0.0392],\n",
      "        [ 0.0484],\n",
      "        [ 0.0288],\n",
      "        [-0.0164],\n",
      "        [ 0.0600],\n",
      "        [ 0.0339],\n",
      "        [ 0.0786],\n",
      "        [ 0.0535],\n",
      "        [ 0.0959],\n",
      "        [ 0.1300],\n",
      "        [ 0.0617],\n",
      "        [ 0.0364],\n",
      "        [ 0.0362],\n",
      "        [ 0.0128],\n",
      "        [ 0.0091]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1032, 0.1040, 0.1047, 0.1032, 0.1004, 0.1015, 0.0994, 0.0976, 0.0951,\n",
      "        0.0993, 0.1040, 0.1031, 0.1034, 0.1009, 0.1010, 0.1018, 0.1018, 0.1016,\n",
      "        0.1053, 0.1057, 0.1077, 0.1081, 0.1047, 0.1040, 0.1049, 0.1074, 0.1087,\n",
      "        0.1081, 0.1068, 0.1047, 0.1063, 0.1052], device='cuda:0')\n",
      "tensor([[ 0.0466],\n",
      "        [ 0.0378],\n",
      "        [ 0.0540],\n",
      "        [-0.0108],\n",
      "        [ 0.0419],\n",
      "        [ 0.0702],\n",
      "        [-0.0002],\n",
      "        [ 0.0453],\n",
      "        [ 0.0578],\n",
      "        [ 0.0020],\n",
      "        [ 0.0655],\n",
      "        [ 0.0420],\n",
      "        [-0.0175],\n",
      "        [ 0.0500],\n",
      "        [-0.0162],\n",
      "        [ 0.0263],\n",
      "        [ 0.1714],\n",
      "        [ 0.0961],\n",
      "        [ 0.1303],\n",
      "        [-0.0230],\n",
      "        [ 0.0870],\n",
      "        [ 0.2277],\n",
      "        [ 0.1977],\n",
      "        [ 0.0782],\n",
      "        [ 0.0256],\n",
      "        [ 0.0701],\n",
      "        [ 0.0099],\n",
      "        [-0.0007],\n",
      "        [ 0.0323],\n",
      "        [ 0.0155],\n",
      "        [-0.0051],\n",
      "        [ 0.0255]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1040, 0.1063, 0.1094, 0.1086, 0.1075, 0.1081, 0.1086, 0.1100, 0.1052,\n",
      "        0.1029, 0.1000, 0.0991, 0.0979, 0.0981, 0.0997, 0.1052, 0.1078, 0.1080,\n",
      "        0.1068, 0.1090, 0.1084, 0.1069, 0.1059, 0.1063, 0.1053, 0.1074, 0.1087,\n",
      "        0.1081, 0.1081, 0.1065, 0.1077, 0.1109], device='cuda:0')\n",
      "tensor([[-0.0171],\n",
      "        [ 0.0134],\n",
      "        [ 0.0391],\n",
      "        [ 0.0223],\n",
      "        [ 0.0659],\n",
      "        [ 0.3011],\n",
      "        [ 0.0798],\n",
      "        [-0.0081],\n",
      "        [ 0.0627],\n",
      "        [ 0.0553],\n",
      "        [ 0.0545],\n",
      "        [ 0.0346],\n",
      "        [ 0.0141],\n",
      "        [ 0.0760],\n",
      "        [ 0.0566],\n",
      "        [ 0.0615],\n",
      "        [ 0.0779],\n",
      "        [ 0.0857],\n",
      "        [ 0.0227],\n",
      "        [ 0.0688],\n",
      "        [ 0.0020],\n",
      "        [ 0.0305],\n",
      "        [ 0.1264],\n",
      "        [ 0.0476],\n",
      "        [ 0.0445],\n",
      "        [ 0.0729],\n",
      "        [ 0.0441],\n",
      "        [-0.0211],\n",
      "        [ 0.0620],\n",
      "        [ 0.1517],\n",
      "        [ 0.0413],\n",
      "        [ 0.0360]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1142, 0.1130, 0.1148, 0.1137, 0.1149, 0.1162, 0.1146, 0.1155, 0.1137,\n",
      "        0.1152, 0.1148, 0.1134, 0.1130, 0.1149, 0.1146, 0.1162, 0.1161, 0.1124,\n",
      "        0.1136, 0.1146, 0.1140, 0.1158, 0.1140, 0.1121, 0.1124, 0.1148, 0.1139,\n",
      "        0.1150, 0.1152, 0.1152, 0.1148, 0.1149], device='cuda:0')\n",
      "tensor([[ 0.0390],\n",
      "        [ 0.0228],\n",
      "        [ 0.0442],\n",
      "        [ 0.0390],\n",
      "        [ 0.0470],\n",
      "        [-0.0215],\n",
      "        [ 0.0435],\n",
      "        [ 0.0127],\n",
      "        [ 0.0010],\n",
      "        [ 0.0781],\n",
      "        [ 0.0985],\n",
      "        [ 0.0262],\n",
      "        [ 0.1887],\n",
      "        [ 0.0764],\n",
      "        [-0.0098],\n",
      "        [ 0.0543],\n",
      "        [-0.0036],\n",
      "        [ 0.0292],\n",
      "        [ 0.0645],\n",
      "        [ 0.1493],\n",
      "        [ 0.0505],\n",
      "        [ 0.0033],\n",
      "        [ 0.1157],\n",
      "        [ 0.0179],\n",
      "        [ 0.0986],\n",
      "        [ 0.0792],\n",
      "        [ 0.0969],\n",
      "        [ 0.1020],\n",
      "        [ 0.0685],\n",
      "        [ 0.0355],\n",
      "        [ 0.0138],\n",
      "        [ 0.0239]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1146, 0.1142, 0.1131, 0.1136, 0.1131, 0.1109, 0.1094, 0.1069, 0.1087,\n",
      "        0.1084, 0.1068, 0.1077, 0.1096, 0.1174, 0.1196, 0.1220, 0.1201, 0.1215,\n",
      "        0.1236, 0.1255, 0.1274, 0.1277, 0.1307, 0.1304, 0.1305, 0.1311, 0.1325,\n",
      "        0.1341, 0.1325, 0.1336, 0.1370, 0.1375], device='cuda:0')\n",
      "tensor([[ 0.1239],\n",
      "        [ 0.0882],\n",
      "        [ 0.0426],\n",
      "        [ 0.0841],\n",
      "        [ 0.0349],\n",
      "        [ 0.1066],\n",
      "        [ 0.1403],\n",
      "        [ 0.1523],\n",
      "        [-0.0051],\n",
      "        [ 0.0043],\n",
      "        [ 0.0499],\n",
      "        [ 0.0596],\n",
      "        [ 0.0029],\n",
      "        [ 0.0488],\n",
      "        [ 0.1129],\n",
      "        [ 0.0313],\n",
      "        [ 0.0052],\n",
      "        [ 0.0117],\n",
      "        [ 0.0384],\n",
      "        [ 0.0403],\n",
      "        [-0.0082],\n",
      "        [ 0.0251],\n",
      "        [-0.0107],\n",
      "        [ 0.0597],\n",
      "        [ 0.0101],\n",
      "        [ 0.0655],\n",
      "        [ 0.0449],\n",
      "        [-0.0262],\n",
      "        [ 0.0914],\n",
      "        [ 0.0430],\n",
      "        [ 0.0499],\n",
      "        [-0.0120]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1397, 0.1401, 0.1429, 0.1455, 0.1435, 0.1407, 0.1381, 0.1385, 0.1339,\n",
      "        0.1353, 0.1328, 0.1354, 0.1350, 0.1384, 0.1376, 0.1372, 0.1357, 0.1332,\n",
      "        0.1307, 0.1332, 0.1320, 0.1302, 0.1317, 0.1167, 0.1155, 0.1128, 0.1125,\n",
      "        0.1148, 0.1152, 0.1140, 0.1152, 0.1133], device='cuda:0')\n",
      "tensor([[ 0.1607],\n",
      "        [-0.0242],\n",
      "        [ 0.0436],\n",
      "        [ 0.0460],\n",
      "        [ 0.0298],\n",
      "        [ 0.1018],\n",
      "        [ 0.0208],\n",
      "        [ 0.0233],\n",
      "        [ 0.0074],\n",
      "        [ 0.0365],\n",
      "        [-0.0139],\n",
      "        [ 0.0553],\n",
      "        [ 0.0391],\n",
      "        [ 0.0511],\n",
      "        [ 0.0830],\n",
      "        [ 0.0574],\n",
      "        [ 0.0216],\n",
      "        [ 0.0742],\n",
      "        [ 0.1181],\n",
      "        [ 0.0601],\n",
      "        [ 0.0429],\n",
      "        [ 0.0082],\n",
      "        [ 0.0240],\n",
      "        [ 0.0620],\n",
      "        [ 0.0804],\n",
      "        [ 0.1081],\n",
      "        [ 0.0674],\n",
      "        [-0.0010],\n",
      "        [ 0.1502],\n",
      "        [-0.0031],\n",
      "        [ 0.0293],\n",
      "        [ 0.0303]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1145, 0.1143, 0.1148, 0.1137, 0.1142, 0.1121, 0.1121, 0.1114, 0.1088,\n",
      "        0.1069, 0.1097, 0.1105, 0.1103, 0.1100, 0.1088, 0.1087, 0.1086, 0.1083,\n",
      "        0.1075, 0.1046, 0.1024, 0.1035, 0.1057, 0.1031, 0.1028, 0.1010, 0.1032,\n",
      "        0.1057, 0.1028, 0.1057, 0.1059, 0.1021], device='cuda:0')\n",
      "tensor([[-0.0088],\n",
      "        [-0.0131],\n",
      "        [ 0.0093],\n",
      "        [ 0.0548],\n",
      "        [ 0.0321],\n",
      "        [ 0.0597],\n",
      "        [ 0.0570],\n",
      "        [ 0.0410],\n",
      "        [ 0.0842],\n",
      "        [ 0.1102],\n",
      "        [ 0.0367],\n",
      "        [ 0.0204],\n",
      "        [ 0.0256],\n",
      "        [ 0.0464],\n",
      "        [ 0.0176],\n",
      "        [ 0.1589],\n",
      "        [ 0.1006],\n",
      "        [-0.0024],\n",
      "        [ 0.0381],\n",
      "        [ 0.0357],\n",
      "        [ 0.0967],\n",
      "        [ 0.0354],\n",
      "        [-0.0094],\n",
      "        [ 0.0096],\n",
      "        [ 0.0112],\n",
      "        [ 0.0759],\n",
      "        [ 0.0614],\n",
      "        [ 0.0260],\n",
      "        [ 0.0251],\n",
      "        [ 0.0936],\n",
      "        [ 0.0541],\n",
      "        [-0.0037]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1037, 0.1032, 0.1026, 0.1006, 0.1043, 0.1043, 0.1047, 0.1049, 0.1037,\n",
      "        0.1040, 0.1060, 0.1063, 0.1047, 0.1026, 0.1024, 0.1012, 0.1016, 0.1015,\n",
      "        0.1006, 0.0995, 0.0993, 0.0982, 0.0998, 0.1000, 0.0978, 0.0984, 0.0969,\n",
      "        0.0981, 0.0972, 0.0960, 0.0954, 0.0969], device='cuda:0')\n",
      "tensor([[ 6.7125e-02],\n",
      "        [-1.4602e-02],\n",
      "        [ 8.1262e-02],\n",
      "        [ 1.4483e-02],\n",
      "        [ 4.5774e-02],\n",
      "        [ 1.5805e-02],\n",
      "        [ 5.1338e-02],\n",
      "        [-1.4456e-04],\n",
      "        [ 7.9376e-03],\n",
      "        [ 2.5660e-02],\n",
      "        [ 1.6422e-02],\n",
      "        [ 3.2768e-02],\n",
      "        [ 5.4084e-02],\n",
      "        [ 5.4763e-02],\n",
      "        [ 8.8765e-02],\n",
      "        [ 1.3796e-01],\n",
      "        [ 6.9288e-02],\n",
      "        [ 5.9854e-02],\n",
      "        [ 4.9641e-02],\n",
      "        [ 8.6652e-02],\n",
      "        [ 2.3766e-02],\n",
      "        [ 5.0785e-02],\n",
      "        [-2.5830e-02],\n",
      "        [-2.6159e-02],\n",
      "        [ 4.1682e-02],\n",
      "        [ 4.3445e-03],\n",
      "        [ 1.6657e-02],\n",
      "        [ 4.7811e-02],\n",
      "        [-2.4290e-03],\n",
      "        [ 2.4281e-02],\n",
      "        [ 1.6956e-01],\n",
      "        [ 5.6295e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0978, 0.0966, 0.0972, 0.0994, 0.0982, 0.0973, 0.0967, 0.0981, 0.0979,\n",
      "        0.0948, 0.0944, 0.0967, 0.0994, 0.1012, 0.0995, 0.0997, 0.0994, 0.0994,\n",
      "        0.1004, 0.1007, 0.1003, 0.1003, 0.0993, 0.1000, 0.0993, 0.0976, 0.0979,\n",
      "        0.0975, 0.0972, 0.0976, 0.0970, 0.0969], device='cuda:0')\n",
      "tensor([[ 0.0857],\n",
      "        [-0.0054],\n",
      "        [ 0.0172],\n",
      "        [-0.0264],\n",
      "        [ 0.0928],\n",
      "        [ 0.0883],\n",
      "        [ 0.1033],\n",
      "        [ 0.0338],\n",
      "        [ 0.0847],\n",
      "        [ 0.0883],\n",
      "        [ 0.0917],\n",
      "        [ 0.0260],\n",
      "        [ 0.0140],\n",
      "        [-0.0150],\n",
      "        [ 0.0156],\n",
      "        [ 0.0386],\n",
      "        [ 0.0520],\n",
      "        [ 0.0711],\n",
      "        [ 0.0767],\n",
      "        [ 0.0479],\n",
      "        [ 0.0732],\n",
      "        [ 0.0575],\n",
      "        [ 0.0334],\n",
      "        [ 0.1003],\n",
      "        [ 0.0557],\n",
      "        [ 0.0465],\n",
      "        [ 0.1141],\n",
      "        [ 0.1396],\n",
      "        [ 0.0159],\n",
      "        [ 0.0415],\n",
      "        [ 0.0178],\n",
      "        [ 0.0589]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0947, 0.0929, 0.0938, 0.0936, 0.0922, 0.0928, 0.0931, 0.0932, 0.0923,\n",
      "        0.0935, 0.0951, 0.0964, 0.0972, 0.0967, 0.0981, 0.1000, 0.0984, 0.1004,\n",
      "        0.1035, 0.1022, 0.1031, 0.1046, 0.1052, 0.1046, 0.1038, 0.1043, 0.1057,\n",
      "        0.1047, 0.1046, 0.1015, 0.1031, 0.1019], device='cuda:0')\n",
      "tensor([[ 0.0215],\n",
      "        [ 0.0282],\n",
      "        [ 0.0248],\n",
      "        [ 0.0956],\n",
      "        [ 0.0426],\n",
      "        [ 0.0282],\n",
      "        [ 0.1458],\n",
      "        [ 0.0836],\n",
      "        [ 0.1392],\n",
      "        [ 0.0221],\n",
      "        [ 0.0848],\n",
      "        [ 0.0746],\n",
      "        [ 0.0670],\n",
      "        [ 0.0350],\n",
      "        [ 0.1471],\n",
      "        [ 0.1575],\n",
      "        [ 0.0380],\n",
      "        [ 0.0783],\n",
      "        [ 0.0323],\n",
      "        [ 0.0537],\n",
      "        [ 0.0384],\n",
      "        [ 0.0233],\n",
      "        [ 0.0499],\n",
      "        [-0.0072],\n",
      "        [ 0.0269],\n",
      "        [ 0.0442],\n",
      "        [ 0.0044],\n",
      "        [ 0.0571],\n",
      "        [ 0.0158],\n",
      "        [ 0.0534],\n",
      "        [-0.0066],\n",
      "        [ 0.0551]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1001, 0.0976, 0.0967, 0.0975, 0.0964, 0.0956, 0.0985, 0.0987, 0.1003,\n",
      "        0.1038, 0.1007, 0.0987, 0.0993, 0.0991, 0.0970, 0.0970, 0.0967, 0.0964,\n",
      "        0.0967, 0.0975, 0.0991, 0.0967, 0.0969, 0.0953, 0.0948, 0.0948, 0.0987,\n",
      "        0.0991, 0.0990, 0.0981, 0.0975, 0.0988], device='cuda:0')\n",
      "tensor([[ 0.1644],\n",
      "        [ 0.0368],\n",
      "        [ 0.1101],\n",
      "        [ 0.0355],\n",
      "        [ 0.0850],\n",
      "        [ 0.0054],\n",
      "        [ 0.0369],\n",
      "        [ 0.0683],\n",
      "        [ 0.0221],\n",
      "        [ 0.0226],\n",
      "        [-0.0065],\n",
      "        [-0.0061],\n",
      "        [ 0.0759],\n",
      "        [ 0.0128],\n",
      "        [ 0.0079],\n",
      "        [ 0.0377],\n",
      "        [ 0.0850],\n",
      "        [-0.0121],\n",
      "        [ 0.0880],\n",
      "        [ 0.0512],\n",
      "        [ 0.0025],\n",
      "        [ 0.1962],\n",
      "        [ 0.0373],\n",
      "        [ 0.0170],\n",
      "        [ 0.0374],\n",
      "        [ 0.0524],\n",
      "        [ 0.0468],\n",
      "        [ 0.0171],\n",
      "        [ 0.0432],\n",
      "        [ 0.0852],\n",
      "        [ 0.0719],\n",
      "        [ 0.0892]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0944, 0.0956, 0.0947, 0.0935, 0.0933, 0.0926, 0.0931, 0.0963, 0.0920,\n",
      "        0.0900, 0.0897, 0.0885, 0.0870, 0.0873, 0.0858, 0.0812, 0.0826, 0.0843,\n",
      "        0.0854, 0.0846, 0.0833, 0.0817, 0.0826, 0.0810, 0.0820, 0.0849, 0.0849,\n",
      "        0.0849, 0.0863, 0.0874, 0.0858, 0.0873], device='cuda:0')\n",
      "tensor([[ 0.0642],\n",
      "        [ 0.0495],\n",
      "        [ 0.0939],\n",
      "        [ 0.0457],\n",
      "        [ 0.0612],\n",
      "        [ 0.0025],\n",
      "        [ 0.0973],\n",
      "        [ 0.1145],\n",
      "        [ 0.0423],\n",
      "        [ 0.0505],\n",
      "        [ 0.0285],\n",
      "        [ 0.0360],\n",
      "        [ 0.0279],\n",
      "        [ 0.0680],\n",
      "        [ 0.1109],\n",
      "        [ 0.1335],\n",
      "        [ 0.0412],\n",
      "        [ 0.0303],\n",
      "        [ 0.0076],\n",
      "        [ 0.0701],\n",
      "        [ 0.0731],\n",
      "        [-0.0246],\n",
      "        [-0.0152],\n",
      "        [ 0.1432],\n",
      "        [ 0.0394],\n",
      "        [ 0.0234],\n",
      "        [ 0.1340],\n",
      "        [ 0.0572],\n",
      "        [ 0.0268],\n",
      "        [ 0.0411],\n",
      "        [ 0.0745],\n",
      "        [ 0.0357]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0874, 0.0897, 0.0925, 0.0898, 0.0885, 0.0880, 0.0873, 0.0898, 0.0933,\n",
      "        0.0935, 0.0945, 0.0932, 0.0904, 0.0936, 0.0911, 0.0907, 0.0914, 0.0908,\n",
      "        0.0892, 0.0891, 0.0870, 0.0886, 0.0897, 0.0885, 0.0869, 0.0861, 0.0867,\n",
      "        0.0873, 0.0895, 0.0879, 0.0867, 0.0866], device='cuda:0')\n",
      "tensor([[ 0.0380],\n",
      "        [ 0.1299],\n",
      "        [ 0.0794],\n",
      "        [ 0.0384],\n",
      "        [ 0.0303],\n",
      "        [ 0.0075],\n",
      "        [ 0.0503],\n",
      "        [-0.0037],\n",
      "        [ 0.0013],\n",
      "        [ 0.0039],\n",
      "        [ 0.0662],\n",
      "        [ 0.0444],\n",
      "        [ 0.1362],\n",
      "        [ 0.0105],\n",
      "        [ 0.0468],\n",
      "        [ 0.0386],\n",
      "        [ 0.0039],\n",
      "        [ 0.0249],\n",
      "        [ 0.0037],\n",
      "        [ 0.0367],\n",
      "        [ 0.0391],\n",
      "        [ 0.0726],\n",
      "        [ 0.2747],\n",
      "        [ 0.0351],\n",
      "        [ 0.0327],\n",
      "        [ 0.0213],\n",
      "        [ 0.0931],\n",
      "        [ 0.0259],\n",
      "        [ 0.0382],\n",
      "        [ 0.0344],\n",
      "        [ 0.0738],\n",
      "        [ 0.0756]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0866, 0.0867, 0.0869, 0.0863, 0.0849, 0.0849, 0.0843, 0.0833, 0.0840,\n",
      "        0.0849, 0.0839, 0.0830, 0.0827, 0.0839, 0.0845, 0.0843, 0.0860, 0.0866,\n",
      "        0.0855, 0.0842, 0.0840, 0.0821, 0.0824, 0.0818, 0.0814, 0.0812, 0.0801,\n",
      "        0.0790, 0.0792, 0.0793, 0.0786, 0.0779], device='cuda:0')\n",
      "tensor([[-0.0229],\n",
      "        [ 0.0749],\n",
      "        [ 0.0164],\n",
      "        [ 0.0279],\n",
      "        [ 0.0026],\n",
      "        [ 0.0164],\n",
      "        [ 0.0485],\n",
      "        [ 0.0393],\n",
      "        [-0.0173],\n",
      "        [ 0.0572],\n",
      "        [ 0.0197],\n",
      "        [ 0.0438],\n",
      "        [ 0.1861],\n",
      "        [ 0.0755],\n",
      "        [ 0.0616],\n",
      "        [ 0.0644],\n",
      "        [ 0.0332],\n",
      "        [ 0.0119],\n",
      "        [ 0.0272],\n",
      "        [ 0.0359],\n",
      "        [-0.0195],\n",
      "        [ 0.0477],\n",
      "        [ 0.0124],\n",
      "        [ 0.0251],\n",
      "        [ 0.0372],\n",
      "        [ 0.0999],\n",
      "        [ 0.0070],\n",
      "        [ 0.1107],\n",
      "        [ 0.0992],\n",
      "        [ 0.0121],\n",
      "        [ 0.0104],\n",
      "        [ 0.0214]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0773, 0.0789, 0.0780, 0.0810, 0.0812, 0.0823, 0.0840, 0.0849, 0.0852,\n",
      "        0.0854, 0.0864, 0.0870, 0.0871, 0.0861, 0.0848, 0.0848, 0.0852, 0.0848,\n",
      "        0.0879, 0.0877, 0.0900, 0.0916, 0.0910, 0.0914, 0.0907, 0.0916, 0.0911,\n",
      "        0.0898, 0.0891, 0.0889, 0.0879, 0.0900], device='cuda:0')\n",
      "tensor([[ 0.0335],\n",
      "        [ 0.0208],\n",
      "        [ 0.0978],\n",
      "        [ 0.0539],\n",
      "        [ 0.0473],\n",
      "        [ 0.0920],\n",
      "        [ 0.0547],\n",
      "        [ 0.0527],\n",
      "        [ 0.0399],\n",
      "        [-0.0146],\n",
      "        [ 0.0443],\n",
      "        [ 0.0279],\n",
      "        [ 0.0257],\n",
      "        [ 0.0076],\n",
      "        [ 0.0896],\n",
      "        [-0.0027],\n",
      "        [-0.0224],\n",
      "        [ 0.0039],\n",
      "        [ 0.0172],\n",
      "        [ 0.0301],\n",
      "        [ 0.0234],\n",
      "        [ 0.1807],\n",
      "        [ 0.0416],\n",
      "        [ 0.0559],\n",
      "        [ 0.0741],\n",
      "        [ 0.0811],\n",
      "        [ 0.0499],\n",
      "        [ 0.0237],\n",
      "        [ 0.0600],\n",
      "        [ 0.2169],\n",
      "        [ 0.0932],\n",
      "        [ 0.0647]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0889, 0.0888, 0.0891, 0.0876, 0.0880, 0.0883, 0.0879, 0.0877, 0.0877,\n",
      "        0.0867, 0.0858, 0.0874, 0.0882, 0.0877, 0.0871, 0.0894, 0.0905, 0.0919,\n",
      "        0.0907, 0.0901, 0.0923, 0.0929, 0.0932, 0.0939, 0.0960, 0.0954, 0.0956,\n",
      "        0.0972, 0.0963, 0.0967, 0.0951, 0.0966], device='cuda:0')\n",
      "tensor([[ 0.1088],\n",
      "        [ 0.0332],\n",
      "        [ 0.0309],\n",
      "        [ 0.0632],\n",
      "        [ 0.0204],\n",
      "        [-0.0286],\n",
      "        [-0.0357],\n",
      "        [ 0.0119],\n",
      "        [ 0.0545],\n",
      "        [ 0.0311],\n",
      "        [ 0.0417],\n",
      "        [ 0.0723],\n",
      "        [ 0.1564],\n",
      "        [-0.0133],\n",
      "        [ 0.0330],\n",
      "        [ 0.0316],\n",
      "        [-0.0410],\n",
      "        [-0.0270],\n",
      "        [ 0.0030],\n",
      "        [-0.0233],\n",
      "        [ 0.0578],\n",
      "        [ 0.0921],\n",
      "        [ 0.0087],\n",
      "        [-0.0005],\n",
      "        [ 0.0750],\n",
      "        [ 0.0270],\n",
      "        [ 0.0241],\n",
      "        [ 0.0924],\n",
      "        [-0.0240],\n",
      "        [-0.0115],\n",
      "        [ 0.0027],\n",
      "        [-0.0076]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0950, 0.0963, 0.0959, 0.0960, 0.0963, 0.0963, 0.0979, 0.0991, 0.0929,\n",
      "        0.0904, 0.0914, 0.0900, 0.0902, 0.0902, 0.0898, 0.0914, 0.0922, 0.0933,\n",
      "        0.0926, 0.0928, 0.0920, 0.0889, 0.0849, 0.0836, 0.0852, 0.0846, 0.0851,\n",
      "        0.0848, 0.0851, 0.0854, 0.0846, 0.0830], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0119],\n",
      "        [ 0.0553],\n",
      "        [-0.0183],\n",
      "        [-0.0184],\n",
      "        [ 0.0329],\n",
      "        [ 0.0886],\n",
      "        [ 0.0805],\n",
      "        [ 0.1071],\n",
      "        [ 0.0356],\n",
      "        [-0.0281],\n",
      "        [ 0.0370],\n",
      "        [ 0.0180],\n",
      "        [ 0.0134],\n",
      "        [ 0.0208],\n",
      "        [ 0.0727],\n",
      "        [ 0.0294],\n",
      "        [ 0.0811],\n",
      "        [ 0.0209],\n",
      "        [-0.0029],\n",
      "        [ 0.0518],\n",
      "        [ 0.0164],\n",
      "        [ 0.1335],\n",
      "        [ 0.0219],\n",
      "        [ 0.2259],\n",
      "        [-0.0201],\n",
      "        [ 0.0795],\n",
      "        [ 0.1014],\n",
      "        [ 0.0310],\n",
      "        [ 0.0178],\n",
      "        [ 0.0245],\n",
      "        [ 0.0386],\n",
      "        [ 0.0560]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0821, 0.0823, 0.0812, 0.0836, 0.0827, 0.0839, 0.0838, 0.0830, 0.0842,\n",
      "        0.0840, 0.0830, 0.0823, 0.0824, 0.0833, 0.0840, 0.0846, 0.0851, 0.0817,\n",
      "        0.0789, 0.0796, 0.0793, 0.0804, 0.0790, 0.0795, 0.0781, 0.0779, 0.0784,\n",
      "        0.0764, 0.0761, 0.0753, 0.0734, 0.0739], device='cuda:0')\n",
      "tensor([[ 0.0329],\n",
      "        [ 0.0104],\n",
      "        [ 0.0463],\n",
      "        [ 0.0355],\n",
      "        [ 0.0470],\n",
      "        [ 0.0157],\n",
      "        [-0.0232],\n",
      "        [ 0.0094],\n",
      "        [ 0.0041],\n",
      "        [-0.0307],\n",
      "        [-0.0095],\n",
      "        [ 0.0339],\n",
      "        [ 0.0788],\n",
      "        [ 0.1311],\n",
      "        [-0.0331],\n",
      "        [ 0.1729],\n",
      "        [ 0.0354],\n",
      "        [ 0.0042],\n",
      "        [-0.0247],\n",
      "        [-0.0240],\n",
      "        [ 0.0886],\n",
      "        [ 0.0381],\n",
      "        [ 0.0102],\n",
      "        [ 0.0226],\n",
      "        [-0.0293],\n",
      "        [ 0.1009],\n",
      "        [ 0.0184],\n",
      "        [ 0.0346],\n",
      "        [ 0.0697],\n",
      "        [ 0.0303],\n",
      "        [ 0.0338],\n",
      "        [ 0.0303]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0749, 0.0733, 0.0745, 0.0734, 0.0734, 0.0737, 0.0728, 0.0668, 0.0643,\n",
      "        0.0616, 0.0615, 0.0616, 0.0616, 0.0624, 0.0604, 0.0584, 0.0600, 0.0587,\n",
      "        0.0597, 0.0621, 0.0624, 0.0613, 0.0585, 0.0590, 0.0604, 0.0585, 0.0575,\n",
      "        0.0564, 0.0573, 0.0573, 0.0566, 0.0553], device='cuda:0')\n",
      "tensor([[ 0.0191],\n",
      "        [ 0.0394],\n",
      "        [-0.0427],\n",
      "        [-0.0016],\n",
      "        [ 0.0747],\n",
      "        [-0.0050],\n",
      "        [ 0.0550],\n",
      "        [-0.0305],\n",
      "        [ 0.0658],\n",
      "        [ 0.0603],\n",
      "        [ 0.0972],\n",
      "        [ 0.1854],\n",
      "        [ 0.0918],\n",
      "        [ 0.0873],\n",
      "        [ 0.0399],\n",
      "        [-0.0167],\n",
      "        [ 0.0039],\n",
      "        [ 0.0264],\n",
      "        [ 0.0619],\n",
      "        [ 0.0361],\n",
      "        [-0.0035],\n",
      "        [ 0.0196],\n",
      "        [ 0.1740],\n",
      "        [ 0.0751],\n",
      "        [ 0.1143],\n",
      "        [ 0.0601],\n",
      "        [ 0.0095],\n",
      "        [ 0.0603],\n",
      "        [ 0.0580],\n",
      "        [-0.0223],\n",
      "        [ 0.0398],\n",
      "        [ 0.1262]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0531, 0.0542, 0.0554, 0.0573, 0.0579, 0.0587, 0.0613, 0.0607, 0.0609,\n",
      "        0.0601, 0.0598, 0.0585, 0.0579, 0.0547, 0.0536, 0.0544, 0.0550, 0.0470,\n",
      "        0.0420, 0.0433, 0.0414, 0.0384, 0.0418, 0.0412, 0.0430, 0.0418, 0.0395,\n",
      "        0.0399, 0.0402, 0.0399, 0.0384, 0.0374], device='cuda:0')\n",
      "tensor([[ 0.0654],\n",
      "        [ 0.0423],\n",
      "        [-0.0175],\n",
      "        [ 0.0586],\n",
      "        [ 0.0532],\n",
      "        [-0.0008],\n",
      "        [ 0.0123],\n",
      "        [ 0.0414],\n",
      "        [ 0.0202],\n",
      "        [ 0.0227],\n",
      "        [-0.0024],\n",
      "        [ 0.0549],\n",
      "        [-0.0112],\n",
      "        [ 0.1019],\n",
      "        [ 0.0107],\n",
      "        [ 0.0739],\n",
      "        [ 0.0125],\n",
      "        [ 0.0574],\n",
      "        [ 0.1292],\n",
      "        [ 0.0834],\n",
      "        [ 0.0815],\n",
      "        [ 0.0959],\n",
      "        [ 0.1350],\n",
      "        [ 0.0942],\n",
      "        [ 0.0625],\n",
      "        [-0.0138],\n",
      "        [-0.0236],\n",
      "        [-0.0423],\n",
      "        [ 0.0356],\n",
      "        [ 0.0452],\n",
      "        [ 0.0355],\n",
      "        [ 0.0054]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0362, 0.0356, 0.0371, 0.0383, 0.0371, 0.0383, 0.0377, 0.0392, 0.0379,\n",
      "        0.0361, 0.0355, 0.0381, 0.0384, 0.0386, 0.0393, 0.0401, 0.0415, 0.0429,\n",
      "        0.0423, 0.0411, 0.0414, 0.0421, 0.0432, 0.0438, 0.0424, 0.0411, 0.0407,\n",
      "        0.0398, 0.0404, 0.0404, 0.0404, 0.0412], device='cuda:0')\n",
      "tensor([[ 0.0180],\n",
      "        [ 0.0390],\n",
      "        [ 0.0448],\n",
      "        [-0.0017],\n",
      "        [ 0.0299],\n",
      "        [-0.0039],\n",
      "        [ 0.0476],\n",
      "        [ 0.0580],\n",
      "        [ 0.1112],\n",
      "        [ 0.0198],\n",
      "        [ 0.0790],\n",
      "        [ 0.0978],\n",
      "        [ 0.0351],\n",
      "        [ 0.1168],\n",
      "        [ 0.0423],\n",
      "        [ 0.0927],\n",
      "        [ 0.0200],\n",
      "        [ 0.0320],\n",
      "        [ 0.0201],\n",
      "        [ 0.0341],\n",
      "        [ 0.0354],\n",
      "        [-0.0171],\n",
      "        [ 0.0378],\n",
      "        [ 0.0717],\n",
      "        [ 0.0541],\n",
      "        [ 0.0038],\n",
      "        [ 0.0104],\n",
      "        [ 0.1571],\n",
      "        [ 0.1142],\n",
      "        [ 0.0443],\n",
      "        [ 0.0810],\n",
      "        [ 0.0879]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0411, 0.0420, 0.0442, 0.0449, 0.0454, 0.0448, 0.0460, 0.0455, 0.0460,\n",
      "        0.0470, 0.0476, 0.0467, 0.0455, 0.0464, 0.0457, 0.0458, 0.0451, 0.0452,\n",
      "        0.0442, 0.0440, 0.0448, 0.0411, 0.0404, 0.0414, 0.0418, 0.0398, 0.0408,\n",
      "        0.0420, 0.0429, 0.0429, 0.0421, 0.0424], device='cuda:0')\n",
      "tensor([[ 0.0363],\n",
      "        [ 0.0682],\n",
      "        [ 0.0628],\n",
      "        [ 0.0320],\n",
      "        [ 0.0350],\n",
      "        [ 0.0663],\n",
      "        [ 0.0021],\n",
      "        [ 0.1610],\n",
      "        [ 0.0393],\n",
      "        [ 0.0749],\n",
      "        [ 0.0432],\n",
      "        [ 0.0686],\n",
      "        [ 0.1552],\n",
      "        [ 0.0156],\n",
      "        [ 0.0252],\n",
      "        [ 0.0439],\n",
      "        [ 0.0301],\n",
      "        [ 0.0358],\n",
      "        [-0.0119],\n",
      "        [ 0.0016],\n",
      "        [ 0.0234],\n",
      "        [ 0.0487],\n",
      "        [ 0.0231],\n",
      "        [-0.0030],\n",
      "        [ 0.0281],\n",
      "        [ 0.0358],\n",
      "        [ 0.0574],\n",
      "        [ 0.0271],\n",
      "        [ 0.0619],\n",
      "        [ 0.0933],\n",
      "        [ 0.0558],\n",
      "        [ 0.1286]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0401, 0.0410, 0.0390, 0.0386, 0.0383, 0.0386, 0.0389, 0.0405, 0.0387,\n",
      "        0.0380, 0.0371, 0.0379, 0.0379, 0.0396, 0.0384, 0.0381, 0.0389, 0.0389,\n",
      "        0.0390, 0.0377, 0.0381, 0.0384, 0.0384, 0.0374, 0.0368, 0.0373, 0.0370,\n",
      "        0.0386, 0.0393, 0.0389, 0.0379, 0.0395], device='cuda:0')\n",
      "tensor([[ 0.0170],\n",
      "        [ 0.0508],\n",
      "        [ 0.0390],\n",
      "        [ 0.0159],\n",
      "        [ 0.0322],\n",
      "        [ 0.0268],\n",
      "        [ 0.0967],\n",
      "        [ 0.1385],\n",
      "        [ 0.0936],\n",
      "        [ 0.0756],\n",
      "        [ 0.1427],\n",
      "        [ 0.0548],\n",
      "        [ 0.0394],\n",
      "        [ 0.0292],\n",
      "        [ 0.0287],\n",
      "        [ 0.0273],\n",
      "        [ 0.0895],\n",
      "        [-0.0114],\n",
      "        [ 0.0619],\n",
      "        [ 0.0260],\n",
      "        [ 0.1426],\n",
      "        [ 0.0244],\n",
      "        [ 0.0482],\n",
      "        [ 0.1223],\n",
      "        [-0.0211],\n",
      "        [ 0.1099],\n",
      "        [-0.0215],\n",
      "        [ 0.0051],\n",
      "        [ 0.0190],\n",
      "        [ 0.0263],\n",
      "        [ 0.0549],\n",
      "        [ 0.0287]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0402, 0.0430, 0.0436, 0.0430, 0.0421, 0.0443, 0.0443, 0.0445, 0.0424,\n",
      "        0.0424, 0.0432, 0.0427, 0.0427, 0.0421, 0.0396, 0.0402, 0.0393, 0.0390,\n",
      "        0.0389, 0.0389, 0.0381, 0.0383, 0.0395, 0.0402, 0.0390, 0.0390, 0.0389,\n",
      "        0.0377, 0.0361, 0.0358, 0.0358, 0.0358], device='cuda:0')\n",
      "tensor([[ 0.0141],\n",
      "        [ 0.0476],\n",
      "        [ 0.0401],\n",
      "        [ 0.1071],\n",
      "        [ 0.0788],\n",
      "        [ 0.0317],\n",
      "        [ 0.0064],\n",
      "        [ 0.0108],\n",
      "        [ 0.0441],\n",
      "        [ 0.0315],\n",
      "        [ 0.0690],\n",
      "        [ 0.0722],\n",
      "        [ 0.0287],\n",
      "        [ 0.0822],\n",
      "        [ 0.0046],\n",
      "        [ 0.0807],\n",
      "        [ 0.3559],\n",
      "        [ 0.0667],\n",
      "        [ 0.1161],\n",
      "        [ 0.0826],\n",
      "        [ 0.0264],\n",
      "        [ 0.0158],\n",
      "        [ 0.0478],\n",
      "        [ 0.0337],\n",
      "        [ 0.0044],\n",
      "        [ 0.0037],\n",
      "        [-0.0055],\n",
      "        [ 0.0496],\n",
      "        [-0.0033],\n",
      "        [ 0.0050],\n",
      "        [ 0.0340],\n",
      "        [ 0.0679]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0376, 0.0370, 0.0367, 0.0368, 0.0346, 0.0322, 0.0314, 0.0322, 0.0319,\n",
      "        0.0306, 0.0308, 0.0346, 0.0327, 0.0325, 0.0333, 0.0325, 0.0319, 0.0331,\n",
      "        0.0324, 0.0319, 0.0317, 0.0318, 0.0306, 0.0300, 0.0299, 0.0291, 0.0315,\n",
      "        0.0312, 0.0315, 0.0317, 0.0331, 0.0325], device='cuda:0')\n",
      "tensor([[ 0.0344],\n",
      "        [-0.0020],\n",
      "        [ 0.0311],\n",
      "        [ 0.0827],\n",
      "        [ 0.0237],\n",
      "        [ 0.0584],\n",
      "        [ 0.0557],\n",
      "        [ 0.0028],\n",
      "        [ 0.0389],\n",
      "        [ 0.1350],\n",
      "        [ 0.0970],\n",
      "        [ 0.0190],\n",
      "        [ 0.1050],\n",
      "        [ 0.0226],\n",
      "        [ 0.0384],\n",
      "        [ 0.0288],\n",
      "        [ 0.0528],\n",
      "        [ 0.1025],\n",
      "        [ 0.0408],\n",
      "        [ 0.0396],\n",
      "        [ 0.0243],\n",
      "        [ 0.0678],\n",
      "        [ 0.0665],\n",
      "        [ 0.0040],\n",
      "        [ 0.1705],\n",
      "        [ 0.0061],\n",
      "        [ 0.0142],\n",
      "        [ 0.0367],\n",
      "        [ 0.0048],\n",
      "        [ 0.0678],\n",
      "        [ 0.0376],\n",
      "        [ 0.0624]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0327, 0.0327, 0.0328, 0.0334, 0.0348, 0.0349, 0.0350, 0.0348, 0.0345,\n",
      "        0.0331, 0.0331, 0.0324, 0.0325, 0.0321, 0.0322, 0.0321, 0.0319, 0.0306,\n",
      "        0.0305, 0.0302, 0.0302, 0.0300, 0.0300, 0.0300, 0.0299, 0.0303, 0.0325,\n",
      "        0.0330, 0.0324, 0.0327, 0.0327, 0.0330], device='cuda:0')\n",
      "tensor([[-0.0174],\n",
      "        [-0.0072],\n",
      "        [ 0.0250],\n",
      "        [-0.0527],\n",
      "        [ 0.0076],\n",
      "        [ 0.0509],\n",
      "        [ 0.0353],\n",
      "        [ 0.1580],\n",
      "        [ 0.0917],\n",
      "        [ 0.0409],\n",
      "        [ 0.0022],\n",
      "        [ 0.0769],\n",
      "        [-0.0314],\n",
      "        [ 0.0415],\n",
      "        [ 0.0523],\n",
      "        [ 0.0014],\n",
      "        [ 0.0942],\n",
      "        [ 0.0857],\n",
      "        [ 0.0154],\n",
      "        [ 0.0082],\n",
      "        [ 0.0657],\n",
      "        [ 0.1939],\n",
      "        [ 0.1429],\n",
      "        [ 0.1129],\n",
      "        [ 0.0613],\n",
      "        [ 0.0233],\n",
      "        [ 0.0082],\n",
      "        [ 0.0240],\n",
      "        [ 0.0436],\n",
      "        [ 0.0472],\n",
      "        [ 0.0737],\n",
      "        [ 0.0739]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0328, 0.0324, 0.0317, 0.0311, 0.0333, 0.0327, 0.0319, 0.0322, 0.0339,\n",
      "        0.0333, 0.0337, 0.0353, 0.0350, 0.0348, 0.0350, 0.0371, 0.0408, 0.0407,\n",
      "        0.0395, 0.0396, 0.0401, 0.0387, 0.0396, 0.0421, 0.0417, 0.0410, 0.0430,\n",
      "        0.0420, 0.0430, 0.0420, 0.0421, 0.0435], device='cuda:0')\n",
      "tensor([[ 0.0834],\n",
      "        [ 0.0315],\n",
      "        [ 0.0592],\n",
      "        [ 0.0244],\n",
      "        [ 0.0214],\n",
      "        [ 0.1058],\n",
      "        [ 0.0207],\n",
      "        [ 0.0795],\n",
      "        [ 0.0277],\n",
      "        [ 0.0453],\n",
      "        [-0.0259],\n",
      "        [ 0.0290],\n",
      "        [ 0.0274],\n",
      "        [ 0.0488],\n",
      "        [ 0.0541],\n",
      "        [ 0.0635],\n",
      "        [ 0.0460],\n",
      "        [ 0.1722],\n",
      "        [ 0.0448],\n",
      "        [ 0.0146],\n",
      "        [ 0.1093],\n",
      "        [ 0.1995],\n",
      "        [ 0.0724],\n",
      "        [ 0.0238],\n",
      "        [-0.0058],\n",
      "        [ 0.0539],\n",
      "        [ 0.0487],\n",
      "        [ 0.0636],\n",
      "        [ 0.0642],\n",
      "        [ 0.0083],\n",
      "        [-0.0463],\n",
      "        [ 0.0169]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0458, 0.0466, 0.0449, 0.0443, 0.0435, 0.0442, 0.0439, 0.0442, 0.0442,\n",
      "        0.0443, 0.0440, 0.0460, 0.0485, 0.0470, 0.0479, 0.0486, 0.0513, 0.0497,\n",
      "        0.0500, 0.0507, 0.0500, 0.0505, 0.0497, 0.0494, 0.0480, 0.0474, 0.0488,\n",
      "        0.0504, 0.0510, 0.0498, 0.0502, 0.0507], device='cuda:0')\n",
      "tensor([[ 0.0202],\n",
      "        [ 0.0364],\n",
      "        [ 0.0279],\n",
      "        [ 0.0705],\n",
      "        [ 0.0511],\n",
      "        [ 0.0411],\n",
      "        [ 0.0059],\n",
      "        [ 0.0487],\n",
      "        [-0.0013],\n",
      "        [ 0.0387],\n",
      "        [ 0.0879],\n",
      "        [ 0.0751],\n",
      "        [ 0.0096],\n",
      "        [ 0.0533],\n",
      "        [ 0.0846],\n",
      "        [ 0.1566],\n",
      "        [ 0.1239],\n",
      "        [ 0.0203],\n",
      "        [ 0.0071],\n",
      "        [ 0.0375],\n",
      "        [ 0.0300],\n",
      "        [ 0.0459],\n",
      "        [ 0.0769],\n",
      "        [ 0.0106],\n",
      "        [ 0.0429],\n",
      "        [ 0.0318],\n",
      "        [ 0.0836],\n",
      "        [ 0.0314],\n",
      "        [ 0.0240],\n",
      "        [ 0.0258],\n",
      "        [ 0.0361],\n",
      "        [ 0.0015]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0500, 0.0494, 0.0501, 0.0500, 0.0486, 0.0482, 0.0469, 0.0460, 0.0460,\n",
      "        0.0500, 0.0495, 0.0473, 0.0482, 0.0489, 0.0474, 0.0474, 0.0473, 0.0466,\n",
      "        0.0421, 0.0448, 0.0440, 0.0435, 0.0432, 0.0436, 0.0445, 0.0451, 0.0452,\n",
      "        0.0430, 0.0429, 0.0440, 0.0439, 0.0432], device='cuda:0')\n",
      "tensor([[-0.0129],\n",
      "        [ 0.0279],\n",
      "        [ 0.0016],\n",
      "        [-0.0449],\n",
      "        [ 0.0173],\n",
      "        [ 0.0395],\n",
      "        [ 0.0099],\n",
      "        [-0.0042],\n",
      "        [ 0.0287],\n",
      "        [ 0.0407],\n",
      "        [ 0.0365],\n",
      "        [ 0.0016],\n",
      "        [ 0.0556],\n",
      "        [ 0.1784],\n",
      "        [ 0.0134],\n",
      "        [ 0.0238],\n",
      "        [ 0.1127],\n",
      "        [ 0.0796],\n",
      "        [ 0.0485],\n",
      "        [ 0.0064],\n",
      "        [ 0.1485],\n",
      "        [ 0.0342],\n",
      "        [ 0.0283],\n",
      "        [ 0.0832],\n",
      "        [ 0.0663],\n",
      "        [ 0.0386],\n",
      "        [ 0.0467],\n",
      "        [-0.0134],\n",
      "        [ 0.0181],\n",
      "        [-0.0025],\n",
      "        [ 0.0424],\n",
      "        [ 0.0092]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0432, 0.0432, 0.0440, 0.0433, 0.0429, 0.0429, 0.0424, 0.0454, 0.0461,\n",
      "        0.0469, 0.0467, 0.0486, 0.0485, 0.0495, 0.0491, 0.0482, 0.0500, 0.0495,\n",
      "        0.0483, 0.0473, 0.0445, 0.0440, 0.0429, 0.0439, 0.0452, 0.0433, 0.0438,\n",
      "        0.0435, 0.0435, 0.0427, 0.0433, 0.0432], device='cuda:0')\n",
      "tensor([[-0.0091],\n",
      "        [ 0.0459],\n",
      "        [ 0.0484],\n",
      "        [ 0.0514],\n",
      "        [ 0.0736],\n",
      "        [ 0.0470],\n",
      "        [-0.0027],\n",
      "        [-0.0188],\n",
      "        [ 0.0315],\n",
      "        [-0.0013],\n",
      "        [-0.0084],\n",
      "        [ 0.1873],\n",
      "        [ 0.1944],\n",
      "        [ 0.0008],\n",
      "        [-0.0055],\n",
      "        [ 0.0394],\n",
      "        [ 0.0260],\n",
      "        [ 0.0941],\n",
      "        [ 0.0645],\n",
      "        [ 0.0265],\n",
      "        [ 0.0645],\n",
      "        [ 0.0604],\n",
      "        [ 0.0311],\n",
      "        [ 0.0130],\n",
      "        [ 0.0350],\n",
      "        [-0.0320],\n",
      "        [ 0.0556],\n",
      "        [-0.0098],\n",
      "        [-0.0064],\n",
      "        [ 0.0568],\n",
      "        [ 0.1496],\n",
      "        [ 0.0313]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0426, 0.0443, 0.0433, 0.0438, 0.0438, 0.0424, 0.0497, 0.0501, 0.0507,\n",
      "        0.0498, 0.0482, 0.0486, 0.0492, 0.0497, 0.0489, 0.0482, 0.0474, 0.0480,\n",
      "        0.0492, 0.0483, 0.0483, 0.0486, 0.0498, 0.0531, 0.0525, 0.0532, 0.0541,\n",
      "        0.0536, 0.0553, 0.0559, 0.0563, 0.0559], device='cuda:0')\n",
      "tensor([[ 0.1162],\n",
      "        [ 0.1181],\n",
      "        [ 0.1563],\n",
      "        [ 0.0370],\n",
      "        [ 0.0090],\n",
      "        [ 0.0314],\n",
      "        [ 0.0287],\n",
      "        [ 0.0482],\n",
      "        [-0.0233],\n",
      "        [ 0.0573],\n",
      "        [ 0.0068],\n",
      "        [ 0.0994],\n",
      "        [-0.0093],\n",
      "        [ 0.0060],\n",
      "        [ 0.0281],\n",
      "        [ 0.0919],\n",
      "        [ 0.0220],\n",
      "        [ 0.0125],\n",
      "        [ 0.0262],\n",
      "        [-0.0375],\n",
      "        [ 0.0517],\n",
      "        [ 0.0024],\n",
      "        [-0.0164],\n",
      "        [ 0.1145],\n",
      "        [ 0.1074],\n",
      "        [ 0.0068],\n",
      "        [ 0.0422],\n",
      "        [ 0.0075],\n",
      "        [ 0.0531],\n",
      "        [ 0.0898],\n",
      "        [-0.0136],\n",
      "        [ 0.0781]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0551, 0.0557, 0.0539, 0.0528, 0.0547, 0.0547, 0.0535, 0.0539, 0.0547,\n",
      "        0.0560, 0.0575, 0.0560, 0.0550, 0.0544, 0.0535, 0.0528, 0.0539, 0.0526,\n",
      "        0.0514, 0.0533, 0.0529, 0.0520, 0.0501, 0.0480, 0.0471, 0.0480, 0.0477,\n",
      "        0.0476, 0.0464, 0.0467, 0.0477, 0.0495], device='cuda:0')\n",
      "tensor([[ 0.1129],\n",
      "        [ 0.1270],\n",
      "        [ 0.0863],\n",
      "        [ 0.0715],\n",
      "        [ 0.0033],\n",
      "        [ 0.0299],\n",
      "        [ 0.0422],\n",
      "        [ 0.0615],\n",
      "        [ 0.0694],\n",
      "        [ 0.2932],\n",
      "        [ 0.0313],\n",
      "        [ 0.0667],\n",
      "        [ 0.1167],\n",
      "        [ 0.0824],\n",
      "        [ 0.0156],\n",
      "        [-0.0068],\n",
      "        [ 0.0501],\n",
      "        [ 0.0426],\n",
      "        [ 0.0162],\n",
      "        [ 0.0320],\n",
      "        [ 0.0054],\n",
      "        [-0.0148],\n",
      "        [ 0.0686],\n",
      "        [ 0.0218],\n",
      "        [ 0.0167],\n",
      "        [ 0.0132],\n",
      "        [ 0.0169],\n",
      "        [ 0.0006],\n",
      "        [ 0.0302],\n",
      "        [ 0.0318],\n",
      "        [ 0.1315],\n",
      "        [ 0.0699]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0479, 0.0479, 0.0464, 0.0467, 0.0544, 0.0532, 0.0542, 0.0544, 0.0545,\n",
      "        0.0542, 0.0538, 0.0550, 0.0542, 0.0551, 0.0553, 0.0544, 0.0554, 0.0569,\n",
      "        0.0564, 0.0570, 0.0560, 0.0567, 0.0570, 0.0573, 0.0590, 0.0612, 0.0607,\n",
      "        0.0606, 0.0603, 0.0626, 0.0634, 0.0626], device='cuda:0')\n",
      "tensor([[ 0.0140],\n",
      "        [ 0.0319],\n",
      "        [ 0.1852],\n",
      "        [ 0.0792],\n",
      "        [ 0.0087],\n",
      "        [ 0.0543],\n",
      "        [ 0.0022],\n",
      "        [-0.0101],\n",
      "        [ 0.0621],\n",
      "        [-0.0155],\n",
      "        [ 0.0558],\n",
      "        [ 0.0635],\n",
      "        [ 0.0389],\n",
      "        [ 0.0085],\n",
      "        [ 0.0674],\n",
      "        [ 0.0500],\n",
      "        [ 0.0081],\n",
      "        [ 0.1322],\n",
      "        [ 0.0230],\n",
      "        [ 0.0590],\n",
      "        [ 0.1347],\n",
      "        [ 0.0156],\n",
      "        [ 0.1666],\n",
      "        [ 0.1032],\n",
      "        [-0.0228],\n",
      "        [-0.0123],\n",
      "        [ 0.0294],\n",
      "        [ 0.0381],\n",
      "        [-0.0317],\n",
      "        [ 0.0280],\n",
      "        [-0.0010],\n",
      "        [-0.0042]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0626, 0.0616, 0.0609, 0.0601, 0.0604, 0.0604, 0.0609, 0.0601, 0.0609,\n",
      "        0.0625, 0.0631, 0.0631, 0.0646, 0.0638, 0.0637, 0.0628, 0.0629, 0.0624,\n",
      "        0.0622, 0.0622, 0.0616, 0.0628, 0.0629, 0.0621, 0.0615, 0.0624, 0.0619,\n",
      "        0.0647, 0.0652, 0.0653, 0.0671, 0.0660], device='cuda:0')\n",
      "tensor([[ 0.1270],\n",
      "        [ 0.0202],\n",
      "        [ 0.0574],\n",
      "        [ 0.0985],\n",
      "        [ 0.0362],\n",
      "        [ 0.0437],\n",
      "        [ 0.0149],\n",
      "        [ 0.0103],\n",
      "        [ 0.1209],\n",
      "        [-0.0093],\n",
      "        [ 0.0296],\n",
      "        [ 0.0634],\n",
      "        [ 0.0742],\n",
      "        [ 0.0795],\n",
      "        [-0.0037],\n",
      "        [ 0.0774],\n",
      "        [-0.0035],\n",
      "        [ 0.0511],\n",
      "        [ 0.0347],\n",
      "        [ 0.0243],\n",
      "        [ 0.0954],\n",
      "        [ 0.1069],\n",
      "        [ 0.0257],\n",
      "        [ 0.0471],\n",
      "        [ 0.1082],\n",
      "        [ 0.0418],\n",
      "        [ 0.0051],\n",
      "        [-0.0225],\n",
      "        [ 0.1079],\n",
      "        [ 0.0178],\n",
      "        [ 0.0113],\n",
      "        [ 0.0528]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0671, 0.0672, 0.0687, 0.0697, 0.0693, 0.0688, 0.0669, 0.0680, 0.0686,\n",
      "        0.0683, 0.0706, 0.0687, 0.0680, 0.0684, 0.0675, 0.0647, 0.0656, 0.0669,\n",
      "        0.0681, 0.0657, 0.0662, 0.0668, 0.0671, 0.0666, 0.0671, 0.0672, 0.0668,\n",
      "        0.0631, 0.0634, 0.0643, 0.0641, 0.0641], device='cuda:0')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[ 0.0635],\n",
      "        [ 0.1861],\n",
      "        [ 0.1630],\n",
      "        [ 0.0137],\n",
      "        [ 0.1086],\n",
      "        [ 0.0397],\n",
      "        [-0.0314],\n",
      "        [ 0.0377],\n",
      "        [ 0.0493],\n",
      "        [ 0.0047],\n",
      "        [ 0.0321],\n",
      "        [ 0.0453],\n",
      "        [ 0.0328],\n",
      "        [ 0.0669],\n",
      "        [ 0.0702],\n",
      "        [ 0.0584],\n",
      "        [ 0.0182],\n",
      "        [ 0.0249],\n",
      "        [ 0.0116],\n",
      "        [ 0.0077],\n",
      "        [ 0.1277],\n",
      "        [ 0.0874],\n",
      "        [ 0.0480],\n",
      "        [ 0.0351],\n",
      "        [ 0.0401],\n",
      "        [ 0.0634],\n",
      "        [ 0.0061],\n",
      "        [ 0.0475],\n",
      "        [ 0.0289],\n",
      "        [ 0.1208],\n",
      "        [ 0.0677],\n",
      "        [ 0.0722]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0643, 0.0628, 0.0650, 0.0650, 0.0653, 0.0649, 0.0635, 0.0652, 0.0641,\n",
      "        0.0631, 0.0637, 0.0640, 0.0635, 0.0653, 0.0643, 0.0677, 0.0675, 0.0675,\n",
      "        0.0684, 0.0669, 0.0686, 0.0675, 0.0678, 0.0686, 0.0681, 0.0694, 0.0699,\n",
      "        0.0712, 0.0705, 0.0705, 0.0709, 0.0722], device='cuda:0')\n",
      "tensor([[-0.0052],\n",
      "        [ 0.0204],\n",
      "        [ 0.0128],\n",
      "        [ 0.0698],\n",
      "        [ 0.0422],\n",
      "        [ 0.0531],\n",
      "        [ 0.0720],\n",
      "        [ 0.0353],\n",
      "        [ 0.0651],\n",
      "        [-0.0055],\n",
      "        [ 0.0342],\n",
      "        [ 0.0032],\n",
      "        [ 0.0547],\n",
      "        [ 0.1238],\n",
      "        [ 0.1443],\n",
      "        [ 0.0896],\n",
      "        [ 0.0298],\n",
      "        [-0.0065],\n",
      "        [ 0.0416],\n",
      "        [-0.0154],\n",
      "        [ 0.0178],\n",
      "        [ 0.0100],\n",
      "        [-0.0068],\n",
      "        [ 0.0170],\n",
      "        [ 0.0364],\n",
      "        [ 0.0404],\n",
      "        [ 0.0192],\n",
      "        [ 0.0169],\n",
      "        [ 0.0574],\n",
      "        [ 0.0392],\n",
      "        [ 0.0536],\n",
      "        [ 0.0584]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0722, 0.0719, 0.0711, 0.0697, 0.0684, 0.0681, 0.0662, 0.0662, 0.0663,\n",
      "        0.0655, 0.0659, 0.0677, 0.0686, 0.0688, 0.0686, 0.0684, 0.0684, 0.0693,\n",
      "        0.0693, 0.0691, 0.0700, 0.0700, 0.0699, 0.0693, 0.0684, 0.0684, 0.0684,\n",
      "        0.0691, 0.0681, 0.0696, 0.0697, 0.0719], device='cuda:0')\n",
      "tensor([[ 0.0567],\n",
      "        [ 0.0522],\n",
      "        [ 0.0030],\n",
      "        [ 0.0455],\n",
      "        [ 0.0254],\n",
      "        [ 0.2303],\n",
      "        [ 0.1571],\n",
      "        [ 0.1288],\n",
      "        [ 0.0458],\n",
      "        [ 0.0571],\n",
      "        [ 0.0707],\n",
      "        [ 0.1017],\n",
      "        [ 0.0270],\n",
      "        [ 0.0236],\n",
      "        [ 0.0013],\n",
      "        [ 0.0645],\n",
      "        [ 0.0349],\n",
      "        [ 0.0897],\n",
      "        [ 0.1069],\n",
      "        [ 0.0445],\n",
      "        [ 0.0462],\n",
      "        [ 0.0530],\n",
      "        [ 0.0285],\n",
      "        [ 0.0709],\n",
      "        [ 0.0588],\n",
      "        [ 0.0993],\n",
      "        [ 0.1476],\n",
      "        [ 0.0374],\n",
      "        [-0.0039],\n",
      "        [ 0.0753],\n",
      "        [ 0.0185],\n",
      "        [-0.0153]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0750, 0.0755, 0.0749, 0.0749, 0.0759, 0.0765, 0.0776, 0.0770, 0.0773,\n",
      "        0.0793, 0.0783, 0.0793, 0.0779, 0.0771, 0.0792, 0.0795, 0.0811, 0.0805,\n",
      "        0.0787, 0.0780, 0.0777, 0.0786, 0.0787, 0.0799, 0.0798, 0.0799, 0.0823,\n",
      "        0.0832, 0.0836, 0.0827, 0.0845, 0.0849], device='cuda:0')\n",
      "tensor([[ 0.0198],\n",
      "        [-0.0202],\n",
      "        [ 0.0157],\n",
      "        [ 0.0140],\n",
      "        [ 0.0203],\n",
      "        [ 0.0389],\n",
      "        [ 0.1111],\n",
      "        [ 0.2263],\n",
      "        [ 0.0938],\n",
      "        [ 0.0184],\n",
      "        [-0.0124],\n",
      "        [ 0.0761],\n",
      "        [ 0.1652],\n",
      "        [ 0.0218],\n",
      "        [ 0.0007],\n",
      "        [ 0.0178],\n",
      "        [ 0.0575],\n",
      "        [ 0.0148],\n",
      "        [ 0.0460],\n",
      "        [ 0.0146],\n",
      "        [ 0.0207],\n",
      "        [ 0.0463],\n",
      "        [ 0.0098],\n",
      "        [ 0.0592],\n",
      "        [-0.0107],\n",
      "        [ 0.0532],\n",
      "        [ 0.1007],\n",
      "        [ 0.0621],\n",
      "        [ 0.0624],\n",
      "        [ 0.0302],\n",
      "        [ 0.0502],\n",
      "        [ 0.0135]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0836, 0.0858, 0.0889, 0.0911, 0.0913, 0.0932, 0.0951, 0.0925, 0.0895,\n",
      "        0.0904, 0.0920, 0.0914, 0.0907, 0.0914, 0.0913, 0.0916, 0.0920, 0.0922,\n",
      "        0.0929, 0.0925, 0.0928, 0.0907, 0.0910, 0.0932, 0.0956, 0.0942, 0.0950,\n",
      "        0.0929, 0.0901, 0.0905, 0.0920, 0.0916], device='cuda:0')\n",
      "tensor([[ 1.2729e-02],\n",
      "        [ 9.0987e-02],\n",
      "        [ 1.1457e-01],\n",
      "        [-1.0903e-03],\n",
      "        [-1.7864e-02],\n",
      "        [ 1.7400e-02],\n",
      "        [ 6.6629e-02],\n",
      "        [ 1.2256e-02],\n",
      "        [ 1.2162e-01],\n",
      "        [ 1.8547e-01],\n",
      "        [ 7.9397e-03],\n",
      "        [ 1.7693e-02],\n",
      "        [ 2.4500e-03],\n",
      "        [ 5.5004e-02],\n",
      "        [ 4.1915e-02],\n",
      "        [ 5.1326e-02],\n",
      "        [ 4.1086e-02],\n",
      "        [-9.7204e-05],\n",
      "        [ 1.5070e-01],\n",
      "        [ 6.5520e-02],\n",
      "        [ 9.9520e-02],\n",
      "        [ 2.0059e-02],\n",
      "        [ 5.6153e-02],\n",
      "        [-3.8520e-03],\n",
      "        [-2.3701e-02],\n",
      "        [-1.9830e-02],\n",
      "        [ 5.0915e-02],\n",
      "        [ 7.1016e-03],\n",
      "        [ 1.5400e-01],\n",
      "        [ 1.1119e-01],\n",
      "        [ 2.7273e-02],\n",
      "        [ 1.1103e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0885, 0.0886, 0.0869, 0.0863, 0.0860, 0.0873, 0.0891, 0.0905, 0.0905,\n",
      "        0.0901, 0.0914, 0.0962, 0.0954, 0.0959, 0.0972, 0.0967, 0.0933, 0.0942,\n",
      "        0.0953, 0.0941, 0.0960, 0.0950, 0.0975, 0.0982, 0.0995, 0.0985, 0.1007,\n",
      "        0.1032, 0.1034, 0.1074, 0.1071, 0.1003], device='cuda:0')\n",
      "tensor([[ 8.3218e-02],\n",
      "        [ 2.9109e-02],\n",
      "        [ 9.4714e-02],\n",
      "        [ 3.3432e-01],\n",
      "        [ 3.0127e-02],\n",
      "        [ 3.8657e-02],\n",
      "        [ 5.0650e-02],\n",
      "        [ 7.6698e-02],\n",
      "        [ 1.6380e-01],\n",
      "        [ 1.6670e-02],\n",
      "        [ 5.6520e-02],\n",
      "        [ 5.2434e-02],\n",
      "        [ 2.3048e-02],\n",
      "        [ 1.3031e-02],\n",
      "        [ 6.3250e-02],\n",
      "        [ 3.0588e-02],\n",
      "        [-5.1211e-02],\n",
      "        [-3.3798e-02],\n",
      "        [ 6.3750e-02],\n",
      "        [-1.7587e-02],\n",
      "        [ 5.5435e-02],\n",
      "        [-1.8280e-02],\n",
      "        [-2.7164e-02],\n",
      "        [-2.9584e-04],\n",
      "        [ 2.9337e-02],\n",
      "        [ 5.8327e-02],\n",
      "        [ 2.7424e-02],\n",
      "        [ 1.1100e-01],\n",
      "        [ 4.7496e-02],\n",
      "        [-6.3673e-03],\n",
      "        [ 9.1748e-02],\n",
      "        [ 1.2978e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1037, 0.1031, 0.1077, 0.1087, 0.1094, 0.1115, 0.1114, 0.1093, 0.1102,\n",
      "        0.1077, 0.1094, 0.1090, 0.1093, 0.1102, 0.1105, 0.1096, 0.1097, 0.1115,\n",
      "        0.1130, 0.1134, 0.1149, 0.1122, 0.1068, 0.1078, 0.1066, 0.1046, 0.1034,\n",
      "        0.1007, 0.1016, 0.1007, 0.1028, 0.1021], device='cuda:0')\n",
      "tensor([[ 0.0084],\n",
      "        [ 0.0852],\n",
      "        [ 0.0773],\n",
      "        [ 0.0502],\n",
      "        [ 0.0111],\n",
      "        [ 0.1037],\n",
      "        [-0.0064],\n",
      "        [ 0.0118],\n",
      "        [ 0.0667],\n",
      "        [ 0.1154],\n",
      "        [ 0.1439],\n",
      "        [-0.1025],\n",
      "        [ 0.1479],\n",
      "        [ 0.1043],\n",
      "        [ 0.0250],\n",
      "        [ 0.0551],\n",
      "        [-0.0253],\n",
      "        [ 0.0383],\n",
      "        [ 0.0301],\n",
      "        [ 0.0065],\n",
      "        [-0.0011],\n",
      "        [ 0.0733],\n",
      "        [-0.0051],\n",
      "        [ 0.0440],\n",
      "        [ 0.0136],\n",
      "        [ 0.0059],\n",
      "        [-0.0106],\n",
      "        [-0.0133],\n",
      "        [-0.0291],\n",
      "        [ 0.0179],\n",
      "        [ 0.0150],\n",
      "        [ 0.0105]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1001, 0.0997, 0.0981, 0.0975, 0.0945, 0.0959, 0.0925, 0.0910, 0.0897,\n",
      "        0.0919, 0.0950, 0.0938, 0.0922, 0.0916, 0.0902, 0.0904, 0.0922, 0.0916,\n",
      "        0.0923, 0.0911, 0.0928, 0.0914, 0.0923, 0.0919, 0.0894, 0.0879, 0.0900,\n",
      "        0.0905, 0.0900, 0.0917, 0.0951, 0.0945], device='cuda:0')\n",
      "tensor([[ 0.0083],\n",
      "        [ 0.0283],\n",
      "        [-0.0016],\n",
      "        [ 0.2267],\n",
      "        [ 0.0331],\n",
      "        [ 0.0680],\n",
      "        [ 0.0768],\n",
      "        [ 0.1177],\n",
      "        [ 0.0487],\n",
      "        [ 0.0421],\n",
      "        [ 0.0431],\n",
      "        [ 0.0160],\n",
      "        [ 0.0120],\n",
      "        [ 0.0024],\n",
      "        [ 0.0265],\n",
      "        [ 0.0070],\n",
      "        [ 0.0379],\n",
      "        [ 0.0476],\n",
      "        [ 0.0995],\n",
      "        [ 0.0292],\n",
      "        [ 0.0079],\n",
      "        [ 0.0343],\n",
      "        [ 0.0241],\n",
      "        [ 0.0563],\n",
      "        [ 0.0466],\n",
      "        [ 0.0699],\n",
      "        [-0.0013],\n",
      "        [ 0.0390],\n",
      "        [ 0.0240],\n",
      "        [-0.0041],\n",
      "        [ 0.0222],\n",
      "        [ 0.0461]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0967, 0.0933, 0.0976, 0.0964, 0.0942, 0.0939, 0.0947, 0.0967, 0.0956,\n",
      "        0.0951, 0.0984, 0.1006, 0.0994, 0.0973, 0.0962, 0.0969, 0.0957, 0.0957,\n",
      "        0.0933, 0.0935, 0.0936, 0.0931, 0.0905, 0.0923, 0.0932, 0.0939, 0.0939,\n",
      "        0.0953, 0.0954, 0.0948, 0.0926, 0.0942], device='cuda:0')\n",
      "tensor([[ 0.0774],\n",
      "        [ 0.1714],\n",
      "        [ 0.0898],\n",
      "        [ 0.0531],\n",
      "        [ 0.0733],\n",
      "        [-0.0156],\n",
      "        [ 0.0433],\n",
      "        [ 0.0084],\n",
      "        [ 0.0525],\n",
      "        [ 0.0062],\n",
      "        [ 0.0267],\n",
      "        [ 0.0051],\n",
      "        [ 0.1024],\n",
      "        [ 0.0713],\n",
      "        [ 0.1138],\n",
      "        [ 0.0537],\n",
      "        [ 0.0048],\n",
      "        [ 0.0108],\n",
      "        [-0.0623],\n",
      "        [ 0.0394],\n",
      "        [ 0.0494],\n",
      "        [-0.0145],\n",
      "        [ 0.0552],\n",
      "        [-0.0074],\n",
      "        [ 0.0518],\n",
      "        [ 0.0856],\n",
      "        [ 0.0288],\n",
      "        [-0.0652],\n",
      "        [ 0.0732],\n",
      "        [ 0.1159],\n",
      "        [ 0.0781],\n",
      "        [ 0.0579]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0938, 0.0938, 0.0926, 0.0951, 0.0944, 0.0933, 0.0923, 0.0914, 0.0873,\n",
      "        0.0858, 0.0892, 0.0863, 0.0880, 0.0885, 0.0891, 0.0894, 0.0871, 0.0886,\n",
      "        0.0880, 0.0861, 0.0833, 0.0854, 0.0860, 0.0832, 0.0838, 0.0838, 0.0827,\n",
      "        0.0789, 0.0835, 0.0842, 0.0944, 0.1012], device='cuda:0')\n",
      "tensor([[ 1.9794e-02],\n",
      "        [ 3.9991e-03],\n",
      "        [ 7.9769e-02],\n",
      "        [ 9.7996e-02],\n",
      "        [ 2.1326e-01],\n",
      "        [-8.0476e-03],\n",
      "        [ 5.4268e-02],\n",
      "        [ 1.4036e-01],\n",
      "        [ 4.6842e-02],\n",
      "        [-7.7541e-03],\n",
      "        [ 4.6637e-02],\n",
      "        [ 3.5084e-02],\n",
      "        [ 1.7198e-02],\n",
      "        [-7.3556e-03],\n",
      "        [ 2.0381e-03],\n",
      "        [ 2.7095e-02],\n",
      "        [-1.0185e-02],\n",
      "        [ 9.7877e-03],\n",
      "        [-2.7972e-03],\n",
      "        [ 9.8041e-03],\n",
      "        [ 4.7029e-02],\n",
      "        [ 6.1898e-02],\n",
      "        [ 3.8996e-02],\n",
      "        [ 3.3464e-02],\n",
      "        [ 4.6910e-02],\n",
      "        [ 1.8586e-02],\n",
      "        [-9.6369e-03],\n",
      "        [ 4.4233e-02],\n",
      "        [-6.1597e-04],\n",
      "        [ 2.8591e-02],\n",
      "        [ 5.5330e-02],\n",
      "        [-5.1159e-05]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1015, 0.1024, 0.1071, 0.1037, 0.1044, 0.1065, 0.1090, 0.1088, 0.1094,\n",
      "        0.1102, 0.1133, 0.1162, 0.1137, 0.1148, 0.1148, 0.1168, 0.1149, 0.1156,\n",
      "        0.1196, 0.1201, 0.1214, 0.1227, 0.1273, 0.1291, 0.1282, 0.1328, 0.1311,\n",
      "        0.1255, 0.1202, 0.1179, 0.1212, 0.1189], device='cuda:0')\n",
      "tensor([[ 0.1682],\n",
      "        [ 0.1027],\n",
      "        [ 0.0013],\n",
      "        [ 0.0539],\n",
      "        [ 0.0343],\n",
      "        [-0.0009],\n",
      "        [ 0.0092],\n",
      "        [ 0.0362],\n",
      "        [ 0.0364],\n",
      "        [-0.0249],\n",
      "        [ 0.0503],\n",
      "        [ 0.0667],\n",
      "        [ 0.0853],\n",
      "        [ 0.0114],\n",
      "        [ 0.1427],\n",
      "        [ 0.0274],\n",
      "        [-0.0089],\n",
      "        [ 0.1462],\n",
      "        [ 0.0341],\n",
      "        [ 0.0328],\n",
      "        [ 0.0178],\n",
      "        [ 0.0167],\n",
      "        [-0.0321],\n",
      "        [ 0.0642],\n",
      "        [ 0.1135],\n",
      "        [ 0.0241],\n",
      "        [ 0.0300],\n",
      "        [ 0.0066],\n",
      "        [ 0.0069],\n",
      "        [ 0.0354],\n",
      "        [ 0.1040],\n",
      "        [ 0.0802]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1190, 0.1156, 0.1192, 0.1156, 0.1176, 0.1187, 0.1223, 0.1279, 0.1245,\n",
      "        0.1189, 0.1164, 0.1156, 0.1091, 0.1115, 0.1121, 0.1103, 0.1121, 0.1111,\n",
      "        0.1196, 0.1221, 0.1198, 0.1217, 0.1199, 0.1177, 0.1195, 0.1124, 0.1155,\n",
      "        0.1171, 0.1050, 0.1053, 0.1052, 0.1074], device='cuda:0')\n",
      "tensor([[ 0.0193],\n",
      "        [ 0.2375],\n",
      "        [ 0.1203],\n",
      "        [ 0.0469],\n",
      "        [ 0.0141],\n",
      "        [ 0.1360],\n",
      "        [-0.0184],\n",
      "        [ 0.0767],\n",
      "        [-0.0042],\n",
      "        [ 0.0108],\n",
      "        [-0.0025],\n",
      "        [-0.0159],\n",
      "        [ 0.0210],\n",
      "        [-0.0053],\n",
      "        [ 0.0566],\n",
      "        [ 0.0546],\n",
      "        [ 0.0871],\n",
      "        [-0.0155],\n",
      "        [ 0.0685],\n",
      "        [ 0.0269],\n",
      "        [ 0.0106],\n",
      "        [ 0.0415],\n",
      "        [ 0.0193],\n",
      "        [ 0.0446],\n",
      "        [ 0.0815],\n",
      "        [ 0.0286],\n",
      "        [ 0.0270],\n",
      "        [ 0.0044],\n",
      "        [ 0.0150],\n",
      "        [ 0.0112],\n",
      "        [ 0.0165],\n",
      "        [ 0.0743]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1071, 0.1068, 0.1086, 0.1080, 0.1090, 0.1080, 0.1081, 0.1081, 0.1084,\n",
      "        0.1071, 0.1057, 0.1057, 0.1071, 0.1063, 0.1078, 0.1090, 0.1094, 0.1090,\n",
      "        0.1117, 0.1131, 0.1118, 0.1111, 0.1097, 0.1091, 0.1086, 0.1069, 0.1074,\n",
      "        0.1068, 0.1052, 0.1057, 0.1046, 0.1003], device='cuda:0')\n",
      "tensor([[ 2.2553e-02],\n",
      "        [-3.0566e-02],\n",
      "        [ 1.6193e-02],\n",
      "        [ 1.3936e-03],\n",
      "        [ 1.0939e-02],\n",
      "        [ 1.3427e-03],\n",
      "        [ 3.6838e-02],\n",
      "        [ 1.2451e-02],\n",
      "        [ 5.4182e-02],\n",
      "        [ 1.8466e-02],\n",
      "        [-1.3845e-04],\n",
      "        [ 2.3385e-02],\n",
      "        [-2.3510e-03],\n",
      "        [ 3.8185e-02],\n",
      "        [ 1.1015e-01],\n",
      "        [ 6.1427e-02],\n",
      "        [ 1.7680e-02],\n",
      "        [-9.3358e-03],\n",
      "        [ 9.7589e-02],\n",
      "        [ 4.7882e-02],\n",
      "        [ 1.1045e-02],\n",
      "        [ 1.3870e-01],\n",
      "        [-1.5181e-03],\n",
      "        [ 1.4933e-02],\n",
      "        [-2.7174e-02],\n",
      "        [ 1.6645e-02],\n",
      "        [-9.2118e-03],\n",
      "        [ 4.6173e-02],\n",
      "        [ 1.7722e-01],\n",
      "        [ 6.4199e-02],\n",
      "        [ 8.9706e-02],\n",
      "        [ 1.7871e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1009, 0.1019, 0.1025, 0.1024, 0.1026, 0.1007, 0.1018, 0.1003, 0.1013,\n",
      "        0.0997, 0.0972, 0.0984, 0.0985, 0.0972, 0.0975, 0.0976, 0.1006, 0.0988,\n",
      "        0.0970, 0.0963, 0.0969, 0.0976, 0.0975, 0.0941, 0.0933, 0.0880, 0.0938,\n",
      "        0.0919, 0.0920, 0.0914, 0.0900, 0.0873], device='cuda:0')\n",
      "tensor([[ 0.0561],\n",
      "        [ 0.0080],\n",
      "        [ 0.0472],\n",
      "        [-0.0301],\n",
      "        [-0.0085],\n",
      "        [ 0.0941],\n",
      "        [ 0.0187],\n",
      "        [ 0.0746],\n",
      "        [ 0.0657],\n",
      "        [ 0.1520],\n",
      "        [ 0.1320],\n",
      "        [ 0.0651],\n",
      "        [ 0.0206],\n",
      "        [ 0.0205],\n",
      "        [-0.0032],\n",
      "        [-0.0014],\n",
      "        [ 0.0126],\n",
      "        [ 0.0141],\n",
      "        [ 0.0481],\n",
      "        [ 0.0736],\n",
      "        [ 0.0070],\n",
      "        [ 0.1017],\n",
      "        [ 0.0084],\n",
      "        [ 0.0454],\n",
      "        [ 0.0308],\n",
      "        [ 0.0416],\n",
      "        [ 0.0196],\n",
      "        [-0.0170],\n",
      "        [ 0.0142],\n",
      "        [ 0.0331],\n",
      "        [ 0.0537],\n",
      "        [ 0.0129]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0891, 0.1031, 0.1034, 0.1044, 0.1075, 0.1077, 0.1074, 0.1093, 0.1097,\n",
      "        0.1102, 0.1137, 0.1148, 0.1134, 0.1131, 0.1099, 0.1121, 0.1117, 0.1106,\n",
      "        0.1106, 0.1112, 0.1133, 0.1137, 0.1142, 0.1136, 0.1127, 0.1165, 0.1167,\n",
      "        0.1158, 0.1168, 0.1161, 0.1143, 0.1171], device='cuda:0')\n",
      "tensor([[ 0.0373],\n",
      "        [ 0.0058],\n",
      "        [ 0.0339],\n",
      "        [-0.0118],\n",
      "        [ 0.0115],\n",
      "        [ 0.0137],\n",
      "        [ 0.1256],\n",
      "        [-0.0064],\n",
      "        [-0.0148],\n",
      "        [ 0.2789],\n",
      "        [ 0.0731],\n",
      "        [ 0.1370],\n",
      "        [ 0.1040],\n",
      "        [-0.0028],\n",
      "        [ 0.0658],\n",
      "        [-0.0013],\n",
      "        [ 0.0683],\n",
      "        [ 0.0253],\n",
      "        [ 0.0556],\n",
      "        [-0.0553],\n",
      "        [ 0.0229],\n",
      "        [ 0.1734],\n",
      "        [ 0.0677],\n",
      "        [ 0.0961],\n",
      "        [ 0.0223],\n",
      "        [ 0.0533],\n",
      "        [ 0.0124],\n",
      "        [ 0.0243],\n",
      "        [ 0.0407],\n",
      "        [ 0.0138],\n",
      "        [-0.0144],\n",
      "        [ 0.0479]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1196, 0.1202, 0.1201, 0.1192, 0.1249, 0.1257, 0.1267, 0.1277, 0.1266,\n",
      "        0.1260, 0.1274, 0.1273, 0.1301, 0.1276, 0.1280, 0.1277, 0.1269, 0.1294,\n",
      "        0.1283, 0.1302, 0.1317, 0.1323, 0.1298, 0.1316, 0.1341, 0.1342, 0.1336,\n",
      "        0.1314, 0.1291, 0.1335, 0.1344, 0.1307], device='cuda:0')\n",
      "tensor([[ 0.0818],\n",
      "        [-0.0103],\n",
      "        [ 0.0599],\n",
      "        [ 0.1634],\n",
      "        [ 0.0514],\n",
      "        [ 0.0578],\n",
      "        [ 0.0402],\n",
      "        [-0.0042],\n",
      "        [-0.0013],\n",
      "        [ 0.0436],\n",
      "        [ 0.0318],\n",
      "        [ 0.0116],\n",
      "        [-0.0093],\n",
      "        [-0.0314],\n",
      "        [ 0.0393],\n",
      "        [ 0.0375],\n",
      "        [ 0.0076],\n",
      "        [-0.0475],\n",
      "        [ 0.0282],\n",
      "        [-0.0055],\n",
      "        [-0.0102],\n",
      "        [ 0.0247],\n",
      "        [ 0.0713],\n",
      "        [ 0.0097],\n",
      "        [ 0.2620],\n",
      "        [ 0.0851],\n",
      "        [ 0.0542],\n",
      "        [ 0.0465],\n",
      "        [ 0.0529],\n",
      "        [ 0.1079],\n",
      "        [-0.0324],\n",
      "        [-0.0867]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1333, 0.1311, 0.1301, 0.1311, 0.1291, 0.1300, 0.1331, 0.1313, 0.1328,\n",
      "        0.1345, 0.1382, 0.1387, 0.1394, 0.1395, 0.1381, 0.1398, 0.1424, 0.1519,\n",
      "        0.1540, 0.1627, 0.1609, 0.1627, 0.1679, 0.1669, 0.1673, 0.1674, 0.1689,\n",
      "        0.1732, 0.1728, 0.1720, 0.1679, 0.1645], device='cuda:0')\n",
      "tensor([[ 0.0734],\n",
      "        [ 0.1662],\n",
      "        [ 0.0990],\n",
      "        [ 0.0031],\n",
      "        [ 0.0531],\n",
      "        [-0.0271],\n",
      "        [ 0.1428],\n",
      "        [ 0.0903],\n",
      "        [ 0.0264],\n",
      "        [ 0.0248],\n",
      "        [ 0.0373],\n",
      "        [ 0.0239],\n",
      "        [ 0.0109],\n",
      "        [ 0.0109],\n",
      "        [ 0.0671],\n",
      "        [ 0.0249],\n",
      "        [-0.0463],\n",
      "        [-0.0336],\n",
      "        [ 0.0675],\n",
      "        [ 0.0498],\n",
      "        [ 0.1209],\n",
      "        [ 0.0280],\n",
      "        [ 0.0138],\n",
      "        [ 0.0786],\n",
      "        [ 0.0546],\n",
      "        [ 0.0388],\n",
      "        [ 0.0060],\n",
      "        [ 0.0748],\n",
      "        [ 0.0223],\n",
      "        [ 0.0198],\n",
      "        [ 0.0601],\n",
      "        [ 0.0410]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1697, 0.1670, 0.1651, 0.1598, 0.1612, 0.1562, 0.1601, 0.1680, 0.1674,\n",
      "        0.1633, 0.1629, 0.1646, 0.1646, 0.1639, 0.1621, 0.1596, 0.1617, 0.1686,\n",
      "        0.1711, 0.1736, 0.1695, 0.1719, 0.1732, 0.1742, 0.1779, 0.1751, 0.1762,\n",
      "        0.1759, 0.1779, 0.1791, 0.1673, 0.1599], device='cuda:0')\n",
      "tensor([[ 0.0578],\n",
      "        [ 0.0239],\n",
      "        [ 0.0597],\n",
      "        [ 0.1238],\n",
      "        [ 0.0310],\n",
      "        [ 0.0544],\n",
      "        [ 0.0586],\n",
      "        [-0.0239],\n",
      "        [ 0.0314],\n",
      "        [ 0.0197],\n",
      "        [-0.0078],\n",
      "        [ 0.0473],\n",
      "        [ 0.0453],\n",
      "        [ 0.0237],\n",
      "        [ 0.0181],\n",
      "        [ 0.0625],\n",
      "        [ 0.0607],\n",
      "        [ 0.0101],\n",
      "        [ 0.0175],\n",
      "        [ 0.0256],\n",
      "        [-0.0048],\n",
      "        [-0.0409],\n",
      "        [-0.0418],\n",
      "        [ 0.0583],\n",
      "        [ 0.0140],\n",
      "        [-0.0174],\n",
      "        [ 0.0411],\n",
      "        [ 0.0372],\n",
      "        [ 0.0278],\n",
      "        [ 0.0745],\n",
      "        [ 0.0262],\n",
      "        [ 0.0281]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1584, 0.1528, 0.1587, 0.1654, 0.1664, 0.1660, 0.1636, 0.1621, 0.1564,\n",
      "        0.1531, 0.1564, 0.1493, 0.1522, 0.1519, 0.1536, 0.1519, 0.1522, 0.1503,\n",
      "        0.1475, 0.1432, 0.1506, 0.1537, 0.1542, 0.1496, 0.1505, 0.1521, 0.1518,\n",
      "        0.1525, 0.1539, 0.1517, 0.1533, 0.1531], device='cuda:0')\n",
      "tensor([[ 0.0726],\n",
      "        [ 0.1148],\n",
      "        [ 0.0207],\n",
      "        [ 0.0043],\n",
      "        [ 0.0489],\n",
      "        [ 0.0289],\n",
      "        [-0.0240],\n",
      "        [-0.0335],\n",
      "        [ 0.1118],\n",
      "        [ 0.0749],\n",
      "        [ 0.1705],\n",
      "        [ 0.0524],\n",
      "        [ 0.0636],\n",
      "        [ 0.0941],\n",
      "        [ 0.0143],\n",
      "        [ 0.0522],\n",
      "        [ 0.0145],\n",
      "        [-0.0017],\n",
      "        [ 0.0237],\n",
      "        [ 0.0447],\n",
      "        [ 0.1166],\n",
      "        [-0.0269],\n",
      "        [ 0.0060],\n",
      "        [ 0.0180],\n",
      "        [ 0.0358],\n",
      "        [-0.0389],\n",
      "        [ 0.1043],\n",
      "        [ 0.0600],\n",
      "        [ 0.0132],\n",
      "        [ 0.0391],\n",
      "        [ 0.0659],\n",
      "        [ 0.0401]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1518, 0.1494, 0.1503, 0.1455, 0.1453, 0.1435, 0.1424, 0.1372, 0.1422,\n",
      "        0.1412, 0.1463, 0.1425, 0.1428, 0.1422, 0.1387, 0.1356, 0.1333, 0.1372,\n",
      "        0.1421, 0.1379, 0.1378, 0.1382, 0.1419, 0.1435, 0.1431, 0.1434, 0.1457,\n",
      "        0.1429, 0.1460, 0.1488, 0.1621, 0.1587], device='cuda:0')\n",
      "tensor([[ 0.0375],\n",
      "        [ 0.0119],\n",
      "        [ 0.0362],\n",
      "        [ 0.4046],\n",
      "        [ 0.0413],\n",
      "        [-0.0130],\n",
      "        [ 0.1049],\n",
      "        [ 0.0892],\n",
      "        [ 0.0538],\n",
      "        [ 0.0429],\n",
      "        [ 0.0647],\n",
      "        [ 0.0562],\n",
      "        [ 0.0151],\n",
      "        [ 0.0436],\n",
      "        [ 0.0427],\n",
      "        [ 0.0438],\n",
      "        [ 0.0435],\n",
      "        [ 0.0590],\n",
      "        [ 0.0434],\n",
      "        [ 0.0557],\n",
      "        [ 0.0398],\n",
      "        [ 0.0260],\n",
      "        [ 0.0485],\n",
      "        [-0.0049],\n",
      "        [-0.0133],\n",
      "        [ 0.0329],\n",
      "        [ 0.0049],\n",
      "        [ 0.0521],\n",
      "        [ 0.0718],\n",
      "        [ 0.0126],\n",
      "        [-0.0258],\n",
      "        [ 0.1075]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1583, 0.1677, 0.1702, 0.1713, 0.1722, 0.1769, 0.1762, 0.1722, 0.1784,\n",
      "        0.1785, 0.1856, 0.1857, 0.1860, 0.1860, 0.1815, 0.1800, 0.1859, 0.1875,\n",
      "        0.1844, 0.1855, 0.1924, 0.1936, 0.1880, 0.1850, 0.1865, 0.1800, 0.1776,\n",
      "        0.1764, 0.1829, 0.1859, 0.1844, 0.1865], device='cuda:0')\n",
      "tensor([[ 0.0122],\n",
      "        [ 0.0307],\n",
      "        [ 0.0474],\n",
      "        [-0.0254],\n",
      "        [-0.0203],\n",
      "        [ 0.0494],\n",
      "        [ 0.0353],\n",
      "        [ 0.0188],\n",
      "        [ 0.0495],\n",
      "        [ 0.0405],\n",
      "        [ 0.0015],\n",
      "        [ 0.0655],\n",
      "        [ 0.0793],\n",
      "        [ 0.0288],\n",
      "        [ 0.0283],\n",
      "        [ 0.0398],\n",
      "        [ 0.0127],\n",
      "        [ 0.0541],\n",
      "        [ 0.0817],\n",
      "        [-0.0082],\n",
      "        [ 0.0191],\n",
      "        [ 0.0340],\n",
      "        [ 0.0504],\n",
      "        [ 0.0641],\n",
      "        [ 0.0391],\n",
      "        [-0.0085],\n",
      "        [ 0.0420],\n",
      "        [ 0.0664],\n",
      "        [ 0.0541],\n",
      "        [ 0.0684],\n",
      "        [ 0.3013],\n",
      "        [ 0.0794]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.1888, 0.1909, 0.1915, 0.1930, 0.1909, 0.1924, 0.1930, 0.1880, 0.1976,\n",
      "        0.1977, 0.1948, 0.1962, 0.1939, 0.1976, 0.2014, 0.2046, 0.2039, 0.2069,\n",
      "        0.2079, 0.2069, 0.2069, 0.2057, 0.2074, 0.2113, 0.2160, 0.2275, 0.2257,\n",
      "        0.2240, 0.2290, 0.2353, 0.2334, 0.2287], device='cuda:0')\n",
      "tensor([[ 0.2287],\n",
      "        [ 0.1448],\n",
      "        [ 0.2234],\n",
      "        [ 0.0467],\n",
      "        [-0.0170],\n",
      "        [ 0.0362],\n",
      "        [ 0.0168],\n",
      "        [ 0.0481],\n",
      "        [ 0.0154],\n",
      "        [ 0.0099],\n",
      "        [ 0.0152],\n",
      "        [ 0.0182],\n",
      "        [-0.0227],\n",
      "        [ 0.0340],\n",
      "        [ 0.0745],\n",
      "        [ 0.0691],\n",
      "        [ 0.0359],\n",
      "        [ 0.0746],\n",
      "        [ 0.1080],\n",
      "        [ 0.0421],\n",
      "        [ 0.0091],\n",
      "        [ 0.0367],\n",
      "        [ 0.0309],\n",
      "        [-0.0132],\n",
      "        [-0.0106],\n",
      "        [ 0.1064],\n",
      "        [ 0.0826],\n",
      "        [ 0.1343],\n",
      "        [ 0.0700],\n",
      "        [ 0.0210],\n",
      "        [ 0.0312],\n",
      "        [-0.0258]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2237, 0.2311, 0.2305, 0.2281, 0.2317, 0.2322, 0.2355, 0.2343, 0.2293,\n",
      "        0.2240, 0.2250, 0.2272, 0.2255, 0.2167, 0.2263, 0.2356, 0.2358, 0.2305,\n",
      "        0.2319, 0.2287, 0.2247, 0.2260, 0.2195, 0.2201, 0.2265, 0.2253, 0.2257,\n",
      "        0.2255, 0.2237, 0.2169, 0.2098, 0.2122], device='cuda:0')\n",
      "tensor([[-0.0121],\n",
      "        [-0.0177],\n",
      "        [ 0.0920],\n",
      "        [ 0.0684],\n",
      "        [ 0.0279],\n",
      "        [ 0.0925],\n",
      "        [ 0.1013],\n",
      "        [ 0.0540],\n",
      "        [ 0.0017],\n",
      "        [ 0.0408],\n",
      "        [-0.0008],\n",
      "        [ 0.0055],\n",
      "        [ 0.0909],\n",
      "        [ 0.0345],\n",
      "        [ 0.0441],\n",
      "        [ 0.0282],\n",
      "        [ 0.0439],\n",
      "        [ 0.0776],\n",
      "        [ 0.0388],\n",
      "        [ 0.0582],\n",
      "        [ 0.0912],\n",
      "        [ 0.0294],\n",
      "        [ 0.0877],\n",
      "        [ 0.1130],\n",
      "        [ 0.0240],\n",
      "        [ 0.0076],\n",
      "        [-0.0365],\n",
      "        [ 0.0740],\n",
      "        [ 0.0500],\n",
      "        [ 0.1380],\n",
      "        [ 0.0054],\n",
      "        [-0.0198]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2116, 0.2080, 0.2160, 0.2160, 0.2139, 0.2151, 0.2260, 0.2246, 0.2206,\n",
      "        0.2207, 0.2231, 0.2287, 0.2311, 0.2252, 0.2277, 0.2271, 0.2283, 0.2330,\n",
      "        0.2293, 0.2278, 0.2286, 0.2275, 0.2247, 0.2209, 0.2166, 0.2061, 0.2110,\n",
      "        0.2291, 0.2290, 0.2178, 0.2122, 0.1933], device='cuda:0')\n",
      "tensor([[ 0.0971],\n",
      "        [ 0.0364],\n",
      "        [ 0.0464],\n",
      "        [ 0.0787],\n",
      "        [-0.0128],\n",
      "        [ 0.0754],\n",
      "        [ 0.1451],\n",
      "        [ 0.0573],\n",
      "        [ 0.0422],\n",
      "        [ 0.1042],\n",
      "        [ 0.0130],\n",
      "        [ 0.0508],\n",
      "        [ 0.0219],\n",
      "        [ 0.0053],\n",
      "        [-0.0175],\n",
      "        [-0.0316],\n",
      "        [ 0.1309],\n",
      "        [ 0.0103],\n",
      "        [ 0.0442],\n",
      "        [ 0.0185],\n",
      "        [-0.0015],\n",
      "        [ 0.0769],\n",
      "        [ 0.0110],\n",
      "        [ 0.0367],\n",
      "        [ 0.0064],\n",
      "        [ 0.0910],\n",
      "        [ 0.1106],\n",
      "        [ 0.0526],\n",
      "        [ 0.0323],\n",
      "        [ 0.0905],\n",
      "        [ 0.0352],\n",
      "        [ 0.0019]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2154, 0.2128, 0.2070, 0.2133, 0.2207, 0.2215, 0.2234, 0.2194, 0.2157,\n",
      "        0.2114, 0.2145, 0.2089, 0.2148, 0.2204, 0.2252, 0.2219, 0.2241, 0.2281,\n",
      "        0.2300, 0.2243, 0.2343, 0.2399, 0.2393, 0.2466, 0.2423, 0.2414, 0.2387,\n",
      "        0.2458, 0.2473, 0.2414, 0.2322, 0.2207], device='cuda:0')\n",
      "tensor([[ 0.1034],\n",
      "        [ 0.0807],\n",
      "        [ 0.0130],\n",
      "        [ 0.0797],\n",
      "        [ 0.0534],\n",
      "        [ 0.0817],\n",
      "        [ 0.0141],\n",
      "        [ 0.0494],\n",
      "        [ 0.0084],\n",
      "        [ 0.0430],\n",
      "        [ 0.0900],\n",
      "        [ 0.0345],\n",
      "        [-0.0107],\n",
      "        [-0.0333],\n",
      "        [-0.0263],\n",
      "        [-0.0301],\n",
      "        [-0.0127],\n",
      "        [ 0.0413],\n",
      "        [ 0.0858],\n",
      "        [ 0.1125],\n",
      "        [ 0.0569],\n",
      "        [ 0.0598],\n",
      "        [ 0.0089],\n",
      "        [ 0.0405],\n",
      "        [ 0.0595],\n",
      "        [ 0.0491],\n",
      "        [ 0.0456],\n",
      "        [ 0.0664],\n",
      "        [ 0.0710],\n",
      "        [ 0.2059],\n",
      "        [ 0.1454],\n",
      "        [ 0.0226]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2178, 0.2190, 0.2257, 0.2216, 0.2169, 0.2219, 0.2229, 0.2136, 0.2148,\n",
      "        0.2209, 0.2234, 0.2243, 0.2278, 0.2302, 0.2321, 0.2293, 0.2269, 0.2268,\n",
      "        0.2170, 0.2172, 0.2219, 0.2231, 0.2250, 0.2287, 0.2367, 0.2172, 0.2154,\n",
      "        0.2150, 0.2125, 0.2086, 0.2098, 0.2126], device='cuda:0')\n",
      "tensor([[ 0.0446],\n",
      "        [-0.0021],\n",
      "        [ 0.0039],\n",
      "        [ 0.0590],\n",
      "        [ 0.0266],\n",
      "        [-0.0271],\n",
      "        [ 0.0123],\n",
      "        [ 0.0214],\n",
      "        [ 0.0381],\n",
      "        [ 0.0227],\n",
      "        [ 0.0066],\n",
      "        [ 0.0402],\n",
      "        [ 0.2031],\n",
      "        [ 0.1182],\n",
      "        [ 0.0723],\n",
      "        [ 0.0230],\n",
      "        [ 0.0782],\n",
      "        [ 0.0641],\n",
      "        [ 0.0534],\n",
      "        [ 0.0316],\n",
      "        [-0.0023],\n",
      "        [ 0.0265],\n",
      "        [ 0.1319],\n",
      "        [ 0.0245],\n",
      "        [ 0.0451],\n",
      "        [ 0.0596],\n",
      "        [ 0.0381],\n",
      "        [ 0.1110],\n",
      "        [ 0.0548],\n",
      "        [ 0.1152],\n",
      "        [ 0.0732],\n",
      "        [ 0.1095]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2139, 0.2182, 0.2154, 0.2129, 0.2159, 0.2122, 0.2122, 0.2190, 0.2232,\n",
      "        0.2237, 0.2225, 0.2216, 0.2234, 0.2234, 0.2231, 0.2237, 0.2228, 0.2293,\n",
      "        0.2299, 0.2274, 0.2215, 0.2219, 0.2145, 0.2144, 0.2125, 0.2077, 0.2110,\n",
      "        0.2148, 0.2175, 0.2160, 0.2198, 0.2190], device='cuda:0')\n",
      "tensor([[ 0.0667],\n",
      "        [ 0.0492],\n",
      "        [ 0.1005],\n",
      "        [ 0.0571],\n",
      "        [ 0.0036],\n",
      "        [ 0.0166],\n",
      "        [-0.0122],\n",
      "        [ 0.0120],\n",
      "        [ 0.0751],\n",
      "        [-0.0174],\n",
      "        [ 0.0820],\n",
      "        [-0.0023],\n",
      "        [-0.0073],\n",
      "        [ 0.0611],\n",
      "        [ 0.0562],\n",
      "        [ 0.0127],\n",
      "        [ 0.0022],\n",
      "        [ 0.0263],\n",
      "        [ 0.0345],\n",
      "        [ 0.0880],\n",
      "        [ 0.0504],\n",
      "        [ 0.0423],\n",
      "        [ 0.1104],\n",
      "        [ 0.0885],\n",
      "        [ 0.0461],\n",
      "        [ 0.0216],\n",
      "        [ 0.0044],\n",
      "        [ 0.1178],\n",
      "        [ 0.4635],\n",
      "        [ 0.1009],\n",
      "        [ 0.0556],\n",
      "        [ 0.0897]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2206, 0.2237, 0.2218, 0.2201, 0.2252, 0.2311, 0.2288, 0.2272, 0.2246,\n",
      "        0.2260, 0.2274, 0.2306, 0.2280, 0.2311, 0.2280, 0.2275, 0.2319, 0.2268,\n",
      "        0.2317, 0.2399, 0.2353, 0.2352, 0.2433, 0.2594, 0.2517, 0.2582, 0.2579,\n",
      "        0.2531, 0.2539, 0.2536, 0.2544, 0.2567], device='cuda:0')\n",
      "tensor([[ 0.1755],\n",
      "        [ 0.1123],\n",
      "        [ 0.0425],\n",
      "        [ 0.0239],\n",
      "        [ 0.0132],\n",
      "        [ 0.0012],\n",
      "        [ 0.0105],\n",
      "        [-0.0045],\n",
      "        [ 0.0409],\n",
      "        [ 0.0531],\n",
      "        [ 0.0572],\n",
      "        [ 0.0254],\n",
      "        [ 0.1011],\n",
      "        [ 0.1912],\n",
      "        [ 0.0723],\n",
      "        [ 0.0484],\n",
      "        [ 0.0913],\n",
      "        [ 0.0135],\n",
      "        [ 0.0824],\n",
      "        [ 0.1021],\n",
      "        [ 0.0251],\n",
      "        [ 0.1238],\n",
      "        [ 0.1169],\n",
      "        [ 0.0528],\n",
      "        [ 0.0645],\n",
      "        [ 0.0381],\n",
      "        [ 0.0498],\n",
      "        [ 0.0657],\n",
      "        [ 0.0302],\n",
      "        [ 0.0394],\n",
      "        [ 0.0802],\n",
      "        [ 0.0079]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2562, 0.2590, 0.2576, 0.2573, 0.2641, 0.2625, 0.2632, 0.2686, 0.2778,\n",
      "        0.2758, 0.2750, 0.2759, 0.2724, 0.2727, 0.2687, 0.2665, 0.2647, 0.2643,\n",
      "        0.2582, 0.2575, 0.2536, 0.2497, 0.2548, 0.2615, 0.2613, 0.2624, 0.2576,\n",
      "        0.2547, 0.2553, 0.2458, 0.2405, 0.2429], device='cuda:0')\n",
      "tensor([[-0.0269],\n",
      "        [ 0.0080],\n",
      "        [ 0.0173],\n",
      "        [ 0.1172],\n",
      "        [-0.0404],\n",
      "        [ 0.0783],\n",
      "        [ 0.0552],\n",
      "        [ 0.0546],\n",
      "        [ 0.0374],\n",
      "        [-0.0111],\n",
      "        [ 0.0005],\n",
      "        [ 0.0579],\n",
      "        [ 0.0260],\n",
      "        [ 0.0439],\n",
      "        [ 0.0721],\n",
      "        [ 0.0449],\n",
      "        [ 0.0342],\n",
      "        [ 0.0341],\n",
      "        [-0.0246],\n",
      "        [ 0.0204],\n",
      "        [ 0.0164],\n",
      "        [ 0.0484],\n",
      "        [ 0.0193],\n",
      "        [-0.0038],\n",
      "        [ 0.0087],\n",
      "        [ 0.0168],\n",
      "        [ 0.0615],\n",
      "        [ 0.0331],\n",
      "        [ 0.1619],\n",
      "        [ 0.0197],\n",
      "        [ 0.0369],\n",
      "        [ 0.1146]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2377, 0.2314, 0.2361, 0.2446, 0.2452, 0.2463, 0.2476, 0.2502, 0.2519,\n",
      "        0.2564, 0.2528, 0.2492, 0.2497, 0.2523, 0.2572, 0.2606, 0.2626, 0.2632,\n",
      "        0.2570, 0.2603, 0.2646, 0.2688, 0.2833, 0.2817, 0.2733, 0.2742, 0.2771,\n",
      "        0.2770, 0.2827, 0.2957, 0.2936, 0.2942], device='cuda:0')\n",
      "tensor([[ 0.0147],\n",
      "        [ 0.0586],\n",
      "        [ 0.0831],\n",
      "        [ 0.0734],\n",
      "        [ 0.1628],\n",
      "        [ 0.0466],\n",
      "        [ 0.0665],\n",
      "        [ 0.0559],\n",
      "        [ 0.0392],\n",
      "        [ 0.0063],\n",
      "        [ 0.0422],\n",
      "        [-0.0102],\n",
      "        [ 0.0437],\n",
      "        [-0.0334],\n",
      "        [ 0.1050],\n",
      "        [-0.0209],\n",
      "        [-0.0185],\n",
      "        [ 0.0434],\n",
      "        [ 0.0634],\n",
      "        [-0.0225],\n",
      "        [ 0.0231],\n",
      "        [-0.0084],\n",
      "        [ 0.0712],\n",
      "        [ 0.0083],\n",
      "        [ 0.1132],\n",
      "        [ 0.1422],\n",
      "        [-0.0267],\n",
      "        [ 0.0446],\n",
      "        [ 0.0741],\n",
      "        [ 0.0415],\n",
      "        [ 0.0148],\n",
      "        [ 0.0479]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2802, 0.2848, 0.2871, 0.2857, 0.2874, 0.2842, 0.2830, 0.2787, 0.2768,\n",
      "        0.2762, 0.2851, 0.2876, 0.2832, 0.2827, 0.2843, 0.2840, 0.2898, 0.2765,\n",
      "        0.2702, 0.2467, 0.2593, 0.2653, 0.2683, 0.2626, 0.2781, 0.2724, 0.2700,\n",
      "        0.2796, 0.2857, 0.2877, 0.2889, 0.2801], device='cuda:0')\n",
      "tensor([[-0.0045],\n",
      "        [ 0.0469],\n",
      "        [ 0.0070],\n",
      "        [ 0.0111],\n",
      "        [ 0.0345],\n",
      "        [ 0.0492],\n",
      "        [ 0.0277],\n",
      "        [ 0.0371],\n",
      "        [ 0.0151],\n",
      "        [ 0.0107],\n",
      "        [ 0.0391],\n",
      "        [ 0.0196],\n",
      "        [ 0.0287],\n",
      "        [ 0.1004],\n",
      "        [ 0.1425],\n",
      "        [ 0.0296],\n",
      "        [ 0.1201],\n",
      "        [ 0.1022],\n",
      "        [ 0.0522],\n",
      "        [ 0.1168],\n",
      "        [ 0.0463],\n",
      "        [ 0.0095],\n",
      "        [ 0.0663],\n",
      "        [ 0.0464],\n",
      "        [ 0.0904],\n",
      "        [ 0.0831],\n",
      "        [ 0.0360],\n",
      "        [ 0.1021],\n",
      "        [ 0.1165],\n",
      "        [ 0.0068],\n",
      "        [-0.0368],\n",
      "        [ 0.0682]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2752, 0.2835, 0.2824, 0.2926, 0.2891, 0.2960, 0.2963, 0.2911, 0.2842,\n",
      "        0.2768, 0.2755, 0.2647, 0.2624, 0.2659, 0.2724, 0.2814, 0.2898, 0.2835,\n",
      "        0.2889, 0.3031, 0.3018, 0.3099, 0.3063, 0.3177, 0.3156, 0.3150, 0.3186,\n",
      "        0.3217, 0.3260, 0.3320, 0.3314, 0.3311], device='cuda:0')\n",
      "tensor([[ 0.1466],\n",
      "        [ 0.0519],\n",
      "        [ 0.0919],\n",
      "        [ 0.0030],\n",
      "        [ 0.0557],\n",
      "        [ 0.0310],\n",
      "        [ 0.0213],\n",
      "        [ 0.0288],\n",
      "        [ 0.0358],\n",
      "        [ 0.0289],\n",
      "        [ 0.0624],\n",
      "        [ 0.0940],\n",
      "        [ 0.0257],\n",
      "        [ 0.0365],\n",
      "        [ 0.0275],\n",
      "        [ 0.0052],\n",
      "        [ 0.0684],\n",
      "        [ 0.0088],\n",
      "        [ 0.0134],\n",
      "        [ 0.0558],\n",
      "        [ 0.0553],\n",
      "        [-0.0267],\n",
      "        [-0.0009],\n",
      "        [-0.0347],\n",
      "        [ 0.0748],\n",
      "        [ 0.1267],\n",
      "        [ 0.0207],\n",
      "        [ 0.0133],\n",
      "        [-0.0196],\n",
      "        [ 0.0183],\n",
      "        [ 0.0546],\n",
      "        [ 0.0893]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3288, 0.3300, 0.3326, 0.3348, 0.3382, 0.3491, 0.3518, 0.3536, 0.3525,\n",
      "        0.3571, 0.3539, 0.3562, 0.3552, 0.3589, 0.3741, 0.3710, 0.3745, 0.3822,\n",
      "        0.3707, 0.3819, 0.3762, 0.3669, 0.3686, 0.3756, 0.3779, 0.3809, 0.3704,\n",
      "        0.3775, 0.3654, 0.3704, 0.3689, 0.3729], device='cuda:0')\n",
      "tensor([[ 0.0245],\n",
      "        [ 0.0154],\n",
      "        [ 0.0879],\n",
      "        [ 0.0760],\n",
      "        [ 0.0077],\n",
      "        [ 0.0239],\n",
      "        [ 0.0035],\n",
      "        [ 0.0689],\n",
      "        [ 0.0281],\n",
      "        [ 0.0969],\n",
      "        [ 0.1680],\n",
      "        [ 0.0052],\n",
      "        [ 0.0330],\n",
      "        [ 0.0087],\n",
      "        [ 0.0221],\n",
      "        [ 0.0306],\n",
      "        [ 0.0310],\n",
      "        [ 0.0340],\n",
      "        [ 0.0474],\n",
      "        [ 0.0605],\n",
      "        [ 0.0546],\n",
      "        [ 0.0526],\n",
      "        [ 0.0599],\n",
      "        [-0.0062],\n",
      "        [ 0.0346],\n",
      "        [ 0.0224],\n",
      "        [ 0.0291],\n",
      "        [-0.0152],\n",
      "        [-0.0702],\n",
      "        [ 0.0266],\n",
      "        [ 0.0404],\n",
      "        [ 0.0750]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3859, 0.3973, 0.4111, 0.4176, 0.4246, 0.4277, 0.4226, 0.4218, 0.4162,\n",
      "        0.4129, 0.4285, 0.4265, 0.4299, 0.4237, 0.4277, 0.4178, 0.4188, 0.4073,\n",
      "        0.4175, 0.4347, 0.4401, 0.4460, 0.4052, 0.4105, 0.4191, 0.4018, 0.4027,\n",
      "        0.4135, 0.4052, 0.3981, 0.3946, 0.3812], device='cuda:0')\n",
      "tensor([[-0.0006],\n",
      "        [ 0.0030],\n",
      "        [ 0.0676],\n",
      "        [ 0.0538],\n",
      "        [ 0.1377],\n",
      "        [-0.0471],\n",
      "        [-0.0248],\n",
      "        [-0.0277],\n",
      "        [ 0.0546],\n",
      "        [ 0.0826],\n",
      "        [ 0.0061],\n",
      "        [-0.0006],\n",
      "        [ 0.0467],\n",
      "        [ 0.0315],\n",
      "        [ 0.0153],\n",
      "        [ 0.0549],\n",
      "        [ 0.0226],\n",
      "        [ 0.0061],\n",
      "        [ 0.0344],\n",
      "        [ 0.1058],\n",
      "        [ 0.0752],\n",
      "        [ 0.0781],\n",
      "        [ 0.0545],\n",
      "        [ 0.0695],\n",
      "        [ 0.0723],\n",
      "        [ 0.0832],\n",
      "        [ 0.0518],\n",
      "        [ 0.0075],\n",
      "        [ 0.0404],\n",
      "        [ 0.0705],\n",
      "        [ 0.0543],\n",
      "        [ 0.0721]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3728, 0.3751, 0.3651, 0.3795, 0.4023, 0.3887, 0.3881, 0.3834, 0.3922,\n",
      "        0.3860, 0.4009, 0.3986, 0.3911, 0.3908, 0.3816, 0.3784, 0.3769, 0.3745,\n",
      "        0.3846, 0.4020, 0.4032, 0.4110, 0.4094, 0.4126, 0.4011, 0.4105, 0.4082,\n",
      "        0.4012, 0.4002, 0.3788, 0.3751, 0.3713], device='cuda:0')\n",
      "tensor([[ 0.0205],\n",
      "        [ 0.0458],\n",
      "        [ 0.0040],\n",
      "        [ 0.0537],\n",
      "        [ 0.1418],\n",
      "        [ 0.0097],\n",
      "        [ 0.0811],\n",
      "        [-0.0070],\n",
      "        [-0.0199],\n",
      "        [ 0.0065],\n",
      "        [ 0.0005],\n",
      "        [ 0.0326],\n",
      "        [ 0.0377],\n",
      "        [-0.0163],\n",
      "        [ 0.0778],\n",
      "        [ 0.0543],\n",
      "        [-0.0138],\n",
      "        [ 0.0340],\n",
      "        [ 0.0119],\n",
      "        [ 0.0223],\n",
      "        [-0.0107],\n",
      "        [ 0.0714],\n",
      "        [ 0.0102],\n",
      "        [-0.0294],\n",
      "        [ 0.0210],\n",
      "        [ 0.1008],\n",
      "        [ 0.2044],\n",
      "        [ 0.1584],\n",
      "        [ 0.2087],\n",
      "        [ 0.0379],\n",
      "        [ 0.0292],\n",
      "        [ 0.0721]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3810, 0.3853, 0.3878, 0.4008, 0.4024, 0.3993, 0.3987, 0.4151, 0.4129,\n",
      "        0.4212, 0.4224, 0.4207, 0.4139, 0.4058, 0.4043, 0.4005, 0.3831, 0.3745,\n",
      "        0.3816, 0.3866, 0.4401, 0.4525, 0.4764, 0.4814, 0.4649, 0.4644, 0.4747,\n",
      "        0.4820, 0.4814, 0.4817, 0.4749, 0.4938], device='cuda:0')\n",
      "tensor([[ 0.0598],\n",
      "        [ 0.0627],\n",
      "        [ 0.0457],\n",
      "        [ 0.0440],\n",
      "        [ 0.0697],\n",
      "        [ 0.0165],\n",
      "        [ 0.0562],\n",
      "        [ 0.0043],\n",
      "        [ 0.0881],\n",
      "        [ 0.0780],\n",
      "        [ 0.1138],\n",
      "        [ 0.0149],\n",
      "        [ 0.0367],\n",
      "        [ 0.0249],\n",
      "        [-0.0126],\n",
      "        [ 0.1134],\n",
      "        [-0.0152],\n",
      "        [ 0.0410],\n",
      "        [ 0.0264],\n",
      "        [-0.0019],\n",
      "        [ 0.0355],\n",
      "        [-0.0709],\n",
      "        [-0.0052],\n",
      "        [ 0.0331],\n",
      "        [ 0.0448],\n",
      "        [ 0.0130],\n",
      "        [-0.0065],\n",
      "        [ 0.0238],\n",
      "        [ 0.0534],\n",
      "        [ 0.0716],\n",
      "        [ 0.0104],\n",
      "        [ 0.0595]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4970, 0.5026, 0.5133, 0.5617, 0.5457, 0.5416, 0.5440, 0.5378, 0.5307,\n",
      "        0.5248, 0.5091, 0.5031, 0.5387, 0.5286, 0.5286, 0.5097, 0.5180, 0.5142,\n",
      "        0.5286, 0.5499, 0.5316, 0.5333, 0.5251, 0.5207, 0.5263, 0.5280, 0.5508,\n",
      "        0.5484, 0.5511, 0.5700, 0.5635, 0.5614], device='cuda:0')\n",
      "tensor([[ 0.0071],\n",
      "        [ 0.0449],\n",
      "        [ 0.0745],\n",
      "        [ 0.0775],\n",
      "        [ 0.0458],\n",
      "        [ 0.0641],\n",
      "        [ 0.0391],\n",
      "        [ 0.0008],\n",
      "        [-0.0216],\n",
      "        [ 0.0280],\n",
      "        [ 0.1836],\n",
      "        [ 0.0643],\n",
      "        [ 0.0667],\n",
      "        [ 0.0100],\n",
      "        [ 0.0274],\n",
      "        [ 0.0495],\n",
      "        [ 0.0852],\n",
      "        [ 0.0402],\n",
      "        [ 0.0783],\n",
      "        [ 0.0317],\n",
      "        [ 0.0582],\n",
      "        [ 0.0273],\n",
      "        [ 0.0121],\n",
      "        [ 0.0708],\n",
      "        [ 0.0294],\n",
      "        [ 0.1783],\n",
      "        [ 0.0131],\n",
      "        [ 0.0750],\n",
      "        [-0.0137],\n",
      "        [ 0.0074],\n",
      "        [-0.0638],\n",
      "        [ 0.0411]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5596, 0.5623, 0.5596, 0.5694, 0.5912, 0.5995, 0.6054, 0.5995, 0.6080,\n",
      "        0.6136, 0.6296, 0.6316, 0.6319, 0.6290, 0.6246, 0.6243, 0.6166, 0.5865,\n",
      "        0.5900, 0.5658, 0.5702, 0.5617, 0.5770, 0.5871, 0.5729, 0.5744, 0.5581,\n",
      "        0.5446, 0.5404, 0.5626, 0.5640, 0.5578], device='cuda:0')\n",
      "tensor([[ 0.1157],\n",
      "        [ 0.0868],\n",
      "        [-0.0218],\n",
      "        [ 0.0491],\n",
      "        [-0.0512],\n",
      "        [ 0.0018],\n",
      "        [ 0.0174],\n",
      "        [-0.0240],\n",
      "        [ 0.0354],\n",
      "        [ 0.0140],\n",
      "        [ 0.1167],\n",
      "        [-0.0176],\n",
      "        [ 0.0619],\n",
      "        [ 0.0434],\n",
      "        [ 0.0406],\n",
      "        [ 0.0549],\n",
      "        [ 0.0356],\n",
      "        [ 0.0324],\n",
      "        [ 0.0538],\n",
      "        [ 0.0061],\n",
      "        [ 0.0213],\n",
      "        [ 0.0578],\n",
      "        [ 0.0790],\n",
      "        [ 0.0409],\n",
      "        [ 0.1318],\n",
      "        [ 0.0943],\n",
      "        [ 0.0621],\n",
      "        [ 0.0632],\n",
      "        [ 0.0341],\n",
      "        [-0.0160],\n",
      "        [ 0.0583],\n",
      "        [ 0.0043]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5443, 0.5632, 0.5528, 0.5635, 0.5823, 0.5877, 0.5658, 0.5614, 0.5558,\n",
      "        0.5685, 0.5570, 0.5587, 0.5614, 0.5664, 0.5626, 0.5691, 0.5818, 0.5753,\n",
      "        0.5894, 0.6042, 0.5983, 0.6172, 0.6184, 0.6060, 0.6104, 0.6039, 0.5947,\n",
      "        0.5729, 0.5953, 0.5812, 0.5720, 0.5570], device='cuda:0')\n",
      "tensor([[ 0.0863],\n",
      "        [ 0.0621],\n",
      "        [ 0.0086],\n",
      "        [ 0.0522],\n",
      "        [ 0.0131],\n",
      "        [-0.0093],\n",
      "        [ 0.0625],\n",
      "        [ 0.0484],\n",
      "        [ 0.0240],\n",
      "        [ 0.0274],\n",
      "        [-0.0227],\n",
      "        [ 0.0450],\n",
      "        [-0.0128],\n",
      "        [ 0.0036],\n",
      "        [ 0.0269],\n",
      "        [ 0.0534],\n",
      "        [ 0.0126],\n",
      "        [ 0.0287],\n",
      "        [ 0.0500],\n",
      "        [ 0.0258],\n",
      "        [ 0.0587],\n",
      "        [ 0.0389],\n",
      "        [ 0.0411],\n",
      "        [ 0.0715],\n",
      "        [ 0.1463],\n",
      "        [ 0.0869],\n",
      "        [ 0.0270],\n",
      "        [ 0.0201],\n",
      "        [ 0.0063],\n",
      "        [ 0.0763],\n",
      "        [ 0.1322],\n",
      "        [ 0.1283]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5711, 0.5617, 0.5640, 0.5478, 0.5522, 0.5369, 0.5469, 0.5570, 0.5437,\n",
      "        0.5304, 0.5168, 0.5204, 0.5003, 0.4770, 0.4861, 0.4902, 0.4861, 0.4867,\n",
      "        0.4861, 0.4105, 0.4244, 0.4241, 0.4318, 0.4200, 0.4291, 0.4448, 0.4377,\n",
      "        0.4285, 0.4265, 0.4132, 0.4070, 0.4244], device='cuda:0')\n",
      "tensor([[ 0.0067],\n",
      "        [ 0.0629],\n",
      "        [ 0.0754],\n",
      "        [ 0.0917],\n",
      "        [ 0.0519],\n",
      "        [ 0.0563],\n",
      "        [ 0.0282],\n",
      "        [-0.0003],\n",
      "        [ 0.0256],\n",
      "        [ 0.0089],\n",
      "        [ 0.0350],\n",
      "        [ 0.0186],\n",
      "        [ 0.0822],\n",
      "        [ 0.2064],\n",
      "        [ 0.0358],\n",
      "        [ 0.1062],\n",
      "        [ 0.1490],\n",
      "        [ 0.0622],\n",
      "        [ 0.0235],\n",
      "        [ 0.0337],\n",
      "        [-0.0190],\n",
      "        [-0.0121],\n",
      "        [ 0.0905],\n",
      "        [ 0.0789],\n",
      "        [ 0.0958],\n",
      "        [ 0.0676],\n",
      "        [ 0.0465],\n",
      "        [ 0.0603],\n",
      "        [ 0.0517],\n",
      "        [-0.0254],\n",
      "        [ 0.1015],\n",
      "        [ 0.0451]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4229, 0.4389, 0.4294, 0.4336, 0.4250, 0.4277, 0.4235, 0.4436, 0.4716,\n",
      "        0.4902, 0.4817, 0.4743, 0.4767, 0.4728, 0.4675, 0.4692, 0.4779, 0.5091,\n",
      "        0.5286, 0.5316, 0.5394, 0.5162, 0.4956, 0.4989, 0.4967, 0.4861, 0.4964,\n",
      "        0.5003, 0.4965, 0.5009, 0.4908, 0.4938], device='cuda:0')\n",
      "tensor([[ 0.0331],\n",
      "        [ 0.0261],\n",
      "        [ 0.0135],\n",
      "        [ 0.0042],\n",
      "        [ 0.0107],\n",
      "        [ 0.0080],\n",
      "        [-0.0034],\n",
      "        [ 0.0428],\n",
      "        [-0.0024],\n",
      "        [-0.0123],\n",
      "        [ 0.1239],\n",
      "        [ 0.0088],\n",
      "        [ 0.1014],\n",
      "        [ 0.0601],\n",
      "        [ 0.0636],\n",
      "        [ 0.0695],\n",
      "        [ 0.0571],\n",
      "        [ 0.0703],\n",
      "        [ 0.0657],\n",
      "        [ 0.0900],\n",
      "        [-0.0151],\n",
      "        [ 0.0574],\n",
      "        [ 0.1688],\n",
      "        [ 0.0883],\n",
      "        [ 0.1127],\n",
      "        [ 0.0378],\n",
      "        [-0.0025],\n",
      "        [-0.0345],\n",
      "        [ 0.0002],\n",
      "        [ 0.1599],\n",
      "        [ 0.0464],\n",
      "        [-0.0259]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4991, 0.4994, 0.4956, 0.4944, 0.4902, 0.5286, 0.5100, 0.5286, 0.5192,\n",
      "        0.5168, 0.5381, 0.5428, 0.5452, 0.5392, 0.5457, 0.5274, 0.5452, 0.5428,\n",
      "        0.5546, 0.5546, 0.5434, 0.5322, 0.5168, 0.5077, 0.5109, 0.5003, 0.5168,\n",
      "        0.5339, 0.5269, 0.5198, 0.5419, 0.5351], device='cuda:0')\n",
      "tensor([[-0.0066],\n",
      "        [ 0.0073],\n",
      "        [ 0.0460],\n",
      "        [ 0.0826],\n",
      "        [ 0.0557],\n",
      "        [ 0.0192],\n",
      "        [ 0.0283],\n",
      "        [ 0.0445],\n",
      "        [ 0.0650],\n",
      "        [ 0.0342],\n",
      "        [ 0.0288],\n",
      "        [ 0.0271],\n",
      "        [ 0.0501],\n",
      "        [ 0.0628],\n",
      "        [ 0.0580],\n",
      "        [ 0.0418],\n",
      "        [-0.0313],\n",
      "        [ 0.1035],\n",
      "        [ 0.0560],\n",
      "        [ 0.1132],\n",
      "        [-0.0183],\n",
      "        [ 0.0159],\n",
      "        [ 0.0691],\n",
      "        [ 0.1198],\n",
      "        [ 0.1099],\n",
      "        [ 0.0313],\n",
      "        [ 0.1118],\n",
      "        [ 0.1128],\n",
      "        [ 0.0714],\n",
      "        [ 0.0279],\n",
      "        [ 0.0472],\n",
      "        [ 0.0808]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5434, 0.5257, 0.5289, 0.5339, 0.5274, 0.5322, 0.5121, 0.5050, 0.4944,\n",
      "        0.5026, 0.4908, 0.4743, 0.4660, 0.4542, 0.4678, 0.4908, 0.4675, 0.4672,\n",
      "        0.4826, 0.4908, 0.4778, 0.4894, 0.4938, 0.4861, 0.4956, 0.5003, 0.5133,\n",
      "        0.5168, 0.5204, 0.5251, 0.5505, 0.5800], device='cuda:0')\n",
      "tensor([[ 0.0562],\n",
      "        [ 0.0446],\n",
      "        [ 0.0345],\n",
      "        [ 0.0821],\n",
      "        [ 0.1445],\n",
      "        [ 0.0548],\n",
      "        [ 0.0381],\n",
      "        [-0.0047],\n",
      "        [ 0.0442],\n",
      "        [-0.0024],\n",
      "        [ 0.0994],\n",
      "        [ 0.0599],\n",
      "        [ 0.0216],\n",
      "        [ 0.0174],\n",
      "        [ 0.0230],\n",
      "        [ 0.0284],\n",
      "        [ 0.0532],\n",
      "        [ 0.0175],\n",
      "        [ 0.0886],\n",
      "        [ 0.0532],\n",
      "        [ 0.0680],\n",
      "        [ 0.0264],\n",
      "        [-0.0094],\n",
      "        [ 0.0232],\n",
      "        [ 0.0401],\n",
      "        [ 0.0037],\n",
      "        [-0.0143],\n",
      "        [ 0.0169],\n",
      "        [ 0.0258],\n",
      "        [ 0.0258],\n",
      "        [ 0.0326],\n",
      "        [ 0.0090]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5593, 0.5428, 0.5605, 0.5398, 0.5570, 0.5531, 0.5711, 0.5605, 0.5623,\n",
      "        0.5576, 0.5446, 0.5180, 0.5032, 0.4767, 0.5091, 0.5074, 0.4767, 0.4719,\n",
      "        0.4838, 0.5121, 0.5026, 0.5032, 0.5074, 0.5097, 0.5068, 0.4914, 0.4891,\n",
      "        0.4902, 0.4991, 0.4956, 0.4672, 0.4740], device='cuda:0')\n",
      "tensor([[ 0.0390],\n",
      "        [ 0.0364],\n",
      "        [ 0.0320],\n",
      "        [-0.0224],\n",
      "        [ 0.1114],\n",
      "        [ 0.0606],\n",
      "        [-0.0628],\n",
      "        [ 0.0081],\n",
      "        [ 0.0552],\n",
      "        [ 0.0094],\n",
      "        [ 0.0252],\n",
      "        [ 0.0165],\n",
      "        [ 0.0573],\n",
      "        [ 0.0253],\n",
      "        [-0.0007],\n",
      "        [ 0.0283],\n",
      "        [ 0.0174],\n",
      "        [ 0.0183],\n",
      "        [ 0.0182],\n",
      "        [ 0.0549],\n",
      "        [ 0.0030],\n",
      "        [ 0.0544],\n",
      "        [ 0.3016],\n",
      "        [ 0.2478],\n",
      "        [ 0.1553],\n",
      "        [ 0.0235],\n",
      "        [ 0.0773],\n",
      "        [ 0.0600],\n",
      "        [-0.0221],\n",
      "        [ 0.0376],\n",
      "        [-0.0251],\n",
      "        [ 0.0616]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4740, 0.4728, 0.4956, 0.4902, 0.4817, 0.4835, 0.4967, 0.4879, 0.4985,\n",
      "        0.4838, 0.4858, 0.5047, 0.4876, 0.4814, 0.4947, 0.5136, 0.5115, 0.5522,\n",
      "        0.5463, 0.5460, 0.5421, 0.5443, 0.5286, 0.5325, 0.5156, 0.5493, 0.5304,\n",
      "        0.5215, 0.5088, 0.5091, 0.5211, 0.4991], device='cuda:0')\n",
      "tensor([[ 0.0448],\n",
      "        [ 0.0534],\n",
      "        [ 0.0453],\n",
      "        [ 0.0771],\n",
      "        [ 0.0720],\n",
      "        [ 0.0056],\n",
      "        [ 0.0125],\n",
      "        [ 0.0291],\n",
      "        [ 0.0582],\n",
      "        [ 0.0214],\n",
      "        [ 0.0085],\n",
      "        [-0.0344],\n",
      "        [-0.0164],\n",
      "        [ 0.0932],\n",
      "        [-0.0307],\n",
      "        [ 0.0244],\n",
      "        [-0.0149],\n",
      "        [ 0.0550],\n",
      "        [ 0.0409],\n",
      "        [ 0.0243],\n",
      "        [ 0.2242],\n",
      "        [ 0.1402],\n",
      "        [ 0.0674],\n",
      "        [ 0.0296],\n",
      "        [ 0.0485],\n",
      "        [ 0.0602],\n",
      "        [ 0.0254],\n",
      "        [-0.0166],\n",
      "        [-0.0258],\n",
      "        [-0.0181],\n",
      "        [ 0.0437],\n",
      "        [ 0.0595]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5181, 0.5192, 0.4982, 0.4979, 0.4767, 0.4590, 0.4770, 0.4687, 0.4625,\n",
      "        0.4749, 0.4719, 0.4716, 0.4790, 0.4687, 0.4944, 0.5345, 0.5227, 0.5121,\n",
      "        0.5097, 0.4997, 0.5018, 0.5088, 0.5109, 0.5026, 0.5204, 0.5286, 0.5280,\n",
      "        0.5301, 0.5422, 0.5416, 0.5463, 0.5505], device='cuda:0')\n",
      "tensor([[ 0.0495],\n",
      "        [ 0.0739],\n",
      "        [ 0.0464],\n",
      "        [ 0.0561],\n",
      "        [ 0.0930],\n",
      "        [ 0.0676],\n",
      "        [ 0.0273],\n",
      "        [ 0.0820],\n",
      "        [-0.0065],\n",
      "        [ 0.0302],\n",
      "        [ 0.0453],\n",
      "        [ 0.0368],\n",
      "        [ 0.0210],\n",
      "        [ 0.0279],\n",
      "        [ 0.0682],\n",
      "        [ 0.0811],\n",
      "        [ 0.1314],\n",
      "        [ 0.1054],\n",
      "        [ 0.0740],\n",
      "        [ 0.0534],\n",
      "        [ 0.0493],\n",
      "        [ 0.0096],\n",
      "        [ 0.0485],\n",
      "        [ 0.0610],\n",
      "        [ 0.0767],\n",
      "        [ 0.0196],\n",
      "        [ 0.0915],\n",
      "        [ 0.0324],\n",
      "        [ 0.1618],\n",
      "        [ 0.0063],\n",
      "        [-0.0301],\n",
      "        [ 0.1372]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5629, 0.5570, 0.5587, 0.5593, 0.5496, 0.5543, 0.5540, 0.5629, 0.5702,\n",
      "        0.5900, 0.6018, 0.6083, 0.5962, 0.6043, 0.6119, 0.6004, 0.6015, 0.6107,\n",
      "        0.5924, 0.5688, 0.5711, 0.5838, 0.5800, 0.5711, 0.5629, 0.5708, 0.5700,\n",
      "        0.5546, 0.5658, 0.5617, 0.5434, 0.5381], device='cuda:0')\n",
      "tensor([[ 2.4794e-02],\n",
      "        [ 2.3492e-02],\n",
      "        [ 6.1987e-03],\n",
      "        [ 1.5426e-02],\n",
      "        [ 5.3231e-02],\n",
      "        [ 1.3432e-04],\n",
      "        [ 4.7133e-02],\n",
      "        [ 3.2885e-02],\n",
      "        [-1.0190e-02],\n",
      "        [ 4.6890e-02],\n",
      "        [-1.6956e-02],\n",
      "        [ 2.0872e-02],\n",
      "        [ 9.0480e-03],\n",
      "        [ 5.8683e-02],\n",
      "        [ 1.0101e-01],\n",
      "        [ 5.2722e-02],\n",
      "        [ 6.0361e-02],\n",
      "        [ 3.9990e-03],\n",
      "        [ 2.5501e-02],\n",
      "        [ 7.7717e-02],\n",
      "        [-1.2033e-02],\n",
      "        [ 1.1700e-02],\n",
      "        [-1.7122e-02],\n",
      "        [ 4.1509e-02],\n",
      "        [-2.8813e-02],\n",
      "        [-6.8485e-03],\n",
      "        [-2.9571e-03],\n",
      "        [ 4.3682e-02],\n",
      "        [ 3.9240e-02],\n",
      "        [ 2.1380e-02],\n",
      "        [ 1.6588e-01],\n",
      "        [ 1.4078e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5251, 0.5127, 0.5372, 0.5029, 0.5209, 0.5153, 0.5286, 0.5378, 0.5233,\n",
      "        0.5097, 0.4678, 0.4959, 0.5056, 0.5145, 0.4315, 0.4362, 0.4283, 0.4194,\n",
      "        0.4126, 0.3943, 0.4188, 0.4232, 0.4215, 0.4460, 0.4463, 0.4622, 0.4536,\n",
      "        0.4545, 0.4640, 0.4531, 0.4504, 0.4200], device='cuda:0')\n",
      "tensor([[ 0.1522],\n",
      "        [ 0.0604],\n",
      "        [ 0.1001],\n",
      "        [ 0.1351],\n",
      "        [ 0.0418],\n",
      "        [ 0.0236],\n",
      "        [ 0.0434],\n",
      "        [ 0.0603],\n",
      "        [-0.0048],\n",
      "        [ 0.1378],\n",
      "        [ 0.1486],\n",
      "        [-0.0230],\n",
      "        [-0.0082],\n",
      "        [-0.0300],\n",
      "        [-0.0182],\n",
      "        [ 0.0566],\n",
      "        [ 0.0308],\n",
      "        [ 0.0257],\n",
      "        [ 0.0576],\n",
      "        [-0.0229],\n",
      "        [ 0.0584],\n",
      "        [ 0.0422],\n",
      "        [ 0.0019],\n",
      "        [ 0.0618],\n",
      "        [ 0.0784],\n",
      "        [ 0.0872],\n",
      "        [ 0.0610],\n",
      "        [-0.0266],\n",
      "        [ 0.0939],\n",
      "        [-0.0033],\n",
      "        [ 0.1002],\n",
      "        [-0.0659]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4409, 0.4507, 0.4501, 0.4448, 0.4622, 0.4684, 0.4460, 0.4460, 0.4528,\n",
      "        0.4457, 0.4430, 0.4522, 0.4224, 0.4324, 0.4454, 0.4690, 0.4377, 0.4206,\n",
      "        0.4389, 0.4294, 0.4241, 0.4117, 0.4173, 0.3955, 0.4082, 0.4064, 0.3869,\n",
      "        0.3660, 0.4011, 0.3813, 0.3807, 0.3834], device='cuda:0')\n",
      "tensor([[-0.0132],\n",
      "        [ 0.0073],\n",
      "        [ 0.0391],\n",
      "        [ 0.0982],\n",
      "        [-0.0541],\n",
      "        [ 0.0372],\n",
      "        [ 0.0095],\n",
      "        [ 0.1011],\n",
      "        [ 0.0578],\n",
      "        [-0.0076],\n",
      "        [ 0.0164],\n",
      "        [ 0.0757],\n",
      "        [ 0.0104],\n",
      "        [ 0.0661],\n",
      "        [ 0.0191],\n",
      "        [-0.0006],\n",
      "        [ 0.0173],\n",
      "        [ 0.1627],\n",
      "        [ 0.0072],\n",
      "        [ 0.0881],\n",
      "        [ 0.0881],\n",
      "        [-0.0132],\n",
      "        [ 0.0614],\n",
      "        [ 0.0217],\n",
      "        [ 0.0634],\n",
      "        [ 0.0806],\n",
      "        [ 0.0028],\n",
      "        [ 0.0428],\n",
      "        [ 0.0742],\n",
      "        [ 0.0560],\n",
      "        [ 0.0991],\n",
      "        [-0.0103]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3822, 0.3813, 0.4277, 0.4209, 0.4247, 0.4226, 0.4179, 0.4221, 0.4232,\n",
      "        0.4238, 0.4188, 0.4374, 0.4923, 0.5062, 0.4935, 0.4959, 0.5023, 0.5038,\n",
      "        0.5201, 0.5238, 0.5315, 0.5097, 0.5194, 0.5016, 0.5108, 0.5201, 0.5329,\n",
      "        0.5196, 0.5097, 0.5234, 0.5180, 0.5244], device='cuda:0')\n",
      "tensor([[ 0.0056],\n",
      "        [ 0.1013],\n",
      "        [ 0.0892],\n",
      "        [ 0.0158],\n",
      "        [ 0.0681],\n",
      "        [ 0.1305],\n",
      "        [ 0.1236],\n",
      "        [ 0.0166],\n",
      "        [ 0.0555],\n",
      "        [ 0.0521],\n",
      "        [ 0.0986],\n",
      "        [ 0.0541],\n",
      "        [ 0.0402],\n",
      "        [ 0.0474],\n",
      "        [ 0.0673],\n",
      "        [-0.0068],\n",
      "        [-0.0067],\n",
      "        [ 0.0313],\n",
      "        [ 0.0515],\n",
      "        [ 0.0216],\n",
      "        [ 0.0946],\n",
      "        [ 0.0198],\n",
      "        [ 0.0412],\n",
      "        [ 0.0413],\n",
      "        [ 0.0263],\n",
      "        [ 0.0935],\n",
      "        [ 0.0193],\n",
      "        [ 0.0179],\n",
      "        [-0.0159],\n",
      "        [ 0.0403],\n",
      "        [ 0.1638],\n",
      "        [ 0.1085]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5323, 0.5239, 0.5074, 0.4885, 0.4951, 0.4719, 0.4781, 0.4653, 0.4526,\n",
      "        0.4816, 0.4639, 0.4762, 0.4814, 0.4887, 0.4836, 0.4497, 0.4317, 0.4454,\n",
      "        0.4292, 0.4321, 0.4063, 0.4181, 0.3978, 0.4015, 0.4016, 0.4224, 0.4313,\n",
      "        0.4507, 0.4266, 0.4296, 0.4350, 0.4278], device='cuda:0')\n",
      "tensor([[ 3.2299e-02],\n",
      "        [ 4.7913e-02],\n",
      "        [ 2.2235e-02],\n",
      "        [ 4.0921e-02],\n",
      "        [ 6.9952e-02],\n",
      "        [ 1.5179e-01],\n",
      "        [ 6.8355e-02],\n",
      "        [ 5.4695e-03],\n",
      "        [ 7.6211e-02],\n",
      "        [ 3.0782e-02],\n",
      "        [ 5.0260e-02],\n",
      "        [ 2.4352e-05],\n",
      "        [ 7.1193e-02],\n",
      "        [ 1.2919e-02],\n",
      "        [-8.9017e-03],\n",
      "        [ 8.7965e-02],\n",
      "        [ 3.3236e-01],\n",
      "        [ 1.3224e-01],\n",
      "        [ 1.2764e-01],\n",
      "        [ 1.2570e-01],\n",
      "        [ 3.4695e-02],\n",
      "        [ 1.8988e-02],\n",
      "        [ 9.9944e-03],\n",
      "        [ 1.8927e-02],\n",
      "        [ 3.1527e-02],\n",
      "        [ 4.2874e-02],\n",
      "        [ 3.1201e-02],\n",
      "        [ 6.6582e-02],\n",
      "        [ 3.7211e-02],\n",
      "        [ 5.8690e-02],\n",
      "        [ 1.3441e-02],\n",
      "        [ 4.6202e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4077, 0.4153, 0.4446, 0.4434, 0.4342, 0.4486, 0.4409, 0.4351, 0.4377,\n",
      "        0.4516, 0.4838, 0.5214, 0.5231, 0.5097, 0.5129, 0.5232, 0.5179, 0.5296,\n",
      "        0.5246, 0.5405, 0.5258, 0.5178, 0.5280, 0.5282, 0.5367, 0.5333, 0.5248,\n",
      "        0.5088, 0.5124, 0.5172, 0.5277, 0.5242], device='cuda:0')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[ 0.0944],\n",
      "        [ 0.0382],\n",
      "        [ 0.0775],\n",
      "        [ 0.0543],\n",
      "        [ 0.0042],\n",
      "        [ 0.0099],\n",
      "        [ 0.1367],\n",
      "        [ 0.0895],\n",
      "        [ 0.0599],\n",
      "        [ 0.1547],\n",
      "        [ 0.0256],\n",
      "        [ 0.0291],\n",
      "        [ 0.0375],\n",
      "        [ 0.0609],\n",
      "        [ 0.0695],\n",
      "        [ 0.0196],\n",
      "        [-0.0159],\n",
      "        [-0.0330],\n",
      "        [ 0.0753],\n",
      "        [ 0.0308],\n",
      "        [ 0.0960],\n",
      "        [ 0.0675],\n",
      "        [ 0.0391],\n",
      "        [-0.0108],\n",
      "        [ 0.0527],\n",
      "        [ 0.0757],\n",
      "        [ 0.0409],\n",
      "        [-0.0110],\n",
      "        [ 0.0795],\n",
      "        [ 0.0321],\n",
      "        [ 0.0506],\n",
      "        [ 0.0171]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5354, 0.5430, 0.5381, 0.5352, 0.5456, 0.5371, 0.5252, 0.5128, 0.5088,\n",
      "        0.5139, 0.5175, 0.5332, 0.5357, 0.5345, 0.5291, 0.5350, 0.5345, 0.5312,\n",
      "        0.5274, 0.5173, 0.5205, 0.5231, 0.5149, 0.5126, 0.5138, 0.5128, 0.5146,\n",
      "        0.5169, 0.5244, 0.5168, 0.5208, 0.5144], device='cuda:0')\n",
      "tensor([[ 0.0612],\n",
      "        [ 0.1025],\n",
      "        [ 0.0280],\n",
      "        [ 0.0483],\n",
      "        [-0.0135],\n",
      "        [-0.0063],\n",
      "        [-0.0539],\n",
      "        [ 0.0570],\n",
      "        [ 0.0707],\n",
      "        [ 0.1145],\n",
      "        [ 0.0005],\n",
      "        [ 0.0177],\n",
      "        [ 0.0288],\n",
      "        [ 0.0276],\n",
      "        [ 0.0539],\n",
      "        [ 0.0212],\n",
      "        [ 0.0193],\n",
      "        [ 0.0179],\n",
      "        [ 0.0304],\n",
      "        [ 0.0183],\n",
      "        [-0.0164],\n",
      "        [ 0.0224],\n",
      "        [ 0.0155],\n",
      "        [ 0.0013],\n",
      "        [ 0.1019],\n",
      "        [ 0.0823],\n",
      "        [ 0.1643],\n",
      "        [ 0.0376],\n",
      "        [ 0.0614],\n",
      "        [ 0.0019],\n",
      "        [ 0.0225],\n",
      "        [ 0.0461]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5102, 0.4838, 0.4753, 0.4623, 0.4712, 0.4873, 0.4933, 0.4900, 0.4933,\n",
      "        0.4733, 0.4719, 0.4800, 0.4807, 0.4744, 0.4761, 0.4814, 0.4753, 0.4807,\n",
      "        0.4777, 0.4864, 0.4946, 0.4917, 0.4838, 0.4826, 0.4728, 0.4723, 0.4764,\n",
      "        0.4807, 0.4823, 0.4767, 0.4802, 0.4747], device='cuda:0')\n",
      "tensor([[ 0.0536],\n",
      "        [ 0.0559],\n",
      "        [ 0.0241],\n",
      "        [ 0.0116],\n",
      "        [ 0.0095],\n",
      "        [ 0.0833],\n",
      "        [ 0.0933],\n",
      "        [ 0.0253],\n",
      "        [-0.0398],\n",
      "        [ 0.0703],\n",
      "        [ 0.0378],\n",
      "        [ 0.0718],\n",
      "        [ 0.0532],\n",
      "        [ 0.1244],\n",
      "        [ 0.0297],\n",
      "        [ 0.0501],\n",
      "        [ 0.0309],\n",
      "        [ 0.0074],\n",
      "        [ 0.0696],\n",
      "        [ 0.0301],\n",
      "        [ 0.1404],\n",
      "        [ 0.0410],\n",
      "        [ 0.0569],\n",
      "        [-0.0055],\n",
      "        [ 0.0326],\n",
      "        [-0.0022],\n",
      "        [ 0.0248],\n",
      "        [ 0.0336],\n",
      "        [ 0.0298],\n",
      "        [ 0.0166],\n",
      "        [ 0.0376],\n",
      "        [ 0.0570]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4724, 0.4620, 0.4718, 0.4672, 0.4861, 0.4855, 0.4764, 0.4726, 0.4548,\n",
      "        0.4528, 0.4601, 0.4547, 0.4436, 0.4369, 0.4364, 0.4216, 0.4360, 0.4342,\n",
      "        0.4219, 0.4082, 0.4285, 0.4268, 0.4120, 0.4058, 0.4139, 0.4186, 0.4236,\n",
      "        0.4386, 0.4403, 0.4437, 0.4460, 0.4395], device='cuda:0')\n",
      "tensor([[-0.0307],\n",
      "        [ 0.0019],\n",
      "        [ 0.0183],\n",
      "        [-0.0392],\n",
      "        [ 0.0164],\n",
      "        [ 0.0127],\n",
      "        [ 0.0633],\n",
      "        [ 0.0548],\n",
      "        [ 0.0271],\n",
      "        [-0.0138],\n",
      "        [ 0.1824],\n",
      "        [ 0.0528],\n",
      "        [ 0.0078],\n",
      "        [ 0.0076],\n",
      "        [ 0.0487],\n",
      "        [ 0.0531],\n",
      "        [ 0.0430],\n",
      "        [ 0.0266],\n",
      "        [ 0.0235],\n",
      "        [ 0.0025],\n",
      "        [-0.0003],\n",
      "        [ 0.0902],\n",
      "        [ 0.0679],\n",
      "        [-0.0044],\n",
      "        [ 0.0053],\n",
      "        [-0.0225],\n",
      "        [-0.0199],\n",
      "        [-0.0095],\n",
      "        [ 0.0190],\n",
      "        [-0.0140],\n",
      "        [ 0.0955],\n",
      "        [ 0.0579]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4401, 0.4502, 0.4570, 0.4625, 0.4618, 0.4667, 0.4590, 0.4656, 0.4778,\n",
      "        0.4805, 0.4935, 0.5034, 0.5058, 0.4938, 0.4939, 0.4912, 0.4998, 0.4979,\n",
      "        0.5001, 0.5173, 0.5185, 0.5183, 0.5196, 0.5232, 0.5319, 0.5208, 0.5227,\n",
      "        0.5215, 0.5239, 0.5260, 0.5208, 0.5256], device='cuda:0')\n",
      "tensor([[ 0.0857],\n",
      "        [ 0.0601],\n",
      "        [-0.0091],\n",
      "        [ 0.0720],\n",
      "        [ 0.0579],\n",
      "        [ 0.0129],\n",
      "        [ 0.0383],\n",
      "        [ 0.2472],\n",
      "        [ 0.0423],\n",
      "        [ 0.0083],\n",
      "        [-0.0705],\n",
      "        [-0.0309],\n",
      "        [ 0.3341],\n",
      "        [ 0.1113],\n",
      "        [ 0.0445],\n",
      "        [ 0.0285],\n",
      "        [ 0.1105],\n",
      "        [ 0.0815],\n",
      "        [-0.0114],\n",
      "        [ 0.0886],\n",
      "        [ 0.0444],\n",
      "        [ 0.0177],\n",
      "        [ 0.0641],\n",
      "        [-0.0051],\n",
      "        [ 0.0358],\n",
      "        [-0.0044],\n",
      "        [ 0.0614],\n",
      "        [ 0.0233],\n",
      "        [ 0.0403],\n",
      "        [-0.0059],\n",
      "        [ 0.0214],\n",
      "        [ 0.0073]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5302, 0.5201, 0.5104, 0.5212, 0.5267, 0.5198, 0.5316, 0.5541, 0.5482,\n",
      "        0.5494, 0.5459, 0.5546, 0.5626, 0.5487, 0.5527, 0.5538, 0.5579, 0.5659,\n",
      "        0.5603, 0.5570, 0.5544, 0.5589, 0.5640, 0.5612, 0.5520, 0.5546, 0.5648,\n",
      "        0.5740, 0.5666, 0.5697, 0.5687, 0.5576], device='cuda:0')\n",
      "tensor([[ 0.0771],\n",
      "        [-0.0130],\n",
      "        [ 0.0396],\n",
      "        [ 0.0138],\n",
      "        [ 0.0457],\n",
      "        [ 0.0702],\n",
      "        [ 0.0987],\n",
      "        [ 0.0217],\n",
      "        [ 0.1402],\n",
      "        [ 0.0240],\n",
      "        [ 0.0685],\n",
      "        [ 0.0691],\n",
      "        [ 0.1111],\n",
      "        [ 0.0050],\n",
      "        [-0.0246],\n",
      "        [ 0.0745],\n",
      "        [ 0.0635],\n",
      "        [-0.0764],\n",
      "        [ 0.0491],\n",
      "        [ 0.0398],\n",
      "        [ 0.0610],\n",
      "        [ 0.0659],\n",
      "        [ 0.0280],\n",
      "        [ 0.0555],\n",
      "        [ 0.0275],\n",
      "        [ 0.0070],\n",
      "        [-0.0016],\n",
      "        [-0.0089],\n",
      "        [ 0.1127],\n",
      "        [ 0.1584],\n",
      "        [ 0.0715],\n",
      "        [ 0.0619]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.5490, 0.5383, 0.5421, 0.5352, 0.5470, 0.5204, 0.5026, 0.4904, 0.4942,\n",
      "        0.4969, 0.4915, 0.4672, 0.4793, 0.4903, 0.4908, 0.4852, 0.4828, 0.4844,\n",
      "        0.4715, 0.4766, 0.4879, 0.4841, 0.4912, 0.4903, 0.4667, 0.4592, 0.4498,\n",
      "        0.4360, 0.4457, 0.4450, 0.4396, 0.4428], device='cuda:0')\n",
      "tensor([[ 0.0808],\n",
      "        [ 0.0251],\n",
      "        [-0.0053],\n",
      "        [ 0.0525],\n",
      "        [ 0.0114],\n",
      "        [ 0.0646],\n",
      "        [ 0.0502],\n",
      "        [ 0.0584],\n",
      "        [ 0.1388],\n",
      "        [ 0.0455],\n",
      "        [ 0.1253],\n",
      "        [ 0.0713],\n",
      "        [ 0.0692],\n",
      "        [-0.0187],\n",
      "        [ 0.0597],\n",
      "        [ 0.0826],\n",
      "        [ 0.0889],\n",
      "        [-0.0027],\n",
      "        [ 0.0155],\n",
      "        [ 0.0247],\n",
      "        [ 0.0231],\n",
      "        [ 0.0230],\n",
      "        [ 0.0165],\n",
      "        [ 0.0372],\n",
      "        [ 0.0674],\n",
      "        [ 0.0423],\n",
      "        [ 0.0736],\n",
      "        [ 0.0304],\n",
      "        [ 0.0160],\n",
      "        [ 0.0401],\n",
      "        [ 0.0610],\n",
      "        [-0.0812]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.4442, 0.4673, 0.4809, 0.4798, 0.4828, 0.4706, 0.4771, 0.4778, 0.4932,\n",
      "        0.4870, 0.4842, 0.4851, 0.4830, 0.4884, 0.4790, 0.4851, 0.4795, 0.4699,\n",
      "        0.4667, 0.4691, 0.4719, 0.4666, 0.4575, 0.4529, 0.4570, 0.4401, 0.3936,\n",
      "        0.3951, 0.4011, 0.3784, 0.3850, 0.3839], device='cuda:0')\n",
      "tensor([[ 0.0285],\n",
      "        [ 0.0510],\n",
      "        [ 0.0510],\n",
      "        [ 0.0994],\n",
      "        [-0.0801],\n",
      "        [ 0.0806],\n",
      "        [ 0.0364],\n",
      "        [-0.0226],\n",
      "        [ 0.0443],\n",
      "        [ 0.0530],\n",
      "        [ 0.0308],\n",
      "        [ 0.0021],\n",
      "        [ 0.0121],\n",
      "        [ 0.0158],\n",
      "        [ 0.0767],\n",
      "        [ 0.0507],\n",
      "        [ 0.0963],\n",
      "        [ 0.0388],\n",
      "        [ 0.0367],\n",
      "        [ 0.0307],\n",
      "        [ 0.0258],\n",
      "        [ 0.0129],\n",
      "        [ 0.0247],\n",
      "        [ 0.0284],\n",
      "        [ 0.0332],\n",
      "        [ 0.1617],\n",
      "        [ 0.0924],\n",
      "        [ 0.1302],\n",
      "        [ 0.1880],\n",
      "        [ 0.0367],\n",
      "        [ 0.0092],\n",
      "        [ 0.1204]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3879, 0.3813, 0.4009, 0.4011, 0.3960, 0.3932, 0.3893, 0.3903, 0.3808,\n",
      "        0.3770, 0.3763, 0.3789, 0.3768, 0.3670, 0.3397, 0.3421, 0.3702, 0.3583,\n",
      "        0.3571, 0.3689, 0.3845, 0.3798, 0.3843, 0.3855, 0.3796, 0.3749, 0.3775,\n",
      "        0.3791, 0.3732, 0.3684, 0.3661, 0.3692], device='cuda:0')\n",
      "tensor([[ 0.0560],\n",
      "        [ 0.0441],\n",
      "        [ 0.0884],\n",
      "        [ 0.0331],\n",
      "        [ 0.0846],\n",
      "        [-0.0201],\n",
      "        [ 0.0720],\n",
      "        [ 0.0069],\n",
      "        [ 0.0327],\n",
      "        [-0.0073],\n",
      "        [ 0.0093],\n",
      "        [ 0.0027],\n",
      "        [ 0.0655],\n",
      "        [ 0.0798],\n",
      "        [ 0.0057],\n",
      "        [ 0.0652],\n",
      "        [ 0.0414],\n",
      "        [-0.0231],\n",
      "        [-0.0060],\n",
      "        [ 0.0637],\n",
      "        [ 0.0549],\n",
      "        [ 0.0034],\n",
      "        [ 0.0145],\n",
      "        [ 0.0352],\n",
      "        [ 0.1166],\n",
      "        [ 0.1380],\n",
      "        [ 0.0542],\n",
      "        [ 0.0023],\n",
      "        [ 0.0526],\n",
      "        [ 0.0721],\n",
      "        [ 0.1236],\n",
      "        [ 0.2336]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3607, 0.3497, 0.3553, 0.3612, 0.3570, 0.3506, 0.3435, 0.3373, 0.3333,\n",
      "        0.3378, 0.3405, 0.3451, 0.3394, 0.3272, 0.3188, 0.3055, 0.3099, 0.3047,\n",
      "        0.3116, 0.3203, 0.3208, 0.3000, 0.3046, 0.3138, 0.3279, 0.3175, 0.3098,\n",
      "        0.3055, 0.3086, 0.3076, 0.3161, 0.3067], device='cuda:0')\n",
      "tensor([[ 0.0027],\n",
      "        [ 0.0139],\n",
      "        [ 0.0590],\n",
      "        [-0.0050],\n",
      "        [ 0.0123],\n",
      "        [ 0.0319],\n",
      "        [ 0.0498],\n",
      "        [ 0.0618],\n",
      "        [ 0.0366],\n",
      "        [ 0.0241],\n",
      "        [ 0.0493],\n",
      "        [ 0.1322],\n",
      "        [ 0.0331],\n",
      "        [ 0.0864],\n",
      "        [ 0.0252],\n",
      "        [ 0.0450],\n",
      "        [ 0.0035],\n",
      "        [ 0.0218],\n",
      "        [ 0.0614],\n",
      "        [ 0.0113],\n",
      "        [-0.0179],\n",
      "        [ 0.0434],\n",
      "        [ 0.0318],\n",
      "        [ 0.0488],\n",
      "        [ 0.0195],\n",
      "        [ 0.0967],\n",
      "        [ 0.1053],\n",
      "        [ 0.1701],\n",
      "        [ 0.1425],\n",
      "        [ 0.1228],\n",
      "        [ 0.1125],\n",
      "        [ 0.1137]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3146, 0.3210, 0.3208, 0.3043, 0.2974, 0.3092, 0.3083, 0.2944, 0.3169,\n",
      "        0.3198, 0.3132, 0.3031, 0.3013, 0.2924, 0.3014, 0.3074, 0.3190, 0.3200,\n",
      "        0.3197, 0.3203, 0.3346, 0.3421, 0.3555, 0.3703, 0.3646, 0.3633, 0.3680,\n",
      "        0.3605, 0.3558, 0.3490, 0.3400, 0.3426], device='cuda:0')\n",
      "tensor([[ 0.0832],\n",
      "        [ 0.0478],\n",
      "        [ 0.1166],\n",
      "        [ 0.0303],\n",
      "        [-0.0009],\n",
      "        [-0.0237],\n",
      "        [ 0.0109],\n",
      "        [ 0.0010],\n",
      "        [ 0.0381],\n",
      "        [-0.0182],\n",
      "        [ 0.0200],\n",
      "        [ 0.0269],\n",
      "        [-0.0037],\n",
      "        [ 0.0173],\n",
      "        [ 0.0065],\n",
      "        [-0.0064],\n",
      "        [ 0.0110],\n",
      "        [ 0.0694],\n",
      "        [ 0.0543],\n",
      "        [ 0.0601],\n",
      "        [ 0.0641],\n",
      "        [ 0.0259],\n",
      "        [ 0.0343],\n",
      "        [ 0.0284],\n",
      "        [ 0.0273],\n",
      "        [ 0.0689],\n",
      "        [ 0.0187],\n",
      "        [ 0.0560],\n",
      "        [ 0.0437],\n",
      "        [ 0.0724],\n",
      "        [ 0.0621],\n",
      "        [ 0.0255]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3368, 0.3225, 0.3290, 0.3217, 0.3265, 0.3326, 0.3378, 0.3312, 0.3202,\n",
      "        0.3232, 0.3223, 0.3196, 0.3092, 0.2868, 0.2826, 0.2800, 0.2629, 0.2783,\n",
      "        0.2737, 0.2658, 0.2561, 0.2696, 0.2624, 0.2641, 0.2481, 0.2493, 0.2502,\n",
      "        0.2408, 0.2527, 0.2826, 0.2803, 0.3042], device='cuda:0')\n",
      "tensor([[ 0.0611],\n",
      "        [ 0.1156],\n",
      "        [ 0.0438],\n",
      "        [ 0.0071],\n",
      "        [ 0.0414],\n",
      "        [ 0.1024],\n",
      "        [ 0.2590],\n",
      "        [ 0.0936],\n",
      "        [ 0.0559],\n",
      "        [ 0.0735],\n",
      "        [ 0.0761],\n",
      "        [ 0.0031],\n",
      "        [ 0.0260],\n",
      "        [ 0.0163],\n",
      "        [ 0.0785],\n",
      "        [ 0.0389],\n",
      "        [ 0.0165],\n",
      "        [ 0.0424],\n",
      "        [ 0.0173],\n",
      "        [ 0.0357],\n",
      "        [ 0.0415],\n",
      "        [ 0.0466],\n",
      "        [ 0.0965],\n",
      "        [ 0.0185],\n",
      "        [ 0.0093],\n",
      "        [-0.0041],\n",
      "        [-0.0272],\n",
      "        [ 0.0402],\n",
      "        [ 0.0811],\n",
      "        [ 0.0756],\n",
      "        [ 0.0319],\n",
      "        [-0.0013]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.2873, 0.3217, 0.3314, 0.3376, 0.3326, 0.3331, 0.3213, 0.3329, 0.3423,\n",
      "        0.3432, 0.3523, 0.3536, 0.3605, 0.3704, 0.3665, 0.3659, 0.3536, 0.3472,\n",
      "        0.3458, 0.3546, 0.3555, 0.3620, 0.3586, 0.3547, 0.3509, 0.3662, 0.3817,\n",
      "        0.3795, 0.3879, 0.3825, 0.3950, 0.3913], device='cuda:0')\n",
      "tensor([[ 0.0508],\n",
      "        [ 0.1384],\n",
      "        [ 0.1167],\n",
      "        [ 0.0498],\n",
      "        [ 0.0520],\n",
      "        [ 0.0994],\n",
      "        [-0.0029],\n",
      "        [ 0.0622],\n",
      "        [ 0.0279],\n",
      "        [ 0.0941],\n",
      "        [ 0.1247],\n",
      "        [ 0.0894],\n",
      "        [ 0.0569],\n",
      "        [ 0.0840],\n",
      "        [ 0.0072],\n",
      "        [ 0.0293],\n",
      "        [-0.0014],\n",
      "        [ 0.0700],\n",
      "        [ 0.0521],\n",
      "        [ 0.0035],\n",
      "        [ 0.0748],\n",
      "        [ 0.0038],\n",
      "        [ 0.0012],\n",
      "        [ 0.0197],\n",
      "        [ 0.0115],\n",
      "        [ 0.0158],\n",
      "        [ 0.0372],\n",
      "        [ 0.0240],\n",
      "        [ 0.0920],\n",
      "        [ 0.2220],\n",
      "        [-0.0115],\n",
      "        [ 0.1772]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3931, 0.3832, 0.3760, 0.3730, 0.3695, 0.3567, 0.3624, 0.3654, 0.3594,\n",
      "        0.3586, 0.3662, 0.3601, 0.3545, 0.3523, 0.3576, 0.3598, 0.3575, 0.3515,\n",
      "        0.3461, 0.3409, 0.3468, 0.3613, 0.3664, 0.3755, 0.3869, 0.3784, 0.3916,\n",
      "        0.3949, 0.3941, 0.3991, 0.3944, 0.3872], device='cuda:0')\n",
      "tensor([[ 0.2036],\n",
      "        [-0.0082],\n",
      "        [ 0.1421],\n",
      "        [ 0.1304],\n",
      "        [ 0.1056],\n",
      "        [ 0.0719],\n",
      "        [ 0.0944],\n",
      "        [ 0.1090],\n",
      "        [ 0.0999],\n",
      "        [ 0.0408],\n",
      "        [ 0.0210],\n",
      "        [-0.0044],\n",
      "        [ 0.0761],\n",
      "        [ 0.0702],\n",
      "        [ 0.0138],\n",
      "        [ 0.0343],\n",
      "        [ 0.0409],\n",
      "        [ 0.0459],\n",
      "        [ 0.0016],\n",
      "        [ 0.0277],\n",
      "        [ 0.0319],\n",
      "        [-0.0083],\n",
      "        [ 0.0188],\n",
      "        [ 0.0837],\n",
      "        [-0.0007],\n",
      "        [ 0.0152],\n",
      "        [-0.0030],\n",
      "        [ 0.0460],\n",
      "        [ 0.1399],\n",
      "        [-0.0053],\n",
      "        [ 0.0808],\n",
      "        [ 0.0552]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3647, 0.3611, 0.3572, 0.3635, 0.3538, 0.3511, 0.3591, 0.3601, 0.3506,\n",
      "        0.3501, 0.3500, 0.3448, 0.3456, 0.3468, 0.3449, 0.3487, 0.3463, 0.3421,\n",
      "        0.3390, 0.3465, 0.3554, 0.3563, 0.3546, 0.3584, 0.3518, 0.3542, 0.3463,\n",
      "        0.3457, 0.3489, 0.3460, 0.3430, 0.3479], device='cuda:0')\n",
      "tensor([[ 0.0423],\n",
      "        [ 0.0244],\n",
      "        [ 0.0024],\n",
      "        [ 0.0905],\n",
      "        [ 0.0243],\n",
      "        [ 0.0395],\n",
      "        [-0.0019],\n",
      "        [ 0.0301],\n",
      "        [-0.0176],\n",
      "        [ 0.0647],\n",
      "        [ 0.0458],\n",
      "        [ 0.0162],\n",
      "        [ 0.1100],\n",
      "        [ 0.0907],\n",
      "        [ 0.0988],\n",
      "        [ 0.1584],\n",
      "        [ 0.2392],\n",
      "        [ 0.0353],\n",
      "        [ 0.0762],\n",
      "        [ 0.1076],\n",
      "        [ 0.0763],\n",
      "        [ 0.0531],\n",
      "        [ 0.0856],\n",
      "        [ 0.1087],\n",
      "        [ 0.0519],\n",
      "        [ 0.0289],\n",
      "        [ 0.0437],\n",
      "        [ 0.0279],\n",
      "        [ 0.0612],\n",
      "        [ 0.0251],\n",
      "        [-0.0286],\n",
      "        [ 0.0487]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3447, 0.3487, 0.3383, 0.3366, 0.3358, 0.3513, 0.3539, 0.3702, 0.3703,\n",
      "        0.3680, 0.3690, 0.3817, 0.3692, 0.3749, 0.3659, 0.3654, 0.3626, 0.3512,\n",
      "        0.3526, 0.3655, 0.3676, 0.3623, 0.3608, 0.3589, 0.3525, 0.3539, 0.3527,\n",
      "        0.3589, 0.3718, 0.3722, 0.3787, 0.3745], device='cuda:0')\n",
      "tensor([[0.0817],\n",
      "        [0.1141],\n",
      "        [0.0444],\n",
      "        [0.0948],\n",
      "        [0.0640],\n",
      "        [0.0946],\n",
      "        [0.0484],\n",
      "        [0.0198],\n",
      "        [0.0824],\n",
      "        [0.0342],\n",
      "        [0.0568],\n",
      "        [0.0884],\n",
      "        [0.0767],\n",
      "        [0.0314],\n",
      "        [0.0055],\n",
      "        [0.0349],\n",
      "        [0.0548],\n",
      "        [0.1172],\n",
      "        [0.0017]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.3852, 0.3857, 0.3831, 0.3769, 0.3828, 0.3853, 0.3817, 0.3864, 0.3943,\n",
      "        0.3894, 0.3941, 0.3901, 0.3872, 0.3942, 0.4011, 0.4057, 0.3997, 0.4053,\n",
      "        0.4010], device='cuda:0')\n",
      "tensor([[0.0590],\n",
      "        [0.0158],\n",
      "        [0.0858],\n",
      "        [0.1367],\n",
      "        [0.0567],\n",
      "        [0.0240],\n",
      "        [0.0429],\n",
      "        [0.0319],\n",
      "        [0.0591],\n",
      "        [0.1722],\n",
      "        [0.1096],\n",
      "        [0.0048],\n",
      "        [0.0220],\n",
      "        [0.0486],\n",
      "        [0.0111],\n",
      "        [0.0384],\n",
      "        [0.0588],\n",
      "        [0.0487],\n",
      "        [0.0402],\n",
      "        [0.0637],\n",
      "        [0.0549],\n",
      "        [0.0552],\n",
      "        [0.0363],\n",
      "        [0.0408],\n",
      "        [0.0115],\n",
      "        [0.0680],\n",
      "        [0.0380],\n",
      "        [0.2117],\n",
      "        [0.0353],\n",
      "        [0.0288],\n",
      "        [0.0449],\n",
      "        [0.0145]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0147, 0.0146, 0.0143, 0.0138, 0.0130, 0.0129, 0.0135, 0.0135, 0.0135,\n",
      "        0.0137, 0.0132, 0.0129, 0.0134, 0.0133, 0.0135, 0.0134, 0.0134, 0.0134,\n",
      "        0.0134, 0.0130, 0.0122, 0.0113, 0.0093, 0.0098, 0.0105, 0.0111, 0.0113,\n",
      "        0.0107, 0.0097, 0.0091, 0.0093, 0.0088], device='cuda:0')\n",
      "tensor([[ 0.1069],\n",
      "        [ 0.0678],\n",
      "        [ 0.0448],\n",
      "        [ 0.0753],\n",
      "        [ 0.0165],\n",
      "        [ 0.0683],\n",
      "        [ 0.0147],\n",
      "        [ 0.1124],\n",
      "        [ 0.0544],\n",
      "        [ 0.0767],\n",
      "        [ 0.0365],\n",
      "        [ 0.0560],\n",
      "        [ 0.0981],\n",
      "        [ 0.1325],\n",
      "        [ 0.1271],\n",
      "        [ 0.0248],\n",
      "        [ 0.0149],\n",
      "        [ 0.0616],\n",
      "        [ 0.0824],\n",
      "        [ 0.0306],\n",
      "        [ 0.0783],\n",
      "        [ 0.0301],\n",
      "        [ 0.0274],\n",
      "        [ 0.0511],\n",
      "        [ 0.0471],\n",
      "        [ 0.0469],\n",
      "        [ 0.0363],\n",
      "        [ 0.0400],\n",
      "        [-0.0053],\n",
      "        [ 0.0162],\n",
      "        [ 0.1255],\n",
      "        [ 0.0381]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0094, 0.0092, 0.0095, 0.0090, 0.0092, 0.0091, 0.0081, 0.0069, 0.0058,\n",
      "        0.0058, 0.0035, 0.0048, 0.0054, 0.0050, 0.0034, 0.0037, 0.0037, 0.0040,\n",
      "        0.0041, 0.0033, 0.0018, 0.0010, 0.0000, 0.0017, 0.0015, 0.0019, 0.0014,\n",
      "        0.0006, 0.0009, 0.0017, 0.0009, 0.0017], device='cuda:0')\n",
      "tensor([[ 0.1075],\n",
      "        [ 0.0425],\n",
      "        [ 0.0662],\n",
      "        [-0.0321],\n",
      "        [ 0.0505],\n",
      "        [ 0.1333],\n",
      "        [ 0.0740],\n",
      "        [ 0.0262],\n",
      "        [ 0.0613],\n",
      "        [ 0.0374],\n",
      "        [ 0.0135],\n",
      "        [ 0.0227],\n",
      "        [ 0.0320],\n",
      "        [ 0.0867],\n",
      "        [ 0.0817],\n",
      "        [ 0.0703],\n",
      "        [ 0.1083],\n",
      "        [ 0.0322],\n",
      "        [ 0.1399],\n",
      "        [ 0.0093],\n",
      "        [ 0.0292],\n",
      "        [-0.0077],\n",
      "        [ 0.0064],\n",
      "        [ 0.0165],\n",
      "        [ 0.0194],\n",
      "        [ 0.0454],\n",
      "        [ 0.0306],\n",
      "        [ 0.1259],\n",
      "        [ 0.0204],\n",
      "        [ 0.0752],\n",
      "        [ 0.0365],\n",
      "        [ 0.0162]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0024, 0.0021, 0.0028, 0.0029, 0.0028, 0.0025, 0.0028, 0.0033, 0.0043,\n",
      "        0.0046, 0.0044, 0.0048, 0.0040, 0.0037, 0.0039, 0.0042, 0.0042, 0.0036,\n",
      "        0.0039, 0.0040, 0.0044, 0.0051, 0.0051, 0.0044, 0.0050, 0.0050, 0.0047,\n",
      "        0.0042, 0.0048, 0.0044, 0.0044, 0.0046], device='cuda:0')\n",
      "tensor([[ 0.0865],\n",
      "        [ 0.0469],\n",
      "        [ 0.0698],\n",
      "        [ 0.0373],\n",
      "        [ 0.0056],\n",
      "        [ 0.0233],\n",
      "        [ 0.0542],\n",
      "        [ 0.0452],\n",
      "        [ 0.0622],\n",
      "        [ 0.0652],\n",
      "        [ 0.0488],\n",
      "        [ 0.1608],\n",
      "        [ 0.2404],\n",
      "        [ 0.0128],\n",
      "        [ 0.0773],\n",
      "        [-0.0043],\n",
      "        [ 0.0865],\n",
      "        [ 0.0658],\n",
      "        [ 0.0820],\n",
      "        [ 0.0553],\n",
      "        [ 0.1043],\n",
      "        [ 0.0219],\n",
      "        [ 0.0219],\n",
      "        [ 0.0892],\n",
      "        [ 0.0434],\n",
      "        [ 0.0613],\n",
      "        [ 0.0441],\n",
      "        [ 0.0275],\n",
      "        [ 0.0658],\n",
      "        [ 0.0514],\n",
      "        [ 0.0045],\n",
      "        [-0.0154]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0050, 0.0051, 0.0051, 0.0053, 0.0055, 0.0055, 0.0065, 0.0066, 0.0065,\n",
      "        0.0064, 0.0055, 0.0054, 0.0051, 0.0057, 0.0051, 0.0048, 0.0052, 0.0048,\n",
      "        0.0049, 0.0048, 0.0049, 0.0049, 0.0052, 0.0056, 0.0054, 0.0051, 0.0048,\n",
      "        0.0045, 0.0035, 0.0040, 0.0031, 0.0028], device='cuda:0')\n",
      "tensor([[ 0.0571],\n",
      "        [-0.0037],\n",
      "        [ 0.0850],\n",
      "        [ 0.0727],\n",
      "        [ 0.1655],\n",
      "        [ 0.0350],\n",
      "        [ 0.1100],\n",
      "        [ 0.0372],\n",
      "        [ 0.0669],\n",
      "        [ 0.0476],\n",
      "        [ 0.0579],\n",
      "        [ 0.0668],\n",
      "        [ 0.0418],\n",
      "        [ 0.0009],\n",
      "        [ 0.0226],\n",
      "        [ 0.0186],\n",
      "        [ 0.0419],\n",
      "        [ 0.0501],\n",
      "        [ 0.0487],\n",
      "        [ 0.0405],\n",
      "        [ 0.0321],\n",
      "        [ 0.0285],\n",
      "        [ 0.0312],\n",
      "        [ 0.0342],\n",
      "        [ 0.0476],\n",
      "        [ 0.0041],\n",
      "        [ 0.0830],\n",
      "        [ 0.0588],\n",
      "        [ 0.0670],\n",
      "        [ 0.1321],\n",
      "        [ 0.1336],\n",
      "        [ 0.0792]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0030, 0.0022, 0.0028, 0.0027, 0.0033, 0.0034, 0.0034, 0.0038, 0.0033,\n",
      "        0.0031, 0.0031, 0.0038, 0.0032, 0.0035, 0.0031, 0.0027, 0.0023, 0.0015,\n",
      "        0.0021, 0.0020, 0.0016, 0.0024, 0.0029, 0.0025, 0.0029, 0.0032, 0.0035,\n",
      "        0.0035, 0.0031, 0.0035, 0.0043, 0.0038], device='cuda:0')\n",
      "tensor([[ 0.0438],\n",
      "        [ 0.0493],\n",
      "        [ 0.0546],\n",
      "        [ 0.0864],\n",
      "        [ 0.0397],\n",
      "        [ 0.0465],\n",
      "        [ 0.0516],\n",
      "        [ 0.0971],\n",
      "        [ 0.0422],\n",
      "        [ 0.0318],\n",
      "        [ 0.0208],\n",
      "        [ 0.0373],\n",
      "        [ 0.0392],\n",
      "        [ 0.1515],\n",
      "        [ 0.0860],\n",
      "        [ 0.0568],\n",
      "        [ 0.1093],\n",
      "        [ 0.0343],\n",
      "        [ 0.0546],\n",
      "        [ 0.0383],\n",
      "        [-0.0110],\n",
      "        [ 0.0197],\n",
      "        [ 0.0548],\n",
      "        [ 0.0209],\n",
      "        [ 0.0045],\n",
      "        [ 0.0864],\n",
      "        [ 0.1122],\n",
      "        [ 0.0135],\n",
      "        [ 0.1014],\n",
      "        [ 0.0698],\n",
      "        [ 0.0496],\n",
      "        [ 0.0438]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0043, 0.0042, 0.0046, 0.0042, 0.0044, 0.0045, 0.0052, 0.0052, 0.0056,\n",
      "        0.0058, 0.0060, 0.0058, 0.0054, 0.0059, 0.0058, 0.0058, 0.0058, 0.0052,\n",
      "        0.0051, 0.0055, 0.0052, 0.0053, 0.0050, 0.0048, 0.0054, 0.0054, 0.0050,\n",
      "        0.0055, 0.0055, 0.0054, 0.0054, 0.0053], device='cuda:0')\n",
      "tensor([[ 5.6927e-02],\n",
      "        [-8.2083e-03],\n",
      "        [-3.3533e-04],\n",
      "        [ 7.3400e-03],\n",
      "        [ 4.5242e-02],\n",
      "        [ 1.2581e-01],\n",
      "        [ 1.1467e-02],\n",
      "        [-1.4305e-04],\n",
      "        [ 6.7276e-02],\n",
      "        [ 1.3943e-04],\n",
      "        [-1.2819e-02],\n",
      "        [ 4.7638e-02],\n",
      "        [ 4.1791e-02],\n",
      "        [ 1.9123e-01],\n",
      "        [ 1.1226e-01],\n",
      "        [ 5.3450e-02],\n",
      "        [ 4.6788e-02],\n",
      "        [ 3.4386e-02],\n",
      "        [ 7.7030e-02],\n",
      "        [ 6.3550e-02],\n",
      "        [ 3.1696e-02],\n",
      "        [ 2.3548e-02],\n",
      "        [ 4.6898e-02],\n",
      "        [ 4.6659e-02],\n",
      "        [ 3.8234e-02],\n",
      "        [ 3.3387e-02],\n",
      "        [ 2.8099e-02],\n",
      "        [ 2.5798e-02],\n",
      "        [ 3.7110e-02],\n",
      "        [ 8.6346e-02],\n",
      "        [ 2.1862e-02],\n",
      "        [ 1.4378e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0050, 0.0057, 0.0057, 0.0055, 0.0061, 0.0062, 0.0063, 0.0064, 0.0068,\n",
      "        0.0069, 0.0065, 0.0068, 0.0067, 0.0068, 0.0068, 0.0068, 0.0069, 0.0071,\n",
      "        0.0075, 0.0073, 0.0071, 0.0074, 0.0074, 0.0072, 0.0072, 0.0071, 0.0071,\n",
      "        0.0072, 0.0070, 0.0071, 0.0070, 0.0070], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([19])) that is different to the input size (torch.Size([19, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0474],\n",
      "        [ 0.0703],\n",
      "        [ 0.0592],\n",
      "        [ 0.0530],\n",
      "        [ 0.0415],\n",
      "        [ 0.0558],\n",
      "        [ 0.0425],\n",
      "        [ 0.0676],\n",
      "        [ 0.0664],\n",
      "        [ 0.1290],\n",
      "        [ 0.1333],\n",
      "        [ 0.0446],\n",
      "        [ 0.0999],\n",
      "        [ 0.0638],\n",
      "        [ 0.1995],\n",
      "        [-0.0003],\n",
      "        [ 0.0100],\n",
      "        [ 0.0051],\n",
      "        [ 0.0823],\n",
      "        [ 0.0615],\n",
      "        [ 0.0382],\n",
      "        [ 0.0218],\n",
      "        [ 0.0559],\n",
      "        [ 0.0374],\n",
      "        [ 0.0714],\n",
      "        [ 0.0342],\n",
      "        [ 0.0388],\n",
      "        [ 0.1048],\n",
      "        [ 0.0565],\n",
      "        [ 0.0703],\n",
      "        [ 0.0321],\n",
      "        [ 0.1090]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0071, 0.0070, 0.0068, 0.0066, 0.0066, 0.0062, 0.0063, 0.0063, 0.0059,\n",
      "        0.0057, 0.0061, 0.0060, 0.0062, 0.0065, 0.0065, 0.0064, 0.0064, 0.0065,\n",
      "        0.0065, 0.0068, 0.0065, 0.0065, 0.0068, 0.0066, 0.0068, 0.0068, 0.0069,\n",
      "        0.0072, 0.0072, 0.0072, 0.0072, 0.0070], device='cuda:0')\n",
      "tensor([[ 0.0032],\n",
      "        [ 0.0480],\n",
      "        [-0.0023],\n",
      "        [ 0.0044],\n",
      "        [ 0.0068],\n",
      "        [ 0.0866],\n",
      "        [ 0.0346],\n",
      "        [ 0.1281],\n",
      "        [ 0.1170],\n",
      "        [ 0.1456],\n",
      "        [ 0.0371],\n",
      "        [ 0.0980],\n",
      "        [ 0.0531],\n",
      "        [-0.0195],\n",
      "        [ 0.0841],\n",
      "        [ 0.0377],\n",
      "        [ 0.0491],\n",
      "        [ 0.0414],\n",
      "        [ 0.0473],\n",
      "        [ 0.0973],\n",
      "        [ 0.1168],\n",
      "        [ 0.0395],\n",
      "        [ 0.0629],\n",
      "        [ 0.0679],\n",
      "        [ 0.0081],\n",
      "        [ 0.0530],\n",
      "        [ 0.0078],\n",
      "        [ 0.0421],\n",
      "        [ 0.0715],\n",
      "        [ 0.0403],\n",
      "        [ 0.0219],\n",
      "        [ 0.0330]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0073, 0.0077, 0.0086, 0.0090, 0.0087, 0.0086, 0.0088, 0.0088, 0.0086,\n",
      "        0.0085, 0.0085, 0.0091, 0.0095, 0.0098, 0.0099, 0.0100, 0.0103, 0.0102,\n",
      "        0.0099, 0.0100, 0.0102, 0.0100, 0.0096, 0.0097, 0.0103, 0.0104, 0.0106,\n",
      "        0.0104, 0.0104, 0.0105, 0.0103, 0.0101], device='cuda:0')\n",
      "tensor([[ 0.1339],\n",
      "        [ 0.0557],\n",
      "        [ 0.0218],\n",
      "        [ 0.0319],\n",
      "        [-0.0149],\n",
      "        [ 0.0184],\n",
      "        [ 0.0492],\n",
      "        [ 0.0427],\n",
      "        [ 0.0632],\n",
      "        [ 0.0223],\n",
      "        [ 0.0090],\n",
      "        [ 0.0165],\n",
      "        [ 0.0631],\n",
      "        [ 0.1308],\n",
      "        [ 0.0611],\n",
      "        [ 0.0914],\n",
      "        [-0.0055],\n",
      "        [ 0.0217],\n",
      "        [ 0.0153],\n",
      "        [ 0.0289],\n",
      "        [ 0.0218],\n",
      "        [ 0.0423],\n",
      "        [ 0.0142],\n",
      "        [ 0.0390],\n",
      "        [ 0.0258],\n",
      "        [ 0.0336],\n",
      "        [ 0.0243],\n",
      "        [ 0.0746],\n",
      "        [-0.0210],\n",
      "        [ 0.0051],\n",
      "        [ 0.0258],\n",
      "        [-0.0109]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0099, 0.0101, 0.0101, 0.0100, 0.0099, 0.0096, 0.0097, 0.0103, 0.0108,\n",
      "        0.0105, 0.0106, 0.0103, 0.0103, 0.0102, 0.0098, 0.0100, 0.0102, 0.0099,\n",
      "        0.0099, 0.0097, 0.0096, 0.0095, 0.0094, 0.0094, 0.0090, 0.0089, 0.0084,\n",
      "        0.0081, 0.0082, 0.0076, 0.0083, 0.0085], device='cuda:0')\n",
      "tensor([[0.0381],\n",
      "        [0.1150],\n",
      "        [0.1001],\n",
      "        [0.0201],\n",
      "        [0.0431],\n",
      "        [0.0635],\n",
      "        [0.0479],\n",
      "        [0.1243],\n",
      "        [0.0157],\n",
      "        [0.0424],\n",
      "        [0.1086],\n",
      "        [0.0209],\n",
      "        [0.0195],\n",
      "        [0.0425],\n",
      "        [0.0646],\n",
      "        [0.0138],\n",
      "        [0.0425],\n",
      "        [0.1281],\n",
      "        [0.0135],\n",
      "        [0.0018],\n",
      "        [0.0238],\n",
      "        [0.0543],\n",
      "        [0.0632],\n",
      "        [0.0384],\n",
      "        [0.1193],\n",
      "        [0.0252],\n",
      "        [0.0436],\n",
      "        [0.0446],\n",
      "        [0.0174],\n",
      "        [0.0572],\n",
      "        [0.0323],\n",
      "        [0.1699]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0088, 0.0082, 0.0085, 0.0082, 0.0081, 0.0079, 0.0080, 0.0081, 0.0080,\n",
      "        0.0078, 0.0078, 0.0077, 0.0076, 0.0077, 0.0077, 0.0079, 0.0080, 0.0086,\n",
      "        0.0081, 0.0081, 0.0079, 0.0083, 0.0085, 0.0083, 0.0084, 0.0087, 0.0088,\n",
      "        0.0093, 0.0095, 0.0093, 0.0092, 0.0092], device='cuda:0')\n",
      "tensor([[ 0.1720],\n",
      "        [ 0.2217],\n",
      "        [ 0.1025],\n",
      "        [ 0.0354],\n",
      "        [ 0.0458],\n",
      "        [ 0.0834],\n",
      "        [ 0.0906],\n",
      "        [ 0.0032],\n",
      "        [ 0.0317],\n",
      "        [ 0.0824],\n",
      "        [ 0.0682],\n",
      "        [ 0.1282],\n",
      "        [ 0.2024],\n",
      "        [ 0.1165],\n",
      "        [ 0.0195],\n",
      "        [ 0.0072],\n",
      "        [ 0.0469],\n",
      "        [ 0.1905],\n",
      "        [ 0.0974],\n",
      "        [ 0.0500],\n",
      "        [ 0.0079],\n",
      "        [ 0.0187],\n",
      "        [ 0.0483],\n",
      "        [ 0.0344],\n",
      "        [ 0.0560],\n",
      "        [-0.0017],\n",
      "        [ 0.0336],\n",
      "        [ 0.0412],\n",
      "        [ 0.0246],\n",
      "        [ 0.0988],\n",
      "        [ 0.0433],\n",
      "        [ 0.0504]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0088, 0.0090, 0.0092, 0.0090, 0.0091, 0.0086, 0.0087, 0.0086, 0.0087,\n",
      "        0.0089, 0.0089, 0.0091, 0.0096, 0.0095, 0.0096, 0.0095, 0.0095, 0.0094,\n",
      "        0.0094, 0.0094, 0.0091, 0.0093, 0.0095, 0.0094, 0.0099, 0.0096, 0.0091,\n",
      "        0.0090, 0.0092, 0.0091, 0.0090, 0.0095], device='cuda:0')\n",
      "tensor([[ 0.0457],\n",
      "        [ 0.1337],\n",
      "        [ 0.1826],\n",
      "        [ 0.0570],\n",
      "        [ 0.0309],\n",
      "        [ 0.0191],\n",
      "        [ 0.0369],\n",
      "        [ 0.0584],\n",
      "        [ 0.0899],\n",
      "        [ 0.0316],\n",
      "        [ 0.0606],\n",
      "        [ 0.0359],\n",
      "        [ 0.0863],\n",
      "        [ 0.1576],\n",
      "        [ 0.0424],\n",
      "        [ 0.1268],\n",
      "        [ 0.1215],\n",
      "        [ 0.0489],\n",
      "        [ 0.0337],\n",
      "        [ 0.0205],\n",
      "        [ 0.0215],\n",
      "        [ 0.0541],\n",
      "        [ 0.0250],\n",
      "        [ 0.0587],\n",
      "        [ 0.0133],\n",
      "        [ 0.0159],\n",
      "        [ 0.0177],\n",
      "        [ 0.0864],\n",
      "        [ 0.0011],\n",
      "        [-0.0202],\n",
      "        [ 0.0402],\n",
      "        [ 0.0303]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0098, 0.0103, 0.0099, 0.0099, 0.0100, 0.0103, 0.0107, 0.0108, 0.0116,\n",
      "        0.0117, 0.0119, 0.0118, 0.0113, 0.0111, 0.0113, 0.0118, 0.0120, 0.0117,\n",
      "        0.0112, 0.0118, 0.0115, 0.0112, 0.0110, 0.0111, 0.0112, 0.0114, 0.0115,\n",
      "        0.0116, 0.0114, 0.0113, 0.0110, 0.0105], device='cuda:0')\n",
      "tensor([[ 0.0293],\n",
      "        [ 0.0452],\n",
      "        [ 0.0578],\n",
      "        [ 0.0382],\n",
      "        [ 0.1887],\n",
      "        [ 0.1013],\n",
      "        [ 0.1534],\n",
      "        [ 0.1209],\n",
      "        [ 0.0093],\n",
      "        [ 0.0665],\n",
      "        [ 0.0008],\n",
      "        [ 0.1023],\n",
      "        [ 0.0659],\n",
      "        [ 0.0364],\n",
      "        [ 0.0636],\n",
      "        [ 0.0656],\n",
      "        [ 0.0583],\n",
      "        [ 0.0709],\n",
      "        [ 0.0273],\n",
      "        [ 0.1459],\n",
      "        [ 0.0141],\n",
      "        [-0.0090],\n",
      "        [ 0.0397],\n",
      "        [ 0.0294],\n",
      "        [ 0.0547],\n",
      "        [ 0.0614],\n",
      "        [ 0.0128],\n",
      "        [ 0.0240],\n",
      "        [ 0.0296],\n",
      "        [ 0.0321],\n",
      "        [ 0.0101],\n",
      "        [ 0.1718]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0105, 0.0100, 0.0100, 0.0104, 0.0108, 0.0113, 0.0117, 0.0116, 0.0111,\n",
      "        0.0114, 0.0112, 0.0112, 0.0110, 0.0110, 0.0107, 0.0107, 0.0107, 0.0112,\n",
      "        0.0112, 0.0111, 0.0112, 0.0111, 0.0112, 0.0116, 0.0118, 0.0122, 0.0127,\n",
      "        0.0133, 0.0128, 0.0129, 0.0127, 0.0130], device='cuda:0')\n",
      "tensor([[0.0464],\n",
      "        [0.0599],\n",
      "        [0.0637],\n",
      "        [0.0575],\n",
      "        [0.0367],\n",
      "        [0.0577],\n",
      "        [0.0573],\n",
      "        [0.1182],\n",
      "        [0.0533],\n",
      "        [0.1722],\n",
      "        [0.0243],\n",
      "        [0.0206],\n",
      "        [0.0861],\n",
      "        [0.0207],\n",
      "        [0.1353],\n",
      "        [0.0540],\n",
      "        [0.0534],\n",
      "        [0.0540],\n",
      "        [0.1119],\n",
      "        [0.1031],\n",
      "        [0.0839],\n",
      "        [0.0796],\n",
      "        [0.0816],\n",
      "        [0.0149],\n",
      "        [0.0071],\n",
      "        [0.0606],\n",
      "        [0.0137],\n",
      "        [0.0426],\n",
      "        [0.0030],\n",
      "        [0.0557],\n",
      "        [0.0336],\n",
      "        [0.0789]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0140, 0.0143, 0.0145, 0.0144, 0.0161, 0.0154, 0.0156, 0.0155, 0.0149,\n",
      "        0.0152, 0.0153, 0.0151, 0.0147, 0.0144, 0.0137, 0.0140, 0.0149, 0.0148,\n",
      "        0.0147, 0.0145, 0.0145, 0.0145, 0.0147, 0.0149, 0.0151, 0.0156, 0.0157,\n",
      "        0.0156, 0.0156, 0.0156, 0.0157, 0.0158], device='cuda:0')\n",
      "tensor([[ 0.0411],\n",
      "        [ 0.0580],\n",
      "        [ 0.0194],\n",
      "        [ 0.0447],\n",
      "        [ 0.0582],\n",
      "        [-0.0027],\n",
      "        [ 0.0701],\n",
      "        [ 0.0205],\n",
      "        [ 0.0695],\n",
      "        [ 0.0768],\n",
      "        [ 0.0328],\n",
      "        [ 0.0917],\n",
      "        [ 0.0677],\n",
      "        [ 0.0442],\n",
      "        [ 0.0275],\n",
      "        [ 0.0078],\n",
      "        [ 0.0743],\n",
      "        [ 0.0809],\n",
      "        [ 0.1572],\n",
      "        [ 0.0824],\n",
      "        [ 0.0261],\n",
      "        [ 0.0854],\n",
      "        [ 0.0333],\n",
      "        [ 0.1823],\n",
      "        [ 0.0481],\n",
      "        [ 0.0485],\n",
      "        [ 0.0097],\n",
      "        [ 0.0531],\n",
      "        [ 0.0579],\n",
      "        [ 0.0838],\n",
      "        [ 0.1105],\n",
      "        [ 0.0863]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0166, 0.0170, 0.0164, 0.0166, 0.0163, 0.0162, 0.0159, 0.0162, 0.0165,\n",
      "        0.0165, 0.0165, 0.0170, 0.0176, 0.0178, 0.0175, 0.0175, 0.0172, 0.0171,\n",
      "        0.0169, 0.0173, 0.0174, 0.0177, 0.0178, 0.0178, 0.0182, 0.0182, 0.0184,\n",
      "        0.0184, 0.0183, 0.0178, 0.0175, 0.0176], device='cuda:0')\n",
      "tensor([[ 0.1482],\n",
      "        [ 0.0978],\n",
      "        [ 0.0920],\n",
      "        [ 0.0898],\n",
      "        [ 0.0963],\n",
      "        [ 0.0568],\n",
      "        [-0.0152],\n",
      "        [ 0.0459],\n",
      "        [ 0.0193],\n",
      "        [ 0.0528],\n",
      "        [ 0.0081],\n",
      "        [ 0.0753],\n",
      "        [ 0.0243],\n",
      "        [ 0.0700],\n",
      "        [ 0.0392],\n",
      "        [ 0.0453],\n",
      "        [ 0.0239],\n",
      "        [ 0.0191],\n",
      "        [-0.0259],\n",
      "        [ 0.0691],\n",
      "        [ 0.0236],\n",
      "        [ 0.0307],\n",
      "        [ 0.0276],\n",
      "        [ 0.0182],\n",
      "        [ 0.0279],\n",
      "        [ 0.0590],\n",
      "        [ 0.0361],\n",
      "        [ 0.0310],\n",
      "        [ 0.0152],\n",
      "        [ 0.0327],\n",
      "        [ 0.0224],\n",
      "        [ 0.0700]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0183, 0.0179, 0.0176, 0.0175, 0.0174, 0.0176, 0.0174, 0.0179, 0.0181,\n",
      "        0.0175, 0.0174, 0.0173, 0.0175, 0.0170, 0.0166, 0.0172, 0.0175, 0.0176,\n",
      "        0.0175, 0.0175, 0.0175, 0.0175, 0.0177, 0.0177, 0.0175, 0.0177, 0.0180,\n",
      "        0.0184, 0.0189, 0.0192, 0.0194, 0.0188], device='cuda:0')\n",
      "tensor([[ 0.0569],\n",
      "        [ 0.0953],\n",
      "        [ 0.0541],\n",
      "        [ 0.1810],\n",
      "        [ 0.0784],\n",
      "        [ 0.0269],\n",
      "        [ 0.1023],\n",
      "        [ 0.0459],\n",
      "        [ 0.1657],\n",
      "        [ 0.0803],\n",
      "        [ 0.1926],\n",
      "        [ 0.0828],\n",
      "        [-0.0077],\n",
      "        [-0.0007],\n",
      "        [ 0.0528],\n",
      "        [ 0.0316],\n",
      "        [-0.0031],\n",
      "        [ 0.0192],\n",
      "        [ 0.0244],\n",
      "        [ 0.0408],\n",
      "        [ 0.0559],\n",
      "        [ 0.0494],\n",
      "        [ 0.0355],\n",
      "        [ 0.0399],\n",
      "        [ 0.0596],\n",
      "        [ 0.0565],\n",
      "        [ 0.0342],\n",
      "        [ 0.0818],\n",
      "        [ 0.0328],\n",
      "        [ 0.0439],\n",
      "        [ 0.0499],\n",
      "        [ 0.0133]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0187, 0.0182, 0.0185, 0.0180, 0.0182, 0.0177, 0.0171, 0.0173, 0.0170,\n",
      "        0.0177, 0.0175, 0.0176, 0.0179, 0.0182, 0.0185, 0.0187, 0.0183, 0.0185,\n",
      "        0.0186, 0.0184, 0.0186, 0.0186, 0.0184, 0.0183, 0.0183, 0.0186, 0.0188,\n",
      "        0.0191, 0.0194, 0.0192, 0.0191, 0.0187], device='cuda:0')\n",
      "tensor([[0.1513],\n",
      "        [0.0382],\n",
      "        [0.1472],\n",
      "        [0.0555],\n",
      "        [0.0693],\n",
      "        [0.0921],\n",
      "        [0.0836],\n",
      "        [0.0373],\n",
      "        [0.0677],\n",
      "        [0.0497],\n",
      "        [0.0286],\n",
      "        [0.0173],\n",
      "        [0.0462],\n",
      "        [0.0721],\n",
      "        [0.0406],\n",
      "        [0.0048],\n",
      "        [0.0706],\n",
      "        [0.0305],\n",
      "        [0.0105],\n",
      "        [0.0387],\n",
      "        [0.0198],\n",
      "        [0.0922],\n",
      "        [0.0171],\n",
      "        [0.0835],\n",
      "        [0.0685],\n",
      "        [0.0315],\n",
      "        [0.0311],\n",
      "        [0.0247],\n",
      "        [0.0569],\n",
      "        [0.0588],\n",
      "        [0.0316],\n",
      "        [0.0483]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0186, 0.0179, 0.0183, 0.0184, 0.0184, 0.0180, 0.0179, 0.0178, 0.0177,\n",
      "        0.0172, 0.0171, 0.0170, 0.0173, 0.0171, 0.0171, 0.0169, 0.0157, 0.0162,\n",
      "        0.0157, 0.0161, 0.0161, 0.0158, 0.0160, 0.0164, 0.0159, 0.0160, 0.0160,\n",
      "        0.0156, 0.0149, 0.0153, 0.0150, 0.0145], device='cuda:0')\n",
      "tensor([[0.0319],\n",
      "        [0.1014],\n",
      "        [0.0468],\n",
      "        [0.0326],\n",
      "        [0.0101],\n",
      "        [0.0333],\n",
      "        [0.0494],\n",
      "        [0.0161],\n",
      "        [0.0657],\n",
      "        [0.1105],\n",
      "        [0.0649],\n",
      "        [0.1455],\n",
      "        [0.0702],\n",
      "        [0.0657],\n",
      "        [0.0266],\n",
      "        [0.0631],\n",
      "        [0.0822],\n",
      "        [0.0838],\n",
      "        [0.1782],\n",
      "        [0.0067],\n",
      "        [0.0943],\n",
      "        [0.0530],\n",
      "        [0.0533],\n",
      "        [0.0179],\n",
      "        [0.0624],\n",
      "        [0.0440],\n",
      "        [0.1082],\n",
      "        [0.0739],\n",
      "        [0.0777],\n",
      "        [0.0948],\n",
      "        [0.0330],\n",
      "        [0.0178]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0144, 0.0146, 0.0152, 0.0154, 0.0154, 0.0155, 0.0157, 0.0157, 0.0154,\n",
      "        0.0150, 0.0143, 0.0142, 0.0132, 0.0135, 0.0143, 0.0149, 0.0142, 0.0143,\n",
      "        0.0142, 0.0146, 0.0147, 0.0153, 0.0150, 0.0152, 0.0151, 0.0150, 0.0148,\n",
      "        0.0146, 0.0142, 0.0142, 0.0145, 0.0147], device='cuda:0')\n",
      "tensor([[ 0.0613],\n",
      "        [ 0.1524],\n",
      "        [ 0.1107],\n",
      "        [ 0.0416],\n",
      "        [ 0.0553],\n",
      "        [ 0.0238],\n",
      "        [ 0.0201],\n",
      "        [ 0.0133],\n",
      "        [ 0.0177],\n",
      "        [ 0.0970],\n",
      "        [ 0.0465],\n",
      "        [ 0.0421],\n",
      "        [ 0.0368],\n",
      "        [ 0.0399],\n",
      "        [-0.0316],\n",
      "        [ 0.2135],\n",
      "        [ 0.0182],\n",
      "        [ 0.0622],\n",
      "        [ 0.0150],\n",
      "        [ 0.0102],\n",
      "        [ 0.0238],\n",
      "        [ 0.0042],\n",
      "        [ 0.0512],\n",
      "        [ 0.0779],\n",
      "        [ 0.0496],\n",
      "        [ 0.0357],\n",
      "        [ 0.0295],\n",
      "        [ 0.0356],\n",
      "        [ 0.1365],\n",
      "        [ 0.2284],\n",
      "        [ 0.1880],\n",
      "        [ 0.0399]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0144, 0.0139, 0.0139, 0.0142, 0.0147, 0.0144, 0.0141, 0.0141, 0.0140,\n",
      "        0.0139, 0.0134, 0.0135, 0.0137, 0.0138, 0.0138, 0.0136, 0.0136, 0.0137,\n",
      "        0.0137, 0.0137, 0.0137, 0.0137, 0.0138, 0.0143, 0.0147, 0.0147, 0.0139,\n",
      "        0.0139, 0.0142, 0.0140, 0.0137, 0.0136], device='cuda:0')\n",
      "tensor([[ 0.0530],\n",
      "        [ 0.0670],\n",
      "        [-0.0033],\n",
      "        [ 0.0409],\n",
      "        [ 0.0143],\n",
      "        [ 0.0566],\n",
      "        [ 0.0605],\n",
      "        [ 0.0674],\n",
      "        [ 0.1278],\n",
      "        [ 0.0429],\n",
      "        [ 0.0523],\n",
      "        [ 0.0372],\n",
      "        [ 0.0042],\n",
      "        [ 0.0090],\n",
      "        [ 0.0274],\n",
      "        [ 0.0216],\n",
      "        [ 0.0103],\n",
      "        [ 0.0528],\n",
      "        [ 0.0145],\n",
      "        [ 0.0756],\n",
      "        [ 0.0737],\n",
      "        [ 0.0834],\n",
      "        [ 0.0895],\n",
      "        [ 0.0494],\n",
      "        [ 0.0246],\n",
      "        [ 0.0541],\n",
      "        [ 0.0421],\n",
      "        [ 0.0227],\n",
      "        [ 0.0277],\n",
      "        [ 0.1254],\n",
      "        [-0.0077],\n",
      "        [ 0.0373]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0135, 0.0132, 0.0128, 0.0128, 0.0132, 0.0136, 0.0135, 0.0128, 0.0128,\n",
      "        0.0129, 0.0133, 0.0131, 0.0131, 0.0131, 0.0132, 0.0134, 0.0134, 0.0133,\n",
      "        0.0131, 0.0133, 0.0132, 0.0130, 0.0131, 0.0130, 0.0126, 0.0125, 0.0129,\n",
      "        0.0136, 0.0142, 0.0140, 0.0140, 0.0141], device='cuda:0')\n",
      "tensor([[0.0390],\n",
      "        [0.0325],\n",
      "        [0.0239],\n",
      "        [0.0198],\n",
      "        [0.0730],\n",
      "        [0.0777],\n",
      "        [0.0488],\n",
      "        [0.0342],\n",
      "        [0.0376],\n",
      "        [0.0556],\n",
      "        [0.0621],\n",
      "        [0.0707],\n",
      "        [0.0483],\n",
      "        [0.0120],\n",
      "        [0.0760],\n",
      "        [0.0574],\n",
      "        [0.0344],\n",
      "        [0.0262],\n",
      "        [0.0435],\n",
      "        [0.0634],\n",
      "        [0.0009],\n",
      "        [0.0684],\n",
      "        [0.0761],\n",
      "        [0.0330],\n",
      "        [0.0753],\n",
      "        [0.0334],\n",
      "        [0.0292],\n",
      "        [0.0790],\n",
      "        [0.0663],\n",
      "        [0.0121],\n",
      "        [0.0231],\n",
      "        [0.0285]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0144, 0.0150, 0.0154, 0.0157, 0.0157, 0.0156, 0.0159, 0.0158, 0.0156,\n",
      "        0.0160, 0.0161, 0.0160, 0.0158, 0.0157, 0.0155, 0.0161, 0.0158, 0.0154,\n",
      "        0.0159, 0.0153, 0.0154, 0.0154, 0.0148, 0.0146, 0.0148, 0.0156, 0.0160,\n",
      "        0.0160, 0.0161, 0.0165, 0.0166, 0.0166], device='cuda:0')\n",
      "tensor([[0.0642],\n",
      "        [0.0971],\n",
      "        [0.0789],\n",
      "        [0.1192],\n",
      "        [0.0572],\n",
      "        [0.0802],\n",
      "        [0.0385],\n",
      "        [0.1516],\n",
      "        [0.1047],\n",
      "        [0.0367],\n",
      "        [0.0492],\n",
      "        [0.0540],\n",
      "        [0.0537],\n",
      "        [0.0637],\n",
      "        [0.1247],\n",
      "        [0.0407],\n",
      "        [0.0734],\n",
      "        [0.0343],\n",
      "        [0.0026],\n",
      "        [0.0523],\n",
      "        [0.0597],\n",
      "        [0.0561],\n",
      "        [0.0753],\n",
      "        [0.1439],\n",
      "        [0.1739],\n",
      "        [0.1687],\n",
      "        [0.0212],\n",
      "        [0.0194],\n",
      "        [0.0391],\n",
      "        [0.0384],\n",
      "        [0.0216],\n",
      "        [0.0330]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0166, 0.0164, 0.0161, 0.0163, 0.0165, 0.0170, 0.0167, 0.0169, 0.0173,\n",
      "        0.0175, 0.0173, 0.0172, 0.0173, 0.0172, 0.0172, 0.0170, 0.0169, 0.0166,\n",
      "        0.0161, 0.0165, 0.0165, 0.0165, 0.0166, 0.0167, 0.0169, 0.0167, 0.0166,\n",
      "        0.0168, 0.0177, 0.0177, 0.0179, 0.0179], device='cuda:0')\n",
      "tensor([[ 0.0239],\n",
      "        [ 0.0476],\n",
      "        [ 0.0013],\n",
      "        [ 0.0610],\n",
      "        [ 0.1145],\n",
      "        [ 0.1094],\n",
      "        [ 0.0377],\n",
      "        [ 0.0737],\n",
      "        [ 0.0625],\n",
      "        [ 0.0766],\n",
      "        [ 0.0732],\n",
      "        [ 0.0494],\n",
      "        [ 0.0473],\n",
      "        [ 0.0221],\n",
      "        [ 0.0350],\n",
      "        [ 0.0076],\n",
      "        [ 0.0240],\n",
      "        [ 0.0261],\n",
      "        [ 0.0343],\n",
      "        [ 0.0691],\n",
      "        [ 0.0495],\n",
      "        [ 0.0569],\n",
      "        [ 0.1228],\n",
      "        [ 0.1062],\n",
      "        [ 0.0947],\n",
      "        [ 0.0702],\n",
      "        [ 0.0507],\n",
      "        [-0.0105],\n",
      "        [-0.0152],\n",
      "        [ 0.0221],\n",
      "        [ 0.0136],\n",
      "        [ 0.1764]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0179, 0.0184, 0.0184, 0.0182, 0.0185, 0.0185, 0.0184, 0.0184, 0.0184,\n",
      "        0.0185, 0.0189, 0.0188, 0.0189, 0.0189, 0.0193, 0.0189, 0.0184, 0.0185,\n",
      "        0.0189, 0.0188, 0.0186, 0.0181, 0.0182, 0.0184, 0.0180, 0.0176, 0.0169,\n",
      "        0.0178, 0.0175, 0.0175, 0.0184, 0.0176], device='cuda:0')\n",
      "tensor([[0.0205],\n",
      "        [0.0711],\n",
      "        [0.0118],\n",
      "        [0.0986],\n",
      "        [0.0398],\n",
      "        [0.0595],\n",
      "        [0.0275],\n",
      "        [0.0104],\n",
      "        [0.0382],\n",
      "        [0.0325],\n",
      "        [0.0423],\n",
      "        [0.0778],\n",
      "        [0.0837],\n",
      "        [0.1759],\n",
      "        [0.0567],\n",
      "        [0.0357],\n",
      "        [0.0719],\n",
      "        [0.0670],\n",
      "        [0.0559],\n",
      "        [0.0108],\n",
      "        [0.0556],\n",
      "        [0.0177],\n",
      "        [0.1588],\n",
      "        [0.1117],\n",
      "        [0.0213],\n",
      "        [0.0150],\n",
      "        [0.0016],\n",
      "        [0.1480],\n",
      "        [0.1478],\n",
      "        [0.0641],\n",
      "        [0.0681],\n",
      "        [0.1242]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0181, 0.0178, 0.0181, 0.0180, 0.0176, 0.0168, 0.0164, 0.0165, 0.0163,\n",
      "        0.0168, 0.0167, 0.0172, 0.0171, 0.0170, 0.0168, 0.0167, 0.0166, 0.0159,\n",
      "        0.0156, 0.0162, 0.0168, 0.0170, 0.0173, 0.0170, 0.0168, 0.0175, 0.0177,\n",
      "        0.0175, 0.0174, 0.0177, 0.0179, 0.0181], device='cuda:0')\n",
      "tensor([[0.0391],\n",
      "        [0.0067],\n",
      "        [0.0720],\n",
      "        [0.0152],\n",
      "        [0.0203],\n",
      "        [0.0359],\n",
      "        [0.0904],\n",
      "        [0.0878],\n",
      "        [0.1690],\n",
      "        [0.1297],\n",
      "        [0.0797],\n",
      "        [0.0498],\n",
      "        [0.0340],\n",
      "        [0.0890],\n",
      "        [0.0456],\n",
      "        [0.0479],\n",
      "        [0.0268],\n",
      "        [0.0602],\n",
      "        [0.0269],\n",
      "        [0.0309],\n",
      "        [0.0486],\n",
      "        [0.0481],\n",
      "        [0.0481],\n",
      "        [0.0764],\n",
      "        [0.0497],\n",
      "        [0.0630],\n",
      "        [0.0524],\n",
      "        [0.0454],\n",
      "        [0.0395],\n",
      "        [0.0299],\n",
      "        [0.0038],\n",
      "        [0.0075]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0181, 0.0174, 0.0172, 0.0170, 0.0174, 0.0174, 0.0173, 0.0178, 0.0182,\n",
      "        0.0184, 0.0182, 0.0185, 0.0189, 0.0186, 0.0188, 0.0188, 0.0187, 0.0188,\n",
      "        0.0193, 0.0195, 0.0195, 0.0194, 0.0195, 0.0193, 0.0195, 0.0197, 0.0202,\n",
      "        0.0200, 0.0200, 0.0201, 0.0201, 0.0200], device='cuda:0')\n",
      "tensor([[ 0.0435],\n",
      "        [ 0.0366],\n",
      "        [ 0.0252],\n",
      "        [ 0.0655],\n",
      "        [ 0.0725],\n",
      "        [ 0.0099],\n",
      "        [ 0.0376],\n",
      "        [ 0.0728],\n",
      "        [ 0.0405],\n",
      "        [ 0.0400],\n",
      "        [ 0.0246],\n",
      "        [ 0.0351],\n",
      "        [ 0.0471],\n",
      "        [ 0.0287],\n",
      "        [ 0.0814],\n",
      "        [ 0.0900],\n",
      "        [ 0.0462],\n",
      "        [ 0.0508],\n",
      "        [ 0.0559],\n",
      "        [ 0.0542],\n",
      "        [ 0.0436],\n",
      "        [ 0.0471],\n",
      "        [ 0.0407],\n",
      "        [ 0.0438],\n",
      "        [ 0.1149],\n",
      "        [ 0.0618],\n",
      "        [ 0.1462],\n",
      "        [ 0.0482],\n",
      "        [ 0.0783],\n",
      "        [ 0.0126],\n",
      "        [-0.0134],\n",
      "        [ 0.0757]], device='cuda:0', grad_fn=<AddmmBackward>)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([0.0201, 0.0202, 0.0204, 0.0203, 0.0202, 0.0204, 0.0204, 0.0210, 0.0208,\n",
      "        0.0208, 0.0210, 0.0213, 0.0210, 0.0212, 0.0214, 0.0213, 0.0210, 0.0213,\n",
      "        0.0211, 0.0210, 0.0211, 0.0206, 0.0208, 0.0210, 0.0212, 0.0210, 0.0213,\n",
      "        0.0216, 0.0213, 0.0213, 0.0213, 0.0215], device='cuda:0')\n",
      "tensor([[ 0.0356],\n",
      "        [ 0.0814],\n",
      "        [ 0.0008],\n",
      "        [-0.0129],\n",
      "        [ 0.0257],\n",
      "        [ 0.0345],\n",
      "        [ 0.0413],\n",
      "        [ 0.0305],\n",
      "        [-0.0054],\n",
      "        [ 0.0464],\n",
      "        [ 0.0531],\n",
      "        [ 0.0186],\n",
      "        [ 0.0305],\n",
      "        [ 0.0430],\n",
      "        [ 0.0268],\n",
      "        [ 0.0942],\n",
      "        [-0.0131],\n",
      "        [ 0.0385],\n",
      "        [ 0.0679],\n",
      "        [ 0.0335],\n",
      "        [ 0.1180],\n",
      "        [ 0.0874],\n",
      "        [ 0.0457],\n",
      "        [ 0.0278],\n",
      "        [ 0.0609],\n",
      "        [ 0.0786],\n",
      "        [ 0.1157],\n",
      "        [ 0.0548],\n",
      "        [ 0.0418],\n",
      "        [ 0.0642],\n",
      "        [ 0.1130],\n",
      "        [ 0.0389]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0217, 0.0218, 0.0223, 0.0223, 0.0224, 0.0223, 0.0220, 0.0225, 0.0226,\n",
      "        0.0227, 0.0227, 0.0228, 0.0230, 0.0230, 0.0231, 0.0226, 0.0227, 0.0228,\n",
      "        0.0231, 0.0231, 0.0235, 0.0237, 0.0234, 0.0234, 0.0233, 0.0229, 0.0229,\n",
      "        0.0229, 0.0223, 0.0221, 0.0213, 0.0202], device='cuda:0')\n",
      "tensor([[ 0.1074],\n",
      "        [-0.0188],\n",
      "        [ 0.0165],\n",
      "        [ 0.0853],\n",
      "        [ 0.0084],\n",
      "        [ 0.1815],\n",
      "        [-0.0411],\n",
      "        [ 0.0325],\n",
      "        [ 0.0244],\n",
      "        [ 0.0675],\n",
      "        [ 0.0669],\n",
      "        [ 0.0741],\n",
      "        [ 0.0421],\n",
      "        [ 0.0041],\n",
      "        [ 0.0704],\n",
      "        [ 0.0530],\n",
      "        [ 0.0322],\n",
      "        [ 0.0530],\n",
      "        [ 0.0252],\n",
      "        [ 0.0588],\n",
      "        [ 0.0765],\n",
      "        [ 0.0578],\n",
      "        [ 0.0153],\n",
      "        [ 0.0242],\n",
      "        [ 0.0605],\n",
      "        [ 0.0310],\n",
      "        [ 0.0159],\n",
      "        [ 0.0352],\n",
      "        [ 0.0548],\n",
      "        [ 0.0566],\n",
      "        [ 0.0455],\n",
      "        [ 0.0274]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0206, 0.0202, 0.0208, 0.0210, 0.0213, 0.0215, 0.0214, 0.0206, 0.0197,\n",
      "        0.0200, 0.0200, 0.0202, 0.0206, 0.0205, 0.0200, 0.0201, 0.0203, 0.0199,\n",
      "        0.0201, 0.0200, 0.0196, 0.0195, 0.0197, 0.0199, 0.0199, 0.0198, 0.0199,\n",
      "        0.0197, 0.0200, 0.0198, 0.0195, 0.0188], device='cuda:0')\n",
      "tensor([[0.0841],\n",
      "        [0.0051],\n",
      "        [0.0288],\n",
      "        [0.0018],\n",
      "        [0.1085],\n",
      "        [0.1032],\n",
      "        [0.0235],\n",
      "        [0.0463],\n",
      "        [0.0142],\n",
      "        [0.0409],\n",
      "        [0.1635],\n",
      "        [0.1405],\n",
      "        [0.0547],\n",
      "        [0.0374],\n",
      "        [0.0350],\n",
      "        [0.0699],\n",
      "        [0.0312],\n",
      "        [0.0225],\n",
      "        [0.0203],\n",
      "        [0.0306],\n",
      "        [0.0248],\n",
      "        [0.0818],\n",
      "        [0.0957],\n",
      "        [0.0719],\n",
      "        [0.0566],\n",
      "        [0.0919],\n",
      "        [0.0583],\n",
      "        [0.0870],\n",
      "        [0.0789],\n",
      "        [0.0699],\n",
      "        [0.0659],\n",
      "        [0.0255]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0184, 0.0188, 0.0194, 0.0196, 0.0208, 0.0206, 0.0203, 0.0199, 0.0198,\n",
      "        0.0195, 0.0193, 0.0198, 0.0199, 0.0203, 0.0207, 0.0211, 0.0214, 0.0220,\n",
      "        0.0216, 0.0211, 0.0215, 0.0212, 0.0211, 0.0209, 0.0206, 0.0206, 0.0210,\n",
      "        0.0213, 0.0205, 0.0201, 0.0203, 0.0204], device='cuda:0')\n",
      "tensor([[ 0.0332],\n",
      "        [ 0.0660],\n",
      "        [ 0.0592],\n",
      "        [ 0.0022],\n",
      "        [ 0.0564],\n",
      "        [ 0.1194],\n",
      "        [ 0.0369],\n",
      "        [ 0.0200],\n",
      "        [ 0.0352],\n",
      "        [ 0.0353],\n",
      "        [ 0.0059],\n",
      "        [-0.0071],\n",
      "        [ 0.0206],\n",
      "        [ 0.1229],\n",
      "        [ 0.0763],\n",
      "        [ 0.0594],\n",
      "        [ 0.0577],\n",
      "        [ 0.0217],\n",
      "        [ 0.0176],\n",
      "        [ 0.0085],\n",
      "        [ 0.0653],\n",
      "        [ 0.0282],\n",
      "        [ 0.0744],\n",
      "        [ 0.0327],\n",
      "        [ 0.0640],\n",
      "        [ 0.0275],\n",
      "        [ 0.0755],\n",
      "        [-0.0019],\n",
      "        [ 0.0557],\n",
      "        [ 0.1683],\n",
      "        [ 0.0639],\n",
      "        [ 0.0108]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0199, 0.0199, 0.0206, 0.0204, 0.0201, 0.0201, 0.0200, 0.0203, 0.0201,\n",
      "        0.0200, 0.0208, 0.0210, 0.0210, 0.0214, 0.0221, 0.0217, 0.0216, 0.0210,\n",
      "        0.0213, 0.0217, 0.0220, 0.0224, 0.0225, 0.0232, 0.0240, 0.0232, 0.0234,\n",
      "        0.0248, 0.0243, 0.0238, 0.0236, 0.0239], device='cuda:0')\n",
      "tensor([[ 0.0603],\n",
      "        [ 0.0428],\n",
      "        [ 0.0660],\n",
      "        [ 0.0341],\n",
      "        [ 0.0788],\n",
      "        [ 0.0260],\n",
      "        [ 0.0149],\n",
      "        [ 0.0731],\n",
      "        [ 0.0161],\n",
      "        [ 0.0993],\n",
      "        [ 0.0638],\n",
      "        [ 0.0373],\n",
      "        [ 0.0696],\n",
      "        [ 0.0248],\n",
      "        [ 0.0705],\n",
      "        [ 0.0895],\n",
      "        [ 0.1022],\n",
      "        [-0.0413],\n",
      "        [ 0.0394],\n",
      "        [-0.0169],\n",
      "        [ 0.0456],\n",
      "        [ 0.0564],\n",
      "        [ 0.0410],\n",
      "        [-0.0354],\n",
      "        [ 0.0085],\n",
      "        [ 0.0685],\n",
      "        [-0.0032],\n",
      "        [ 0.1112],\n",
      "        [ 0.1078],\n",
      "        [ 0.1163],\n",
      "        [ 0.0253],\n",
      "        [ 0.0761]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0244, 0.0244, 0.0233, 0.0244, 0.0249, 0.0244, 0.0246, 0.0248, 0.0246,\n",
      "        0.0239, 0.0231, 0.0225, 0.0217, 0.0220, 0.0225, 0.0220, 0.0216, 0.0217,\n",
      "        0.0214, 0.0224, 0.0235, 0.0233, 0.0242, 0.0248, 0.0245, 0.0246, 0.0245,\n",
      "        0.0236, 0.0226, 0.0217, 0.0213, 0.0205], device='cuda:0')\n",
      "tensor([[-0.0041],\n",
      "        [ 0.0295],\n",
      "        [ 0.1346],\n",
      "        [ 0.1992],\n",
      "        [ 0.1624],\n",
      "        [-0.0659],\n",
      "        [ 0.1002],\n",
      "        [ 0.0493],\n",
      "        [ 0.0496],\n",
      "        [ 0.0729],\n",
      "        [ 0.0337],\n",
      "        [ 0.0463],\n",
      "        [ 0.0263],\n",
      "        [ 0.0131],\n",
      "        [ 0.0117],\n",
      "        [ 0.1040],\n",
      "        [ 0.0820],\n",
      "        [ 0.0786],\n",
      "        [ 0.0666],\n",
      "        [ 0.0003],\n",
      "        [ 0.0817],\n",
      "        [ 0.0901],\n",
      "        [ 0.0141],\n",
      "        [ 0.0359],\n",
      "        [ 0.0445],\n",
      "        [ 0.0457],\n",
      "        [ 0.0517],\n",
      "        [ 0.0160],\n",
      "        [ 0.0237],\n",
      "        [ 0.0245],\n",
      "        [ 0.0174],\n",
      "        [ 0.0056]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0202, 0.0208, 0.0219, 0.0219, 0.0215, 0.0216, 0.0212, 0.0216, 0.0229,\n",
      "        0.0235, 0.0236, 0.0235, 0.0228, 0.0226, 0.0221, 0.0222, 0.0218, 0.0221,\n",
      "        0.0226, 0.0225, 0.0230, 0.0234, 0.0229, 0.0228, 0.0228, 0.0222, 0.0226,\n",
      "        0.0230, 0.0230, 0.0224, 0.0220, 0.0226], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0862],\n",
      "        [ 0.0980],\n",
      "        [ 0.0337],\n",
      "        [ 0.0314],\n",
      "        [ 0.0196],\n",
      "        [ 0.0644],\n",
      "        [ 0.0328],\n",
      "        [ 0.0407],\n",
      "        [ 0.0228],\n",
      "        [ 0.0313],\n",
      "        [ 0.0595],\n",
      "        [ 0.0767],\n",
      "        [ 0.0457],\n",
      "        [ 0.0277],\n",
      "        [ 0.0675],\n",
      "        [ 0.0401],\n",
      "        [ 0.1014],\n",
      "        [ 0.0612],\n",
      "        [ 0.0360],\n",
      "        [ 0.0428],\n",
      "        [ 0.0930],\n",
      "        [ 0.0624],\n",
      "        [ 0.0626],\n",
      "        [ 0.0304],\n",
      "        [ 0.0252],\n",
      "        [-0.0217],\n",
      "        [ 0.0894],\n",
      "        [ 0.1336],\n",
      "        [ 0.0549],\n",
      "        [ 0.0789],\n",
      "        [ 0.0466],\n",
      "        [ 0.1353]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0226, 0.0218, 0.0217, 0.0219, 0.0213, 0.0210, 0.0199, 0.0200, 0.0206,\n",
      "        0.0213, 0.0212, 0.0212, 0.0209, 0.0206, 0.0209, 0.0220, 0.0218, 0.0213,\n",
      "        0.0211, 0.0203, 0.0203, 0.0196, 0.0196, 0.0195, 0.0190, 0.0179, 0.0170,\n",
      "        0.0184, 0.0186, 0.0186, 0.0185, 0.0182], device='cuda:0')\n",
      "tensor([[ 0.0912],\n",
      "        [ 0.0281],\n",
      "        [ 0.0065],\n",
      "        [ 0.0620],\n",
      "        [ 0.0465],\n",
      "        [ 0.0380],\n",
      "        [ 0.1573],\n",
      "        [ 0.0298],\n",
      "        [ 0.0433],\n",
      "        [ 0.0425],\n",
      "        [ 0.0790],\n",
      "        [ 0.0452],\n",
      "        [ 0.0196],\n",
      "        [ 0.0831],\n",
      "        [ 0.0489],\n",
      "        [ 0.0344],\n",
      "        [ 0.1336],\n",
      "        [ 0.0487],\n",
      "        [ 0.0251],\n",
      "        [ 0.0096],\n",
      "        [ 0.0429],\n",
      "        [ 0.0651],\n",
      "        [ 0.0416],\n",
      "        [ 0.1397],\n",
      "        [ 0.0787],\n",
      "        [ 0.0506],\n",
      "        [ 0.0388],\n",
      "        [-0.0258],\n",
      "        [ 0.0344],\n",
      "        [ 0.0308],\n",
      "        [ 0.0440],\n",
      "        [ 0.1179]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0179, 0.0172, 0.0179, 0.0186, 0.0184, 0.0189, 0.0203, 0.0196, 0.0196,\n",
      "        0.0188, 0.0180, 0.0184, 0.0184, 0.0193, 0.0194, 0.0184, 0.0180, 0.0182,\n",
      "        0.0174, 0.0173, 0.0173, 0.0168, 0.0153, 0.0172, 0.0167, 0.0177, 0.0182,\n",
      "        0.0180, 0.0181, 0.0191, 0.0182, 0.0183], device='cuda:0')\n",
      "tensor([[0.1279],\n",
      "        [0.0302],\n",
      "        [0.1144],\n",
      "        [0.0570],\n",
      "        [0.0222],\n",
      "        [0.0117],\n",
      "        [0.0732],\n",
      "        [0.0120],\n",
      "        [0.0397],\n",
      "        [0.0585],\n",
      "        [0.0370],\n",
      "        [0.0208],\n",
      "        [0.0481],\n",
      "        [0.0911],\n",
      "        [0.0325],\n",
      "        [0.0285],\n",
      "        [0.1232],\n",
      "        [0.0378],\n",
      "        [0.0415],\n",
      "        [0.0482],\n",
      "        [0.0199],\n",
      "        [0.0311],\n",
      "        [0.0333],\n",
      "        [0.0299],\n",
      "        [0.0623],\n",
      "        [0.0622],\n",
      "        [0.0806],\n",
      "        [0.1525],\n",
      "        [0.0219],\n",
      "        [0.0573],\n",
      "        [0.0697],\n",
      "        [0.1091]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0188, 0.0188, 0.0196, 0.0196, 0.0201, 0.0203, 0.0199, 0.0209, 0.0214,\n",
      "        0.0213, 0.0216, 0.0219, 0.0220, 0.0224, 0.0223, 0.0220, 0.0224, 0.0231,\n",
      "        0.0229, 0.0226, 0.0218, 0.0218, 0.0228, 0.0240, 0.0245, 0.0248, 0.0251,\n",
      "        0.0244, 0.0241, 0.0247, 0.0251, 0.0258], device='cuda:0')\n",
      "tensor([[ 0.0601],\n",
      "        [ 0.0418],\n",
      "        [-0.0114],\n",
      "        [ 0.0206],\n",
      "        [-0.0094],\n",
      "        [ 0.0832],\n",
      "        [ 0.0188],\n",
      "        [ 0.0341],\n",
      "        [ 0.0661],\n",
      "        [ 0.0200],\n",
      "        [ 0.0375],\n",
      "        [ 0.0073],\n",
      "        [ 0.1467],\n",
      "        [ 0.0355],\n",
      "        [-0.0005],\n",
      "        [ 0.0989],\n",
      "        [ 0.0268],\n",
      "        [ 0.0860],\n",
      "        [ 0.0413],\n",
      "        [ 0.0858],\n",
      "        [ 0.0191],\n",
      "        [ 0.0397],\n",
      "        [ 0.0595],\n",
      "        [ 0.0420],\n",
      "        [ 0.0394],\n",
      "        [ 0.0317],\n",
      "        [ 0.0627],\n",
      "        [ 0.1578],\n",
      "        [ 0.0442],\n",
      "        [ 0.0629],\n",
      "        [ 0.1131],\n",
      "        [ 0.0455]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0260, 0.0252, 0.0257, 0.0259, 0.0258, 0.0248, 0.0246, 0.0244, 0.0248,\n",
      "        0.0247, 0.0244, 0.0241, 0.0239, 0.0241, 0.0243, 0.0246, 0.0243, 0.0238,\n",
      "        0.0242, 0.0254, 0.0263, 0.0267, 0.0273, 0.0270, 0.0275, 0.0261, 0.0265,\n",
      "        0.0269, 0.0268, 0.0268, 0.0277, 0.0279], device='cuda:0')\n",
      "tensor([[0.0738],\n",
      "        [0.1000],\n",
      "        [0.0538],\n",
      "        [0.0550],\n",
      "        [0.0491],\n",
      "        [0.0366],\n",
      "        [0.0346],\n",
      "        [0.0627],\n",
      "        [0.0716],\n",
      "        [0.0289],\n",
      "        [0.0562],\n",
      "        [0.0940],\n",
      "        [0.0358],\n",
      "        [0.0876],\n",
      "        [0.0924],\n",
      "        [0.0319],\n",
      "        [0.1129],\n",
      "        [0.0625],\n",
      "        [0.1089],\n",
      "        [0.1503],\n",
      "        [0.1969],\n",
      "        [0.0538],\n",
      "        [0.0463],\n",
      "        [0.0427],\n",
      "        [0.0782],\n",
      "        [0.0521],\n",
      "        [0.0427],\n",
      "        [0.0428],\n",
      "        [0.0072],\n",
      "        [0.0673],\n",
      "        [0.0362],\n",
      "        [0.0695]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0275, 0.0276, 0.0281, 0.0285, 0.0279, 0.0271, 0.0275, 0.0278, 0.0277,\n",
      "        0.0277, 0.0291, 0.0296, 0.0296, 0.0303, 0.0312, 0.0319, 0.0311, 0.0309,\n",
      "        0.0307, 0.0308, 0.0306, 0.0309, 0.0299, 0.0315, 0.0327, 0.0328, 0.0327,\n",
      "        0.0327, 0.0326, 0.0323, 0.0323, 0.0327], device='cuda:0')\n",
      "tensor([[ 0.1057],\n",
      "        [ 0.0622],\n",
      "        [ 0.0221],\n",
      "        [ 0.0341],\n",
      "        [ 0.0269],\n",
      "        [ 0.0595],\n",
      "        [ 0.0270],\n",
      "        [ 0.0195],\n",
      "        [ 0.0666],\n",
      "        [ 0.0689],\n",
      "        [ 0.0236],\n",
      "        [ 0.0311],\n",
      "        [ 0.0467],\n",
      "        [ 0.0336],\n",
      "        [ 0.0565],\n",
      "        [ 0.0369],\n",
      "        [ 0.0430],\n",
      "        [ 0.0864],\n",
      "        [ 0.0567],\n",
      "        [ 0.0868],\n",
      "        [ 0.2176],\n",
      "        [ 0.1060],\n",
      "        [ 0.0433],\n",
      "        [ 0.0594],\n",
      "        [ 0.0304],\n",
      "        [ 0.0323],\n",
      "        [-0.0100],\n",
      "        [ 0.0334],\n",
      "        [ 0.0430],\n",
      "        [ 0.0570],\n",
      "        [ 0.0424],\n",
      "        [ 0.0789]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0328, 0.0321, 0.0329, 0.0339, 0.0339, 0.0332, 0.0332, 0.0332, 0.0345,\n",
      "        0.0352, 0.0348, 0.0347, 0.0347, 0.0340, 0.0327, 0.0328, 0.0332, 0.0343,\n",
      "        0.0335, 0.0328, 0.0339, 0.0335, 0.0346, 0.0349, 0.0348, 0.0351, 0.0359,\n",
      "        0.0361, 0.0360, 0.0366, 0.0376, 0.0373], device='cuda:0')\n",
      "tensor([[ 0.0699],\n",
      "        [ 0.0274],\n",
      "        [ 0.0279],\n",
      "        [ 0.0896],\n",
      "        [ 0.0983],\n",
      "        [ 0.1231],\n",
      "        [ 0.1079],\n",
      "        [ 0.0100],\n",
      "        [ 0.0578],\n",
      "        [ 0.0228],\n",
      "        [ 0.0299],\n",
      "        [ 0.0835],\n",
      "        [ 0.0777],\n",
      "        [ 0.0518],\n",
      "        [ 0.0553],\n",
      "        [ 0.0436],\n",
      "        [ 0.0376],\n",
      "        [ 0.1105],\n",
      "        [ 0.0269],\n",
      "        [ 0.0350],\n",
      "        [ 0.0350],\n",
      "        [ 0.0379],\n",
      "        [ 0.0314],\n",
      "        [ 0.0791],\n",
      "        [ 0.0895],\n",
      "        [ 0.0394],\n",
      "        [ 0.0176],\n",
      "        [ 0.0251],\n",
      "        [ 0.0164],\n",
      "        [ 0.0874],\n",
      "        [ 0.0142],\n",
      "        [-0.0179]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0394, 0.0394, 0.0377, 0.0377, 0.0377, 0.0376, 0.0375, 0.0368, 0.0352,\n",
      "        0.0358, 0.0359, 0.0359, 0.0355, 0.0367, 0.0368, 0.0369, 0.0365, 0.0365,\n",
      "        0.0356, 0.0356, 0.0366, 0.0362, 0.0362, 0.0358, 0.0369, 0.0361, 0.0357,\n",
      "        0.0371, 0.0374, 0.0378, 0.0381, 0.0383], device='cuda:0')\n",
      "tensor([[-0.0210],\n",
      "        [ 0.0488],\n",
      "        [ 0.0304],\n",
      "        [ 0.0703],\n",
      "        [ 0.0860],\n",
      "        [ 0.0648],\n",
      "        [ 0.1061],\n",
      "        [ 0.1261],\n",
      "        [ 0.0644],\n",
      "        [ 0.0209],\n",
      "        [ 0.0520],\n",
      "        [ 0.0368],\n",
      "        [ 0.0517],\n",
      "        [ 0.0602],\n",
      "        [ 0.1138],\n",
      "        [ 0.0648],\n",
      "        [ 0.0405],\n",
      "        [ 0.0448],\n",
      "        [ 0.0835],\n",
      "        [ 0.2169],\n",
      "        [ 0.0400],\n",
      "        [ 0.0194],\n",
      "        [ 0.0289],\n",
      "        [ 0.0264],\n",
      "        [ 0.0269],\n",
      "        [ 0.0246],\n",
      "        [ 0.0314],\n",
      "        [ 0.0321],\n",
      "        [ 0.0381],\n",
      "        [ 0.0750],\n",
      "        [ 0.1455],\n",
      "        [-0.0288]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0388, 0.0397, 0.0397, 0.0397, 0.0395, 0.0395, 0.0394, 0.0394, 0.0400,\n",
      "        0.0410, 0.0402, 0.0397, 0.0397, 0.0395, 0.0397, 0.0400, 0.0399, 0.0399,\n",
      "        0.0402, 0.0405, 0.0401, 0.0402, 0.0401, 0.0402, 0.0401, 0.0393, 0.0395,\n",
      "        0.0396, 0.0392, 0.0387, 0.0397, 0.0404], device='cuda:0')\n",
      "tensor([[ 0.0997],\n",
      "        [ 0.0762],\n",
      "        [ 0.0513],\n",
      "        [ 0.0490],\n",
      "        [ 0.0653],\n",
      "        [ 0.0611],\n",
      "        [ 0.1660],\n",
      "        [ 0.1741],\n",
      "        [ 0.0140],\n",
      "        [ 0.0751],\n",
      "        [ 0.0216],\n",
      "        [ 0.0383],\n",
      "        [ 0.0890],\n",
      "        [ 0.0779],\n",
      "        [ 0.0286],\n",
      "        [ 0.0703],\n",
      "        [ 0.1479],\n",
      "        [ 0.0242],\n",
      "        [ 0.0046],\n",
      "        [ 0.0634],\n",
      "        [ 0.0348],\n",
      "        [ 0.0489],\n",
      "        [ 0.0349],\n",
      "        [ 0.0276],\n",
      "        [ 0.0158],\n",
      "        [ 0.0526],\n",
      "        [-0.0009],\n",
      "        [ 0.0533],\n",
      "        [ 0.0139],\n",
      "        [ 0.0531],\n",
      "        [ 0.0783],\n",
      "        [ 0.0909]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0405, 0.0407, 0.0415, 0.0409, 0.0407, 0.0409, 0.0409, 0.0410, 0.0404,\n",
      "        0.0392, 0.0388, 0.0385, 0.0386, 0.0391, 0.0388, 0.0395, 0.0395, 0.0391,\n",
      "        0.0393, 0.0388, 0.0381, 0.0381, 0.0387, 0.0389, 0.0397, 0.0398, 0.0400,\n",
      "        0.0403, 0.0401, 0.0402, 0.0413, 0.0418], device='cuda:0')\n",
      "tensor([[0.0393],\n",
      "        [0.0480],\n",
      "        [0.0450],\n",
      "        [0.0040],\n",
      "        [0.0674],\n",
      "        [0.0068],\n",
      "        [0.0399],\n",
      "        [0.0353],\n",
      "        [0.1031],\n",
      "        [0.0750],\n",
      "        [0.1580],\n",
      "        [0.0310],\n",
      "        [0.0078],\n",
      "        [0.0998],\n",
      "        [0.0675],\n",
      "        [0.0441],\n",
      "        [0.0265],\n",
      "        [0.0792],\n",
      "        [0.1728],\n",
      "        [0.0344],\n",
      "        [0.0086],\n",
      "        [0.0670],\n",
      "        [0.0495],\n",
      "        [0.1107],\n",
      "        [0.0633],\n",
      "        [0.1187],\n",
      "        [0.0290],\n",
      "        [0.0676],\n",
      "        [0.0615],\n",
      "        [0.0456],\n",
      "        [0.0584],\n",
      "        [0.0510]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0418, 0.0411, 0.0411, 0.0414, 0.0418, 0.0414, 0.0446, 0.0448, 0.0460,\n",
      "        0.0451, 0.0454, 0.0457, 0.0455, 0.0448, 0.0456, 0.0456, 0.0478, 0.0478,\n",
      "        0.0482, 0.0480, 0.0492, 0.0492, 0.0499, 0.0496, 0.0487, 0.0498, 0.0506,\n",
      "        0.0513, 0.0505, 0.0504, 0.0503, 0.0509], device='cuda:0')\n",
      "tensor([[ 0.1518],\n",
      "        [ 0.0392],\n",
      "        [ 0.0874],\n",
      "        [ 0.0441],\n",
      "        [ 0.0216],\n",
      "        [ 0.0494],\n",
      "        [ 0.0434],\n",
      "        [ 0.0246],\n",
      "        [ 0.0863],\n",
      "        [-0.0251],\n",
      "        [ 0.0418],\n",
      "        [ 0.1093],\n",
      "        [ 0.1043],\n",
      "        [-0.0137],\n",
      "        [ 0.0272],\n",
      "        [ 0.0421],\n",
      "        [ 0.0493],\n",
      "        [ 0.0280],\n",
      "        [ 0.0260],\n",
      "        [ 0.1278],\n",
      "        [ 0.0170],\n",
      "        [ 0.1363],\n",
      "        [ 0.0156],\n",
      "        [ 0.0488],\n",
      "        [ 0.0255],\n",
      "        [ 0.0493],\n",
      "        [ 0.0349],\n",
      "        [ 0.0044],\n",
      "        [ 0.0422],\n",
      "        [ 0.0560],\n",
      "        [ 0.0801],\n",
      "        [ 0.0729]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0513, 0.0512, 0.0508, 0.0497, 0.0495, 0.0492, 0.0493, 0.0488, 0.0492,\n",
      "        0.0500, 0.0504, 0.0500, 0.0510, 0.0528, 0.0535, 0.0516, 0.0537, 0.0531,\n",
      "        0.0532, 0.0536, 0.0532, 0.0532, 0.0530, 0.0535, 0.0551, 0.0550, 0.0554,\n",
      "        0.0563, 0.0568, 0.0570, 0.0564, 0.0567], device='cuda:0')\n",
      "tensor([[ 0.0465],\n",
      "        [ 0.1756],\n",
      "        [ 0.1158],\n",
      "        [ 0.0431],\n",
      "        [ 0.1220],\n",
      "        [ 0.0849],\n",
      "        [ 0.0797],\n",
      "        [ 0.0709],\n",
      "        [ 0.1719],\n",
      "        [ 0.0635],\n",
      "        [ 0.0945],\n",
      "        [ 0.0626],\n",
      "        [ 0.0028],\n",
      "        [ 0.0399],\n",
      "        [ 0.0217],\n",
      "        [ 0.0315],\n",
      "        [ 0.0310],\n",
      "        [ 0.0586],\n",
      "        [ 0.2129],\n",
      "        [ 0.1004],\n",
      "        [ 0.1212],\n",
      "        [ 0.0843],\n",
      "        [ 0.0440],\n",
      "        [-0.0039],\n",
      "        [ 0.0659],\n",
      "        [ 0.0590],\n",
      "        [ 0.0681],\n",
      "        [ 0.0568],\n",
      "        [ 0.0589],\n",
      "        [ 0.0592],\n",
      "        [ 0.0946],\n",
      "        [ 0.0404]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0572, 0.0560, 0.0537, 0.0536, 0.0545, 0.0542, 0.0532, 0.0535, 0.0545,\n",
      "        0.0545, 0.0548, 0.0532, 0.0523, 0.0502, 0.0508, 0.0513, 0.0514, 0.0520,\n",
      "        0.0526, 0.0535, 0.0543, 0.0535, 0.0535, 0.0541, 0.0541, 0.0524, 0.0543,\n",
      "        0.0532, 0.0536, 0.0538, 0.0533, 0.0527], device='cuda:0')\n",
      "tensor([[-0.0102],\n",
      "        [ 0.0876],\n",
      "        [ 0.0787],\n",
      "        [ 0.0365],\n",
      "        [ 0.0207],\n",
      "        [ 0.0527],\n",
      "        [ 0.0357],\n",
      "        [ 0.0916],\n",
      "        [ 0.0501],\n",
      "        [ 0.0824],\n",
      "        [ 0.0414],\n",
      "        [ 0.0037],\n",
      "        [ 0.0576],\n",
      "        [ 0.0446],\n",
      "        [ 0.0331],\n",
      "        [ 0.0025],\n",
      "        [ 0.0441],\n",
      "        [ 0.0933],\n",
      "        [ 0.0786],\n",
      "        [ 0.0445],\n",
      "        [ 0.0608],\n",
      "        [ 0.0973],\n",
      "        [ 0.0905],\n",
      "        [ 0.0149],\n",
      "        [ 0.0481],\n",
      "        [ 0.0498],\n",
      "        [ 0.0253],\n",
      "        [ 0.0467],\n",
      "        [ 0.0279],\n",
      "        [ 0.0212],\n",
      "        [ 0.0429],\n",
      "        [ 0.1118]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0509, 0.0515, 0.0511, 0.0507, 0.0500, 0.0507, 0.0491, 0.0482, 0.0482,\n",
      "        0.0498, 0.0499, 0.0489, 0.0498, 0.0510, 0.0515, 0.0504, 0.0501, 0.0509,\n",
      "        0.0504, 0.0492, 0.0489, 0.0471, 0.0480, 0.0501, 0.0498, 0.0492, 0.0508,\n",
      "        0.0510, 0.0505, 0.0484, 0.0503, 0.0505], device='cuda:0')\n",
      "tensor([[ 0.0960],\n",
      "        [ 0.0232],\n",
      "        [ 0.0274],\n",
      "        [ 0.0524],\n",
      "        [ 0.1012],\n",
      "        [ 0.0242],\n",
      "        [ 0.0242],\n",
      "        [ 0.0137],\n",
      "        [ 0.0483],\n",
      "        [ 0.0483],\n",
      "        [ 0.0448],\n",
      "        [ 0.0222],\n",
      "        [ 0.0313],\n",
      "        [ 0.0799],\n",
      "        [ 0.1173],\n",
      "        [ 0.0219],\n",
      "        [-0.0238],\n",
      "        [ 0.0018],\n",
      "        [ 0.0716],\n",
      "        [ 0.0527],\n",
      "        [ 0.0096],\n",
      "        [ 0.0499],\n",
      "        [-0.0020],\n",
      "        [ 0.0715],\n",
      "        [ 0.0198],\n",
      "        [ 0.0307],\n",
      "        [ 0.0099],\n",
      "        [ 0.0160],\n",
      "        [ 0.0640],\n",
      "        [ 0.0531],\n",
      "        [ 0.0356],\n",
      "        [ 0.0924]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0494, 0.0500, 0.0492, 0.0499, 0.0501, 0.0509, 0.0513, 0.0516, 0.0531,\n",
      "        0.0552, 0.0557, 0.0562, 0.0560, 0.0551, 0.0565, 0.0564, 0.0574, 0.0573,\n",
      "        0.0569, 0.0567, 0.0563, 0.0559, 0.0558, 0.0581, 0.0578, 0.0582, 0.0585,\n",
      "        0.0597, 0.0607, 0.0617, 0.0629, 0.0620], device='cuda:0')\n",
      "tensor([[ 0.0503],\n",
      "        [ 0.0198],\n",
      "        [ 0.0302],\n",
      "        [ 0.1030],\n",
      "        [ 0.0823],\n",
      "        [ 0.0628],\n",
      "        [ 0.0864],\n",
      "        [ 0.0530],\n",
      "        [ 0.0875],\n",
      "        [ 0.0894],\n",
      "        [ 0.0833],\n",
      "        [ 0.0371],\n",
      "        [ 0.1141],\n",
      "        [ 0.1092],\n",
      "        [ 0.1740],\n",
      "        [-0.0181],\n",
      "        [ 0.1034],\n",
      "        [ 0.0120],\n",
      "        [ 0.0005],\n",
      "        [-0.0104],\n",
      "        [ 0.0343],\n",
      "        [ 0.0182],\n",
      "        [ 0.0352],\n",
      "        [ 0.0417],\n",
      "        [ 0.1233],\n",
      "        [ 0.0560],\n",
      "        [ 0.0147],\n",
      "        [ 0.0891],\n",
      "        [ 0.0099],\n",
      "        [ 0.0330],\n",
      "        [ 0.0233],\n",
      "        [ 0.0460]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0617, 0.0619, 0.0619, 0.0613, 0.0608, 0.0598, 0.0600, 0.0597, 0.0590,\n",
      "        0.0575, 0.0575, 0.0587, 0.0584, 0.0578, 0.0585, 0.0593, 0.0600, 0.0624,\n",
      "        0.0650, 0.0693, 0.0680, 0.0669, 0.0676, 0.0681, 0.0683, 0.0681, 0.0657,\n",
      "        0.0647, 0.0626, 0.0626, 0.0654, 0.0653], device='cuda:0')\n",
      "tensor([[ 0.0288],\n",
      "        [ 0.0671],\n",
      "        [ 0.0661],\n",
      "        [ 0.0101],\n",
      "        [ 0.0639],\n",
      "        [ 0.0337],\n",
      "        [ 0.0837],\n",
      "        [ 0.0675],\n",
      "        [ 0.0334],\n",
      "        [ 0.0421],\n",
      "        [ 0.0329],\n",
      "        [ 0.0645],\n",
      "        [ 0.0678],\n",
      "        [ 0.0673],\n",
      "        [ 0.0979],\n",
      "        [ 0.0711],\n",
      "        [ 0.0402],\n",
      "        [ 0.0551],\n",
      "        [ 0.0496],\n",
      "        [-0.0043],\n",
      "        [ 0.0731],\n",
      "        [ 0.0593],\n",
      "        [ 0.0122],\n",
      "        [ 0.0752],\n",
      "        [ 0.1132],\n",
      "        [ 0.0325],\n",
      "        [ 0.0194],\n",
      "        [ 0.0122],\n",
      "        [ 0.0478],\n",
      "        [ 0.0592],\n",
      "        [ 0.0334],\n",
      "        [ 0.0131]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0630, 0.0644, 0.0659, 0.0643, 0.0637, 0.0639, 0.0653, 0.0669, 0.0665,\n",
      "        0.0653, 0.0645, 0.0650, 0.0646, 0.0653, 0.0622, 0.0615, 0.0619, 0.0600,\n",
      "        0.0591, 0.0590, 0.0607, 0.0605, 0.0601, 0.0600, 0.0606, 0.0601, 0.0598,\n",
      "        0.0607, 0.0618, 0.0608, 0.0611, 0.0622], device='cuda:0')\n",
      "tensor([[ 0.0492],\n",
      "        [ 0.0412],\n",
      "        [ 0.0431],\n",
      "        [ 0.0594],\n",
      "        [ 0.0579],\n",
      "        [ 0.0406],\n",
      "        [ 0.0432],\n",
      "        [ 0.0573],\n",
      "        [ 0.0279],\n",
      "        [ 0.0699],\n",
      "        [ 0.0734],\n",
      "        [ 0.0960],\n",
      "        [ 0.0328],\n",
      "        [ 0.0063],\n",
      "        [ 0.0349],\n",
      "        [ 0.0601],\n",
      "        [ 0.0597],\n",
      "        [ 0.0429],\n",
      "        [ 0.0327],\n",
      "        [ 0.0224],\n",
      "        [ 0.0672],\n",
      "        [ 0.0167],\n",
      "        [ 0.0266],\n",
      "        [ 0.0749],\n",
      "        [ 0.0279],\n",
      "        [ 0.0464],\n",
      "        [ 0.0289],\n",
      "        [ 0.0076],\n",
      "        [ 0.0633],\n",
      "        [ 0.0680],\n",
      "        [ 0.0295],\n",
      "        [-0.0051]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0621, 0.0619, 0.0606, 0.0610, 0.0606, 0.0606, 0.0598, 0.0602, 0.0608,\n",
      "        0.0610, 0.0611, 0.0607, 0.0603, 0.0603, 0.0604, 0.0601, 0.0603, 0.0600,\n",
      "        0.0589, 0.0603, 0.0603, 0.0600, 0.0592, 0.0598, 0.0580, 0.0574, 0.0589,\n",
      "        0.0587, 0.0588, 0.0585, 0.0575, 0.0562], device='cuda:0')\n",
      "tensor([[ 0.0002],\n",
      "        [ 0.0216],\n",
      "        [ 0.0242],\n",
      "        [ 0.0296],\n",
      "        [ 0.0213],\n",
      "        [-0.0118],\n",
      "        [ 0.0323],\n",
      "        [ 0.0318],\n",
      "        [ 0.0425],\n",
      "        [ 0.0349],\n",
      "        [-0.0013],\n",
      "        [ 0.0399],\n",
      "        [ 0.0356],\n",
      "        [ 0.0129],\n",
      "        [ 0.1375],\n",
      "        [ 0.1205],\n",
      "        [ 0.0422],\n",
      "        [ 0.0413],\n",
      "        [ 0.0670],\n",
      "        [ 0.0544],\n",
      "        [ 0.0350],\n",
      "        [ 0.0286],\n",
      "        [ 0.1421],\n",
      "        [ 0.1248],\n",
      "        [ 0.0910],\n",
      "        [ 0.0441],\n",
      "        [ 0.0625],\n",
      "        [ 0.0842],\n",
      "        [ 0.0284],\n",
      "        [ 0.1030],\n",
      "        [ 0.1572],\n",
      "        [ 0.0801]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0551, 0.0561, 0.0580, 0.0580, 0.0572, 0.0558, 0.0555, 0.0548, 0.0538,\n",
      "        0.0532, 0.0537, 0.0551, 0.0539, 0.0555, 0.0552, 0.0563, 0.0572, 0.0575,\n",
      "        0.0580, 0.0569, 0.0575, 0.0577, 0.0581, 0.0580, 0.0586, 0.0597, 0.0595,\n",
      "        0.0584, 0.0587, 0.0583, 0.0577, 0.0580], device='cuda:0')\n",
      "tensor([[ 0.0271],\n",
      "        [ 0.0138],\n",
      "        [ 0.0067],\n",
      "        [ 0.0140],\n",
      "        [-0.0231],\n",
      "        [ 0.0354],\n",
      "        [ 0.0698],\n",
      "        [ 0.0922],\n",
      "        [ 0.0612],\n",
      "        [ 0.0380],\n",
      "        [ 0.0483],\n",
      "        [ 0.0260],\n",
      "        [ 0.0144],\n",
      "        [-0.0115],\n",
      "        [ 0.0574],\n",
      "        [ 0.0740],\n",
      "        [ 0.1406],\n",
      "        [ 0.0370],\n",
      "        [ 0.0347],\n",
      "        [ 0.0592],\n",
      "        [ 0.0131],\n",
      "        [ 0.1069],\n",
      "        [ 0.0559],\n",
      "        [-0.0019],\n",
      "        [ 0.0465],\n",
      "        [ 0.0359],\n",
      "        [ 0.0605],\n",
      "        [ 0.0551],\n",
      "        [ 0.0086],\n",
      "        [ 0.0543],\n",
      "        [ 0.0662],\n",
      "        [ 0.0078]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0582, 0.0565, 0.0555, 0.0553, 0.0562, 0.0577, 0.0568, 0.0558, 0.0565,\n",
      "        0.0562, 0.0561, 0.0548, 0.0551, 0.0548, 0.0544, 0.0522, 0.0524, 0.0530,\n",
      "        0.0539, 0.0529, 0.0516, 0.0536, 0.0536, 0.0546, 0.0533, 0.0516, 0.0523,\n",
      "        0.0523, 0.0517, 0.0515, 0.0515, 0.0515], device='cuda:0')\n",
      "tensor([[ 0.0413],\n",
      "        [ 0.0109],\n",
      "        [ 0.0827],\n",
      "        [ 0.0541],\n",
      "        [ 0.0577],\n",
      "        [ 0.0517],\n",
      "        [ 0.0246],\n",
      "        [ 0.0134],\n",
      "        [ 0.1019],\n",
      "        [ 0.0736],\n",
      "        [-0.0027],\n",
      "        [ 0.0373],\n",
      "        [ 0.0462],\n",
      "        [ 0.0930],\n",
      "        [ 0.1310],\n",
      "        [ 0.1329],\n",
      "        [ 0.2252],\n",
      "        [ 0.0266],\n",
      "        [ 0.0102],\n",
      "        [ 0.0579],\n",
      "        [ 0.2051],\n",
      "        [ 0.0380],\n",
      "        [ 0.0268],\n",
      "        [ 0.0102],\n",
      "        [ 0.0236],\n",
      "        [ 0.0478],\n",
      "        [ 0.0469],\n",
      "        [ 0.0495],\n",
      "        [ 0.0883],\n",
      "        [ 0.0296],\n",
      "        [ 0.0732],\n",
      "        [ 0.1569]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0507, 0.0508, 0.0507, 0.0504, 0.0507, 0.0508, 0.0509, 0.0511, 0.0523,\n",
      "        0.0529, 0.0540, 0.0536, 0.0516, 0.0516, 0.0505, 0.0505, 0.0508, 0.0507,\n",
      "        0.0512, 0.0506, 0.0500, 0.0506, 0.0510, 0.0518, 0.0518, 0.0515, 0.0524,\n",
      "        0.0523, 0.0515, 0.0503, 0.0506, 0.0520], device='cuda:0')\n",
      "tensor([[ 0.0587],\n",
      "        [ 0.1149],\n",
      "        [ 0.1822],\n",
      "        [ 0.1229],\n",
      "        [ 0.0284],\n",
      "        [ 0.0796],\n",
      "        [ 0.0214],\n",
      "        [ 0.0721],\n",
      "        [ 0.0446],\n",
      "        [ 0.0389],\n",
      "        [ 0.0748],\n",
      "        [ 0.0646],\n",
      "        [ 0.0775],\n",
      "        [ 0.1014],\n",
      "        [ 0.1023],\n",
      "        [ 0.0377],\n",
      "        [ 0.0445],\n",
      "        [ 0.0782],\n",
      "        [ 0.0750],\n",
      "        [-0.0081],\n",
      "        [ 0.0475],\n",
      "        [ 0.0265],\n",
      "        [ 0.0390],\n",
      "        [ 0.0357],\n",
      "        [ 0.0727],\n",
      "        [ 0.0805],\n",
      "        [ 0.1113],\n",
      "        [ 0.0522],\n",
      "        [ 0.0445],\n",
      "        [ 0.0256],\n",
      "        [ 0.0053],\n",
      "        [ 0.0301]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0515, 0.0524, 0.0529, 0.0529, 0.0531, 0.0535, 0.0538, 0.0542, 0.0549,\n",
      "        0.0546, 0.0542, 0.0541, 0.0533, 0.0531, 0.0544, 0.0548, 0.0545, 0.0538,\n",
      "        0.0541, 0.0536, 0.0532, 0.0535, 0.0535, 0.0545, 0.0542, 0.0552, 0.0558,\n",
      "        0.0573, 0.0580, 0.0582, 0.0576, 0.0578], device='cuda:0')\n",
      "tensor([[ 0.1182],\n",
      "        [ 0.0368],\n",
      "        [ 0.1655],\n",
      "        [ 0.1001],\n",
      "        [-0.0099],\n",
      "        [ 0.0128],\n",
      "        [ 0.1293],\n",
      "        [ 0.0104],\n",
      "        [ 0.1046],\n",
      "        [ 0.0085],\n",
      "        [ 0.0861],\n",
      "        [ 0.0130],\n",
      "        [ 0.0410],\n",
      "        [ 0.0804],\n",
      "        [ 0.0455],\n",
      "        [ 0.0277],\n",
      "        [ 0.0954],\n",
      "        [ 0.0860],\n",
      "        [ 0.0085],\n",
      "        [ 0.0185],\n",
      "        [ 0.0225],\n",
      "        [ 0.0427],\n",
      "        [ 0.0425],\n",
      "        [ 0.0396],\n",
      "        [-0.0006],\n",
      "        [ 0.0960],\n",
      "        [ 0.0514],\n",
      "        [ 0.0246],\n",
      "        [ 0.0124],\n",
      "        [ 0.0356],\n",
      "        [ 0.0905],\n",
      "        [ 0.1231]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0581, 0.0590, 0.0584, 0.0586, 0.0580, 0.0578, 0.0590, 0.0596, 0.0587,\n",
      "        0.0588, 0.0573, 0.0562, 0.0569, 0.0570, 0.0580, 0.0580, 0.0568, 0.0567,\n",
      "        0.0561, 0.0562, 0.0558, 0.0561, 0.0558, 0.0551, 0.0545, 0.0540, 0.0538,\n",
      "        0.0535, 0.0543, 0.0548, 0.0549, 0.0549], device='cuda:0')\n",
      "tensor([[ 0.1427],\n",
      "        [ 0.0151],\n",
      "        [ 0.0145],\n",
      "        [ 0.0329],\n",
      "        [ 0.0120],\n",
      "        [ 0.0279],\n",
      "        [ 0.0056],\n",
      "        [ 0.0207],\n",
      "        [-0.0164],\n",
      "        [ 0.0369],\n",
      "        [ 0.1534],\n",
      "        [ 0.1164],\n",
      "        [ 0.0801],\n",
      "        [ 0.0488],\n",
      "        [ 0.0414],\n",
      "        [ 0.2157],\n",
      "        [ 0.1091],\n",
      "        [ 0.1195],\n",
      "        [ 0.0446],\n",
      "        [ 0.1183],\n",
      "        [ 0.0868],\n",
      "        [-0.0281],\n",
      "        [ 0.0302],\n",
      "        [ 0.0635],\n",
      "        [ 0.0083],\n",
      "        [ 0.0473],\n",
      "        [ 0.0081],\n",
      "        [ 0.0362],\n",
      "        [ 0.0349],\n",
      "        [ 0.0526],\n",
      "        [-0.0099],\n",
      "        [ 0.0137]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0549, 0.0545, 0.0552, 0.0576, 0.0564, 0.0586, 0.0590, 0.0605, 0.0604,\n",
      "        0.0629, 0.0637, 0.0629, 0.0601, 0.0595, 0.0580, 0.0590, 0.0567, 0.0571,\n",
      "        0.0583, 0.0581, 0.0570, 0.0559, 0.0564, 0.0556, 0.0555, 0.0547, 0.0546,\n",
      "        0.0552, 0.0574, 0.0585, 0.0579, 0.0597], device='cuda:0')\n",
      "tensor([[0.0227],\n",
      "        [0.0072],\n",
      "        [0.0405],\n",
      "        [0.0611],\n",
      "        [0.1914],\n",
      "        [0.0731],\n",
      "        [0.0782],\n",
      "        [0.0212],\n",
      "        [0.0537],\n",
      "        [0.0918],\n",
      "        [0.0388],\n",
      "        [0.0464],\n",
      "        [0.0524],\n",
      "        [0.1147],\n",
      "        [0.0339],\n",
      "        [0.0770],\n",
      "        [0.1072],\n",
      "        [0.0385],\n",
      "        [0.0413],\n",
      "        [0.1142],\n",
      "        [0.0463],\n",
      "        [0.0154],\n",
      "        [0.0508],\n",
      "        [0.0065],\n",
      "        [0.0306],\n",
      "        [0.0594],\n",
      "        [0.1044],\n",
      "        [0.0609],\n",
      "        [0.0973],\n",
      "        [0.0273],\n",
      "        [0.0519],\n",
      "        [0.0377]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0601, 0.0595, 0.0595, 0.0585, 0.0588, 0.0598, 0.0607, 0.0609, 0.0613,\n",
      "        0.0615, 0.0626, 0.0631, 0.0634, 0.0613, 0.0610, 0.0617, 0.0629, 0.0622,\n",
      "        0.0619, 0.0612, 0.0611, 0.0606, 0.0599, 0.0607, 0.0630, 0.0619, 0.0623,\n",
      "        0.0620, 0.0626, 0.0627, 0.0630, 0.0636], device='cuda:0')\n",
      "tensor([[ 0.0388],\n",
      "        [ 0.0613],\n",
      "        [ 0.0439],\n",
      "        [ 0.0234],\n",
      "        [ 0.0201],\n",
      "        [ 0.0779],\n",
      "        [ 0.0156],\n",
      "        [ 0.1359],\n",
      "        [ 0.0408],\n",
      "        [ 0.1408],\n",
      "        [ 0.1598],\n",
      "        [ 0.0386],\n",
      "        [ 0.1944],\n",
      "        [ 0.0601],\n",
      "        [-0.0067],\n",
      "        [ 0.0144],\n",
      "        [ 0.0045],\n",
      "        [ 0.0643],\n",
      "        [ 0.0139],\n",
      "        [ 0.0277],\n",
      "        [ 0.0550],\n",
      "        [ 0.0596],\n",
      "        [ 0.0290],\n",
      "        [ 0.0313],\n",
      "        [ 0.0070],\n",
      "        [ 0.0414],\n",
      "        [ 0.0355],\n",
      "        [ 0.0250],\n",
      "        [ 0.0461],\n",
      "        [ 0.1359],\n",
      "        [ 0.1067],\n",
      "        [ 0.0255]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0654, 0.0651, 0.0650, 0.0629, 0.0626, 0.0625, 0.0623, 0.0619, 0.0621,\n",
      "        0.0621, 0.0630, 0.0624, 0.0614, 0.0627, 0.0626, 0.0627, 0.0641, 0.0643,\n",
      "        0.0638, 0.0636, 0.0641, 0.0650, 0.0647, 0.0649, 0.0667, 0.0666, 0.0661,\n",
      "        0.0649, 0.0656, 0.0659, 0.0656, 0.0656], device='cuda:0')\n",
      "tensor([[ 0.0375],\n",
      "        [ 0.0353],\n",
      "        [ 0.0013],\n",
      "        [ 0.0443],\n",
      "        [ 0.0731],\n",
      "        [ 0.0777],\n",
      "        [ 0.0490],\n",
      "        [ 0.0767],\n",
      "        [ 0.0256],\n",
      "        [ 0.0367],\n",
      "        [ 0.0532],\n",
      "        [ 0.0919],\n",
      "        [ 0.0135],\n",
      "        [ 0.0276],\n",
      "        [ 0.0279],\n",
      "        [ 0.0722],\n",
      "        [ 0.0052],\n",
      "        [ 0.0143],\n",
      "        [ 0.0624],\n",
      "        [ 0.1896],\n",
      "        [-0.0186],\n",
      "        [ 0.0077],\n",
      "        [ 0.0723],\n",
      "        [ 0.0598],\n",
      "        [ 0.0668],\n",
      "        [ 0.0892],\n",
      "        [ 0.0176],\n",
      "        [ 0.0273],\n",
      "        [ 0.0330],\n",
      "        [ 0.0387],\n",
      "        [-0.0004],\n",
      "        [ 0.0307]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0659, 0.0659, 0.0669, 0.0673, 0.0676, 0.0674, 0.0668, 0.0665, 0.0663,\n",
      "        0.0665, 0.0655, 0.0645, 0.0636, 0.0624, 0.0625, 0.0634, 0.0650, 0.0657,\n",
      "        0.0648, 0.0646, 0.0650, 0.0650, 0.0647, 0.0648, 0.0647, 0.0647, 0.0656,\n",
      "        0.0653, 0.0642, 0.0637, 0.0658, 0.0673], device='cuda:0')\n",
      "tensor([[0.0387],\n",
      "        [0.0315],\n",
      "        [0.0625],\n",
      "        [0.0414],\n",
      "        [0.0725],\n",
      "        [0.0416],\n",
      "        [0.0126],\n",
      "        [0.0526],\n",
      "        [0.0274],\n",
      "        [0.0661],\n",
      "        [0.0336],\n",
      "        [0.0698],\n",
      "        [0.0678],\n",
      "        [0.1160],\n",
      "        [0.0784],\n",
      "        [0.0877],\n",
      "        [0.0445],\n",
      "        [0.0373],\n",
      "        [0.0304],\n",
      "        [0.0670],\n",
      "        [0.0622],\n",
      "        [0.0579],\n",
      "        [0.0118],\n",
      "        [0.0340],\n",
      "        [0.1294],\n",
      "        [0.0912],\n",
      "        [0.0521],\n",
      "        [0.0182],\n",
      "        [0.0088],\n",
      "        [0.1006],\n",
      "        [0.0603],\n",
      "        [0.1382]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0659, 0.0637, 0.0646, 0.0660, 0.0653, 0.0656, 0.0668, 0.0669, 0.0677,\n",
      "        0.0678, 0.0678, 0.0680, 0.0679, 0.0676, 0.0691, 0.0690, 0.0708, 0.0680,\n",
      "        0.0634, 0.0649, 0.0646, 0.0648, 0.0648, 0.0630, 0.0623, 0.0613, 0.0607,\n",
      "        0.0599, 0.0617, 0.0618, 0.0618, 0.0607], device='cuda:0')\n",
      "tensor([[ 0.1863],\n",
      "        [ 0.0231],\n",
      "        [ 0.0358],\n",
      "        [ 0.0624],\n",
      "        [ 0.0277],\n",
      "        [-0.0051],\n",
      "        [ 0.0972],\n",
      "        [ 0.0308],\n",
      "        [ 0.1408],\n",
      "        [ 0.0350],\n",
      "        [ 0.0659],\n",
      "        [ 0.0977],\n",
      "        [ 0.0753],\n",
      "        [ 0.0296],\n",
      "        [ 0.0564],\n",
      "        [ 0.0317],\n",
      "        [ 0.0520],\n",
      "        [ 0.0627],\n",
      "        [ 0.0793],\n",
      "        [ 0.0060],\n",
      "        [ 0.1032],\n",
      "        [-0.0068],\n",
      "        [ 0.1354],\n",
      "        [ 0.1327],\n",
      "        [-0.0212],\n",
      "        [ 0.0826],\n",
      "        [ 0.0322],\n",
      "        [ 0.0516],\n",
      "        [ 0.0160],\n",
      "        [ 0.0071],\n",
      "        [ 0.0243],\n",
      "        [ 0.0223]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0621, 0.0633, 0.0624, 0.0646, 0.0639, 0.0631, 0.0632, 0.0633, 0.0637,\n",
      "        0.0639, 0.0633, 0.0621, 0.0622, 0.0620, 0.0611, 0.0600, 0.0594, 0.0586,\n",
      "        0.0585, 0.0575, 0.0555, 0.0578, 0.0583, 0.0584, 0.0573, 0.0563, 0.0569,\n",
      "        0.0568, 0.0569, 0.0562, 0.0568, 0.0582], device='cuda:0')\n",
      "tensor([[ 0.0326],\n",
      "        [ 0.0312],\n",
      "        [ 0.0129],\n",
      "        [ 0.0504],\n",
      "        [ 0.0565],\n",
      "        [ 0.1311],\n",
      "        [ 0.0622],\n",
      "        [ 0.2555],\n",
      "        [ 0.2076],\n",
      "        [ 0.0887],\n",
      "        [ 0.0493],\n",
      "        [ 0.0753],\n",
      "        [ 0.1001],\n",
      "        [ 0.0854],\n",
      "        [-0.0121],\n",
      "        [-0.0024],\n",
      "        [ 0.1005],\n",
      "        [ 0.0607],\n",
      "        [ 0.0795],\n",
      "        [ 0.0380],\n",
      "        [ 0.0491],\n",
      "        [ 0.0799],\n",
      "        [ 0.0413],\n",
      "        [ 0.0269],\n",
      "        [ 0.1043],\n",
      "        [ 0.0773],\n",
      "        [ 0.0230],\n",
      "        [ 0.0726],\n",
      "        [ 0.1362],\n",
      "        [ 0.0153],\n",
      "        [ 0.0426],\n",
      "        [ 0.0736]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0594, 0.0594, 0.0603, 0.0607, 0.0605, 0.0591, 0.0578, 0.0564, 0.0563,\n",
      "        0.0572, 0.0577, 0.0590, 0.0580, 0.0574, 0.0571, 0.0565, 0.0569, 0.0574,\n",
      "        0.0565, 0.0546, 0.0539, 0.0537, 0.0519, 0.0493, 0.0516, 0.0511, 0.0508,\n",
      "        0.0476, 0.0476, 0.0486, 0.0492, 0.0493], device='cuda:0')\n",
      "tensor([[ 2.5568e-02],\n",
      "        [ 2.3704e-02],\n",
      "        [ 2.7914e-02],\n",
      "        [ 3.1771e-02],\n",
      "        [ 9.0620e-03],\n",
      "        [ 4.4936e-02],\n",
      "        [ 1.6783e-02],\n",
      "        [ 1.0716e-01],\n",
      "        [ 9.4034e-02],\n",
      "        [ 2.4532e-02],\n",
      "        [-3.1999e-03],\n",
      "        [ 5.1696e-02],\n",
      "        [ 5.5738e-02],\n",
      "        [ 5.0812e-03],\n",
      "        [ 7.0206e-02],\n",
      "        [ 4.0036e-03],\n",
      "        [ 7.8675e-02],\n",
      "        [ 3.0386e-02],\n",
      "        [ 5.4360e-02],\n",
      "        [ 1.8330e-01],\n",
      "        [ 1.5306e-01],\n",
      "        [ 1.6605e-01],\n",
      "        [ 6.3959e-02],\n",
      "        [ 5.0442e-02],\n",
      "        [ 9.8178e-03],\n",
      "        [ 4.3699e-02],\n",
      "        [-1.0135e-02],\n",
      "        [-6.2894e-05],\n",
      "        [ 3.1772e-02],\n",
      "        [ 4.1676e-02],\n",
      "        [ 4.4706e-02],\n",
      "        [ 9.4487e-02]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([0.0482, 0.0474, 0.0457, 0.0441, 0.0447, 0.0445, 0.0418, 0.0399, 0.0387,\n",
      "        0.0393, 0.0376, 0.0379, 0.0419, 0.0438, 0.0464, 0.0485, 0.0476, 0.0476,\n",
      "        0.0448, 0.0445, 0.0436, 0.0441, 0.0434, 0.0420, 0.0419, 0.0419, 0.0447,\n",
      "        0.0435, 0.0450, 0.0446, 0.0441, 0.0415], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e053730fdeda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPytorchRegressionTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_wandb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproject_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproject_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\School\\Master_Thesis\\StonksMarketPrediction\\trainers\\pytorch_base_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, dataloader, debug)\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mepoch_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0mepoch_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ludo\\documents\\school\\master_thesis\\stonksmarketprediction\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.pytorch_linear_model import LinearModel\n",
    "from trainers.pytorch_regression_trainer import PytorchRegressionTrainer\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "config = dict(\n",
    "    lr=1e-5,\n",
    "    loss=nn.MSELoss,\n",
    "    n_epochs=5,\n",
    "    optimizer=torch.optim.Adam,\n",
    ")\n",
    "model = LinearModel(config, input_dim=X_train.shape[1], output_dim=1, device=device)\n",
    "print(model)\n",
    "\n",
    "\n",
    "trainer = PytorchRegressionTrainer(model, device=device, use_wandb=True, project_label=project_label)\n",
    "trainer.train(dataloader=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "compact-romantic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': 0.053123485, 'r2_score': -0.6882013477330817}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "yellow-albuquerque",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, labels = trainer.predict(test_dataloader)\n",
    "\n",
    "\n",
    "scaled_preds = data_wrapper.get_unscaled_values(predictions, 'Close')\n",
    "scaled_labels = data_wrapper.get_unscaled_values(labels, 'Close')\n",
    "\n",
    "ax = plot_predictions(scaled_labels, scaled_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "passive-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4438.000000\n",
      "mean       97.034689\n",
      "std        53.681507\n",
      "min        -3.896271\n",
      "25%        53.918960\n",
      "50%        95.035768\n",
      "75%       134.424397\n",
      "max       257.817749\n",
      "Name: Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(scaled_preds.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "narrow-nashville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prices_diffs = [(p-y) for p,y in zip(scaled_preds, scaled_labels)]\n",
    "ax = plot_normalized_histogram(series=pd.Series(prices_diffs, name=\"Differences\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
